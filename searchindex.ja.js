var relearn_searchindex = [
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 6. Advanced Features",
    "content": "先ほどHelmチャートを使用してSplunk Distribution of the OpenTelemetry Collectorをインストールした際、AlwaysOn ProfilingとMetricsを有効にするように設定しました。これにより、OpenTelemetry JavaはアプリケーションのCPUとメモリのプロファイリングを自動的に生成し、Splunk Observability Cloudに送信します。\nPetClinicアプリケーションをデプロイしてアノテーションを設定すると、collectorは自動的にアプリケーションを検出し、トレースとプロファイリングのためにインストルメントします。これを確認するために、次のスクリプトを実行して、インストルメントしているJavaコンテナの1つの起動ログを調べることができます：\nログには、Javaの自動検出と設定によって取得されたフラグが表示されます：\n​ Run the script Example output . ~/workshop/petclinic/scripts/get_logs.sh 2024/02/15 09:42:00 Problem with dial: dial tcp 10.43.104.25:8761: connect: connection refused. Sleeping 1s 2024/02/15 09:42:01 Problem with dial: dial tcp 10.43.104.25:8761: connect: connection refused. Sleeping 1s 2024/02/15 09:42:02 Connected to tcp://discovery-server:8761 Picked up JAVA_TOOL_OPTIONS: -javaagent:/otel-auto-instrumentation-java/javaagent.jar Picked up _JAVA_OPTIONS: -Dspring.profiles.active=docker,mysql -Dsplunk.profiler.call.stack.interval=150 OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended [otel.javaagent 2024-02-15 09:42:03:056 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: splunk-1.30.1-otel-1.32.1 [otel.javaagent 2024-02-15 09:42:03:768 +0000] [main] INFO com.splunk.javaagent.shaded.io.micrometer.core.instrument.push.PushMeterRegistry - publishing metrics for SignalFxMeterRegistry every 30s [otel.javaagent 2024-02-15 09:42:07:478 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-02-15 09:42:07:478 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - Profiler configuration: [otel.javaagent 2024-02-15 09:42:07:480 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.enabled : true [otel.javaagent 2024-02-15 09:42:07:505 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.directory : /tmp [otel.javaagent 2024-02-15 09:42:07:505 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.recording.duration : 20s [otel.javaagent 2024-02-15 09:42:07:506 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.keep-files : false [otel.javaagent 2024-02-15 09:42:07:510 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.logs-endpoint : http://10.13.2.38:4317 [otel.javaagent 2024-02-15 09:42:07:513 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - otel.exporter.otlp.endpoint : http://10.13.2.38:4317 [otel.javaagent 2024-02-15 09:42:07:513 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.enabled : true [otel.javaagent 2024-02-15 09:42:07:515 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.tlab.enabled : true [otel.javaagent 2024-02-15 09:42:07:516 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.event.rate : 150/s [otel.javaagent 2024-02-15 09:42:07:516 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.call.stack.interval : PT0.15S [otel.javaagent 2024-02-15 09:42:07:517 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.include.internal.stacks : false [otel.javaagent 2024-02-15 09:42:07:517 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.tracing.stacks.only : false [otel.javaagent 2024-02-15 09:42:07:517 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-02-15 09:42:07:518 +0000] [main] INFO com.splunk.opentelemetry.profiler.JfrActivator - Profiler is active. 私たちが注目しているのは、com.splunk.opentelemetry.profiler.ConfigurationLoggerによって書き込まれたセクション、つまりProfiling Configurationです。\nsplunk.profiler.directoryなど、制御できるさまざまな設定を確認できます。これは、エージェントがSplunkに送信する前にコールスタックを書き込む場所です。（これは、コンテナの設定方法によって異なる場合があります。）\n変更したいもう1つのパラメータはsplunk.profiler.call.stack.intervalです。これは、システムがCPU Stack traceをキャプチャする頻度です。Pet Clinicアプリケーションのような短いスパンがある場合は、このインターバル設定を短くすることをお勧めします。デモアプリケーションでは、デフォルトのインターバル値を変更しなかったため、スパンに常にCPU Call Stackが関連付けられているとは限りません。\nこれらのパラメータを設定する方法はこちらで確認できます。以下の例では、deployment.yamlでコールスタックのより高い収集レートを設定する方法を示しています。これは、JAVA_OPTIONS configセクションでこの値を設定することで行います。\nenv: - name: JAVA_OPTIONS value: \"-Xdebug -Dsplunk.profiler.call.stack.interval=150\"",
    "description": "先ほどHelmチャートを使用してSplunk Distribution of the OpenTelemetry Collectorをインストールした際、AlwaysOn ProfilingとMetricsを有効にするように設定しました。これにより、OpenTelemetry JavaはアプリケーションのCPUとメモリのプロファイリングを自動的に生成し、Splunk Observability Cloudに送信します。\nPetClinicアプリケーションをデプロイしてアノテーションを設定すると、collectorは自動的にアプリケーションを検出し、トレースとプロファイリングのためにインストルメントします。これを確認するために、次のスクリプトを実行して、インストルメントしているJavaコンテナの1つの起動ログを調べることができます：\nログには、Javaの自動検出と設定によって取得されたフラグが表示されます：\n​ Run the script Example output . ~/workshop/petclinic/scripts/get_logs.sh 2024/02/15 09:42:00 Problem with dial: dial tcp 10.43.104.25:8761: connect: connection refused. Sleeping 1s 2024/02/15 09:42:01 Problem with dial: dial tcp 10.43.104.25:8761: connect: connection refused. Sleeping 1s 2024/02/15 09:42:02 Connected to tcp://discovery-server:8761 Picked up JAVA_TOOL_OPTIONS: -javaagent:/otel-auto-instrumentation-java/javaagent.jar Picked up _JAVA_OPTIONS: -Dspring.profiles.active=docker,mysql -Dsplunk.profiler.call.stack.interval=150 OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended [otel.javaagent 2024-02-15 09:42:03:056 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: splunk-1.30.1-otel-1.32.1 [otel.javaagent 2024-02-15 09:42:03:768 +0000] [main] INFO com.splunk.javaagent.shaded.io.micrometer.core.instrument.push.PushMeterRegistry - publishing metrics for SignalFxMeterRegistry every 30s [otel.javaagent 2024-02-15 09:42:07:478 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-02-15 09:42:07:478 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - Profiler configuration: [otel.javaagent 2024-02-15 09:42:07:480 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.enabled : true [otel.javaagent 2024-02-15 09:42:07:505 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.directory : /tmp [otel.javaagent 2024-02-15 09:42:07:505 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.recording.duration : 20s [otel.javaagent 2024-02-15 09:42:07:506 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.keep-files : false [otel.javaagent 2024-02-15 09:42:07:510 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.logs-endpoint : http://10.13.2.38:4317 [otel.javaagent 2024-02-15 09:42:07:513 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - otel.exporter.otlp.endpoint : http://10.13.2.38:4317 [otel.javaagent 2024-02-15 09:42:07:513 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.enabled : true [otel.javaagent 2024-02-15 09:42:07:515 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.tlab.enabled : true [otel.javaagent 2024-02-15 09:42:07:516 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.event.rate : 150/s [otel.javaagent 2024-02-15 09:42:07:516 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.call.stack.interval : PT0.15S [otel.javaagent 2024-02-15 09:42:07:517 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.include.internal.stacks : false [otel.javaagent 2024-02-15 09:42:07:517 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.tracing.stacks.only : false [otel.javaagent 2024-02-15 09:42:07:517 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-02-15 09:42:07:518 +0000] [main] INFO com.splunk.opentelemetry.profiler.JfrActivator - Profiler is active. 私たちが注目しているのは、com.splunk.opentelemetry.profiler.ConfigurationLoggerによって書き込まれたセクション、つまりProfiling Configurationです。",
    "tags": [],
    "title": "Always-On Profiling \u0026 Metrics",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/6-profiling-db-query/1-profiling/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 5. APM Features",
    "content": "上記のマップは、すべてのサービス間のすべての相互作用を示しています。PetClinic Microserviceアプリケーションが起動して完全に同期するまで数分かかるため、マップはまだ中間状態にある可能性があります。時間フィルタを**-2mと入力してカスタム時間の2分に減らすと役立ちます。画面右上のRefreshボタン(1)**をクリックできます。赤い円で示される初期起動関連のエラーは最終的に消えます。\n次に、各サービスで利用可能なメトリクスを調べるために、リクエスト、エラー、期間（RED）メトリクスダッシュボードを見てみましょう。\nこの演習では、サービスオペレーションが高いレイテンシやエラーを示している場合に使用する一般的なシナリオを使用します。\n依存関係マップでcustomers-serviceをクリックし、Servicesドロップダウンボックス**(1)でcustomers-serviceが選択されていることを確認します。次に、サービス名に隣接するOperationsドロップダウン(2)**からGET /ownersを選択します。\nこれにより、以下に示すようにGET /ownersでフィルタリングされたワークフローが表示されます：",
    "description": "上記のマップは、すべてのサービス間のすべての相互作用を示しています。PetClinic Microserviceアプリケーションが起動して完全に同期するまで数分かかるため、マップはまだ中間状態にある可能性があります。時間フィルタを**-2mと入力してカスタム時間の2分に減らすと役立ちます。画面右上のRefreshボタン(1)**をクリックできます。赤い円で示される初期起動関連のエラーは最終的に消えます。\n次に、各サービスで利用可能なメトリクスを調べるために、リクエスト、エラー、期間（RED）メトリクスダッシュボードを見てみましょう。\nこの演習では、サービスオペレーションが高いレイテンシやエラーを示している場合に使用する一般的なシナリオを使用します。\n依存関係マップでcustomers-serviceをクリックし、Servicesドロップダウンボックス**(1)でcustomers-serviceが選択されていることを確認します。次に、サービス名に隣接するOperationsドロップダウン(2)**からGET /ownersを選択します。\nこれにより、以下に示すようにGET /ownersでフィルタリングされたワークフローが表示されます：",
    "tags": [],
    "title": "APM Service Map",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/5-traces/1-service-map/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "APM サービスマップは、APM で計装された（インストルメンテーション）サービスと推測されるサービスの間の依存関係と接続を表示します。このマップは、時間範囲、環境、ワークフロー、サービス、タグフィルターでの選択に基づいて動的に生成されます。\nRUM ウォーターフォールで APM リンクをクリックすると、そのワークフロー名（frontend:/cart/checkout）に関連するサービスを表示するために、サービスマップビューに自動的にフィルターが追加されました。\nワークフローに関連するサービスはService Mapで確認できます。サイドペインのBusiness Workflowの下には、選択したワークフローのチャートが表示されています。Service Mapとビジネスワークフローチャートは同期しています。Service Mapでサービスを選択すると、Business Workflowペインのチャートが更新され、選択したサービスのメトリクスが表示されます。\n演習 サービスマップでpaymentserviceをクリックします。 Splunk APM はまた、リアルタイムで発生している問題を確認し、問題がサービス、特定のエンドポイント、または基盤となるインフラストラクチャに関連しているかどうかを迅速に判断するのに役立つ組み込みの Service Centric View(サービス中心ビュー) も提供しています。より詳しく見てみましょう。\n演習 右側のペインで、青色のpaymentserviceをクリックします。",
    "description": "APM サービスマップは、APM で計装された（インストルメンテーション）サービスと推測されるサービスの間の依存関係と接続を表示します。このマップは、時間範囲、環境、ワークフロー、サービス、タグフィルターでの選択に基づいて動的に生成されます。\nRUM ウォーターフォールで APM リンクをクリックすると、そのワークフロー名（frontend:/cart/checkout）に関連するサービスを表示するために、サービスマップビューに自動的にフィルターが追加されました。\nワークフローに関連するサービスはService Mapで確認できます。サイドペインのBusiness Workflowの下には、選択したワークフローのチャートが表示されています。Service Mapとビジネスワークフローチャートは同期しています。Service Mapでサービスを選択すると、Business Workflowペインのチャートが更新され、選択したサービスのメトリクスが表示されます。\n演習 サービスマップでpaymentserviceをクリックします。 Splunk APM はまた、リアルタイムで発生している問題を確認し、問題がサービス、特定のエンドポイント、または基盤となるインフラストラクチャに関連しているかどうかを迅速に判断するのに役立つ組み込みの Service Centric View(サービス中心ビュー) も提供しています。より詳しく見てみましょう。\n演習 右側のペインで、青色のpaymentserviceをクリックします。",
    "tags": [],
    "title": "1. APM探索",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/6-apm/1-apm-explore/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "EC2 インスタンスへ接続 各参加者のために、AWS/EC2 に Ubuntu Linux インスタンスを用意しました。\nインストラクターから提供された IP アドレスとパスワードを使用して、以下のいずれかの方法で EC2 インスタンスに接続してください：\nMac OS / Linux ssh splunk@IP アドレス Windows 10+ OpenSSH クライアントを使用 以前のバージョンの Windows Putty を使用",
    "description": "EC2 インスタンスへ接続 各参加者のために、AWS/EC2 に Ubuntu Linux インスタンスを用意しました。\nインストラクターから提供された IP アドレスとパスワードを使用して、以下のいずれかの方法で EC2 インスタンスに接続してください：\nMac OS / Linux ssh splunk@IP アドレス Windows 10+ OpenSSH クライアントを使用 以前のバージョンの Windows Putty を使用",
    "tags": [],
    "title": "EC2インスタンスへの接続",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/1-connect-to-instance/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 3. Receivers",
    "content": "Host Metrics Receiver Host Metrics Receiver は、さまざまなソースからスクレイピングしたホストシステムに関するメトリクスを生成します。これは、Collector がエージェントとしてデプロイされる場合に使用することを想定しており、このワークショップでもその方法を採用します。\n/etc/otel-contrib/config.yaml ファイルを更新して、hostmetrics Receiver を設定しましょう。以下の YAML を receivers セクションの下に挿入してください。インデントはスペース2つで行います。\nsudo vi /etc/otelcol-contrib/config.yaml ​ Host Metrics Receiver Configuration receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process:",
    "description": "Host Metrics Receiver Host Metrics Receiver は、さまざまなソースからスクレイピングしたホストシステムに関するメトリクスを生成します。これは、Collector がエージェントとしてデプロイされる場合に使用することを想定しており、このワークショップでもその方法を採用します。\n/etc/otel-contrib/config.yaml ファイルを更新して、hostmetrics Receiver を設定しましょう。以下の YAML を receivers セクションの下に挿入してください。インデントはスペース2つで行います。\nsudo vi /etc/otelcol-contrib/config.yaml ​ Host Metrics Receiver Configuration receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process:",
    "tags": [],
    "title": "OpenTelemetry Collector Receivers",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/3-receivers/1-hostmetrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 3. レシーバー",
    "content": "Host Metrics レシーバー Host Metrics レシーバー は、さまざまなソースからスクレイピングされたホストシステムに関するメトリクスを生成します。これは、コレクターがエージェントとしてデプロイされるときに使用さます。\netc/otel-contrib/config.yaml ファイルを更新して、hostmetrics レシーバーを設定してみましょう。以下の YAML を receivers セクションの下に挿入します。\nsudo vi /etc/otelcol-contrib/config.yaml Tips: vi or nano vi/vimの操作に慣れていない場合は、nano もお試しいただくと良いかもしれません。nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nsudo nano /etc/otelcol-contrib/config.yaml Alt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 ​ Host Metrics Receiver Configuration receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process:",
    "description": "Host Metrics レシーバー Host Metrics レシーバー は、さまざまなソースからスクレイピングされたホストシステムに関するメトリクスを生成します。これは、コレクターがエージェントとしてデプロイされるときに使用さます。\netc/otel-contrib/config.yaml ファイルを更新して、hostmetrics レシーバーを設定してみましょう。以下の YAML を receivers セクションの下に挿入します。\nsudo vi /etc/otelcol-contrib/config.yaml Tips: vi or nano vi/vimの操作に慣れていない場合は、nano もお試しいただくと良いかもしれません。nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nsudo nano /etc/otelcol-contrib/config.yaml Alt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 ​ Host Metrics Receiver Configuration receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process:",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/3-receivers/1-hostmetrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic モノリスワークショップ",
    "content": "Splunk OpenTelemetry Collector は、インフラストラクチャとアプリケーションの計装における中核コンポーネントです。その役割は以下のデータを収集して送信することです：\nインフラストラクチャメトリクス（ディスク、CPU、メモリなど） Application Performance Monitoring (APM) トレース プロファイリングデータ ホストおよびアプリケーションのログ 既存の OpenTelemetry Collector の削除 Splunk IM ワークショップを完了している場合は、続行する前に Kubernetes で実行中の Collector を削除してください。以下のコマンドを実行して削除できます：\nhelm delete splunk-otel-collector EC2 インスタンスには、古いバージョンの Collector がすでにインストールされている場合があります。Collector をアンインストールするには、以下のコマンドを実行してください：\ncurl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh sudo sh /tmp/splunk-otel-collector.sh --uninstall インスタンスが正しく設定されていることを確認するために、このワークショップに必要な環境変数が正しく設定されているか確認する必要があります。ターミナルで以下のコマンドを実行してください：\n. ~/workshop/petclinic/scripts/check_env.sh 出力で、以下のすべての環境変数が存在し、値が設定されていることを確認してください。不足している場合は、インストラクターに連絡してください：\nACCESS_TOKEN REALM RUM_TOKEN HEC_TOKEN HEC_URL INSTANCE これで Collector のインストールに進むことができます。インストールスクリプトには、いくつかの追加パラメータが渡されます：\n--with-instrumentation - Splunk ディストリビューションの OpenTelemetry Java からエージェントをインストールします。これにより、PetClinic Java アプリケーションの起動時に自動的にロードされます。設定は不要です！ --deployment-environment - リソース属性 deployment.environment を指定された値に設定します。これは UI でビューをフィルタリングするために使用されます。 --enable-profiler - Java アプリケーションのプロファイラを有効にします。これによりアプリケーションの CPU プロファイルが生成されます。 --enable-profiler-memory - Java アプリケーションのプロファイラを有効にします。これによりアプリケーションのメモリプロファイルが生成されます。 --enable-metrics - Micrometer メトリクスのエクスポートを有効にします --hec-token - Collector が使用する HEC トークンを設定します --hec-url - Collector が使用する HEC URL を設定します curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh \u0026\u0026 \\ sudo sh /tmp/splunk-otel-collector.sh --realm $REALM -- $ACCESS_TOKEN --mode agent --without-fluentd --with-instrumentation --deployment-environment $INSTANCE-petclinic --enable-profiler --enable-profiler-memory --enable-metrics --hec-token $HEC_TOKEN --hec-url $HEC_URL 次に、Collector にパッチを適用して、AWS インスタンス ID ではなくインスタンスのホスト名を公開するようにします。これにより、UI でのデータのフィルタリングが容易になります：\nsudo sed -i 's/gcp, ecs, ec2, azure, system/system, gcp, ecs, ec2, azure/g' /etc/otel/collector/agent_config.yaml agent_config.yaml にパッチを適用したら、Collector を再起動する必要があります：\nsudo systemctl restart splunk-otel-collector インストールが完了したら、Hosts with agent installed ダッシュボードに移動して、ホストからのデータを確認できます。Dashboards → Hosts with agent installed の順に移動してください。\nダッシュボードフィルタを使用して host.name を選択し、ワークショップインスタンスのホスト名を入力または選択してください（これはターミナルセッションのコマンドプロンプトから取得できます）。ホストのデータが流れていることを確認したら、APM コンポーネントの作業を開始する準備が整いました。",
    "description": "Splunk OpenTelemetry Collector は、インフラストラクチャとアプリケーションの計装における中核コンポーネントです。その役割は以下のデータを収集して送信することです：\nインフラストラクチャメトリクス（ディスク、CPU、メモリなど） Application Performance Monitoring (APM) トレース プロファイリングデータ ホストおよびアプリケーションのログ 既存の OpenTelemetry Collector の削除 Splunk IM ワークショップを完了している場合は、続行する前に Kubernetes で実行中の Collector を削除してください。以下のコマンドを実行して削除できます：\nhelm delete splunk-otel-collector EC2 インスタンスには、古いバージョンの Collector がすでにインストールされている場合があります。Collector をアンインストールするには、以下のコマンドを実行してください：\ncurl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh sudo sh /tmp/splunk-otel-collector.sh --uninstall インスタンスが正しく設定されていることを確認するために、このワークショップに必要な環境変数が正しく設定されているか確認する必要があります。ターミナルで以下のコマンドを実行してください：\n. ~/workshop/petclinic/scripts/check_env.sh 出力で、以下のすべての環境変数が存在し、値が設定されていることを確認してください。不足している場合は、インストラクターに連絡してください：\nACCESS_TOKEN REALM RUM_TOKEN HEC_TOKEN HEC_URL INSTANCE これで Collector のインストールに進むことができます。インストールスクリプトには、いくつかの追加パラメータが渡されます：\n--with-instrumentation - Splunk ディストリビューションの OpenTelemetry Java からエージェントをインストールします。これにより、PetClinic Java アプリケーションの起動時に自動的にロードされます。設定は不要です！ --deployment-environment - リソース属性 deployment.environment を指定された値に設定します。これは UI でビューをフィルタリングするために使用されます。 --enable-profiler - Java アプリケーションのプロファイラを有効にします。これによりアプリケーションの CPU プロファイルが生成されます。 --enable-profiler-memory - Java アプリケーションのプロファイラを有効にします。これによりアプリケーションのメモリプロファイルが生成されます。 --enable-metrics - Micrometer メトリクスのエクスポートを有効にします --hec-token - Collector が使用する HEC トークンを設定します --hec-url - Collector が使用する HEC URL を設定します curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh \u0026\u0026 \\ sudo sh /tmp/splunk-otel-collector.sh --realm $REALM -- $ACCESS_TOKEN --mode agent --without-fluentd --with-instrumentation --deployment-environment $INSTANCE-petclinic --enable-profiler --enable-profiler-memory --enable-metrics --hec-token $HEC_TOKEN --hec-url $HEC_URL 次に、Collector にパッチを適用して、AWS インスタンス ID ではなくインスタンスのホスト名を公開するようにします。これにより、UI でのデータのフィルタリングが容易になります：",
    "tags": [],
    "title": "OpenTelemetry Collector のインストール",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/1-petclinic-monolith/1-otel-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. はじめに OpenTelemetry Collector は、インフラストラクチャーとアプリケーションを計装するためのコアコンポーネントです。 その役割は収集と送信です：\nインフラストラクチャーのメトリクス（ディスク、CPU、メモリなど） Application Performance Monitoring（APM）のトレース情報 プロファイリングに関するデータ ホストおよびアプリケーションのログ Splunk Observability Cloud では、インフラストラクチャーとアプリケーションの両方で Collector のセットアップを案内するウィザードを提供しています。デフォルトでは、ウィザードはコレクターのインストールのみを行うコマンドのみを提供します。\n2. 環境変数を設定する すでに Splunk IM ワークショップを終了している場合は、既存の環境変数を利用することができます。そうでない場合は、ACCESS_TOKENとREALMの環境変数を設定して、OpenTelemetry Collector のインストールコマンドを実行していきます。\n例えば、Realm が us1 の場合、export REALM=us1 と入力し、eu0 の場合は export REALM=eu0 と入力します。\n​ ACCESS TOKENを環境変数に設定する export ACCESS_TOKEN=\"\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e\" ​ REALMを環境変数に設定する export REALM=\"\u003creplace_with_REALM\u003e\" 既存のOpenTelemetryコレクターをすべて削除する 同じ VM インスタンスに Splunk IM ワークショップのセットアップをしている場合、Otel Collector をインストールする前に Kubernetes で実行中の Collector を削除していることを確認してください。これは、以下のコマンドを実行することで行うことができます：\nhelm delete splunk-otel-collector 3. OpenTelemetry Collector をインストールする 次に、Collector をインストールします。インストールスクリプトに渡される追加のパラメータは --deployment-environment です。\ncurl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh \u0026\u0026 \\ sudo sh /tmp/splunk-otel-collector.sh --deployment-environment $(hostname)-petclinic --realm $REALM -- $ACCESS_TOKEN AWS/EC2インスタンスの場合 。 AWS/EC2 インスタンス上でこのワークショップを行う場合、インスタンスのホスト名を公開するためにコレクターにパッチを適用する必要があります：\nsudo sed -i 's/gcp, ecs, ec2, azure, system/system, gcp, ecs, ec2, azure/g' /etc/otel/collector/agent_config.yaml agent_config.yaml にパッチを適用したあと、Collector を再起動してください：\nsudo systemctl restart splunk-otel-collector インストールが完了したら、Splunk Observability の Hosts with agent installed ダッシュボードに移動して、Dashboards → Hosts with agent installed からホストのデータを確認してみましょう。\nダッシュボードのフィルタを使用して host.nameを選択し、仮想マシンのホスト名を入力または選択します。ホストのデータが表示されたら、APM コンポーネントを使用する準備が整いました。",
    "description": "1. はじめに OpenTelemetry Collector は、インフラストラクチャーとアプリケーションを計装するためのコアコンポーネントです。 その役割は収集と送信です：\nインフラストラクチャーのメトリクス（ディスク、CPU、メモリなど） Application Performance Monitoring（APM）のトレース情報 プロファイリングに関するデータ ホストおよびアプリケーションのログ Splunk Observability Cloud では、インフラストラクチャーとアプリケーションの両方で Collector のセットアップを案内するウィザードを提供しています。デフォルトでは、ウィザードはコレクターのインストールのみを行うコマンドのみを提供します。\n2. 環境変数を設定する すでに Splunk IM ワークショップを終了している場合は、既存の環境変数を利用することができます。そうでない場合は、ACCESS_TOKENとREALMの環境変数を設定して、OpenTelemetry Collector のインストールコマンドを実行していきます。\n例えば、Realm が us1 の場合、export REALM=us1 と入力し、eu0 の場合は export REALM=eu0 と入力します。\n​ ACCESS TOKENを環境変数に設定する export ACCESS_TOKEN=\"\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e\" ​ REALMを環境変数に設定する export REALM=\"\u003creplace_with_REALM\u003e\" 既存のOpenTelemetryコレクターをすべて削除する 同じ VM インスタンスに Splunk IM ワークショップのセットアップをしている場合、Otel Collector をインストールする前に Kubernetes で実行中の Collector を削除していることを確認してください。これは、以下のコマンドを実行することで行うことができます：",
    "tags": [],
    "title": "OpenTelemetry Collectorをインストールする",
    "uri": "/observability-workshop/ja/other/pet-clinic/docs/imt/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 2. 準備",
    "content": "オブザーバビリティシグナル（メトリクス、トレース、ログ）を Splunk Observability Cloud に送信するには、Kubernetes クラスターに Splunk OpenTelemetry Collector をデプロイする必要があります。\nこのワークショップでは、Splunk OpenTelemetry Collector Helm Chart を使用します。まず、Helm chart リポジトリを Helm に追加し、helm repo update を実行して最新バージョンを確認します：\n​ Install Helm Chart Output helm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart \u0026\u0026 helm repo update Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 \"splunk-otel-collector-chart\" has been added to your repositories Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"splunk-otel-collector-chart\" chart repository Update Complete. ⎈Happy Helming!⎈ Splunk Observability Cloud では、Kubernetes 上での OpenTelemetry Collector のセットアップを案内する UI ウィザードが提供されていますが、時間の都合上、以下の Helm install コマンドを使用します。自動ディスカバリーおよび設定とコードプロファイリング用のオペレーターを有効にするための追加パラメータが設定されています。\n--set=\"operator.enabled=true\" - 自動ディスカバリーおよび設定を処理するための OpenTelemetry オペレーターをインストールします。 --set=\"splunkObservability.profilingEnabled=true\" - オペレーター経由でコードプロファイリングを有効にします。 Collector をインストールするには、以下のコマンドを実行してください。これを編集しないでください：\n​ Helm Install Output helm install splunk-otel-collector --version 0.136.0 \\ --set=\"operatorcrds.install=true\", \\ --set=\"operator.enabled=true\", \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-k3s-cluster\" \\ --set=\"splunkObservability.profilingEnabled=true\" \\ --set=\"agent.service.enabled=true\" \\ --set=\"environment=$INSTANCE-workshop\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ splunk-otel-collector-chart/splunk-otel-collector \\ -f ~/workshop/k3s/otel-collector.yaml LAST DEPLOYED: Fri Apr 19 09:39:54 2024 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Platform endpoint \"https://http-inputs-o11y-workshop-eu0.splunkcloud.com:443/services/collector/event\". Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Observability realm eu0. [INFO] You've enabled the operator's auto-instrumentation feature (operator.enabled=true)! The operator can automatically instrument Kubernetes hosted applications. - Status: Instrumentation language maturity varies. See `operator.instrumentation.spec` and documentation for utilized instrumentation details. - Splunk Support: We offer full support for Splunk distributions and best-effort support for native OpenTelemetry distributions of auto-instrumentation libraries. 続行する前に、Pod が Running として報告されていることを確認してください（通常約30秒かかります）。\n​ kubectl get pods Output kubectl get pods | grep splunk-otel splunk-otel-collector-k8s-cluster-receiver-6bd5567d95-5f8cj 1/1 Running 0 10m splunk-otel-collector-agent-tspd2 1/1 Running 0 10m splunk-otel-collector-operator-69d476cb7-j7zwd 2/2 Running 0 10m Splunk OpenTelemetry Collector からエラーが報告されていないことを確認してください（ctrl + c で終了）。または、インストール済みの素晴らしい k9s ターミナル UI を使用するとボーナスポイントです！\n​ kubectl logs Output kubectl logs -l app=splunk-otel-collector -f --container otel-collector 2021-03-21T16:11:10.900Z INFO service/service.go:364 Starting receivers... 2021-03-21T16:11:10.900Z INFO builder/receivers_builder.go:70 Receiver is starting... {\"component_kind\": \"receiver\", \"component_type\": \"prometheus\", \"component_name\": \"prometheus\"} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:75 Receiver started. {\"component_kind\": \"receiver\", \"component_type\": \"prometheus\", \"component_name\": \"prometheus\"} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:70 Receiver is starting... {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"} 2021-03-21T16:11:11.009Z INFO k8sclusterreceiver@v0.21.0/watcher.go:195 Configured Kubernetes MetadataExporter {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\", \"exporter_name\": \"signalfx\"} 2021-03-21T16:11:11.009Z INFO builder/receivers_builder.go:75 Receiver started. {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"} 2021-03-21T16:11:11.009Z INFO healthcheck/handler.go:128 Health Check state change {\"component_kind\": \"extension\", \"component_type\": \"health_check\", \"component_name\": \"health_check\", \"status\": \"ready\"} 2021-03-21T16:11:11.009Z INFO service/service.go:267 Everything is ready. Begin running and processing data. 2021-03-21T16:11:11.009Z INFO k8sclusterreceiver@v0.21.0/receiver.go:59 Starting shared informers and wait for initial cache sync. {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"} 2021-03-21T16:11:11.281Z INFO k8sclusterreceiver@v0.21.0/receiver.go:75 Completed syncing shared informer caches. {\"component_kind\": \"receiver\", \"component_type\": \"k8s_cluster\", \"component_name\": \"k8s_cluster\"} 失敗したインストールの削除 OpenTelemetry Collector のインストールでエラーが発生した場合は、 以下のコマンドでインストールを削除してやり直すことができます：\nhelm delete splunk-otel-collector",
    "description": "オブザーバビリティシグナル（メトリクス、トレース、ログ）を Splunk Observability Cloud に送信するには、Kubernetes クラスターに Splunk OpenTelemetry Collector をデプロイする必要があります。\nこのワークショップでは、Splunk OpenTelemetry Collector Helm Chart を使用します。まず、Helm chart リポジトリを Helm に追加し、helm repo update を実行して最新バージョンを確認します：\n​ Install Helm Chart Output helm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart \u0026\u0026 helm repo update Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 \"splunk-otel-collector-chart\" has been added to your repositories Using ACCESS_TOKEN={REDACTED} Using REALM=eu0 Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"splunk-otel-collector-chart\" chart repository Update Complete. ⎈Happy Helming!⎈ Splunk Observability Cloud では、Kubernetes 上での OpenTelemetry Collector のセットアップを案内する UI ウィザードが提供されていますが、時間の都合上、以下の Helm install コマンドを使用します。自動ディスカバリーおよび設定とコードプロファイリング用のオペレーターを有効にするための追加パラメータが設定されています。",
    "tags": [],
    "title": "Splunk OpenTelemetry Collector のデプロイ",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/2-preparation/1-otel/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting",
    "content": "はじめに このワークショップでは、Chrome DevTools Recorder を使用して、Splunk デモインスタンスに対する Synthetic トランザクションを作成する方法を説明します。\nChrome DevTools Recorder からエクスポートした JSON を使用して、Splunk Synthetic Monitoring の Real Browser Test を作成します。\nまた、API Test や Uptime Test など、他の Splunk Synthetic Monitoring チェックについても学びます。\n前提条件 Google Chrome ブラウザがインストールされていること Splunk Observability Cloud へのアクセス権があること",
    "description": "はじめに このワークショップでは、Chrome DevTools Recorder を使用して、Splunk デモインスタンスに対する Synthetic トランザクションを作成する方法を説明します。\nChrome DevTools Recorder からエクスポートした JSON を使用して、Splunk Synthetic Monitoring の Real Browser Test を作成します。\nまた、API Test や Uptime Test など、他の Splunk Synthetic Monitoring チェックについても学びます。\n前提条件 Google Chrome ブラウザがインストールされていること Splunk Observability Cloud へのアクセス権があること",
    "tags": [],
    "title": "1. Real Browser Test",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "Splunk Observability Cloud のメインメニューから、RUMをクリックします。RUM ホームページに到着します。このビューについては、先ほどの短い紹介ですでに説明しました。\n演習 ドロップダウンが以下のように設定/選択されていることを確認して、ワークショップを選択してください： 時間枠は -15m に設定されていること。 選択されているEnvironmentは [ワークショップ名]-workshop であること。 選択されているAppは [ワークショップ名]-store であること。 SourceはAllに設定されていること。 次に、Page Views / JavaScript Errorsチャートの上にある [ワークショップ名]-store をクリックします。 これにより、UX Metrics、Front-end Health、Back-end Health、Custom Eventsごとにメトリクスを分類し、過去のメトリクス（デフォルトでは 1 時間）と比較する新しいダッシュボードビューが表示されます。 UX Metrics: ページビュー、ページロード、Web バイタルメトリクス。 Front-end Health: JavaScript エラーとロングタスクの期間と数の内訳。 Back-end Health: ネットワークエラー、リクエスト、最初のバイトまでの時間。 Custom Events: Custom Events の RED メトリクス（レート、エラー、期間）。 演習 各タブ（UX Metrics、Front-end Health、Back-end Health、Custom Events）をクリックしてデータを調べます。 ​ 質問 回答 「Custom Events」タブのチャートを調べると、どのチャートがレイテンシースパイクを明確に示していますか？\nそれは 「Custom Event Latency」 チャートです",
    "description": "Splunk Observability Cloud のメインメニューから、RUMをクリックします。RUM ホームページに到着します。このビューについては、先ほどの短い紹介ですでに説明しました。\n演習 ドロップダウンが以下のように設定/選択されていることを確認して、ワークショップを選択してください： 時間枠は -15m に設定されていること。 選択されているEnvironmentは [ワークショップ名]-workshop であること。 選択されているAppは [ワークショップ名]-store であること。 SourceはAllに設定されていること。 次に、Page Views / JavaScript Errorsチャートの上にある [ワークショップ名]-store をクリックします。 これにより、UX Metrics、Front-end Health、Back-end Health、Custom Eventsごとにメトリクスを分類し、過去のメトリクス（デフォルトでは 1 時間）と比較する新しいダッシュボードビューが表示されます。 UX Metrics: ページビュー、ページロード、Web バイタルメトリクス。 Front-end Health: JavaScript エラーとロングタスクの期間と数の内訳。 Back-end Health: ネットワークエラー、リクエスト、最初のバイトまでの時間。 Custom Events: Custom Events の RED メトリクス（レート、エラー、期間）。 演習 各タブ（UX Metrics、Front-end Health、Back-end Health、Custom Events）をクリックしてデータを調べます。 ​ 質問 回答 「Custom Events」タブのチャートを調べると、どのチャートがレイテンシースパイクを明確に示していますか？",
    "tags": [],
    "title": "1. RUMダッシュボード",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/5-rum/1-rum-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "Splunk Observability Cloud のメインメニューから、Syntheticsをクリックします。AllまたはBrowser testsをクリックして、アクティブなテストのリストを表示します。\nRUM セクションでの調査中に、Place orderトランザクションに問題があることがわかりました。Synthetics テストからもこれを確認できるか見てみましょう。テストの 4 ページ目のFirst byte timeというメトリクスを使用します。これはPlace orderステップです。\n演習 Searchボックスに [ワークショップ名] を入力し、あなたのワークショップのテストを選択します（インストラクターがどれを選択するか指示します）。 Performance KPIsの下で、時間選択を過去 1 時間に設定して Enter キーを押します。 Locationをクリックし、ドロップダウンからPageを選択します。次のフィルターには、テストの一部であるページが表示されます。 Durationをクリックし、Durationの選択を解除してFirst byte timeを選択します。 凡例を見て、First byte time - Page 4の色に注目してください。 First byte time - Page 4の最も高いデータポイントを選択します。これで、この特定のテスト実行のRun resultsに移動します。",
    "description": "Splunk Observability Cloud のメインメニューから、Syntheticsをクリックします。AllまたはBrowser testsをクリックして、アクティブなテストのリストを表示します。\nRUM セクションでの調査中に、Place orderトランザクションに問題があることがわかりました。Synthetics テストからもこれを確認できるか見てみましょう。テストの 4 ページ目のFirst byte timeというメトリクスを使用します。これはPlace orderステップです。\n演習 Searchボックスに [ワークショップ名] を入力し、あなたのワークショップのテストを選択します（インストラクターがどれを選択するか指示します）。 Performance KPIsの下で、時間選択を過去 1 時間に設定して Enter キーを押します。 Locationをクリックし、ドロップダウンからPageを選択します。次のフィルターには、テストの一部であるページが表示されます。 Durationをクリックし、Durationの選択を解除してFirst byte timeを選択します。 凡例を見て、First byte time - Page 4の色に注目してください。 First byte time - Page 4の最も高いデータポイントを選択します。これで、この特定のテスト実行のRun resultsに移動します。",
    "tags": [],
    "title": "1. Syntheticsダッシュボード",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/8-synthetics/1-synthetics-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 8. Real User Monitoring",
    "content": "左側のメニューで RUM をクリックして、RUM の簡単な概要ツアーを始めましょう。次に、Environment フィルター (1) をドロップダウンボックスから変更し、ワークショップインスタンスの名前 \u003cINSTANCE\u003e-workshop (1) を選択します (ここで INSTANCE は、以前に実行したシェルスクリプトの値です)。これのみが選択されていることを確認してください。\n次に、App (2) ドロップダウンボックスをアプリの名前に変更します。これは \u003cINSTANCE\u003e-store になります。\nEnvironment と App を選択すると、アプリケーションの RUM ステータスを示す概要ページが表示されます。(Summary Dashboard が単一行の数値だけの場合は、縮小表示になっています。アプリケーション名の前にある \u003e (1) をクリックして展開できます)。JavaScript エラーが発生した場合は、以下のように表示されます:\n続けるには、青いリンク (ワークショップ名) をクリックして詳細ページに移動します。これにより、UX Metrics、Front-end Health、Back-end Health、Custom Events によるインタラクションの内訳が表示され、過去のメトリクス (デフォルトでは 1 時間) と比較される新しいダッシュボードビューが表示されます。\n通常、最初のチャートには 1 つの線のみがあります。Petclinic ショップに関連するリンクをクリックしてください。 この例では http://198.19.249.202:81 です:\nこれにより、Tag Spotlight ページに移動します。",
    "description": "左側のメニューで RUM をクリックして、RUM の簡単な概要ツアーを始めましょう。次に、Environment フィルター (1) をドロップダウンボックスから変更し、ワークショップインスタンスの名前 \u003cINSTANCE\u003e-workshop (1) を選択します (ここで INSTANCE は、以前に実行したシェルスクリプトの値です)。これのみが選択されていることを確認してください。\n次に、App (2) ドロップダウンボックスをアプリの名前に変更します。これは \u003cINSTANCE\u003e-store になります。\nEnvironment と App を選択すると、アプリケーションの RUM ステータスを示す概要ページが表示されます。(Summary Dashboard が単一行の数値だけの場合は、縮小表示になっています。アプリケーション名の前にある \u003e (1) をクリックして展開できます)。JavaScript エラーが発生した場合は、以下のように表示されます:\n続けるには、青いリンク (ワークショップ名) をクリックして詳細ページに移動します。これにより、UX Metrics、Front-end Health、Back-end Health、Custom Events によるインタラクションの内訳が表示され、過去のメトリクス (デフォルトでは 1 時間) と比較される新しいダッシュボードビューが表示されます。\n通常、最初のチャートには 1 つの線のみがあります。Petclinic ショップに関連するリンクをクリックしてください。 この例では http://198.19.249.202:81 です:",
    "tags": [],
    "title": "Select the RUM view for the Petclinic App",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/8-rum/1-rum-tour/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "はじめに\nこのワークショップの目的は、Splunk Observability Cloud を使用して問題のトラブルシューティングを行い、根本原因を特定する実践的な経験を提供することです。私たちは、Kubernetes 上で動作する完全に計装されたマイクロサービスベースのアプリケーションを用意しており、これがメトリクス、トレース、ログを Splunk Observability Cloud にリアルタイム分析のために送信します。\n対象者\nこのワークショップは、Splunk Observability Cloud の実践的な知識を得たいと考えている方を対象としています。Observability Cloud を含む Splunk Platform に関する事前知識がほとんど、または全くない方向けに設計されています。\n必要なもの\nノートパソコンと外部ウェブサイトにアクセスできるブラウザが必要です。ワークショップは対面または Zoom を通じて参加できます。Zoom クライアントをインストールしていない場合でも、ブラウザを使用して参加できます。\nワークショップ概要\nこの 3 時間のセッションでは、ストリーミング分析と NoSample で完全に忠実な分散トレースを提供する唯一のプラットフォームである Splunk Observability の基礎を、インタラクティブなハンズオン形式で説明します。以下が期待できる内容です：\nOpenTelemetry\n最新の Observability に OpenTelemetry が不可欠である理由と、システムの可視性をどのように向上させるかを学びます。\nSplunk Observability ユーザーインターフェイスツアー\nSplunk Observability Cloud のインターフェイスのガイド付きツアーで、APM、RUM、Log Observer、Synthetics、Infrastructure という 5 つの主要コンポーネントの操作方法を紹介します。\n実際のユーザーデータを生成\nオンラインブティックというウェブサイトでシミュレートされた小売体験に飛び込みます。ブラウザ、モバイル、またはタブレットを使用して、サイトを探索し、メトリクス（問題はありますか？）、トレース（問題はどこにありますか？）、ログ（何が問題を引き起こしていますか？）を含む実際のユーザーデータを生成します。\nSplunk Real User Monitoring（RUM）\n参加者のブラウザセッションから収集された実際のユーザーデータを分析します。あなたの課題は、パフォーマンスの悪いセッションを特定し、トラブルシューティングプロセスを開始することです。\nSplunk Application Performance Monitoring（APM）\nRUM トレース（フロントエンド）を APM トレース（バックエンド）にリンクすることで、End to End を可視化する能力を理解しましょう。様々なサービスからのテレメトリが Splunk Observability Cloud でどのように取得され、視覚化されるかを探り、異常とエラーを検出します。\nSplunk Log Observer（LO）\nRelated Content 機能を活用してコンポーネント間を簡単に移動する方法を学びます。このワークショップでは、APM トレースから関連するログに移動して、問題についてより深い洞察を得ます。\nSplunk Synthetics\nSynthetics がアプリケーションの 24 時間 365 日のモニタリングにどのように役立つかを発見します。オンラインブティックウェブサイトのパフォーマンスと可用性を監視するために、毎分実行される簡単な合成テストの設定方法を説明します。\nこのセッションを終えると、Splunk Observability Cloud の実践的な経験と、アプリケーションスタック全体の問題をトラブルシューティングして解決する方法についての確かな理解が得られるでしょう。",
    "description": "ワークショップ概要",
    "tags": [],
    "title": "ワークショップ概要",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/1-workshop-goals/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "OpenTelemetry Collector Contrib ディストリビューションのダウンロード OpenTelemetry Collector をインストールする最初のステップは、ダウンロードです。このラボでは、wget コマンドを使用して OpenTelemetry の GitHub リポジトリから .deb パッケージをダウンロードします。\nお使いのプラットフォーム用の .deb パッケージを OpenTelemetry Collector Contrib リリースページ から取得します。\nwget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.111.0/otelcol-contrib_0.111.0_linux_amd64.deb OpenTelemetry Collector Contrib ディストリビューションのインストール dpkg を使用して .deb パッケージをインストールします。インストールが成功した場合の出力例は、下の dpkg Output タブを確認してください\n​ インストール dpkg 出力 sudo dpkg -i otelcol-contrib_0.111.0_linux_amd64.deb Selecting previously unselected package otelcol-contrib. (Reading database ... 89232 files and directories currently installed.) Preparing to unpack otelcol-contrib_0.111.0_linux_amd64.deb ... Unpacking otelcol-contrib (0.111.0) ... Setting up otelcol-contrib (0.111.0) ... Created symlink /etc/systemd/system/multi-user.target.wants/otelcol-contrib.service → /lib/systemd/system/otelcol-contrib.service.",
    "description": "OpenTelemetry Collector Contrib ディストリビューションのダウンロード OpenTelemetry Collector をインストールする最初のステップは、ダウンロードです。このラボでは、wget コマンドを使用して OpenTelemetry の GitHub リポジトリから .deb パッケージをダウンロードします。\nお使いのプラットフォーム用の .deb パッケージを OpenTelemetry Collector Contrib リリースページ から取得します。\nwget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.111.0/otelcol-contrib_0.111.0_linux_amd64.deb OpenTelemetry Collector Contrib ディストリビューションのインストール dpkg を使用して .deb パッケージをインストールします。インストールが成功した場合の出力例は、下の dpkg Output タブを確認してください\n​ インストール dpkg 出力 sudo dpkg -i otelcol-contrib_0.111.0_linux_amd64.deb Selecting previously unselected package otelcol-contrib. (Reading database ... 89232 files and directories currently installed.) Preparing to unpack otelcol-contrib_0.111.0_linux_amd64.deb ... Unpacking otelcol-contrib (0.111.0) ... Setting up otelcol-contrib (0.111.0) ... Created symlink /etc/systemd/system/multi-user.target.wants/otelcol-contrib.service → /lib/systemd/system/otelcol-contrib.service.",
    "tags": [],
    "title": "OpenTelemetry Collector Contrib のインストール",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/1-installation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "OpenTelemetry Collector の Contrib ディストリビューションをダウンロードする OpenTelemetry Collector のインストールのために、まずはダウンロードするのが最初のステップです。このラボでは、 wget コマンドを使って OpenTelemetry の GitHub リポジトリから .deb パッケージをダウンロードしていきます。\nOpenTelemetry Collector Contrib releases page から、ご利用のプラットフォーム用の .deb パッケージを入手してください。\nwget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.80.0/otelcol-contrib_0.80.0_linux_amd64.deb OpenTelemetry Collector の Contrib ディストリビューションをインストールする dpkg を使って、 .deb パッケージをインストールします。下記の dpkg Output のようになれば、インストールは成功です！\n​ Install dpkg Output sudo dpkg -i otelcol-contrib_0.80.0_linux_amd64.deb Selecting previously unselected package otelcol-contrib. (Reading database ... 64218 files and directories currently installed.) Preparing to unpack otelcol-contrib_0.75.0_linux_amd64.deb ... Unpacking otelcol-contrib (0.75.0) ... Setting up otelcol-contrib (0.75.0) ... Created symlink /etc/systemd/system/multi-user.target.wants/otelcol-contrib.service → /lib/systemd/system/otelcol-contrib.service.",
    "description": "OpenTelemetry Collector の Contrib ディストリビューションをダウンロードする OpenTelemetry Collector のインストールのために、まずはダウンロードするのが最初のステップです。このラボでは、 wget コマンドを使って OpenTelemetry の GitHub リポジトリから .deb パッケージをダウンロードしていきます。\nOpenTelemetry Collector Contrib releases page から、ご利用のプラットフォーム用の .deb パッケージを入手してください。\nwget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.80.0/otelcol-contrib_0.80.0_linux_amd64.deb OpenTelemetry Collector の Contrib ディストリビューションをインストールする dpkg を使って、 .deb パッケージをインストールします。下記の dpkg Output のようになれば、インストールは成功です！\n​ Install dpkg Output sudo dpkg -i otelcol-contrib_0.80.0_linux_amd64.deb Selecting previously unselected package otelcol-contrib. (Reading database ... 64218 files and directories currently installed.) Preparing to unpack otelcol-contrib_0.75.0_linux_amd64.deb ... Unpacking otelcol-contrib (0.75.0) ... Setting up otelcol-contrib (0.75.0) ... Created symlink /etc/systemd/system/multi-user.target.wants/otelcol-contrib.service → /lib/systemd/system/otelcol-contrib.service.",
    "tags": [],
    "title": "OpenTelemetry Collector Contrib をインストールする",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/1-installation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "前提条件 Observability ワークショップインスタンス Observability ワークショップは、多くの場合、Splunk が提供する事前設定済みの Ubuntu EC2 インスタンス上で実施されます。\nワークショップのインストラクターから、割り当てられたワークショップインスタンスの認証情報が提供されます。\nインスタンスには以下の環境変数が既に設定されているはずです：\nACCESS_TOKEN REALM これらはワークショップ用の Splunk Observability Cloud の Access Token と Realm です。 これらは OpenTelemetry Collector によって、データを正しい Splunk Observability Cloud 組織に転送するために使用されます。 また、Multipass を使用してローカルの Observability ワークショップインスタンスをデプロイすることもできます。\nAWS Command Line Interface (awscli) AWS Command Line Interface、またはawscliは、AWS リソースと対話するために使用される API です。このワークショップでは、特定のスクリプトがデプロイするリソースと対話するために使用されます。\nSplunk が提供するワークショップインスタンスには、既に awscli がインストールされているはずです。\nインスタンスに aws コマンドがインストールされているか、次のコマンドで確認します：\nwhich aws 予想される出力は /usr/local/bin/aws です インスタンスに aws コマンドがインストールされていない場合は、次のコマンドを実行します：\nsudo apt install awscli Terraform Terraform は、リソースを構成ファイルで定義することで、デプロイ、管理、破棄するための Infrastructure as Code（IaC）プラットフォームです。Terraform は HCL を使用してこれらのリソースを定義し、さまざまなプラットフォームやテクノロジのための複数のプロバイダーをサポートしています。\nこのワークショップでは、コマンドラインで Terraform を使用して、以下のリソースをデプロイします：\nAWS API Gateway Lambda 関数 Kinesis Stream CloudWatch ロググループ S3 バケット およびその他のサポートリソース Splunk が提供するワークショップインスタンスには、既に terraform がインストールされているはずです。\nインスタンスに terraform コマンドがインストールされているか確認します：\nwhich terraform 予想される出力は /usr/local/bin/terraform です インスタンスに terraform コマンドがインストールされていない場合は、以下の Terraform が推奨するインストールコマンドを実行してください：\nwget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026\u0026 sudo apt install terraform ワークショップディレクトリ (o11y-lambda-workshop) ワークショップディレクトリ o11y-lambda-workshop は、今日使用する例の Lambda ベースのアプリケーションの自動計装と手動計装の両方を完了するための、すべての設定ファイルとスクリプトを含むリポジトリです。\nホームディレクトリにワークショップディレクトリがあることを確認します：\ncd \u0026\u0026 ls 予想される出力には o11y-lambda-workshop が含まれるはずです o11y-lambda-workshop ディレクトリがホームディレクトリにない場合は、次のコマンドでクローンします：\ngit clone https://github.com/gkono-splunk/o11y-lambda-workshop.git AWS \u0026 Terraform 変数 AWS AWS の CLI では、サービスによってデプロイされたリソースにアクセスし管理するための認証情報が必要です。このワークショップでは、Terraform と Python スクリプトの両方がタスクを実行するためにこれらの変数を必要とします。\nこのワークショップのために awscli を access key ID、secret access key および region で構成します：\naws configure このコマンドは以下のようなプロンプトを表示するはずです：\nAWS Access Key ID [None]: XXXXXXXXXXXXXXXX AWS Secret Acces Key [None]: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Default region name [None]: us-east-1 Default outoput format [None]: インスタンスで awscli が設定されていない場合は、次のコマンドを実行し、インストラクターから提供される値を入力してください。\naws configure Terraform Terraform では、機密情報や動的データを.tf 設定ファイルにハードコーディングさせない、またはそれらの値をリソース定義全体で再利用できるようにするため、変数の受け渡しをサポートしています。\nこのワークショップでは、OpenTelemetry Lambda layer の適切な値で Lambda 関数をデプロイするため、Splunk Observability Cloud の取り込み値のため、そして環境とリソースを独自で即座に認識できるようにするための変数を Terraform で必要とします。\nTerraform 変数(variable)は以下の方法で定義されます：\n変数を main.tf ファイルまたは variables.tf に定義する 以下のいずれかの方法で変数の値を設定する： ホストレベルで環境変数を設定し、その定義と同じ変数名を使用して、接頭辞として TF_VAR をつける terraform.tfvars ファイルに変数の値を設定する terraform apply 実行時に引数として値を渡す このワークショップでは、variables.tf と terraform.tfvars ファイルの組み合わせを使用して変数を設定します。\nvi または nano のいずれかを使用して、auto または manual ディレクトリにある terraform.tfvars ファイルを開きます\nvi ~/o11y-lambda-workshop/auto/terraform.tfvars 変数に値を設定します。CHANGEME プレースホルダーをインストラクターから提供された値に置き換えてください。\no11y_access_token = \"CHANGEME\" o11y_realm = \"CHANGEME\" otel_lambda_layer = [\"CHANGEME\"] prefix = \"CHANGEME\" 引用符（\"）や括弧 ( [ ] ) はそのまま残し、プレースホルダーCHANGEMEのみを変更してください。 prefix は、他の参加者のリソースと区別するため、任意の文字列で設定する固有の識別子です。氏名やメールアドレスのエイリアスを使用することをお勧めします。 prefix には小文字のみを使用してください。S3 のような特定の AWS リソースでは、大文字を使用するとエラーが発生します。 ファイルを保存してエディタを終了します。\n最後に、編集した terraform.tfvars ファイルを他のディレクトリにコピーします。\ncp ~/o11y-lambda-workshop/auto/terraform.tfvars ~/o11y-lambda-workshop/manual これは、自動計装と手動計装の両方の部分で同じ値を使用するためです ファイル権限 他のすべてのファイルはそのままでよいですが、autoとmanualの両方にあるsend_message.pyスクリプトは、ワークショップの一部として実行する必要があります。そのため、期待通りに実行するには、適切な権限が必要です。以下の手順に従って設定してください。\nまず、o11y-lambda-workshopディレクトリにいることを確認します：\ncd ~/o11y-lambda-workshop 次に、以下のコマンドを実行してsend_message.pyスクリプトに実行権限を設定します：\nsudo chmod 755 auto/send_message.py manual/send_message.py これで前提条件が整いましたので、ワークショップを始めることができます！",
    "description": "前提条件 Observability ワークショップインスタンス Observability ワークショップは、多くの場合、Splunk が提供する事前設定済みの Ubuntu EC2 インスタンス上で実施されます。\nワークショップのインストラクターから、割り当てられたワークショップインスタンスの認証情報が提供されます。\nインスタンスには以下の環境変数が既に設定されているはずです：\nACCESS_TOKEN REALM これらはワークショップ用の Splunk Observability Cloud の Access Token と Realm です。 これらは OpenTelemetry Collector によって、データを正しい Splunk Observability Cloud 組織に転送するために使用されます。 また、Multipass を使用してローカルの Observability ワークショップインスタンスをデプロイすることもできます。",
    "tags": [],
    "title": "セットアップ",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/1-setup/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 9. サービスヘルスダッシュボード",
    "content": "Log Observer 演習ですでにいくつかの便利なログチャートをダッシュボードに保存したので、そのダッシュボードを拡張していきます。\n演習 2 つのログチャートがあるダッシュボードに戻るには、メインメニューからDashboardをクリックすると、チームダッシュボードビューに移動します。Dashboardの下にあるSearch Dashboardをクリックして、あなたのサービスヘルスダッシュボードグループを検索します。 名前をクリックすると、以前に保存したダッシュボードが表示されます。 ログ情報は便利ですが、チームにとって意味のあるものにするにはさらに情報が必要なので、もう少し情報を追加しましょう。 最初のステップは、ダッシュボードに説明チャートを追加することです。New text noteをクリックし、ノート内のテキストを次のテキストに置き換えてから、Save and Closeボタンをクリックし、チャートに手順と名前をつけます。 テキストノートで使用する情報 これは**支払いサービス**のためのカスタムヘルスダッシュボードです。 ログのエラーに注意してください。 詳細については[リンク](https://https://www.splunk.com/en_us/products/observability.html)をご覧ください。 チャートが適切な順序になっていません。チャートを役立つように並べ替えましょう。 手順チャートの上端にマウスを移動すると、マウスポインタが ☩ に変わります。これにより、ダッシュボード内でチャートをドラッグできるようになります。手順チャートを左上の位置にドラッグし、右端をドラッグしてページの 1/3 のサイズにリサイズします。 ログタイムラインビューチャートを手順チャートの横にドラッグして追加し、ページの残りの 2/3 を埋めるようにリサイズして、2 つのチャートの横にエラー率チャートを配置し、ページ全体を埋めるようにリサイズします。 次に、ログラインチャートをページの幅にリサイズし、少なくとも 2 倍の長さになるようにリサイズします。 以下のダッシュボードに似た形になっているはずです： これは素晴らしいですね。引き続き、より意味のあるチャートを追加していきましょう。",
    "description": "Log Observer 演習ですでにいくつかの便利なログチャートをダッシュボードに保存したので、そのダッシュボードを拡張していきます。\n演習 2 つのログチャートがあるダッシュボードに戻るには、メインメニューからDashboardをクリックすると、チームダッシュボードビューに移動します。Dashboardの下にあるSearch Dashboardをクリックして、あなたのサービスヘルスダッシュボードグループを検索します。 名前をクリックすると、以前に保存したダッシュボードが表示されます。 ログ情報は便利ですが、チームにとって意味のあるものにするにはさらに情報が必要なので、もう少し情報を追加しましょう。 最初のステップは、ダッシュボードに説明チャートを追加することです。New text noteをクリックし、ノート内のテキストを次のテキストに置き換えてから、Save and Closeボタンをクリックし、チャートに手順と名前をつけます。 テキストノートで使用する情報 これは**支払いサービス**のためのカスタムヘルスダッシュボードです。 ログのエラーに注意してください。 詳細については[リンク](https://https://www.splunk.com/en_us/products/observability.html)をご覧ください。 チャートが適切な順序になっていません。チャートを役立つように並べ替えましょう。 手順チャートの上端にマウスを移動すると、マウスポインタが ☩ に変わります。これにより、ダッシュボード内でチャートをドラッグできるようになります。手順チャートを左上の位置にドラッグし、右端をドラッグしてページの 1/3 のサイズにリサイズします。 ログタイムラインビューチャートを手順チャートの横にドラッグして追加し、ページの残りの 2/3 を埋めるようにリサイズして、2 つのチャートの横にエラー率チャートを配置し、ページ全体を埋めるようにリサイズします。 次に、ログラインチャートをページの幅にリサイズし、少なくとも 2 倍の長さになるようにリサイズします。 以下のダッシュボードに似た形になっているはずです： これは素晴らしいですね。引き続き、より意味のあるチャートを追加していきましょう。",
    "tags": [],
    "title": "ダッシュボードの強化",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/9-custom-dashboard/1-custom-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 4. 自動検出と設定",
    "content": "自動検出と設定を構成するには、デプロイメントに計装アノテーションを追加するためのパッチを適用する必要があります。パッチが適用されると、OpenTelemetry Collectorが自動検出と設定ライブラリを注入し、Podが再起動されてトレースとプロファイリングデータの送信が開始されます。まず、以下を実行してapi-gatewayにsplunk-otel-javaイメージがないことを確認します：\n​ Describe api-gateway Describe Output kubectl describe pods api-gateway | grep Image: Image: quay.io/phagen/spring-petclinic-api-gateway:0.0.2 次に、デプロイメントにアノテーションを追加して、すべてのサービスのJava自動検出と設定を有効にします。以下のコマンドは、すべてのデプロイメントにパッチを適用します。これにより、OpenTelemetry Operatorがsplunk-otel-javaイメージをPodに注入します：\n​ Patch all PetClinic services Patch Output kubectl get deployments -l app.kubernetes.io/part-of=spring-petclinic -o name | xargs -I % kubectl patch % -p \"{\\\"spec\\\": {\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"instrumentation.opentelemetry.io/inject-java\\\":\\\"default/splunk-otel-collector\\\"}}}}}\" deployment.apps/config-server patched (no change) deployment.apps/admin-server patched (no change) deployment.apps/customers-service patched deployment.apps/visits-service patched deployment.apps/discovery-server patched (no change) deployment.apps/vets-service patched deployment.apps/api-gateway patched config-server、discovery-server、admin-serverについては、すでにパッチが適用されているため変更はありません。\napi-gateway Podのコンテナイメージを再度確認するには、以下のコマンドを実行します：\n​ Describe api-gateway Describe Output kubectl describe pods api-gateway | grep Image: Image: ghcr.io/signalfx/splunk-otel-java/splunk-otel-java:v1.30.0 Image: quay.io/phagen/spring-petclinic-api-gateway:0.0.2 api-gatewayに新しいイメージが追加され、ghcr.ioからsplunk-otel-javaがプルされます（注：2つのapi-gatewayコンテナが表示される場合、元のコンテナがまだ終了処理中の可能性があるため、数秒待ってください）。\nSplunk Observability CloudのKubernetes Navigatorに戻ります。数分後、Podがオペレーターによって再起動され、自動検出と設定コンテナが追加されることが確認できます。以下のスクリーンショットのような表示になります：\nKubernetes NavigatorでPodが緑色になるまで待ってから、次のセクションに進んでください。",
    "description": "自動検出と設定を構成するには、デプロイメントに計装アノテーションを追加するためのパッチを適用する必要があります。パッチが適用されると、OpenTelemetry Collectorが自動検出と設定ライブラリを注入し、Podが再起動されてトレースとプロファイリングデータの送信が開始されます。まず、以下を実行してapi-gatewayにsplunk-otel-javaイメージがないことを確認します：\n​ Describe api-gateway Describe Output kubectl describe pods api-gateway | grep Image: Image: quay.io/phagen/spring-petclinic-api-gateway:0.0.2 次に、デプロイメントにアノテーションを追加して、すべてのサービスのJava自動検出と設定を有効にします。以下のコマンドは、すべてのデプロイメントにパッチを適用します。これにより、OpenTelemetry Operatorがsplunk-otel-javaイメージをPodに注入します：\n​ Patch all PetClinic services Patch Output kubectl get deployments -l app.kubernetes.io/part-of=spring-petclinic -o name | xargs -I % kubectl patch % -p \"{\\\"spec\\\": {\\\"template\\\":{\\\"metadata\\\":{\\\"annotations\\\":{\\\"instrumentation.opentelemetry.io/inject-java\\\":\\\"default/splunk-otel-collector\\\"}}}}}\" deployment.apps/config-server patched (no change) deployment.apps/admin-server patched (no change) deployment.apps/customers-service patched deployment.apps/visits-service patched deployment.apps/discovery-server patched (no change) deployment.apps/vets-service patched deployment.apps/api-gateway patched config-server、discovery-server、admin-serverについては、すでにパッチが適用されているため変更はありません。",
    "tags": [],
    "title": "デプロイメントのパッチ適用",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/4-apm/1-patching-deployment/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "1. Splunk Observability Cloud にサインインする Splunk が主催するワークショップの場合、Workshop Org に招待するメールを受け取っているはずです。このメールは下のスクリーンショットのようになっています。見つからない場合は、迷惑メールフォルダを確認するか、インストラクターにお知らせください。また、ログイン FAQで他の解決策を確認することもできます。\n進めるには、Join Now（参加する）ボタンをクリックするか、メールに記載されているリンクをクリックしてください。\n登録プロセスをすでに完了している場合は、残りの手順をスキップして直接 Splunk Observability Cloud にログインできます：\nhttps://app.eu0.signalfx.com (EMEA) https://app.us1.signalfx.com (APAC/AMER) Splunk Observability Cloud を初めて使用する場合は、登録フォームが表示されます。フルネームと希望するパスワードを入力してください。パスワードの要件は次のとおりです：\n8 文字から 32 文字の間である 少なくとも 1 つの大文字を含む 少なくとも 1 つの数字を含む 少なくとも 1 つの記号（例：!@#$%^\u0026*()_+）を含む 利用規約に同意するためのチェックボックスをクリックし、SIGN IN NOW（今すぐサインイン）ボタンをクリックします。",
    "description": "Splunk Observability Cloudの使い方を学びます。",
    "tags": [],
    "title": "はじめに",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/1-homepage/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "Log Observer (LO)は、複数の方法で使用できます。クイックツアーでは、LO のコード不要インターフェースを使用して、ログ内の特定のエントリを検索しました。しかし、このセクションでは、関連コンテンツリンクを使用して APM のトレースから LO に到達したと想定しています。\nこれの利点は、RUM と APM 間のリンクと同様に、以前のアクションのコンテキスト内でログを見ていることです。この場合、コンテキストはトレースの時間枠（1）とtrace_idに設定されたフィルター（2）です。\nこのビューには、エンドユーザーとオンラインブティックのやり取りによって開始されたバックエンドトランザクションに参加したすべてのアプリケーションまたはサービスからのすべてのログ行が含まれます。\n私たちのオンラインブティックのような小さなアプリケーションでさえ、見つかるログの膨大な量により、調査している実際のインシデントに関連する特定のログ行を見つけることが難しくなる場合があります。\n演習 ログ内のエラーメッセージだけに焦点を当てる必要があります：\nGroup By（グループ化）ドロップダウンボックスをクリックし、フィルターを使用してSeverity（重要度）を見つけます。 選択したらApplyボタンをクリックします（チャートの凡例がデバッグ、エラー、情報を表示するように変わることに注意してください）。 エラーログのみを選択するには、凡例の「error」（1）という単語をクリックし、Add to filterを選択します。次にRun Searchをクリックします。 複数のサービスにエラー行がある場合は、sf_service=paymentserviceなどのサービス名もフィルターに追加できますが、今回のケースでは必要ありません。 次に、ログエントリの詳細を見ていきます。",
    "description": "Log Observer (LO)は、複数の方法で使用できます。クイックツアーでは、LO のコード不要インターフェースを使用して、ログ内の特定のエントリを検索しました。しかし、このセクションでは、関連コンテンツリンクを使用して APM のトレースから LO に到達したと想定しています。\nこれの利点は、RUM と APM 間のリンクと同様に、以前のアクションのコンテキスト内でログを見ていることです。この場合、コンテキストはトレースの時間枠（1）とtrace_idに設定されたフィルター（2）です。\nこのビューには、エンドユーザーとオンラインブティックのやり取りによって開始されたバックエンドトランザクションに参加したすべてのアプリケーションまたはサービスからのすべてのログ行が含まれます。\n私たちのオンラインブティックのような小さなアプリケーションでさえ、見つかるログの膨大な量により、調査している実際のインシデントに関連する特定のログ行を見つけることが難しくなる場合があります。\n演習 ログ内のエラーメッセージだけに焦点を当てる必要があります：\nGroup By（グループ化）ドロップダウンボックスをクリックし、フィルターを使用してSeverity（重要度）を見つけます。 選択したらApplyボタンをクリックします（チャートの凡例がデバッグ、エラー、情報を表示するように変わることに注意してください）。 エラーログのみを選択するには、凡例の「error」（1）という単語をクリックし、Add to filterを選択します。次にRun Searchをクリックします。 複数のサービスにエラー行がある場合は、sf_service=paymentserviceなどのサービス名もフィルターに追加できますが、今回のケースでは必要ありません。 次に、ログエントリの詳細を見ていきます。",
    "tags": [],
    "title": "1. ログフィルタリング",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/7-log-observer/1-log-filtering/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 10. ワークショップ まとめ",
    "content": "このワークショップを通じて、Splunk Observability Cloud と OpenTelemetry シグナル（メトリクス、トレース、ログ）の組み合わせが、検出までの平均時間（MTTD）と解決までの平均時間（MTTR）をどのように短縮できるかを見てきました。\nメインユーザーインターフェイスとそのコンポーネント、ランディング、インフラストラクチャ、APM、RUM、Synthetics、ダッシュボードページ、そして設定ページについて理解を深めました。 時間に応じて、インフラストラクチャの演習を行い、Kubernetes ナビゲーターで使用されるメトリクスを確認し、Kubernetes クラスターで見つかった関連サービスを見ました： ユーザーが何を体験しているかを理解し、RUM と APM を使用して特に長いページ読み込みのトラブルシューティングを行いました。フロントエンドとバックエンド全体でトレースをたどり、ログエントリーまで追跡しました。 RUM のセッション再生と APM の依存関係マップを使用し、ブレークダウン機能を使って問題の原因を発見しました： RUM と APM の両方でTag Spotlightを使用して、影響範囲を理解し、パフォーマンス問題とエラーのトレンドやコンテキストを検出しました。APM のトレースウォーターフォールでスパンを詳しく調べ、サービスがどのように相互作用し、エラーを見つけました： 関連コンテンツ機能を使用して、トレースからトレースに関連するログへの直接のリンクをたどり、フィルターを使用して問題の正確な原因まで掘り下げました。 次に、Web とモバイルトラフィックをシミュレートできる Synthetics を調べ、利用可能な Synthetics テストを使用して、まず RUM/APM と Log Observer での発見を確認し、次にテストの実行時間が SLA を超えた場合にアラートを受け取るためのディテクターを作成しました。\n最後の演習では、開発者と SRE のために TV スクリーンで継続的に表示するヘルスダッシュボードを作成しました：",
    "description": "このワークショップを通じて、Splunk Observability Cloud と OpenTelemetry シグナル（メトリクス、トレース、ログ）の組み合わせが、検出までの平均時間（MTTD）と解決までの平均時間（MTTR）をどのように短縮できるかを見てきました。\nメインユーザーインターフェイスとそのコンポーネント、ランディング、インフラストラクチャ、APM、RUM、Synthetics、ダッシュボードページ、そして設定ページについて理解を深めました。 時間に応じて、インフラストラクチャの演習を行い、Kubernetes ナビゲーターで使用されるメトリクスを確認し、Kubernetes クラスターで見つかった関連サービスを見ました： ユーザーが何を体験しているかを理解し、RUM と APM を使用して特に長いページ読み込みのトラブルシューティングを行いました。フロントエンドとバックエンド全体でトレースをたどり、ログエントリーまで追跡しました。 RUM のセッション再生と APM の依存関係マップを使用し、ブレークダウン機能を使って問題の原因を発見しました： RUM と APM の両方でTag Spotlightを使用して、影響範囲を理解し、パフォーマンス問題とエラーのトレンドやコンテキストを検出しました。APM のトレースウォーターフォールでスパンを詳しく調べ、サービスがどのように相互作用し、エラーを見つけました： 関連コンテンツ機能を使用して、トレースからトレースに関連するログへの直接のリンクをたどり、フィルターを使用して問題の正確な原因まで掘り下げました。 次に、Web とモバイルトラフィックをシミュレートできる Synthetics を調べ、利用可能な Synthetics テストを使用して、まず RUM/APM と Log Observer での発見を確認し、次にテストの実行時間が SLA を超えた場合にアラートを受け取るためのディテクターを作成しました。\n最後の演習では、開発者と SRE のために TV スクリーンで継続的に表示するヘルスダッシュボードを作成しました：",
    "tags": [],
    "title": "主要なポイント",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/10-wrap-up/key-takeaways/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 1. Agent Configuration",
    "content": "OpenTelemetry Gateway は、テレメトリーデータの受信、処理、エクスポートのための中央ハブとして機能します。テレメトリーソース（アプリケーションやサービスなど）と Splunk Observability Cloud のようなオブザーバビリティバックエンドの間に位置します。\nテレメトリートラフィックを集中化することで、Gateway はデータのフィルタリング、エンリッチメント、変換、および1つ以上の宛先へのルーティングなどの高度な機能を実現します。個々のサービスからテレメトリー処理をオフロードすることで負担を軽減し、分散システム全体で一貫した標準化されたデータを確保します。\nこれにより、オブザーバビリティパイプラインの管理、スケーリング、分析が容易になります。特に複雑なマルチサービス環境では効果的です。\nExercise 2つ目のターミナルウィンドウを開くか作成し、Gateway と名前を付けます。最初の演習ディレクトリ [WORKSHOP]/1-agent-gateway に移動し、gateway.yaml ファイルの内容を確認します。\nこのファイルは、Gateway モードでデプロイされた OpenTelemetry Collector のコア構造を示しています。\nGateway 設定の理解 このワークショップで Gateway モードの OpenTelemetry Collector がどのように設定されているかを定義する gateway.yaml ファイルを確認しましょう。この Gateway は、Agent からテレメトリーを受信し、処理してから検査または転送のためにエクスポートする役割を担います。\nOTLP Receiver（カスタムポート）\nreceivers: otlp: protocols: http: endpoint: \"0.0.0.0:5318\" ポート 5318 は Agent 設定の otlphttp Exporter と一致しており、Agent が送信するすべてのテレメトリーデータが Gateway で受け入れられることを保証します。\nメモ このポートの分離により、競合を回避し、Agent と Gateway の役割間の責任を明確に保ちます。\nFile Exporter\nGateway は3つの File Exporter を使用して、テレメトリーデータをローカルファイルに出力します。これらの Exporter は以下のように定義されています\nexporters: # List of exporters debug: # Debug exporter verbosity: detailed # Enable detailed debug output file/traces: # Exporter Type/Name path: \"./gateway-traces.out\" # Path for OTLP JSON output for traces append: false # Overwrite the file each time file/metrics: # Exporter Type/Name path: \"./gateway-metrics.out\" # Path for OTLP JSON output for metrics append: false # Overwrite the file each time file/logs: # Exporter Type/Name path: \"./gateway-logs.out\" # Path for OTLP JSON output for logs append: false # Overwrite the file each time 各 Exporter は、特定のシグナルタイプを対応するファイルに書き込みます。\nこれらのファイルは Gateway が起動すると作成され、Agent がデータを送信すると実際のテレメトリーが書き込まれます。これらのファイルをリアルタイムで監視して、パイプラインを通過するテレメトリーの流れを観察できます。",
    "description": "OpenTelemetry Gateway は、テレメトリーデータの受信、処理、エクスポートのための中央ハブとして機能します。テレメトリーソース（アプリケーションやサービスなど）と Splunk Observability Cloud のようなオブザーバビリティバックエンドの間に位置します。\nテレメトリートラフィックを集中化することで、Gateway はデータのフィルタリング、エンリッチメント、変換、および1つ以上の宛先へのルーティングなどの高度な機能を実現します。個々のサービスからテレメトリー処理をオフロードすることで負担を軽減し、分散システム全体で一貫した標準化されたデータを確保します。\nこれにより、オブザーバビリティパイプラインの管理、スケーリング、分析が容易になります。特に複雑なマルチサービス環境では効果的です。\nExercise 2つ目のターミナルウィンドウを開くか作成し、Gateway と名前を付けます。最初の演習ディレクトリ [WORKSHOP]/1-agent-gateway に移動し、gateway.yaml ファイルの内容を確認します。\nこのファイルは、Gateway モードでデプロイされた OpenTelemetry Collector のコア構造を示しています。\nGateway 設定の理解 このワークショップで Gateway モードの OpenTelemetry Collector がどのように設定されているかを定義する gateway.yaml ファイルを確認しましょう。この Gateway は、Agent からテレメトリーを受信し、処理してから検査または転送のためにエクスポートする役割を担います。",
    "tags": [],
    "title": "1.1 Gateway 設定の確認",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/1-agent-gateway/1-1-gateway/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 2. API Test",
    "content": "Global Variables API テストを実行するために使用するグローバル変数を確認します。歯車アイコンの下にある Global Variables をクリックします。env.encoded_auth という名前のグローバル変数を使用して、Spotify API トランザクションを構築します。",
    "description": "Global Variables API テストを実行するために使用するグローバル変数を確認します。歯車アイコンの下にある Global Variables をクリックします。env.encoded_auth という名前のグローバル変数を使用して、Spotify API トランザクションを構築します。",
    "tags": [],
    "title": "Global Variables",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/2-api-test/1-global-varilables/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 1. インストール",
    "content": "Collector が動作していることを確認する Collector が動作しているはずです。systemctl コマンドを使用して root として確認します。ステータス表示を終了するには q を押してください。\n​ コマンド ステータス出力 sudo systemctl status otelcol-contrib ● otelcol-contrib.service - OpenTelemetry Collector Contrib Loaded: loaded (/lib/systemd/system/otelcol-contrib.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2024-10-07 10:27:49 BST; 52s ago Main PID: 17113 (otelcol-contrib) Tasks: 13 (limit: 19238) Memory: 34.8M CPU: 155ms CGroup: /system.slice/otelcol-contrib.service └─17113 /usr/bin/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: Descriptor: Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e Name: up Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e Description: The scraping was successful Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e Unit: Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e DataType: Gauge Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: NumberDataPoints #0 Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: StartTimestamp: 1970-01-01 00:00:00 +0000 UTC Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: Timestamp: 2024-10-07 09:28:36.942 +0000 UTC Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: Value: 1.000000 Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: {\"kind\": \"exporter\", \"data_type\": \"metrics\", \"name\": \"debug\"} このワークショップでは、設定ファイルの変更、環境変数の設定、Collector の再起動を複数回行うため、Collector サービスを停止し、起動時の自動起動を無効にする必要があります。\n​ コマンド sudo systemctl stop otelcol-contrib \u0026\u0026 sudo systemctl disable otelcol-contrib Ninja: Open Telemetry Collector Builder (ocb) を使用して独自の Collector をビルドする このパートでは、システムに以下がインストールされている必要があります\nGolang（最新バージョン）\ncd /tmp wget https://golang.org/dl/go1.20.linux-amd64.tar.gz sudo tar -C /usr/local -xzf go1.20.linux-amd64.tar.gz .profile を編集して、以下の環境変数を追加します\nexport GOROOT=/usr/local/go export GOPATH=$HOME/go export PATH=$GOPATH/bin:$GOROOT/bin:$PATH シェルセッションを更新します\nsource ~/.profile Go のバージョンを確認します\ngo version ocb のインストール\nプロジェクトリリースから ocb バイナリをダウンロードし、以下のコマンドを実行します\nmv ocb_0.80.0_darwin_arm64 /usr/bin/ocb chmod 755 /usr/bin/ocb 別の方法として、golang ツールチェーンを使用してローカルでバイナリをビルドすることもできます\ngo install go.opentelemetry.io/collector/cmd/builder@v0.80.0 mv $(go env GOPATH)/bin/builder /usr/bin/ocb （オプション）Docker\nなぜ独自の Collector をビルドするのか？ Collector のデフォルトディストリビューション（core と contrib）は、提供する機能が多すぎるか少なすぎるかのどちらかです。\nまた、contrib Collector を本番環境で実行することは推奨されません。これは、インストールされるコンポーネントの量が多く、そのほとんどがデプロイメントに必要ないためです。\n独自の Collector をビルドするメリットは？ 独自の Collector バイナリ（一般的にディストリビューションと呼ばれる）を作成することは、必要なものだけをビルドすることを意味します。\nこれには以下のメリットがあります\nより小さなサイズのバイナリ 脆弱性に対して既存の Go スキャナーを使用できる 組織と連携できる内部コンポーネントを含めることができる Collector をビルドする際の考慮事項は？ さて、いくつかのデメリットがなければ 🥷 Ninja ゾーンとは言えません\nGo の経験が推奨される（必須ではないが） Splunk サポートなし ディストリビューションとライフサイクル管理の責任 プロジェクトは安定性に向けて取り組んでいますが、変更によってワークフローが壊れないとは限らないことに注意することが重要です。Splunk のチームは、より高いサポートと安定性を提供しており、デプロイメントのニーズに応じたキュレーションされた体験を提供できます。\nNinja ゾーン 必要なツールがすべてインストールされたら、otelcol-builder.yaml という名前の新しいファイルを作成し、以下のディレクトリ構造に従います\n. └── otelcol-builder.yaml ファイルを作成したら、いくつかの追加メタデータとともにインストールするコンポーネントのリストを追加する必要があります。\nこの例では、入門用の設定に必要なコンポーネントのみをインストールするビルダーマニフェストを作成します\ndist: name: otelcol-ninja description: A custom build of the Open Telemetry Collector output_path: ./dist extensions: - gomod: go.opentelemetry.io/collector/extension/ballastextension v0.80.0 - gomod: go.opentelemetry.io/collector/extension/zpagesextension v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/httpforwarder v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckextension v0.80.0 exporters: - gomod: go.opentelemetry.io/collector/exporter/loggingexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlpexporter v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/splunkhecexporter v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/signalfxexporter v0.80.0 processors: - gomod: go.opentelemetry.io/collector/processor/batchprocessor v0.80.0 - gomod: go.opentelemetry.io/collector/processor/memorylimiterprocessor v0.80.0 receivers: - gomod: go.opentelemetry.io/collector/receiver/otlpreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/hostmetricsreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/zipkinreceiver v0.80.0 yaml ファイルが ocb 用に更新されたら、以下のコマンドを実行します\nocb --config=otelcol-builder.yaml これにより、以下のディレクトリ構造が作成されます\n├── dist │ ├── components.go │ ├── components_test.go │ ├── go.mod │ ├── go.sum │ ├── main.go │ ├── main_others.go │ ├── main_windows.go │ └── otelcol-ninja └── otelcol-builder.yaml 参考資料 https://opentelemetry.io/docs/collector/custom-collector/ デフォルト設定 OpenTelemetry は YAML ファイルを通じて設定されます。これらのファイルには、ニーズに合わせて変更できるデフォルト設定があります。提供されるデフォルト設定を見てみましょう\n​ コマンド config.yaml cat /etc/otelcol-contrib/config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # To limit exposure to denial of service attacks, change the host in endpoints below from 0.0.0.0 to a specific network interface. # See https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md#safeguards-against-denial-of-service-attacks extensions: health_check: pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 opencensus: endpoint: 0.0.0.0:55678 # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_binary: endpoint: 0.0.0.0:6832 thrift_compact: endpoint: 0.0.0.0:6831 thrift_http: endpoint: 0.0.0.0:14268 zipkin: endpoint: 0.0.0.0:9411 processors: batch: exporters: debug: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [debug] logs: receivers: [otlp] processors: [batch] exporters: [debug] extensions: [health_check, pprof, zpages] おめでとうございます！OpenTelemetry Collector のダウンロードとインストールに成功しました。OTel Ninja への道を順調に歩んでいます。しかしまず、設定ファイルと OpenTelemetry Collector の異なるディストリビューションについて説明していきましょう。\nメモ Splunk は独自の、完全にサポートされた OpenTelemetry Collector ディストリビューションを提供しています。このディストリビューションは、Splunk GitHub リポジトリからインストールするか、Splunk Observability Cloud のウィザードを使用してコピー＆ペーストするだけの簡単なインストールスクリプトを作成できます。このディストリビューションには、OpenTelemetry Collector Contrib ディストリビューションでは利用できない多くの追加機能と拡張が含まれています。\nSplunk Distribution of the OpenTelemetry Collector は本番環境でテスト済みです。大多数のお客様が本番環境で使用しています。 このディストリビューションを使用するお客様は、SLA 内で Splunk の公式サポートから直接サポートを受けることができます。 お客様は、メトリクスとトレース収集のコア設定体験に対する将来の破壊的変更を心配することなく、Splunk Distribution of the OpenTelemetry Collector を使用または移行できます（OpenTelemetry ログ収集の設定はベータ版です）。Collector のメトリクスには破壊的変更がある可能性があります。 これから設定ファイルの各セクションを説明し、ホストメトリクスを Splunk Observability Cloud に送信するように変更していきます。",
    "description": "Collector が動作していることを確認する Collector が動作しているはずです。systemctl コマンドを使用して root として確認します。ステータス表示を終了するには q を押してください。\n​ コマンド ステータス出力 sudo systemctl status otelcol-contrib ● otelcol-contrib.service - OpenTelemetry Collector Contrib Loaded: loaded (/lib/systemd/system/otelcol-contrib.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2024-10-07 10:27:49 BST; 52s ago Main PID: 17113 (otelcol-contrib) Tasks: 13 (limit: 19238) Memory: 34.8M CPU: 155ms CGroup: /system.slice/otelcol-contrib.service └─17113 /usr/bin/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: Descriptor: Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e Name: up Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e Description: The scraping was successful Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e Unit: Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: -\u003e DataType: Gauge Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: NumberDataPoints #0 Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: StartTimestamp: 1970-01-01 00:00:00 +0000 UTC Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: Timestamp: 2024-10-07 09:28:36.942 +0000 UTC Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: Value: 1.000000 Oct 07 10:28:36 petclinic-rum-testing otelcol-contrib[17113]: {\"kind\": \"exporter\", \"data_type\": \"metrics\", \"name\": \"debug\"} このワークショップでは、設定ファイルの変更、環境変数の設定、Collector の再起動を複数回行うため、Collector サービスを停止し、起動時の自動起動を無効にする必要があります。",
    "tags": [],
    "title": "OpenTelemetry Collector Contrib のインストール",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/1-installation/1-confirmation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 1. インストール",
    "content": "Collector が動作していることを確認する これで、Collector が動いているはずです。root権限で systemctl コマンドを使って、それを確かめてみましょう。\n​ Command Status Output sudo systemctl status otelcol-contrib ● otelcol-contrib.service - OpenTelemetry Collector Contrib Loaded: loaded (/lib/systemd/system/otelcol-contrib.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2023-05-16 08:23:23 UTC; 25s ago Main PID: 1415 (otelcol-contrib) Tasks: 5 (limit: 1141) Memory: 22.2M CPU: 125ms CGroup: /system.slice/otelcol-contrib.service └─1415 /usr/bin/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: NumberDataPoints #0 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Data point attributes: May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e exporter: Str(logging) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_instance_id: Str(df8a57f4-abdc-46b9-a847-acd62db1001f) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_name: Str(otelcol-contrib) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_version: Str(0.75.0) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: StartTimestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Timestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Value: 0.000000 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: {\"kind\": \"exporter\", \"data_type\": \"metrics\", \"name\": \"logging\"} Tips: status 表示を中止するには systemctl status コマンドの表示を中止するときは q キーを押してください。\nサービスを停止するときは、 stop コマンドを使います。\n​ Command sudo systemctl stop otelcol-contrib 更新した設定ファイルを読み込ませるときは、 restart コマンドでサービスの再起動をしましょう。\n​ Command sudo systemctl restart otelcol-contrib Ninja: Open Telemetry Collector Builder (ocb) を使って、独自のコレクターを作る このパートでは、お使いのシステムに以下のものがインストールされている必要があります：\nGo (latest version)\ncd /tmp wget https://golang.org/dl/go1.20.linux-amd64.tar.gz sudo tar -C /usr/local -xzf go1.20.linux-amd64.tar.gz .profile を編集して、次の環境変数をセットします:\nexport GOROOT=/usr/local/go export GOPATH=$HOME/go export PATH=$GOPATH/bin:$GOROOT/bin:$PATH そして、シェルのセッションを更新します:\nsource ~/.profile Go のバージョンを確認します:\ngo version ocb のインストール\nocb バイナリーを project releases からダウンロードして、次のコマンドを実行します:\nmv ocb_0.80.0_darwin_arm64 /usr/bin/ocb chmod 755 /usr/bin/ocb 別のアプローチとして、Go のツールチェーンを使ってバイナリをローカルにビルドする方法もあります:\ngo install go.opentelemetry.io/collector/cmd/builder@v0.80.0 mv $(go env GOPATH)/bin/builder /usr/bin/ocb (Optional) Docker\nなぜ独自のコレクターをビルドするの？ コレクターのデフォルトのディストリビューション（core および contrib）は、含まれれるコンポーネントが少なすぎたり、もしくは多すぎたりします。\n本番環境で contrib コレクターを実行することはできますが、インストールされているコンポーネントの量が多く、デプロイに必要ではないものも含まれるため、一般的には推奨されません。\n独自のコレクターをビルドする利点は？ 独自のコレクターバイナリー（通常は「ディストリビューション」と呼ばれる）を作成することで、必要なものだけをビルドすることができます。\nメリットは次のとおりです:\nバイナリーのサイズが小さい 一般的な Go の脆弱性スキャナーを利用できる 組織独自のコンポーネントを組み込むことができる カスタムコレクターをビルドするときの注意事項は？ さて、これは Ninja ゾーンの人たちにあえて言うことではないかもしれませんが:\nGo の開発経験を、必須ではないが、推奨される Splunk の サポートがない ディストリビューションのライフサイクルを管理しなければならない プロジェクトは安定性に向けて進んでいますが、行われた変更がワークフローを壊す可能性があることに注意してください。Splunk チームは、より高い安定性とサポートを提供し、デプロイメントニーズに対応するためのキュレーションされた経験を提供しています。\nNinja ゾーン 必要なツールをすべてインストールしたら、以下のディレクトリ構造に従い、 otelcol-builder.yaml という新しいファイルを作成します:\n. └── otelcol-builder.yaml ファイルを作成したら、インストールするコンポーネントのリストと追加のメタデータを追加する必要があります。\nこの例では、導入設定に必要なコンポーネントのみをインストールするためのビルダーマニフェストを作成します:\ndist: name: otelcol-ninja description: A custom build of the Open Telemetry Collector output_path: ./dist extensions: - gomod: go.opentelemetry.io/collector/extension/ballastextension v0.80.0 - gomod: go.opentelemetry.io/collector/extension/zpagesextension v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/httpforwarder v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckextension v0.80.0 exporters: - gomod: go.opentelemetry.io/collector/exporter/loggingexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlpexporter v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/splunkhecexporter v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/signalfxexporter v0.80.0 processors: - gomod: go.opentelemetry.io/collector/processor/batchprocessor v0.80.0 - gomod: go.opentelemetry.io/collector/processor/memorylimiterprocessor v0.80.0 receivers: - gomod: go.opentelemetry.io/collector/receiver/otlpreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/hostmetricsreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/zipkinreceiver v0.80.0 ocb のためのyamlファイルを作成して更新したら、 次のコマンドを実行します:\nocb --config=otelcol-builder.yaml すると、次のようなディレクトリ構造が作成されます:\n├── dist │ ├── components.go │ ├── components_test.go │ ├── go.mod │ ├── go.sum │ ├── main.go │ ├── main_others.go │ ├── main_windows.go │ └── otelcol-ninja └── otelcol-builder.yaml 最後に、 ./dist/otelcol-ninja を実行すれば、独自ビルドのCollectorが動作することがわかります。このコマンドを実行する前に、 otelcol-contrib サービスが停止していることを確認してください。\n./dist/otelcol-ninja --config=file:/etc/otelcol-contrib/config.yaml この設定ファイルで記述されているコンポーネントは、ビルドに含まれていないかもしれません。エラーの内容を含めて、何が起こるかを見てみましょう 。\nリファレンス https://opentelemetry.io/docs/collector/custom-collector/ デフォルト設定 OpenTelemetry Collector は YAML ファイルを使って設定をしていきます。これらのファイルには、必要に応じて変更できるデフォルト設定が含まれています。提供されているデフォルト設定を見てみましょう:\n​ Command config.yaml cat /etc/otelcol-contrib/config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 extensions: health_check: pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] おめでとうございます！OpenTelemetry Collector のダウンロードとインストールに成功しました。あなたは OTel Ninja になる準備ができました。しかしまずは、設定ファイルと OpenTelemetry Collector の異なるディストリビューションについて見ていきましょう。\nメモ Splunk は、自社で完全にサポートされた OpenTelemetry Collector のディストリビューションを提供しています。このディストリビューションは、Splunk GitHub Repository からインストールするか、Splunk Observability Cloud のウィザードを使用して、簡単なインストールスクリプトを作成し、コピー＆ペーストすることで利用できます。このディストリビューションには、OpenTelemetry Collector Contrib ディストリビューションにはない追加機能や強化が含まれています。\nSplunk の OpenTelemetry Collector ディストリビューションは本番環境でテスト済みであり、多くの顧客が本番環境で使用しています。 このディストリビューションを使用する顧客は、公式の Splunk サポートから、SLA の範囲内で直接支援を受けることができます。 メトリクスとトレース収集のコア構成体験に将来的な破壊的変更がないことを心配せずに、Splunk の OpenTelemetry Collector ディストリビューションを使用または移行することができます（OpenTelemetry ログ収集の設定はベータ版です）。Collector 自身のメトリクスに破壊的変更がある可能性はあります。 このセクションでは、ホストメトリクスを Splunk Observability Cloud に送信するために、設定ファイルの各セクションを詳しく見ていき、変更する方法について説明します。",
    "description": "Collector が動作していることを確認する これで、Collector が動いているはずです。root権限で systemctl コマンドを使って、それを確かめてみましょう。\n​ Command Status Output sudo systemctl status otelcol-contrib ● otelcol-contrib.service - OpenTelemetry Collector Contrib Loaded: loaded (/lib/systemd/system/otelcol-contrib.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2023-05-16 08:23:23 UTC; 25s ago Main PID: 1415 (otelcol-contrib) Tasks: 5 (limit: 1141) Memory: 22.2M CPU: 125ms CGroup: /system.slice/otelcol-contrib.service └─1415 /usr/bin/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: NumberDataPoints #0 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Data point attributes: May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e exporter: Str(logging) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_instance_id: Str(df8a57f4-abdc-46b9-a847-acd62db1001f) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_name: Str(otelcol-contrib) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_version: Str(0.75.0) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: StartTimestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Timestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Value: 0.000000 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: {\"kind\": \"exporter\", \"data_type\": \"metrics\", \"name\": \"logging\"} Tips: status 表示を中止するには systemctl status コマンドの表示を中止するときは q キーを押してください。",
    "tags": [],
    "title": "OpenTelemetry Collector Contribをインストールする",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/1-installation/1-confirmation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 1. Real Browser Test",
    "content": "開始 URL を開く ワークショップの開始 URL を Chrome で開きます。以下の適切なリンクをクリックして、新しいタブでサイトを開きます。\nメモ ワークショップの開始 URL は EMEA と AMER/APAC で異なります。お住まいの地域に応じて正しい URL を使用してください。\n​ EMEA Workshop URL AMER/APAC Workshop URL https://online-boutique-eu.splunko11y.com/\nhttps://online-boutique-us.splunko11y.com/\nChrome DevTools Recorder を開く 次に、（上記で開いた新しいタブで）Developer Tools を開きます。Windows では Ctrl + Shift + I、Mac では Cmd + Option + I を押し、トップレベルメニューまたは More tools フライアウトメニューから Recorder を選択します。\n注意 サイトの要素はビューポートの幅によって変わる場合があります。記録する前に、作成するテストの種類（デスクトップ、タブレット、モバイル）に応じてブラウザウィンドウを適切な幅に設定してください。必要に応じて、DevTools の「dock side」を別ウィンドウとしてポップアウトさせると便利です。\n新しい記録を作成 DevTools ウィンドウで Recorder パネルを開いた状態で、Create a new recording ボタンをクリックして開始します。\nRecording Name には、イニシャルを接頭辞として使用します（例: \u003cyour initials\u003e - Online Boutique）。Start Recording をクリックして、アクションの記録を開始します。\n記録が開始されたら、サイトで以下のアクションを実行します:\nVintage Camera Lens をクリック Add to Cart をクリック Place Order をクリック Recorder パネルの End recording をクリック 記録のエクスポート Export ボタンをクリックします:\nフォーマットとして JSON を選択し、Save をクリックします。\nおめでとうございます！ Chrome DevTools Recorder を使用した記録の作成に成功しました。次に、この記録を使用して Splunk Synthetic Monitoring で Real Browser Test を作成します。\nJSON ファイルを表示するにはここをクリック { \"title\": \"RWC - Online Boutique\", \"steps\": [ { \"type\": \"setViewport\", \"width\": 1430, \"height\": 1016, \"deviceScaleFactor\": 1, \"isMobile\": false, \"hasTouch\": false, \"isLandscape\": false }, { \"type\": \"navigate\", \"url\": \"https://online-boutique-eu.splunko11y.com/\", \"assertedEvents\": [ { \"type\": \"navigation\", \"url\": \"https://online-boutique-eu.splunko11y.com/\", \"title\": \"Online Boutique\" } ] }, { \"type\": \"click\", \"target\": \"main\", \"selectors\": [ [ \"div:nth-of-type(2) \u003e div:nth-of-type(2) a \u003e div\" ], [ \"xpath//html/body/main/div/div/div[2]/div[2]/div/a/div\" ], [ \"pierce/div:nth-of-type(2) \u003e div:nth-of-type(2) a \u003e div\" ] ], \"offsetY\": 170, \"offsetX\": 180, \"assertedEvents\": [ { \"type\": \"navigation\", \"url\": \"https://online-boutique-eu.splunko11y.com/product/66VCHSJNUP\", \"title\": \"\" } ] }, { \"type\": \"click\", \"target\": \"main\", \"selectors\": [ [ \"aria/ADD TO CART\" ], [ \"button\" ], [ \"xpath//html/body/main/div[1]/div/div[2]/div/form/div/button\" ], [ \"pierce/button\" ], [ \"text/Add to Cart\" ] ], \"offsetY\": 35.0078125, \"offsetX\": 46.4140625, \"assertedEvents\": [ { \"type\": \"navigation\", \"url\": \"https://online-boutique-eu.splunko11y.com/cart\", \"title\": \"\" } ] }, { \"type\": \"click\", \"target\": \"main\", \"selectors\": [ [ \"aria/PLACE ORDER\" ], [ \"div \u003e div \u003e div.py-3 button\" ], [ \"xpath//html/body/main/div/div/div[4]/div/form/div[4]/button\" ], [ \"pierce/div \u003e div \u003e div.py-3 button\" ], [ \"text/Place order\" ] ], \"offsetY\": 29.8125, \"offsetX\": 66.8203125, \"assertedEvents\": [ { \"type\": \"navigation\", \"url\": \"https://online-boutique-eu.splunko11y.com/cart/checkout\", \"title\": \"\" } ] } ] }",
    "description": "開始 URL を開く ワークショップの開始 URL を Chrome で開きます。以下の適切なリンクをクリックして、新しいタブでサイトを開きます。\nメモ ワークショップの開始 URL は EMEA と AMER/APAC で異なります。お住まいの地域に応じて正しい URL を使用してください。\n​ EMEA Workshop URL AMER/APAC Workshop URL https://online-boutique-eu.splunko11y.com/\nhttps://online-boutique-us.splunko11y.com/\nChrome DevTools Recorder を開く 次に、（上記で開いた新しいタブで）Developer Tools を開きます。Windows では Ctrl + Shift + I、Mac では Cmd + Option + I を押し、トップレベルメニューまたは More tools フライアウトメニューから Recorder を選択します。",
    "tags": [],
    "title": "1.1 テストの記録",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/1-recording-a-test/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 2. Building Resilience",
    "content": "この演習では、agent.yaml ファイルの extensions: セクションを更新します。このセクションは OpenTelemetry 設定 YAML の一部であり、OpenTelemetry Collector の動作を拡張または変更するオプションのコンポーネントを定義します。\nこれらのコンポーネントはテレメトリーデータを直接処理しませんが、Collector の機能を向上させる貴重な機能とサービスを提供します。\nExercise 重要 すべての ターミナルウィンドウを 2-building-resilience ディレクトリに移動し、clear コマンドを実行してください。\nディレクトリ構造は以下のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml agent.yaml の更新: Agent ターミナル ウィンドウで、既存の health_check Extension の下に file_storage Extension を追加します\nfile_storage/checkpoint: # Extension Type/Name directory: \"./checkpoint-dir\" # Define directory create_directory: true # Create directory timeout: 1s # Timeout for file operations compaction: # Compaction settings on_start: true # Start compaction at Collector startup # Define compaction directory directory: \"./checkpoint-dir/tmp\" max_transaction_size: 65536 # Max. size limit before compaction occurs Exporter への file_storage の追加: otlphttp Exporter を変更して、リトライとキューイングメカニズムを設定し、障害が発生した場合にデータが保持され再送信されるようにします。endpoint: \"http://localhost:5318\" の下に以下を追加し、インデントが endpoint と一致していることを確認してください\nretry_on_failure: enabled: true # Enable retry on failure sending_queue: # enabled: true # Enable sending queue num_consumers: 10 # No. of consumers queue_size: 10000 # Max. queue size storage: file_storage/checkpoint # File storage extension services セクションの更新: 既存の extensions: セクションに file_storage/checkpoint Extension を追加します。設定は以下のようになります\nservice: extensions: - health_check - file_storage/checkpoint # Enabled extensions for this collector metrics パイプラインの更新: この演習では、デバッグとログのノイズを減らすために、Metric パイプラインから hostmetrics Receiver をコメントアウトします。設定は以下のようになります\nmetrics: receivers: # - hostmetrics # Hostmetric reciever (cpu only) - otlp otelbin.io を使用して Agent 設定を検証してください。参考までに、パイプラインの metrics: セクションは以下のようになります\n%%{init:{\"fontFamily\":\"monospace\"}}%% graph LR %% Nodes REC1(\u0026nbsp;\u0026nbsp;otlp\u0026nbsp;\u0026nbsp;\u003cbr\u003efa:fa-download):::receiver PRO1(memory_limiter\u003cbr\u003efa:fa-microchip):::processor PRO2(resourcedetection\u003cbr\u003efa:fa-microchip):::processor PRO3(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor EXP1(\u0026ensp;debug\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter EXP2(otlphttp\u003cbr\u003efa:fa-upload):::exporter EXP3(\u0026ensp;file\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter %% Links subID1:::sub-metrics subgraph \" \" subgraph subID1[**Metrics**] direction LR REC1 --\u003e PRO1 PRO1 --\u003e PRO2 PRO2 --\u003e PRO3 PRO3 --\u003e EXP1 PRO3 --\u003e EXP3 PRO3 --\u003e EXP2 end end classDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff; classDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff; classDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff; classDef sub-metrics stroke:#38bdf8,stroke-width:1px, color:#38bdf8,stroke-dasharray: 3 3;",
    "description": "この演習では、agent.yaml ファイルの extensions: セクションを更新します。このセクションは OpenTelemetry 設定 YAML の一部であり、OpenTelemetry Collector の動作を拡張または変更するオプションのコンポーネントを定義します。\nこれらのコンポーネントはテレメトリーデータを直接処理しませんが、Collector の機能を向上させる貴重な機能とサービスを提供します。\nExercise 重要 すべての ターミナルウィンドウを 2-building-resilience ディレクトリに移動し、clear コマンドを実行してください。\nディレクトリ構造は以下のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml agent.yaml の更新: Agent ターミナル ウィンドウで、既存の health_check Extension の下に file_storage Extension を追加します\nfile_storage/checkpoint: # Extension Type/Name directory: \"./checkpoint-dir\" # Define directory create_directory: true # Create directory timeout: 1s # Timeout for file operations compaction: # Compaction settings on_start: true # Start compaction at Collector startup # Define compaction directory directory: \"./checkpoint-dir/tmp\" max_transaction_size: 65536 # Max. size limit before compaction occurs Exporter への file_storage の追加: otlphttp Exporter を変更して、リトライとキューイングメカニズムを設定し、障害が発生した場合にデータが保持され再送信されるようにします。endpoint: \"http://localhost:5318\" の下に以下を追加し、インデントが endpoint と一致していることを確認してください",
    "tags": [],
    "title": "2.1 File Storage の設定",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/2-building-resilience/2-1-configuration/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 2. Extensions",
    "content": "Health Check 拡張機能は、インストール手順で参照した同じ config.yaml ファイルで設定します。config.yaml ファイルを編集して拡張機能を設定しましょう。pprof と zpages 拡張機能はデフォルトの config.yaml ファイルに既に設定されていることに注意してください。このワークショップでは、Collector のヘルス状態にアクセスできるよう、すべてのネットワークインターフェースでポートを公開するように health_check 拡張機能のみを更新します。\n​ Command sudo vi /etc/otelcol-contrib/config.yaml ​ Extensions Configuration extensions: health_check: endpoint: 0.0.0.0:13133 Collector を起動します\n​ Command otelcol-contrib --config=file:/etc/otelcol-contrib/config.yaml この拡張機能により、OpenTelemetry Collector のステータスを確認するためにプローブできる HTTP URL が有効になります。この拡張機能は、Kubernetes で liveness プローブや readiness プローブとして使用できます。curl コマンドについて詳しく知るには、curl man page を確認してください。\n新しいターミナルセッションを開き、インスタンスに SSH 接続して以下のコマンドを実行します\n​ curl Command curl Output curl http://localhost:13133 {\"status\":\"Server available\",\"upSince\":\"2024-10-07T11:00:08.004685295+01:00\",\"uptime\":\"12.56420005s\"}",
    "description": "Health Check 拡張機能は、インストール手順で参照した同じ config.yaml ファイルで設定します。config.yaml ファイルを編集して拡張機能を設定しましょう。pprof と zpages 拡張機能はデフォルトの config.yaml ファイルに既に設定されていることに注意してください。このワークショップでは、Collector のヘルス状態にアクセスできるよう、すべてのネットワークインターフェースでポートを公開するように health_check 拡張機能のみを更新します。\n​ Command sudo vi /etc/otelcol-contrib/config.yaml ​ Extensions Configuration extensions: health_check: endpoint: 0.0.0.0:13133 Collector を起動します\n​ Command otelcol-contrib --config=file:/etc/otelcol-contrib/config.yaml この拡張機能により、OpenTelemetry Collector のステータスを確認するためにプローブできる HTTP URL が有効になります。この拡張機能は、Kubernetes で liveness プローブや readiness プローブとして使用できます。curl コマンドについて詳しく知るには、curl man page を確認してください。",
    "tags": [],
    "title": "OpenTelemetry Collector Extensions",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/2-extensions/1-health/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 2. エクステンション",
    "content": "Health Check エクステンション 他のコンポーネントと同様に、エクステンションは config.yaml ファイルで設定できます。ここでは実際に config.yaml ファイルを編集して、エクステンションを設定していきましょう。デフォルトの config.yaml では、すでに pprof エクステンションと zpages エクステンションが設定されていることを確認してみてください。このワークショップでは、設定ファイルをアップデートして health_check エクステンションを追加し、ポートを解放し、外部ネットワークからコレクターのヘルスチェックにアクセスできるようにしていきます。\n​ Command sudo vi /etc/otelcol-contrib/config.yaml ​ Extensions Configuration extensions: health_check: endpoint: 0.0.0.0:13133 コレクターを起動します:\n​ Command sudo systemctl restart otelcol-contrib このエクステンションは HTTP の URL を公開し、OpenTelemetry Collector の稼働状況をチェックするプローブを提供します。このエクステンションは Kubernetes 環境での Liveness/Readiness プローブとしても使われています。 curl コマンドの使い方は、curl man page を参照してください。\n次のコマンドを実行します:\n​ curl Command curl Output curl http://localhost:13133 {\"status\":\"Server available\",\"upSince\":\"2023-04-27T10:11:22.153295874+01:00\",\"uptime\":\"16m24.684476004s\"}",
    "description": "Health Check エクステンション 他のコンポーネントと同様に、エクステンションは config.yaml ファイルで設定できます。ここでは実際に config.yaml ファイルを編集して、エクステンションを設定していきましょう。デフォルトの config.yaml では、すでに pprof エクステンションと zpages エクステンションが設定されていることを確認してみてください。このワークショップでは、設定ファイルをアップデートして health_check エクステンションを追加し、ポートを解放し、外部ネットワークからコレクターのヘルスチェックにアクセスできるようにしていきます。\n​ Command sudo vi /etc/otelcol-contrib/config.yaml ​ Extensions Configuration extensions: health_check: endpoint: 0.0.0.0:13133 コレクターを起動します:\n​ Command sudo systemctl restart otelcol-contrib このエクステンションは HTTP の URL を公開し、OpenTelemetry Collector の稼働状況をチェックするプローブを提供します。このエクステンションは Kubernetes 環境での Liveness/Readiness プローブとしても使われています。 curl コマンドの使い方は、curl man page を参照してください。",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/2-extensions/1-health/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 3. Spanのドロップ",
    "content": "Exercise Gateway terminal ウィンドウに切り替えて、gateway.yaml ファイルを開きます。以下の設定で processors セクションを更新します\nfilter プロセッサを追加する /_healthz という名前のSpanを除外するようにGatewayを設定します。error_mode: ignore ディレクティブは、フィルタリング中に発生したエラーを無視し、パイプラインがスムーズに動作し続けることを保証します。traces セクションはフィルタリングルールを定義し、/_healthz という名前のSpanを除外対象として指定します。\nfilter/health: # Defines a filter processor error_mode: ignore # Ignore errors traces: # Filtering rules for traces span: # Exclude spans named \"/_healthz\" - 'name == \"/_healthz\"' traces パイプラインに filter プロセッサを追加する traces パイプラインに filter/health プロセッサを追加します。最適なパフォーマンスを得るために、フィルターはできるだけ早い段階に配置します。memory_limiter の直後、batch プロセッサの前に配置してください。設定は次のようになります\ntraces: receivers: - otlp processors: - memory_limiter - filter/health # Filters data based on rules - resource/add_mode - batch exporters: - debug - file/traces この設定により、ヘルスチェック関連のSpan（/_healthz）がパイプラインの早い段階でフィルタリングされ、テレメトリーデータの不要なノイズが削減されます。\notelbin.io を使用してAgent設定を検証します。参考として、パイプラインの traces: セクションは次のようになります\n%%{init:{\"fontFamily\":\"monospace\"}}%% graph LR %% Nodes REC1(\u0026nbsp;\u0026nbsp;otlp\u0026nbsp;\u0026nbsp;\u003cbr\u003efa:fa-download):::receiver PRO1(memory_limiter\u003cbr\u003efa:fa-microchip):::processor PRO3(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO4(filter\u003cbr\u003efa:fa-microchip\u003cbr\u003ehealth):::processor PRO5(batch\u003cbr\u003efa:fa-microchip):::processor EXP1(\u0026ensp;debug\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter EXP2(\u0026ensp;\u0026ensp;file\u0026ensp;\u0026ensp;\u003cbr\u003efa:fa-upload\u003cbr\u003etraces):::exporter %% Links subID1:::sub-traces subgraph \" \" subgraph subID1[**Traces**] direction LR REC1 --\u003e PRO1 PRO1 --\u003e PRO4 PRO4 --\u003e PRO3 PRO3 --\u003e PRO5 PRO5 --\u003e EXP1 PRO5 --\u003e EXP2 end end classDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff; classDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff; classDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff; classDef sub-traces stroke:#fbbf24,stroke-width:1px, color:#fbbf24,stroke-dasharray: 3 3;",
    "description": "Exercise Gateway terminal ウィンドウに切り替えて、gateway.yaml ファイルを開きます。以下の設定で processors セクションを更新します\nfilter プロセッサを追加する /_healthz という名前のSpanを除外するようにGatewayを設定します。error_mode: ignore ディレクティブは、フィルタリング中に発生したエラーを無視し、パイプラインがスムーズに動作し続けることを保証します。traces セクションはフィルタリングルールを定義し、/_healthz という名前のSpanを除外対象として指定します。\nfilter/health: # Defines a filter processor error_mode: ignore # Ignore errors traces: # Filtering rules for traces span: # Exclude spans named \"/_healthz\" - 'name == \"/_healthz\"' traces パイプラインに filter プロセッサを追加する traces パイプラインに filter/health プロセッサを追加します。最適なパフォーマンスを得るために、フィルターはできるだけ早い段階に配置します。memory_limiter の直後、batch プロセッサの前に配置してください。設定は次のようになります\ntraces: receivers: - otlp processors: - memory_limiter - filter/health # Filters data based on rules - resource/add_mode - batch exporters: - debug - file/traces この設定により、ヘルスチェック関連のSpan（/_healthz）がパイプラインの早い段階でフィルタリングされ、テレメトリーデータの不要なノイズが削減されます。",
    "tags": [],
    "title": "3.1 設定",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/3-dropping-spans/3-1-configuration/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 4. Processors",
    "content": "Batch Processor デフォルトでは、batch processor のみが有効になっています。この processor は、データをエクスポートする前にバッチ処理するために使用されます。これは、exporter へのネットワーク呼び出しの回数を減らすのに役立ちます。このワークショップでは、Collector にハードコードされている以下のデフォルト値を継承します\nsend_batch_size（デフォルト = 8192）：タイムアウトに関係なくバッチが送信されるスパン、メトリクスデータポイント、またはログレコードの数。send_batch_size はトリガーとして機能し、バッチのサイズには影響しません。パイプラインの次のコンポーネントに送信されるバッチサイズの制限を強制する必要がある場合は、send_batch_max_size を参照してください。 timeout（デフォルト = 200ms）：サイズに関係なくバッチが送信されるまでの時間。ゼロに設定すると、send_batch_max_size のみに従ってデータが即座に送信されるため、send_batch_size は無視されます。 send_batch_max_size（デフォルト = 0）：バッチサイズの上限。0 はバッチサイズに上限がないことを意味します。このプロパティは、大きなバッチを小さな単位に分割することを保証します。send_batch_size 以上である必要があります。 Batch processor の詳細については、Batch Processor のドキュメントを参照してください。",
    "description": "Batch Processor デフォルトでは、batch processor のみが有効になっています。この processor は、データをエクスポートする前にバッチ処理するために使用されます。これは、exporter へのネットワーク呼び出しの回数を減らすのに役立ちます。このワークショップでは、Collector にハードコードされている以下のデフォルト値を継承します\nsend_batch_size（デフォルト = 8192）：タイムアウトに関係なくバッチが送信されるスパン、メトリクスデータポイント、またはログレコードの数。send_batch_size はトリガーとして機能し、バッチのサイズには影響しません。パイプラインの次のコンポーネントに送信されるバッチサイズの制限を強制する必要がある場合は、send_batch_max_size を参照してください。 timeout（デフォルト = 200ms）：サイズに関係なくバッチが送信されるまでの時間。ゼロに設定すると、send_batch_max_size のみに従ってデータが即座に送信されるため、send_batch_size は無視されます。 send_batch_max_size（デフォルト = 0）：バッチサイズの上限。0 はバッチサイズに上限がないことを意味します。このプロパティは、大きなバッチを小さな単位に分割することを保証します。send_batch_size 以上である必要があります。 Batch processor の詳細については、Batch Processor のドキュメントを参照してください。",
    "tags": [],
    "title": "OpenTelemetry Collector Processors",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/4-processors/1-batch-processor/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 4. プロセッサー",
    "content": "Batch プロセッサー デフォルトでは、batch プロセッサーだけが有効になっています。このプロセッサーは、データをエクスポートする前にバッチ処理して、エクスポーターへのネットワーク・コールの回数を減らすために使われます。このワークショップではデフォルトの設定を使用します：\nsend_batch_size (デフォルト = 8192): タイムアウトに関係なく、バッチを送信するスパン、メトリクスデータポイント、またはログレコードの数。パイプラインの次のコンポーネントに送信されるバッチサイズを制限する場合には、 send_batch_max_size を使います。 timeout (デフォルト = 200ms): サイズに関係なく、バッチが送信されるまでの時間。ゼロに設定すると、send_batch_size の設定を無視して send_batch_max_size だけが適用され、データは直ちに送信されます。 send_batch_max_size (デフォルト = 0): バッチサイズの上限。0 を設定すると、バッチサイズの上限がないことして扱われます。この設定は、大きなバッチが小さなユニットに分割されることを保証します。send_batch_size 以上でなければななりません。",
    "description": "Batch プロセッサー デフォルトでは、batch プロセッサーだけが有効になっています。このプロセッサーは、データをエクスポートする前にバッチ処理して、エクスポーターへのネットワーク・コールの回数を減らすために使われます。このワークショップではデフォルトの設定を使用します：\nsend_batch_size (デフォルト = 8192): タイムアウトに関係なく、バッチを送信するスパン、メトリクスデータポイント、またはログレコードの数。パイプラインの次のコンポーネントに送信されるバッチサイズを制限する場合には、 send_batch_max_size を使います。 timeout (デフォルト = 200ms): サイズに関係なく、バッチが送信されるまでの時間。ゼロに設定すると、send_batch_size の設定を無視して send_batch_max_size だけが適用され、データは直ちに送信されます。 send_batch_max_size (デフォルト = 0): バッチサイズの上限。0 を設定すると、バッチサイズの上限がないことして扱われます。この設定は、大きなバッチが小さなユニットに分割されることを保証します。send_batch_size 以上でなければななりません。",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/4-processors/1-batch-processor/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 4. 機密データ",
    "content": "このステップでは、agent.yaml を修正して attributes と redaction プロセッサを追加します。これらのプロセッサは、Span属性内の機密データがログに記録またはエクスポートされる前に適切に処理されるようにします。\n以前、コンソールに表示されたSpan属性の一部に個人情報や機密データが含まれていることに気づいたかもしれません。これから、この情報を効果的にフィルタリングおよび秘匿化するために必要なプロセッサを設定します。\nAttributes: -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(+1555-867-5309) -\u003e user.email: Str(george@deathstar.email) -\u003e user.account_password: Str(LOTR\u003eStarWars1-2-3) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) {\"kind\": \"exporter\", \"data_type\": \"traces\", \"name\": \"debug\"} Exercise Agent terminal ウィンドウに切り替えて、エディタで agent.yaml ファイルを開きます。テレメトリーデータのセキュリティとプライバシーを強化するために、2つのプロセッサを追加します。\n1. attributes プロセッサを追加する：Attributes Processor を使用すると、Span属性（タグ）の値を更新、削除、またはハッシュ化して変更できます。これは、機密情報をエクスポートする前に難読化する場合に特に便利です。\nこのステップでは\nuser.phone_number 属性を静的な値（\"UNKNOWN NUMBER\"）に更新します。 user.email 属性をハッシュ化して、元のメールアドレスが公開されないようにします。 user.password 属性を削除して、Spanから完全に取り除きます。 attributes/update: actions: # Actions - key: user.phone_number # Target key action: update # Update action value: \"UNKNOWN NUMBER\" # New value - key: user.email # Target key action: hash # Hash the email value - key: user.password # Target key action: delete # Delete the password 2. redaction プロセッサを追加する：Redaction Processor は、クレジットカード番号やその他の個人識別情報（PII）などの定義済みパターンに基づいて、Span属性内の機密データを検出して秘匿化します。\nこのステップでは\nすべての属性が処理されるように allow_all_keys: true を設定します（false に設定すると、明示的に許可されたキーのみが保持されます）。\nVisa と MasterCard のクレジットカード番号を検出して秘匿化するための正規表現を blocked_values で定義します。\nsummary: debug オプションは、デバッグ目的で秘匿化プロセスに関する詳細情報をログに記録します。\nredaction/redact: allow_all_keys: true # If false, only allowed keys will be retained blocked_values: # List of regex patterns to block - '\\b4[0-9]{3}[\\s-]?[0-9]{4}[\\s-]?[0-9]{4}[\\s-]?[0-9]{4}\\b' # Visa - '\\b5[1-5][0-9]{2}[\\s-]?[0-9]{4}[\\s-]?[0-9]{4}[\\s-]?[0-9]{4}\\b' # MasterCard summary: debug # Show debug details about redaction traces パイプラインを更新する：両方のプロセッサを traces パイプラインに統合します。最初は redaction プロセッサをコメントアウトしておいてください（後の演習で有効にします）。設定は次のようになります\ntraces: receivers: - otlp processors: - memory_limiter - attributes/update # Update, hash, and remove attributes #- redaction/redact # Redact sensitive fields using regex - resourcedetection - resource/add_mode - batch exporters: - debug - file - otlphttp otelbin.io を使用してAgent設定を検証します。参考として、パイプラインの traces: セクションは次のようになります\n%%{init:{\"fontFamily\":\"monospace\"}}%% graph LR %% Nodes REC1(\u0026nbsp;\u0026nbsp;otlp\u0026nbsp;\u0026nbsp;\u003cbr\u003efa:fa-download):::receiver PRML(memory_limiter\u003cbr\u003efa:fa-microchip):::processor PRRD(resourcedetection\u003cbr\u003efa:fa-microchip):::processor PRRS(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRUP(attributes\u003cbr\u003efa:fa-microchip\u003cbr\u003eupdate):::processor EXP1(otlphttp\u003cbr\u003efa:fa-upload):::exporter EXP2(\u0026ensp;\u0026ensp;debug\u0026ensp;\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter EXP3(file\u003cbr\u003efa:fa-upload):::exporter %% Links subID1:::sub-traces subgraph \" \" subgraph subID1[**Traces**] direction LR REC1 --\u003e PRML PRML --\u003e PRUP PRUP --\u003e PRRD PRRD --\u003e PRRS PRRS --\u003e EXP2 PRRS --\u003e EXP3 PRRS --\u003e EXP1 end end classDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff; classDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff; classDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff; classDef sub-traces stroke:#fbbf24,stroke-width:1px, color:#fbbf24,stroke-dasharray: 3 3;",
    "description": "このステップでは、agent.yaml を修正して attributes と redaction プロセッサを追加します。これらのプロセッサは、Span属性内の機密データがログに記録またはエクスポートされる前に適切に処理されるようにします。\n以前、コンソールに表示されたSpan属性の一部に個人情報や機密データが含まれていることに気づいたかもしれません。これから、この情報を効果的にフィルタリングおよび秘匿化するために必要なプロセッサを設定します。\nAttributes: -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(+1555-867-5309) -\u003e user.email: Str(george@deathstar.email) -\u003e user.account_password: Str(LOTR\u003eStarWars1-2-3) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) {\"kind\": \"exporter\", \"data_type\": \"traces\", \"name\": \"debug\"} Exercise Agent terminal ウィンドウに切り替えて、エディタで agent.yaml ファイルを開きます。テレメトリーデータのセキュリティとプライバシーを強化するために、2つのプロセッサを追加します。\n1. attributes プロセッサを追加する：Attributes Processor を使用すると、Span属性（タグ）の値を更新、削除、またはハッシュ化して変更できます。これは、機密情報をエクスポートする前に難読化する場合に特に便利です。",
    "tags": [],
    "title": "4.1 設定",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/4-sensitive-data/4-1-configuration/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 5. Transform Data",
    "content": "Exercise transform プロセッサーを追加する: Gateway terminal ウィンドウに切り替え、gateway.yaml を編集して次の transform プロセッサーを追加します\ntransform/logs: # Processor Type/Name log_statements: # Log Processing Statements - context: resource # Log Context statements: # List of attribute keys to keep - keep_keys(attributes, [\"com.splunk.sourcetype\", \"host.name\", \"otelcol.service.mode\"]) -context: resource キーを使用することで、ログの resourceLog 属性をターゲットにしています。\nこの設定により、関連するリソース属性（com.splunk.sourcetype、host.name、otelcol.service.mode）のみが保持され、ログの効率が向上し、不要なメタデータが削減されます。\nログ重大度マッピング用のコンテキストブロックを追加する: ログレコードの severity_text と severity_number フィールドを適切に設定するために、log_statements 内に log コンテキストブロックを追加します。この設定では、ログ本文から level 値を抽出し、severity_text にマッピングし、ログレベルに基づいて対応する severity_number を割り当てます\n- context: log # Log Context statements: # Transform Statements Array - set(cache, ParseJSON(body)) where IsMatch(body, \"^\\\\{\") # Parse JSON log body into a cache object - flatten(cache, \"\") # Flatten nested JSON structure - merge_maps(attributes, cache, \"upsert\") # Merge cache into attributes, updating existing keys - set(severity_text, attributes[\"level\"]) # Set severity_text from the \"level\" attribute - set(severity_number, 1) where severity_text == \"TRACE\" # Map severity_text to severity_number - set(severity_number, 5) where severity_text == \"DEBUG\" - set(severity_number, 9) where severity_text == \"INFO\" - set(severity_number, 13) where severity_text == \"WARN\" - set(severity_number, 17) where severity_text == \"ERROR\" - set(severity_number, 21) where severity_text == \"FATAL\" merge_maps 関数は、2つのマップ（辞書）を1つに結合するために使用されます。この場合、cache オブジェクト（ログ本文からパースされたJSONデータを含む）を attributes マップにマージします。\nパラメータ: attributes: データがマージされるターゲットマップ cache: パースされたJSONデータを含むソースマップ \"upsert\": このモードは、attributes マップにすでにキーが存在する場合、その値が cache の値で更新されることを保証します。キーが存在しない場合は、挿入されます。 このステップは、ログ本文からのすべての関連フィールド（例：level、message など）が attributes マップに追加され、さらなる処理やエクスポートで利用可能になることを保証するため、非常に重要です。\n主要な変換の概要:\nParse JSON: ログ本文から構造化データを抽出します。 Flatten JSON: ネストされたJSONオブジェクトをフラットな構造に変換します。 Merge Attributes: 抽出されたデータをログ属性に統合します。 Map Severity Text: ログの level 属性から severity_text を割り当てます。 Assign Severity Numbers: 重大度レベルを標準化された数値に変換します。 重要 resource 用のコンテキストブロックと log 用のコンテキストブロックの2つを含む 単一の transform プロセッサーが必要です。\nこの設定により、ログの重大度が正しく抽出、標準化され、効率的な処理のために構造化されます。\nTip すべてのJSONフィールドをトップレベルの属性にマッピングするこの方法は、OTTLのテストとデバッグのみに使用してください。本番環境では高いカーディナリティが発生します。\nlogs パイプラインを更新する: logs: パイプラインに transform/logs: プロセッサーを追加し、設定が次のようになるようにします\nlogs: # Logs pipeline receivers: - otlp # OTLP receiver processors: # Processors for logs - memory_limiter - resource/add_mode - transform/logs - batch exporters: - debug # Debug exporter - file/logs https://otelbin.io を使用して Agent の設定を検証します。参考として、パイプラインの logs: セクションは次のようになります\n%%{init:{\"fontFamily\":\"monospace\"}}%%\rgraph LR\r%% Nodes\rREC1(\u0026nbsp;\u0026nbsp;otlp\u0026nbsp;\u0026nbsp;\u003cbr\u003efa:fa-download):::receiver\rPRO1(memory_limiter\u003cbr\u003efa:fa-microchip):::processor\rPRO3(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor\rPRO4(transform\u003cbr\u003efa:fa-microchip\u003cbr\u003elogs):::processor\rPRO5(batch\u003cbr\u003efa:fa-microchip):::processor\rEXP1(file\u003cbr\u003efa:fa-upload\u003cbr\u003elogs):::exporter\rEXP2(\u0026ensp;\u0026ensp;debug\u0026ensp;\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter\r%% Links\rsubID1:::sub-logs\rsubgraph \" \"\rsubgraph subID1[**Logs**]\rdirection LR\rREC1 --\u003e PRO1\rPRO1 --\u003e PRO3\rPRO3 --\u003e PRO4\rPRO4 --\u003e PRO5\rPRO5 --\u003e EXP2\rPRO5 --\u003e EXP1\rend\rend\rclassDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff;\rclassDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff;\rclassDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff;\rclassDef sub-logs stroke:#34d399,stroke-width:1px, color:#34d399,stroke-dasharray: 3 3;",
    "description": "Exercise transform プロセッサーを追加する: Gateway terminal ウィンドウに切り替え、gateway.yaml を編集して次の transform プロセッサーを追加します\ntransform/logs: # Processor Type/Name log_statements: # Log Processing Statements - context: resource # Log Context statements: # List of attribute keys to keep - keep_keys(attributes, [\"com.splunk.sourcetype\", \"host.name\", \"otelcol.service.mode\"]) -context: resource キーを使用することで、ログの resourceLog 属性をターゲットにしています。\nこの設定により、関連するリソース属性（com.splunk.sourcetype、host.name、otelcol.service.mode）のみが保持され、ログの効率が向上し、不要なメタデータが削減されます。\nログ重大度マッピング用のコンテキストブロックを追加する: ログレコードの severity_text と severity_number フィールドを適切に設定するために、log_statements 内に log コンテキストブロックを追加します。この設定では、ログ本文から level 値を抽出し、severity_text にマッピングし、ログレベルに基づいて対応する severity_number を割り当てます\n- context: log # Log Context statements: # Transform Statements Array - set(cache, ParseJSON(body)) where IsMatch(body, \"^\\\\{\") # Parse JSON log body into a cache object - flatten(cache, \"\") # Flatten nested JSON structure - merge_maps(attributes, cache, \"upsert\") # Merge cache into attributes, updating existing keys - set(severity_text, attributes[\"level\"]) # Set severity_text from the \"level\" attribute - set(severity_number, 1) where severity_text == \"TRACE\" # Map severity_text to severity_number - set(severity_number, 5) where severity_text == \"DEBUG\" - set(severity_number, 9) where severity_text == \"INFO\" - set(severity_number, 13) where severity_text == \"WARN\" - set(severity_number, 17) where severity_text == \"ERROR\" - set(severity_number, 21) where severity_text == \"FATAL\" merge_maps 関数は、2つのマップ（辞書）を1つに結合するために使用されます。この場合、cache オブジェクト（ログ本文からパースされたJSONデータを含む）を attributes マップにマージします。",
    "tags": [],
    "title": "5.1 Configuration",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/5-transform-data/5-1-configuration/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 5. Exporters",
    "content": "OTLP HTTP Exporter HTTP 経由で Splunk Observability Cloud にメトリクスを送信するには、otlphttp exporter を設定する必要があります。\n/etc/otelcol-contrib/config.yaml ファイルを編集して、otlphttp exporter を設定しましょう。以下の YAML を exporters セクションの下に挿入してください。インデントは2スペースで行ってください。\nまた、ディスクがいっぱいにならないように、logging exporter の詳細度を変更します。デフォルトの detailed は非常に冗長です。\nexporters: logging: verbosity: normal otlphttp/splunk: 次に、metrics_endpoint を定義してターゲット URL を設定する必要があります。\nメモ Splunk 主催のワークショップに参加されている場合、使用しているインスタンスにはすでに Realm 環境変数が設定されています。設定ファイルでその環境変数を参照します。それ以外の場合は、新しい環境変数を作成して Realm を設定する必要があります。例\nexport REALM=\"us1\" 使用する URL は https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp です。（Splunk は、データレジデンシーのために世界中の主要な地理的場所に Realm を持っています）。\notlphttp exporter は、traces_endpoint と logs_endpoint のターゲット URL を定義することで、トレースとログを送信するように設定することもできます。これらの設定は、このワークショップの範囲外です。\nexporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp デフォルトでは、すべてのエンドポイントで gzip 圧縮が有効になっています。これは、exporter 設定で compression: none を設定することで無効にできます。このワークショップでは、データを送信する最も効率的な方法であるため、圧縮を有効のままにしてデフォルトを使用します。\nSplunk Observability Cloud にメトリクスを送信するには、アクセストークンを使用する必要があります。これは、Splunk Observability Cloud UI で新しいトークンを作成することで行えます。トークンの作成方法の詳細については、Create a token を参照してください。トークンは INGEST タイプである必要があります。\nメモ Splunk 主催のワークショップに参加されている場合、使用しているインスタンスにはすでにアクセストークンが設定されています（環境変数として設定されています）。設定ファイルでその環境変数を参照します。それ以外の場合は、新しいトークンを作成して環境変数として設定する必要があります。例\nexport ACCESS_TOKEN=\u003creplace-with-your-token\u003e トークンは、headers: セクションの下に X-SF-TOKEN: ${env:ACCESS_TOKEN} を挿入することで設定ファイルに定義されます\nexporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-TOKEN: ${env:ACCESS_TOKEN} 設定の確認 Exporter について説明したので、設定の変更を確認しましょう\nCheck-inReview your configuration ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 # To limit exposure to denial of service attacks, change the host in endpoints below from 0.0.0.0 to a specific network interface. # See https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md#safeguards-against-denial-of-service-attacks extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 opencensus: endpoint: 0.0.0.0:55678 # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_binary: endpoint: 0.0.0.0:6832 thrift_compact: endpoint: 0.0.0.0:6831 thrift_http: endpoint: 0.0.0.0:14268 zipkin: endpoint: 0.0.0.0:9411 processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: debug: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-Token: ${env:ACCESS_TOKEN} service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [debug] logs: receivers: [otlp] processors: [batch] exporters: [debug] extensions: [health_check, pprof, zpages] もちろん、OTLP プロトコルをサポートする他のソリューションを指すように metrics_endpoint を簡単に設定できます。\n次に、config.yaml の service セクションで、設定した receivers、processors、exporters を有効にする必要があります。",
    "description": "OTLP HTTP Exporter HTTP 経由で Splunk Observability Cloud にメトリクスを送信するには、otlphttp exporter を設定する必要があります。\n/etc/otelcol-contrib/config.yaml ファイルを編集して、otlphttp exporter を設定しましょう。以下の YAML を exporters セクションの下に挿入してください。インデントは2スペースで行ってください。\nまた、ディスクがいっぱいにならないように、logging exporter の詳細度を変更します。デフォルトの detailed は非常に冗長です。\nexporters: logging: verbosity: normal otlphttp/splunk: 次に、metrics_endpoint を定義してターゲット URL を設定する必要があります。\nメモ Splunk 主催のワークショップに参加されている場合、使用しているインスタンスにはすでに Realm 環境変数が設定されています。設定ファイルでその環境変数を参照します。それ以外の場合は、新しい環境変数を作成して Realm を設定する必要があります。例\nexport REALM=\"us1\" 使用する URL は https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp です。（Splunk は、データレジデンシーのために世界中の主要な地理的場所に Realm を持っています）。",
    "tags": [],
    "title": "OpenTelemetry Collector Exporters",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/5-exporters/1-otlphttp/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 5. エクスポーター",
    "content": "OTLP HTTP エクスポーター Splunk Observability Cloud へ HTTP 経由でメトリックスを送信するためには、otlphttp エクスポーターを設定する必要があります。\n/etc/otelcol-contrib/config.yaml ファイルを編集し、otlphttp エクスポーターを設定しましょう。以下の YAML を exporters セクションの下に挿入し、例えば2スペースでインデントしてください。\nまた、ディスクの容量不足を防ぐために、ロギングエクスポーターの詳細度を変更します。デフォルトの detailed は非常に詳細です。\nexporters: logging: verbosity: normal otlphttp/splunk: 次に、metrics_endpoint を定義して、ターゲットURLを設定していきます。\nメモ Splunk 主催のワークショップの参加者である場合、使用しているインスタンスにはすでに Realm 環境変数が設定されています。その環境変数を設定ファイルで参照します。それ以外の場合は、新しい環境変数を作成して Realm を設定する必要があります。例えば：\nexport REALM=\"us1\" 使用するURLは https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp です。（Splunkは、データの居住地に応じて世界中の主要地域に Realm を持っています）。\notlphttp エクスポーターは、traces_endpoint と logs_endpoint それぞれのターゲットURLを定義することにより、トレースとログを送信するようにも設定できますが、そのような設定はこのワークショップの範囲外とします。\nexporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp デフォルトでは、すべてのエンドポイントで gzip 圧縮が有効になっています。エクスポーターの設定で compression: none を設定することにより、圧縮を無効にすることができます。このワークショップでは圧縮を有効にしたままにし、データを送信する最も効率的な方法としてデフォルト設定を使っていきます。\nSplunk Observability Cloud にメトリクスを送信するためには、アクセストークンを使用する必要があります。これは、Splunk Observability Cloud UI で新しいトークンを作成することにより行うことができます。トークンの作成方法についての詳細は、Create a token を参照してください。トークンは INGEST タイプである必要があります。\nメモ Splunk　主催のワークショップの参加者である場合、使用しているインスタンスにはすでにアクセストークンが設定されています（環境変数として設定されています）ので、その環境変数を設定ファイルで参照します。それ以外の場合は、新しいトークンを作成し、それを環境変数として設定する必要があります。例えば：\nexport ACCESS_TOKEN=\u003creplace-with-your-token\u003e トークンは、設定ファイル内で headers: セクションの下に X-SF-TOKEN: ${env:ACCESS_TOKEN} を挿入することにで定義します：\nexporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-TOKEN: ${env:ACCESS_TOKEN} 設定を確認しましょう これで、エクスポーターもカバーできました。設定を確認していきましょう：\nCheck-in設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-TOKEN: ${env:ACCESS_TOKEN} service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] もちろん、OTLP プロトコルをサポートする他のソリューションを指すように metrics_endpoint を簡単に設定することができます。\n次に、config.yaml のサービスセクションで、今設定したレシーバー、プロセッサー、エクスポーターを有効にしていきます。",
    "description": "OTLP HTTP エクスポーター Splunk Observability Cloud へ HTTP 経由でメトリックスを送信するためには、otlphttp エクスポーターを設定する必要があります。\n/etc/otelcol-contrib/config.yaml ファイルを編集し、otlphttp エクスポーターを設定しましょう。以下の YAML を exporters セクションの下に挿入し、例えば2スペースでインデントしてください。\nまた、ディスクの容量不足を防ぐために、ロギングエクスポーターの詳細度を変更します。デフォルトの detailed は非常に詳細です。\nexporters: logging: verbosity: normal otlphttp/splunk: 次に、metrics_endpoint を定義して、ターゲットURLを設定していきます。\nメモ Splunk 主催のワークショップの参加者である場合、使用しているインスタンスにはすでに Realm 環境変数が設定されています。その環境変数を設定ファイルで参照します。それ以外の場合は、新しい環境変数を作成して Realm を設定する必要があります。例えば：\nexport REALM=\"us1\" 使用するURLは https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp です。（Splunkは、データの居住地に応じて世界中の主要地域に Realm を持っています）。\notlphttp エクスポーターは、traces_endpoint と logs_endpoint それぞれのターゲットURLを定義することにより、トレースとログを送信するようにも設定できますが、そのような設定はこのワークショップの範囲外とします。",
    "tags": [],
    "title": "OpenTelemetry Collector エクスポーター",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/5-exporters/otlphttp/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 6. Service",
    "content": "Hostmetrics Receiver ワークショップの Receivers セクションで、さまざまなソースからスクレイプされるホストシステムに関するメトリクスを生成する Host Metrics Receiver を定義したことを思い出してください。この receiver を有効にするには、metrics パイプラインに hostmetrics receiver を含める必要があります。\nmetrics パイプラインで、metrics の receivers セクションに hostmetrics を追加します。\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus] processors: [batch] exporters: [debug]",
    "description": "Hostmetrics Receiver ワークショップの Receivers セクションで、さまざまなソースからスクレイプされるホストシステムに関するメトリクスを生成する Host Metrics Receiver を定義したことを思い出してください。この receiver を有効にするには、metrics パイプラインに hostmetrics receiver を含める必要があります。\nmetrics パイプラインで、metrics の receivers セクションに hostmetrics を追加します。\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus] processors: [batch] exporters: [debug]",
    "tags": [],
    "title": "OpenTelemetry Collector Service",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/6-service/1-hostmetrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Hostmetrics レシーバー ワークショップのレシーバー部分で振り返ると、ホストシステムに関するメトリクスを生成するために、様々なソースからスクレイピングする Host Metrics レシーバーを定義しました。このレシーバーを有効にするためには、メトリクスパイプラインに hostmetrics レシーバーを含める必要があります。\nmetrics パイプラインで、メトリクスの receivers セクションに hostmetrics を追加します。\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus] processors: [batch] exporters: [logging]",
    "description": "Hostmetrics レシーバー ワークショップのレシーバー部分で振り返ると、ホストシステムに関するメトリクスを生成するために、様々なソースからスクレイピングする Host Metrics レシーバーを定義しました。このレシーバーを有効にするためには、メトリクスパイプラインに hostmetrics レシーバーを含める必要があります。\nmetrics パイプラインで、メトリクスの receivers セクションに hostmetrics を追加します。\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus] processors: [batch] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/6-service/1-hostmetrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 6. Routing Data",
    "content": "この演習では、gateway.yaml で Routing Connector を設定します。Routing Connector はメトリクス、トレース、ログを任意の属性に基づいてルーティングできますが、ここでは deployment.environment 属性に基づくトレースルーティングに焦点を当てます（ただし、任意のスパン/ログ/メトリクス属性を使用できます）。\nExercise 新しい file エクスポーターを追加する: routing コネクターには、ルーティング用に異なるターゲットが必要です。Gateway terminal で、gateway.yaml の exporters セクションに 2 つの新しいファイルエクスポーター file/traces/route1-regular と file/traces/route2-security を作成し、データが正しく振り分けられるようにします\nfile/traces/route1-regular: # Exporter for regular traces path: \"./gateway-traces-route1-regular.out\" # Path for saving trace data append: false # Overwrite the file each time file/traces/route2-security: # Exporter for security traces path: \"./gateway-traces-route2-security.out\" # Path for saving trace data append: false # Overwrite the file each time ルーティングを有効にする: routing コネクターを追加します。OpenTelemetry の設定ファイルでは、connectors はレシーバーやプロセッサーと同様に専用のセクションを持っています。\n#connectors: セクションを見つけてコメントを解除します。次に、connectors: セクションの下に以下を追加します\nrouting: default_pipelines: [traces/route1-regular] # Default pipeline if no rule matches error_mode: ignore # Ignore errors in routing table: # Define routing rules # Routes spans to a target pipeline if the resourceSpan attribute matches the rule - statement: route() where attributes[\"deployment.environment\"] == \"security-applications\" pipelines: [traces/route2-security] # Security target pipeline 設定ファイルのデフォルトパイプラインは、キャッチオールとして機能します。ルーティングルールテーブルのルールに一致しないすべてのデータ（この場合はスパン）のルーティング先となります。このテーブルには、[\"deployment.environment\"] == \"security-applications\" ルールに一致するスパンのターゲットパイプラインが定義されています。\nrouting の設定が完了したら、次のステップはこれらのルーティングルールを適用する pipelines を設定することです。",
    "description": "この演習では、gateway.yaml で Routing Connector を設定します。Routing Connector はメトリクス、トレース、ログを任意の属性に基づいてルーティングできますが、ここでは deployment.environment 属性に基づくトレースルーティングに焦点を当てます（ただし、任意のスパン/ログ/メトリクス属性を使用できます）。\nExercise 新しい file エクスポーターを追加する: routing コネクターには、ルーティング用に異なるターゲットが必要です。Gateway terminal で、gateway.yaml の exporters セクションに 2 つの新しいファイルエクスポーター file/traces/route1-regular と file/traces/route2-security を作成し、データが正しく振り分けられるようにします\nfile/traces/route1-regular: # Exporter for regular traces path: \"./gateway-traces-route1-regular.out\" # Path for saving trace data append: false # Overwrite the file each time file/traces/route2-security: # Exporter for security traces path: \"./gateway-traces-route2-security.out\" # Path for saving trace data append: false # Overwrite the file each time ルーティングを有効にする: routing コネクターを追加します。OpenTelemetry の設定ファイルでは、connectors はレシーバーやプロセッサーと同様に専用のセクションを持っています。",
    "tags": [],
    "title": "6.1 Configure the Routing Connector",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/6-routing-data/6-1-connector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 7. Count \u0026 Sum Connector",
    "content": "Exercise Gateway を起動する Gateway terminal ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent を起動する Agent terminal ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Loadgen で12行のログを送信する Spans terminal ウィンドウで、12行のログを送信します。これらは2つのインターバルで読み取られるはずです。以下の loadgen コマンドを実行してください\n​ Loadgen ../loadgen -logs -json -count 12 Agent と Gateway の両方がデバッグ情報を表示し、データを処理していることを示します。loadgen が完了するまで待ちます。\nメトリクスが生成されたことを確認する ログが処理されると、Agent がメトリクスを生成して Gateway に転送し、Gateway がそれらを gateway-metrics.out に書き込みます。\n出力に logs.full.count、logs.sw.count、logs.lotr.count、logs.error.count のメトリクスが含まれているか確認するには、以下の jq クエリを実行します\n​ jq query command jq example output jq '.resourceMetrics[].scopeMetrics[].metrics[] | select(.name == \"logs.full.count\" or .name == \"logs.sw.count\" or .name == \"logs.lotr.count\" or .name == \"logs.error.count\") | {name: .name, value: (.sum.dataPoints[0].asInt // \"-\")}' gateway-metrics.out { \"name\": \"logs.sw.count\", \"value\": \"2\" } { \"name\": \"logs.lotr.count\", \"value\": \"2\" } { \"name\": \"logs.full.count\", \"value\": \"4\" } { \"name\": \"logs.error.count\", \"value\": \"2\" } { \"name\": \"logs.error.count\", \"value\": \"1\" } { \"name\": \"logs.sw.count\", \"value\": \"2\" } { \"name\": \"logs.lotr.count\", \"value\": \"6\" } { \"name\": \"logs.full.count\", \"value\": \"8\" } Tip 注：logs.full.count は通常 logs.sw.count + logs.lotr.count と等しくなりますが、logs.error.count はランダムな数値になります。\n重要 それぞれのターミナルで Ctrl-C を押して Agent と Gateway のプロセスを停止してください。",
    "description": "Exercise Gateway を起動する Gateway terminal ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent を起動する Agent terminal ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Loadgen で12行のログを送信する Spans terminal ウィンドウで、12行のログを送信します。これらは2つのインターバルで読み取られるはずです。以下の loadgen コマンドを実行してください\n​ Loadgen ../loadgen -logs -json -count 12 Agent と Gateway の両方がデバッグ情報を表示し、データを処理していることを示します。loadgen が完了するまで待ちます。",
    "tags": [],
    "title": "7.1 Count Connector のテスト",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/7-sum-count/7-1-count-test/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ",
    "content": "このワークショップでは、Splunk Observability Cloud がフロントエンドアプリケーションからバックエンドサービスまで、ユーザー体験に関する即時の可視性をどのように提供するかをデモンストレーションします。他の可観測性ソリューションと一線を画す、プラットフォームの最も強力な機能をいくつか体験していただきます：\nインフラ監視（Infrastructure Monitoring, IM） 完全で忠実な Real User Monitoring（RUM） Application Performance Monitoring（APM）による End to End の NoSample で完全忠実なトレースの可視性 コード入力を必要としないログクエリ 外形監視・合成監視（Synthetic Monitoring） タグ分析とエラースタックによる根本原因分析 Related Contents によるコンポーネント間のシームレスなナビゲーション Splunk Observability Cloud のコアとなる強みの一つは、テレメトリデータを統合し、エンドユーザーエクスペリエンスとアプリケーションスタック全体の包括的な全体像を作成する能力です。\nこのワークショップでは、AWS EC2 インスタンス上にデプロイされたマイクロサービスベースの e コマースアプリケーションに焦点を当てます。ユーザーは商品を閲覧し、カートに商品を追加し、注文を完了できます。このアプリケーションは、詳細なパフォーマンスデータを取得するために OpenTelemetry で計装されています。\nOpenTelemetry とは？\nOpenTelemetry は、メトリクス、トレース、ログなどのテレメトリデータの計装、生成、収集、エクスポートを支援するために設計されたオープンソースのツール、API、ソフトウェア開発キット（SDK）のコレクションです。このデータにより、ソフトウェアのパフォーマンスと動作の詳細な分析が可能になります。\nOpenTelemetry コミュニティは急速に成長しており、Splunk、Google、Microsoft、Amazon などの大手企業からのサポートを受けています。現在、Cloud Native Computing Foundation において、Kubernetes に次いで 2 番目に多くのコントリビューターを抱えています。",
    "description": "このワークショップでは、Splunk Observability Cloudがフロントエンドアプリケーションからバックエンドサービスまで、ユーザー体験の視点からどのように即座に可視性を提供するかをお見せします - Splunk Observability Cloudの最も魅力的な機能と差別化要因を体験していただきます。",
    "tags": [],
    "title": "Observability Cloud",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ",
    "content": "概要 OpenTelemetry を始めたばかりの組織では、まずオブザーバビリティバックエンドに直接データを送信することから始めることが多いでしょう。これは初期テストには有効ですが、OpenTelemetry Collector をオブザーバビリティアーキテクチャの一部として使用することで多くのメリットがあり、本番環境へのデプロイには推奨されています。\nこのワークショップでは、OpenTelemetry Collector の使用に焦点を当て、Splunk Observability Cloud で使用するための Receiver、Processor、Exporter の設定の基本から始めます。参加者は初心者から、分散プラットフォームのビジネスオブザーバビリティニーズを解決するためのカスタムコンポーネントを追加できるレベルまで到達します。\nNinja セクション ワークショップを通じて、展開可能な Ninja セクション があります。これらはより実践的で、ワークショップ中または自分の時間に探求できる詳細な技術情報を提供します。\nOpenTelemetry プロジェクトは頻繁に開発が行われているため、これらのセクションの内容が古くなる可能性があることに注意してください。詳細が同期していない場合はリンクが提供されます。更新が必要な箇所を見つけた場合はお知らせください。\nNinja: テストしてみよう！ このワークショップを完了すると、正式に OpenTelemetry Collector Ninja になれます！\n対象者 このインタラクティブなワークショップは、OpenTelemetry Collector のアーキテクチャとデプロイについて詳しく学びたい開発者およびシステム管理者を対象としています。\n前提条件 データ収集の基本的な理解があること コマンドラインと vim/vi の経験があること Ubuntu 20.04 LTS または 22.04 LTS を実行しているインスタンス/ホスト/VM があること 最小要件は AWS/EC2 t2.micro（1 CPU、1GB RAM、8GB ストレージ）です 学習目標 このワークショップを終えると、参加者は以下ができるようになります\nOpenTelemetry のコンポーネントを理解する Receiver、Processor、Exporter を使用してデータを収集・分析する OpenTelemetry を使用するメリットを理解する ビジネスニーズを解決するカスタムコンポーネントを構築する OpenTelemetry アーキテクチャ %%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "OpenTelemetry Collector の概念と、Splunk Observability Cloud へデータを送信する方法を学びます。",
    "tags": [],
    "title": "OpenTelemetry でオブザーバビリティをクラウドネイティブに",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6.2 Optional Exercise",
    "content": "This is the first section of our optimal Kubernetes Navigator exercise. Below is some high-level information regarding Kubernetes, just in case you’re not familiar with it.\nKubernetes Terminology K8s, short for Kubernetes, is an open-source container orchestration platform. It manages the deployment, scaling, and maintenance of containerized applications, and we use it in this workshop to host our e-commerce application\nSome terminology:\nA Kubernetes cluster is a group of machines, called nodes, that work together to run containerized applications. Nodes are individual servers or VMs in the cluster. Typically, you would have several nodes in a cluster but you may have just one node, just like in this workshop. Pods are the smallest deployable units in Kubernetes, representing one or more containers that share the same network and storage, enabling efficient application scaling and management Applications are a collection of one or more Pods interacting together to provide a service. Namespaces help you keep your applications organized and separate within the cluster, by providing a logical separation for multiple teams or projects within a cluster. Workloads are like a task list and define how many instances of your application should run, how they should be created, and how they should respond to failures Please select the K8s nodes tile from the Tile pane if you have not yet done so. (Select Kubernetes as your Technology). This will bring you to the Kubernetes Navigator Page.\nThe screenshot above shows the main part of the Kubernetes navigator. It will show all the clusters \u0026 their nodes that send metrics to Splunk Observability Cloud, and the first row of charts that show cluster-based Metrics. In the workshop, you will mostly see single-node Kubernetes clusters.\nBefore we dive deeper, let’s make sure we are looking at our cluster.\nExercise First, use the option to pick your cluster. This can be done by selecting k8s.cluster.name from the filter drop-down box. You then can start typing the name of your cluster, (as provided by your instructor). The name should also appear in the drop-down values. Select yours and make sure just the one for your workshop is highlighted with a . Click the Apply Filter button to focus on our Cluster We now should have a single cluster visible. Let’s move on to the next page of this exercise and look at your cluster in detail.",
    "description": "This is the first section of our optimal Kubernetes Navigator exercise. Below is some high-level information regarding Kubernetes, just in case you’re not familiar with it.\nKubernetes Terminology K8s, short for Kubernetes, is an open-source container orchestration platform. It manages the deployment, scaling, and maintenance of containerized applications, and we use it in this workshop to host our e-commerce application\nSome terminology:\nA Kubernetes cluster is a group of machines, called nodes, that work together to run containerized applications. Nodes are individual servers or VMs in the cluster. Typically, you would have several nodes in a cluster but you may have just one node, just like in this workshop. Pods are the smallest deployable units in Kubernetes, representing one or more containers that share the same network and storage, enabling efficient application scaling and management Applications are a collection of one or more Pods interacting together to provide a service. Namespaces help you keep your applications organized and separate within the cluster, by providing a logical separation for multiple teams or projects within a cluster. Workloads are like a task list and define how many instances of your application should run, how they should be created, and how they should respond to failures Please select the K8s nodes tile from the Tile pane if you have not yet done so. (Select Kubernetes as your Technology). This will bring you to the Kubernetes Navigator Page.",
    "tags": [],
    "title": "Infrastructure Exercise - Part 1",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/30-im-exercise/1-im-exercise/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ",
    "content": "このワークショップでは、Splunk Observabilityプラットフォームの以下のコンポーネントを構成するための、基本的なステップを体験できます：\nSplunk Infrastructure Monitoring (IM) Splunk APM Endpoint Performance Database Query Performance AlwaysOn Profiling Splunk Real User Monitoring (RUM) Splunk LogObserver ワークショップの中では、Javaのサンプルアプリケーション（Spring Pet Clinic）をクローン（ダウンロード）し、アプリケーションのコンパイル、パッケージ、実行していきます。\nアプリケーションを起動すると、OpenTelemetry Javaエージェントを通じて、Splunk APMでメトリクスとトレースが即座に表示されるようになります。\nその後、Splunk OpenTelemetry Javascript Libraries (RUM)を使用して、Pet Clinicのエンドユーザーインターフェース（アプリケーションによってレンダリングされるHTMLページ）を計装し、エンドユーザーが実行する個々のクリックとページロードのすべてについて、RUMトレースを生成していきます。\n前提条件 このワークショップは、ホスト/インスタンスが提供されるSplunk実行ワークショップ または 自前のホスト/Multipassインスタンス で行う、自己主導型のワークショップです。\nご自身のシステムには、以下のものがインストールされ、有効になっている必要があります：\nJDK 17 ポート 8083 が開いていること（インバウンド/アウトバウンド）",
    "description": "JavaアプリケーションをつかったSplunk Oservabilityのワークショップです",
    "tags": [],
    "title": "Pet Clinic Java ワークショップ",
    "uri": "/observability-workshop/ja/other/pet-clinic/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ",
    "content": "このワークショップの目的は、Splunk Observability Cloud プラットフォームの以下のコンポーネントを設定するための基本的な手順を説明することです：\nSplunk Infrastructure Monitoring (IM) Splunk Automatic Discovery for Java (APM) Database Query Performance AlwaysOn Profiling Splunk Real User Monitoring (RUM) RUM から APM への相関 Splunk Log Observer (LO) また、サンプル Java アプリケーション（Spring PetClinic）のクローン（ダウンロード）方法、およびアプリケーションのコンパイル、パッケージ化、実行方法についても説明します。\nアプリケーションが起動して実行されると、Splunk APM 製品で使用される Java 2.x 向けの自動ディスカバリーおよび設定機能により、メトリクス、トレース、ログが即座に表示されるようになります。\nその後、Splunk OpenTelemetry Javascript Libraries (RUM) を使用して PetClinic のエンドユーザーインターフェース（アプリケーションがレンダリングする HTML ページ）を計装します。これにより、エンドユーザーが実行するすべてのクリックやページ読み込みに対して RUM トレースが生成されます。\n最後に、PetClinic アプリケーションログへのトレースメタデータの自動インジェクションによって生成されたログを確認します。\n前提条件 ポート 2222 へのアウトバウンド SSH アクセス ポート 8083 へのアウトバウンド HTTP アクセス bash シェルおよび vi/vim エディタの基本的な知識",
    "description": "Spring PetClinic サンプルアプリケーションを使用して、Java アプリケーション向けの Splunk Observability Cloud の自動ディスカバリーおよび設定機能をデモンストレーションするハンズオンワークショップです。",
    "tags": [],
    "title": "PetClinic モノリスワークショップ",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/1-petclinic-monolith/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Splunk Observabilityワークショップへようこそ Splunk Observability Cloud の監視、分析、対応ツールを使用して、アプリケーションとインフラストラクチャをリアルタイムで把握することができます。\nこのワークショップでは、メトリクス、トレース、ログを取り込み、監視し、可視化し、分析するためのクラス最高のオブザーバビリティ（可観測性）プラットフォームについて説明します。\nOpenTelemetry このワークショップでOpenTelemetryをアプリケーションやインフラの分析に役立つテレメトリデータ（メトリクス、トレース、ログ）の計装、生成、収集、エクスポートに使用します。\nGitHub このドキュメントには、issue や pull request で 貢献 することができます。より良いワークショップにするために、是非ご協力ください。\nTwitter SplunkのTwitterチャンネルでは、アップデート情報や興味深い読み物を紹介しています。\nSplunk4Rookies ワークショップ\r以下は初心者向けワークショップです。\rSplunk4Ninjas Workshops\rThe following workshops require Ninja skills, wax on, wax off.\rその他のワークショップ\rPet Clinic Java ワークショップ\rJavaアプリケーションをつかったSplunk Oservabilityのワークショップです\rOpenTelemetry Collector\rOpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。\rリソース\rよくある質問とその回答\rオブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\rディメンション、プロパティ、タグ\rディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。\rOpenTelemetryでのタグ付け\r大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "description": "Splunk を使用したオブザーバビリティソリューションの構築方法をご紹介します。",
    "tags": [],
    "title": "Splunk Observability Workshops",
    "uri": "/observability-workshop/ja/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "Observability Cloud\nこのワークショップでは、Splunk Observability Cloudがフロントエンドアプリケーションからバックエンドサービスまで、ユーザー体験の視点からどのように即座に可視性を提供するかをお見せします - Splunk Observability Cloudの最も魅力的な機能と差別化要因を体験していただきます。 {class=“children children-type-tree children-sort-”}",
    "description": "以下は初心者向けワークショップです。",
    "tags": [],
    "title": "Splunk4Rookies ワークショップ",
    "uri": "/observability-workshop/ja/splunk4rookies/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e リソース",
    "content": "オブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\nQ: アラートとインシデント対応、インシデント管理の違いは？ A: アラート、インシデント対応、インシデント管理は関連する機能です。これらは一緒にインシデント対応および解決プロセスを構成します。\nモニタリングやオブザーバビリティのツールはインシデント対応プラットフォームにアラートを送信します。これらのプラットフォームはアラートのコレクションを収集し、それらをインシデントとして相関させます。\nこれらのインシデントは記録のためにインシデント管理（ITSM）プラットフォームに記録されます。アラートは何かが起こったことを示すトリガーであり、インシデントへのコンテキストを提供します。\nインシデントには、アラートの内容、インシデントが作成されてから関連するすべての活動、およびフォローされるオンコールポリシーが含まれます。ITSMは、インシデントがアクティブであるときおよび解決された後のインシデントを記録するシステムです。\nインシデント対応および管理をより良く実践するために、これらのコンポーネントが必要になります。\nOn-Call Q: オブザーバビリティはモニタリングとは違うものですか？ A: モニタリングとオブザーバビリティの主な違いは、「既知の未知」と「未知の未知」の違いです。\nモニタリングでは、オペレーターは通常、システムのアーキテクチャと要素に関する事前の知識を持っています。彼らは要素間の関係とそれに関連するメタデータを確実に予測することができます。モニタリングは、頻繁に変更されない状態のインフラストラクチャに適しています。\nオブザーバビリティは、オペレーターがシステム内のすべての要素とそれらの関係を予測し、追跡する能力が限定されているシステム向けです。\nオブザーバビリティは、従来のメトリクスのモニタリングを含む一連のプラクティスと技術です。\nこれらのプラクティスと技術を組み合わせることで、オペレーターはシステムのすべての要素に関する事前の知識がなくても、頻繁に変更がある複雑な環境を理解することができます。オブザーバビリティ技術は、環境の変動やメタデータの変化（カーディナリティ）を従来のモニタリングよりもよく考慮できるため、より静的なモニタリングと比較して優れています。\nObservability Q: トレースとスパンとは何ですか？ A: トレースとスパンは、メトリクスとログと共に、現代のオブザーバビリティツールにフィードされるコアタイプのデータを構成します。それらは特定の要素と機能を持っていますが、一緒にうまく機能します。\nマイクロサービスベースのアーキテクチャは分散しているため、システム内のトランザクションは完了する前に複数のサービスにアクセスします。これにより、問題の場所を正確に特定することが困難になります。トレースは、分散システム内のすべてのサービスを通るリクエストの完全なパスを追跡するための方法です。スパンは、各サービスでの時間のかかる操作です。トレースはスパンの結合したものであり、一緒になると個々のサービスプロセスについてより詳細な情報を提供します。メトリクスはシステムの健康状態の良いスナップショットを提供し、ログは問題を調査する際に深さを提供しますが、トレースとスパンはオペレーターに問題の源泉をより多くのコンテキストでナビゲートするのに役立ちます。これにより、インシデントの調査にかかる時間が節約され、現代のアーキテクチャの複雑さがサポートされます。\nAPM Q: サイドカーパターンとは何ですか？ A: サイドカーパターンは、関連するサービスをインフラストラクチャによって直接接続するためのデザインパターンです。関連するサービスは、接続されているアプリケーションロジックに機能を追加したりサポートしたりすることができます。これは、管理計画に関連するエージェントをアプリケーションサービスと共に展開する方法として広く使用されます。\nオブザーバビリティでは、サイドカーサービスはアプリケーションロジックであり、そのサービスからデータを収集するエージェントです。このセットアップには、アプリケーションサービスを含むコンテナと、エージェントを実行するコンテナの2つが必要です。コンテナはポッドを共有し、ディスク、ネットワーク、名前空間などのリソースを共有します。また、一緒にデプロイされ、同じライフサイクルを共有します。\nObservability",
    "description": "オブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。",
    "tags": [],
    "title": "よくある質問とその回答",
    "uri": "/observability-workshop/ja/resources/faq/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops",
    "content": "PetClinic モノリスワークショップ\rSpring PetClinic サンプルアプリケーションを使用して、Java アプリケーション向けの Splunk Observability Cloud の自動ディスカバリーおよび設定機能をデモンストレーションするハンズオンワークショップです。\rPetClinic Kubernetes ワークショップ\rKubernetes で実行される Java ベースのアプリケーション向けの自動ディスカバリーおよび設定を有効にする方法を学びます。リアルタイムモニタリングを体験し、エンドツーエンドの可視性でアプリケーションの動作を最大限に活用しましょう。",
    "description": "Java アプリケーション向けの Splunk 自動ディスカバリーおよび設定機能の活用方法を学びます。これらのワークショップでは、ゼロコード計装を使用して、モノリスおよび Kubernetes デプロイメント全体でメトリクス、トレース、ログを即座に生成し、包括的なオブザーバビリティを実現する方法をデモンストレーションします。",
    "tags": [],
    "title": "自動ディスカバリーワークショップ",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "Spring PetClinic Java アプリケーションは、フロントエンドとバックエンドのサービスで構成されるシンプルなマイクロサービスアプリケーションです。フロントエンドサービスは、バックエンドサービスと対話するための Web インターフェースを提供する Spring Boot アプリケーションです。バックエンドサービスは、MySQL データベースと対話するための RESTful API を提供する Spring Boot アプリケーションです。\nこのワークショップを終えるころには、Kubernetes で実行される Java ベースのアプリケーション向けの自動ディスカバリーおよび設定を有効にする方法をより深く理解できるようになります。\n以下の図は、Splunk OpenTelemetry Operator と自動ディスカバリーおよび設定を有効にした状態で Kubernetes 上で実行される Spring PetClinic Java アプリケーションのアーキテクチャを詳しく示しています。\nJosh Voravong が作成したサンプルに基づいています。",
    "description": "Spring PetClinic Java アプリケーションは、フロントエンドとバックエンドのサービスで構成されるシンプルなマイクロサービスアプリケーションです。フロントエンドサービスは、バックエンドサービスと対話するための Web インターフェースを提供する Spring Boot アプリケーションです。バックエンドサービスは、MySQL データベースと対話するための RESTful API を提供する Spring Boot アプリケーションです。\nこのワークショップを終えるころには、Kubernetes で実行される Java ベースのアプリケーション向けの自動ディスカバリーおよび設定を有効にする方法をより深く理解できるようになります。\n以下の図は、Splunk OpenTelemetry Operator と自動ディスカバリーおよび設定を有効にした状態で Kubernetes 上で実行される Spring PetClinic Java アプリケーションのアーキテクチャを詳しく示しています。\nJosh Voravong が作成したサンプルに基づいています。",
    "tags": [],
    "title": "アーキテクチャ",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/1-architecture/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 7. Log Observer",
    "content": "ログを表示するには、左側のメニューで Log Observer をクリックします。Log Observer に入ったら、フィルターバーの Index が splunk4rookies-workshop に設定されていることを確認してください。(1)\n次に、Add Filter をクリックし、Fields (2) オプションを使用して deployment.environment フィールド (3) を検索します。ドロップダウンリストから、あなたのワークショップインスタンスを選択し (4)、= (含める) をクリックします。これで、PetClinic アプリケーションからのログメッセージのみが表示されます。\n次に、service.name フィールドを検索し、値 customers-service を選択して = (含める) をクリックします。これがフィルターバー (1) に表示されます。次に、Run Search ボタン (2) をクリックします。\nこれによりログエントリがリフレッシュされ、customers-service からのエントリのみが表示されるように絞り込まれます。\n“Saving pet” で始まるエントリ (1) をクリックします。サイドペーンが開き、関連するトレースIDやスパンID (2) を含む詳細情報を確認できます。",
    "description": "ログを表示するには、左側のメニューで Log Observer をクリックします。Log Observer に入ったら、フィルターバーの Index が splunk4rookies-workshop に設定されていることを確認してください。(1)\n次に、Add Filter をクリックし、Fields (2) オプションを使用して deployment.environment フィールド (3) を検索します。ドロップダウンリストから、あなたのワークショップインスタンスを選択し (4)、= (含める) をクリックします。これで、PetClinic アプリケーションからのログメッセージのみが表示されます。\n次に、service.name フィールドを検索し、値 customers-service を選択して = (含める) をクリックします。これがフィルターバー (1) に表示されます。次に、Run Search ボタン (2) をクリックします。\nこれによりログエントリがリフレッシュされ、customers-service からのエントリのみが表示されるように絞り込まれます。",
    "tags": [],
    "title": "ログを確認する",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/7-log-observer-connect/1-view-logs/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 1. はじめに",
    "content": "Splunk Observability Cloud に登録してログインすると、ホームページ（ランディングページ）に移動します。ここでは、開始に役立ついくつかの便利な機能が見つかります。\nデータ探索パネル: どの統合が有効になっているかを表示し、管理者の場合は追加の統合を追加できます。 ドキュメントパネル: Splunk Observability Cloud の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 最近のアクティビティパネル: 最近作成/訪問したダッシュボードやディテクターにすぐにアクセスできます。 メインメニューパネル: Splunk Observability Cloud のコンポーネントを操作します。 組織切り替え: 複数の組織のメンバーである場合は、組織間を簡単に切り替えることができます。 メインメニューの展開/縮小: スペースが限られている場合にメインメニューを展開 » / 折りたたむ « ことができます。 最初の演習から始めましょう：\n演習 メインメニューを展開し、設定をクリックします。 組織切り替えで、複数の組織にアクセスできるかどうかを確認します。 ヒント 以前に Splunk Observability を使用したことがある場合は、以前に使用した組織に配置されている可能性があります。正しいワークショップ組織にいることを確認してください。複数の組織へのアクセス権がある場合は、インストラクターに確認してください。\n演習 オンボーディングガイダンスをクリックします（ここでオンボーディングパネルの表示/非表示を切り替えることができます。製品に十分に精通していて、より多くの情報を表示するためにスペースを使用できる場合に便利です）。 ホームページのオンボーディングコンテンツを非表示にします。 メニューの下部で、お好みのテーマ：Light、Dark、または**System(Auto)**モードを選択します。 これがLog outオプションがある場所であることにも気づきましたか？どうかログアウトしないでください 😊！ \u003c をクリックしてメインメニューに戻ります。 次に、Splunk Real User Monitoring (RUM) を確認しましょう。",
    "description": "Splunk Observability Cloud に登録してログインすると、ホームページ（ランディングページ）に移動します。ここでは、開始に役立ついくつかの便利な機能が見つかります。\nデータ探索パネル: どの統合が有効になっているかを表示し、管理者の場合は追加の統合を追加できます。 ドキュメントパネル: Splunk Observability Cloud の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 最近のアクティビティパネル: 最近作成/訪問したダッシュボードやディテクターにすぐにアクセスできます。 メインメニューパネル: Splunk Observability Cloud のコンポーネントを操作します。 組織切り替え: 複数の組織のメンバーである場合は、組織間を簡単に切り替えることができます。 メインメニューの展開/縮小: スペースが限られている場合にメインメニューを展開 » / 折りたたむ « ことができます。 最初の演習から始めましょう：\n演習 メインメニューを展開し、設定をクリックします。 組織切り替えで、複数の組織にアクセスできるかどうかを確認します。 ヒント 以前に Splunk Observability を使用したことがある場合は、以前に使用した組織に配置されている可能性があります。正しいワークショップ組織にいることを確認してください。複数の組織へのアクセス権がある場合は、インストラクターに確認してください。\n演習 オンボーディングガイダンスをクリックします（ここでオンボーディングパネルの表示/非表示を切り替えることができます。製品に十分に精通していて、より多くの情報を表示するためにスペースを使用できる場合に便利です）。 ホームページのオンボーディングコンテンツを非表示にします。 メニューの下部で、お好みのテーマ：Light、Dark、または**System(Auto)**モードを選択します。 これがLog outオプションがある場所であることにも気づきましたか？どうかログアウトしないでください 😊！ \u003c をクリックしてメインメニューに戻ります。 次に、Splunk Real User Monitoring (RUM) を確認しましょう。",
    "tags": [],
    "title": "ホームページ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/1-homepage/1-home-page/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 2. API Test",
    "content": "新しい API テストを作成 Add new test ボタンをクリックし、ドロップダウンから API test を選択して新しい API テストを作成します。テスト名には イニシャル に続けて Spotify API と入力します（例: RWC - Spotify API）。",
    "description": "新しい API テストを作成 Add new test ボタンをクリックし、ドロップダウンから API test を選択して新しい API テストを作成します。テスト名には イニシャル に続けて Spotify API と入力します（例: RWC - Spotify API）。",
    "tags": [],
    "title": "新しい API テストの作成",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/2-api-test/2-create-new-check/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 1. Real Browser Test",
    "content": "Splunk Observability Cloud で Synthetics に移動し、Add new test をクリックします。\nドロップダウンから Browser test を選択します。\nBrowser test content 設定ページが表示されます。",
    "description": "Splunk Observability Cloud で Synthetics に移動し、Add new test をクリックします。\nドロップダウンから Browser test を選択します。\nBrowser test content 設定ページが表示されます。",
    "tags": [],
    "title": "1.2 Real Browser Test の作成",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/2-create-real-browser-test/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting",
    "content": "API Test は、API エンドポイントの機能とパフォーマンスを柔軟にチェックする方法を提供します。API ファーストの開発へのシフトにより、フロントエンドのコア機能を提供するバックエンドサービスをモニタリングする必要性が高まっています。\nマルチステップの API インタラクションのテストに興味がある場合でも、エンドポイントのパフォーマンスを可視化したい場合でも、API Test は目標の達成を支援します。",
    "description": "API Test は、API エンドポイントの機能とパフォーマンスを柔軟にチェックする方法を提供します。API ファーストの開発へのシフトにより、フロントエンドのコア機能を提供するバックエンドサービスをモニタリングする必要性が高まっています。\nマルチステップの API インタラクションのテストに興味がある場合でも、エンドポイントのパフォーマンスを可視化したい場合でも、API Test は目標の達成を支援します。",
    "tags": [],
    "title": "API Test",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/2-api-test/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 5. APM Features",
    "content": "トレースを選択するには、Service Requests \u0026 Errorsチャート**(1)**の線を選択します。関連するトレースの選択肢が表示されます。\n関連するトレースのリストが表示されたら、青い**(2)** Trace ID Linkをクリックします。選択するトレースがServicesカラムに記載されている3つのサービスと同じものであることを確認してください。\nこれにより、ウォーターフォールビューで選択されたトレースが表示されます：\nここにはいくつかのセクションがあります：\nWaterfall Pane (1)：トレースとスパンとして表示されるすべてのインストルメントされた関数が、その期間表示と順序/関係とともに表示されます。 Trace Info Pane (2)：選択されたスパン情報が表示されます（Waterfall Pane内でスパンの周りにボックスでハイライトされています）。 Span Pane (3)：選択されたスパンで送信されたすべてのタグを見つけることができます。下にスクロールしてすべてを確認できます。 Process Pane：スパンを作成したプロセスに関連するタグが表示されます（スクリーンショットに含まれていないため、下にスクロールして確認してください）。 Trace Properties：ペインの右上にあり、デフォルトでは折りたたまれています。",
    "description": "トレースを選択するには、Service Requests \u0026 Errorsチャート**(1)**の線を選択します。関連するトレースの選択肢が表示されます。\n関連するトレースのリストが表示されたら、青い**(2)** Trace ID Linkをクリックします。選択するトレースがServicesカラムに記載されている3つのサービスと同じものであることを確認してください。\nこれにより、ウォーターフォールビューで選択されたトレースが表示されます：\nここにはいくつかのセクションがあります：\nWaterfall Pane (1)：トレースとスパンとして表示されるすべてのインストルメントされた関数が、その期間表示と順序/関係とともに表示されます。 Trace Info Pane (2)：選択されたスパン情報が表示されます（Waterfall Pane内でスパンの周りにボックスでハイライトされています）。 Span Pane (3)：選択されたスパンで送信されたすべてのタグを見つけることができます。下にスクロールしてすべてを確認できます。 Process Pane：スパンを作成したプロセスに関連するタグが表示されます（スクリーンショットに含まれていないため、下にスクロールして確認してください）。 Trace Properties：ペインの右上にあり、デフォルトでは折りたたまれています。",
    "tags": [],
    "title": "APM Trace",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/5-traces/2-trace/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "サービスビュー サービスオーナーとして、Splunk APM のサービスビューを使用して、単一のパネルでサービスの健全性の完全なビューを取得できます。サービスビューには、可用性、依存関係、リクエスト、エラー、および期間（RED）メトリクス、ランタイムメトリクス、インフラストラクチャメトリクス、Tag Spotlight、エンドポイント、および選択したサービスのログのためのサービスレベルインジケーター（SLI）が含まれています。また、サービスビューからサービスのコードプロファイリングとメモリプロファイリングにすぐにアクセスすることもできます。\n演習 時間ボックスを確認すると、ダッシュボードは以前に選択した APM トレースが完了するまでにかかった時間に関連するデータのみを表示していることがわかります（チャートは静的であることに注意してください）。 時間ボックスで時間枠を -1h に変更します。 これらのチャートはパフォーマンスの問題を素早く特定するのに非常に役立ちます。このダッシュボードを使用して、サービスの健全性を監視できます。 ページを下にスクロールしてInfrustructure Metricsを展開します。ここでホストと Pod のメトリクスが表示されます。 Runtime Metricsは、Node.js で書かれたサービスにはプロファイリングデータが利用できないため、使用できません。 では、探索ビューに戻りましょう。ブラウザの戻るボタンを押してください。 演習 ​ 質問 回答 サービスマップでpaymentserviceの上にカーソルを置いてください。ポップアップサービスチャートからどのような結論を導き出せますか？\nエラーの割合が非常に高い。\nこのエラー率にパターンがあるかどうかを理解する必要があります。そのための便利なツール、Tag Spotlightがあります。",
    "description": "サービスビュー サービスオーナーとして、Splunk APM のサービスビューを使用して、単一のパネルでサービスの健全性の完全なビューを取得できます。サービスビューには、可用性、依存関係、リクエスト、エラー、および期間（RED）メトリクス、ランタイムメトリクス、インフラストラクチャメトリクス、Tag Spotlight、エンドポイント、および選択したサービスのログのためのサービスレベルインジケーター（SLI）が含まれています。また、サービスビューからサービスのコードプロファイリングとメモリプロファイリングにすぐにアクセスすることもできます。\n演習 時間ボックスを確認すると、ダッシュボードは以前に選択した APM トレースが完了するまでにかかった時間に関連するデータのみを表示していることがわかります（チャートは静的であることに注意してください）。 時間ボックスで時間枠を -1h に変更します。 これらのチャートはパフォーマンスの問題を素早く特定するのに非常に役立ちます。このダッシュボードを使用して、サービスの健全性を監視できます。 ページを下にスクロールしてInfrustructure Metricsを展開します。ここでホストと Pod のメトリクスが表示されます。 Runtime Metricsは、Node.js で書かれたサービスにはプロファイリングデータが利用できないため、使用できません。 では、探索ビューに戻りましょう。ブラウザの戻るボタンを押してください。 演習 ​ 質問 回答 サービスマップでpaymentserviceの上にカーソルを置いてください。ポップアップサービスチャートからどのような結論を導き出せますか？",
    "tags": [],
    "title": "2. APMサービスビュー",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/6-apm/2-apm-service-view/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 4. 自動検出と設定",
    "content": "左側のメニューでAPMをクリックして、新しく計装されたサービスからのトレースによって生成されたデータを確認します。\nドロップダウンボックスでEnvironmentフィルター (1) をワークショップインスタンスの名前に変更します。\nメモ これは**\u003cINSTANCE\u003e-workshopになります。ここでINSTANCE**は、先ほど実行したシェルスクリプトの値です。これのみが選択されていることを確認してください。\nService Map (2) ペインをクリックして、次のセクションの準備をします。",
    "description": "左側のメニューでAPMをクリックして、新しく計装されたサービスからのトレースによって生成されたデータを確認します。\nドロップダウンボックスでEnvironmentフィルター (1) をワークショップインスタンスの名前に変更します。\nメモ これは**\u003cINSTANCE\u003e-workshopになります。ここでINSTANCE**は、先ほど実行したシェルスクリプトの値です。これのみが選択されていることを確認してください。\nService Map (2) ペインをクリックして、次のセクションの準備をします。",
    "tags": [],
    "title": "Splunk APMでのデータの表示",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/4-apm/2-apm-data/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "OpenTelemetry Collector がインストールできたので、OpenTelemetry Collector の拡張機能について見ていきましょう。拡張機能はオプションであり、主にテレメトリデータの処理を伴わないタスクに使用されます。拡張機能の例としては、ヘルスモニタリング、サービスディスカバリ、データ転送などがあります。\n%%{ init:{ \"theme\": \"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style E fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "OpenTelemetry Collector がインストールできたので、OpenTelemetry Collector の拡張機能について見ていきましょう。拡張機能はオプションであり、主にテレメトリデータの処理を伴わないタスクに使用されます。拡張機能の例としては、ヘルスモニタリング、サービスディスカバリ、データ転送などがあります。\n%%{ init:{ \"theme\": \"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style E fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector Extensions",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/2-extensions/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 8. Real User Monitoring",
    "content": "TAG Spotlight ビューでは、RUM データに関連付けられたすべてのタグが表示されます。タグは、データを識別するために使用されるキーバリューペアです。この場合、タグは OpenTelemetry インストルメンテーションによって自動的に生成されます。タグは、データをフィルタリングし、チャートやテーブルを作成するために使用されます。Tag Spotlight ビューでは、動作の傾向を検出し、ユーザーセッションにドリルダウンできます。\nUser Sessions (1) をクリックすると、タイムウィンドウ中に発生したユーザーセッションのリストが表示されます。\nセッションの 1 つを見たいので、Duration (2) をクリックして期間でソートし、長いものの 1 つのリンク (3) をクリックしてください:",
    "description": "TAG Spotlight ビューでは、RUM データに関連付けられたすべてのタグが表示されます。タグは、データを識別するために使用されるキーバリューペアです。この場合、タグは OpenTelemetry インストルメンテーションによって自動的に生成されます。タグは、データをフィルタリングし、チャートやテーブルを作成するために使用されます。Tag Spotlight ビューでは、動作の傾向を検出し、ユーザーセッションにドリルダウンできます。\nUser Sessions (1) をクリックすると、タイムウィンドウ中に発生したユーザーセッションのリストが表示されます。\nセッションの 1 つを見たいので、Duration (2) をクリックして期間でソートし、長いものの 1 つのリンク (3) をクリックしてください:",
    "tags": [],
    "title": "RUM trace Waterfall view \u0026 linking to APM",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/8-rum/2-rum-tour/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. Spring PetClinic アプリケーションを動かす APMをセットアップするためにまず必要なのは…そう、アプリケーションです！この演習では、Spring PetClinicアプリケーションを使用します。これはSpringフレームワーク（Spring Boot）で作られた、非常に人気のあるサンプルJavaアプリケーションです。\nまずはPetClinicリポジトリをクローンし、そして、アプリケーションをコンパイル、ビルド、パッケージ、テストしていきます。\ngit clone https://github.com/spring-projects/spring-petclinic spring-petclinic ディレクトリに移動します:\ncd spring-petclinic PetClinic が使用する MySQL データベースを起動します:\ndocker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/biarms/mysql:5.7 そして、Splunk版のOpenTelemetry Java APMエージェントをダウンロードしておきましょう。\ncurl -L https://github.com/signalfx/splunk-otel-java/releases/latest/download/splunk-otel-javaagent.jar \\ -o splunk-otel-javaagent.jar 次に、mavenコマンドを実行してPetClinicをコンパイル/ビルド/パッケージ化します:\n./mvnw package -Dmaven.test.skip=true 情報 実際にアプリをコンパイルする前に、mavenが多くの依存ライブラリをダウンロードするため、初回実行時には数分かかるでしょう。2回目以降の実行はもっと短くなります。\nそして、以下のコマンドでアプリケーションを実行することができます:\njava -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.314 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql アプリケーションが動作しているかどうかは、http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスして確認することができます。 次に、トラフィックを生成し、クリックしまくり、エラーを生成し、ペットを追加するなどしてください。\n-Dotel.service.name=$(hostname).service では、アプリケーションの名前を定義しています。サービスマップ上のアプリケーションの名前等に反映されます。 -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.314 では、Environmentと、versionを定義しています。 deployment.environment=$(hostname) は、Splunk APM UIの上部「Environment」に反映されます。 version=0.314 はここでは、アプリケーションのバージョンを示しています。トレースをドリルダウンしたり、サービスマップの Breakdown の機能で分析したり、Tag Spotlightを開くと version 毎のパフォーマンス分析が使えます。 -Dsplunk.profiler.enabled=true および splunk.profiler.memory.enabled=true では、CPUとメモリのプロファイリングを有効にしています。Splunk APM UIから、AlwaysOn Profilingを開いてみてください。 -Dsplunk.metrics.enabled=true では、メモリやスレッドなどJVMメトリクスの送信を有効にしています。Dashboardsから、APM java servicesを開いてみてください。 その後、Splunk APM UIにアクセスして、それぞれのテレメトリーデータを確認してみましょう！\nTroubleshooting MetricSetsを追加する サービスマップやTab Spotlightで、 version などのカスタム属性で分析できるようにするためには、Troubleshooting MetricSetsの設定をあらかじめ追加する必要があります。 左メニューの Settings → APM MetricSets で、設定を管理することができます。 もしお使いのアカウントで分析できなければ、設定を追加してみましょう。\n次のセクションではカスタム計装を追加して、OpenTelemetryでは何ができるのか、さらに見ていきます。",
    "description": "1. Spring PetClinic アプリケーションを動かす APMをセットアップするためにまず必要なのは…そう、アプリケーションです！この演習では、Spring PetClinicアプリケーションを使用します。これはSpringフレームワーク（Spring Boot）で作られた、非常に人気のあるサンプルJavaアプリケーションです。\nまずはPetClinicリポジトリをクローンし、そして、アプリケーションをコンパイル、ビルド、パッケージ、テストしていきます。\ngit clone https://github.com/spring-projects/spring-petclinic spring-petclinic ディレクトリに移動します:\ncd spring-petclinic PetClinic が使用する MySQL データベースを起動します:\ndocker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/biarms/mysql:5.7 そして、Splunk版のOpenTelemetry Java APMエージェントをダウンロードしておきましょう。\ncurl -L https://github.com/signalfx/splunk-otel-java/releases/latest/download/splunk-otel-javaagent.jar \\ -o splunk-otel-javaagent.jar 次に、mavenコマンドを実行してPetClinicをコンパイル/ビルド/パッケージ化します:\n./mvnw package -Dmaven.test.skip=true 情報 実際にアプリをコンパイルする前に、mavenが多くの依存ライブラリをダウンロードするため、初回実行時には数分かかるでしょう。2回目以降の実行はもっと短くなります。",
    "tags": [],
    "title": "OpenTelemetry Javaエージェントをインストールする",
    "uri": "/observability-workshop/ja/other/pet-clinic/docs/apm/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "OpenTelemetry クラウドコンピューティング、マイクロサービスアーキテクチャ、そして複雑化するビジネス要件の増加に伴い、可観測性の必要性はかつてないほど高まっています。可観測性とは、システムの出力を調査することで、そのシステムの内部状態を理解する能力です。ソフトウェアの文脈では、これはメトリクス、トレース、ログを含むテレメトリデータを調査することでシステムの内部状態を理解できることを意味します。\nシステムを観測可能にするには、計装が必要です。つまり、コードはトレース、メトリクス、ログを発行する必要があります。この計装データは、Splunk Observability Cloudなどの可観測性バックエンドに送信される必要があります。\nメトリクス トレース ログ 問題がありますか？ 問題はどこですか？ 問題は何ですか？ OpenTelemetry は 2 つの重要なことを行います：\n独自のデータフォーマットやツールに縛られるのではなく、生成したデータを所有できるようにします。 単一のAPI セットと規約を学ぶことができます これら 2 つの要素が組み合わさることで、今日の現代的なコンピューティング環境で必要な柔軟性をチームや組織に提供します。\n可観測性を始めるにあたっては、重要な質問を含め多くの変数を考慮する必要があります： 「どのようにしてデータを可観測性ツールに取り込むのか？」 OpenTelemetry の業界全体での採用は、この質問に答えることをこれまで以上に容易にしています。\nなぜ重要なのか？ OpenTelemetry は完全にオープンソースで無料で使用できます。過去のモニタリングや可観測性ツールは、独自のエージェントに大きく依存していたため、追加のツールを変更したり設定したりするために必要な労力は、インフラレベルからアプリケーションレベルまで、システム全体に大規模な変更を必要としていました。\nOpenTelemetry はベンダー中立であり、可観測性分野の多くの業界リーダーにサポートされているため、採用者は計装にわずかな変更を加えるだけで、サポートされている可観測性ツール間をいつでも切り替えることができます。これは、Linux のように様々なディストリビューションが設定やアドオンをバンドルしていても、基本的にはすべてがコミュニティ主導の OpenTelemetry プロジェクトに基づいているため、どの OpenTelemetry ディストリビューションを使用しても変わりません。\nSplunk は完全に OpenTelemetry にコミットしており、お客様があらゆる種類、あらゆる構造、あらゆるソースから、あらゆる規模で、すべてリアルタイムですべてのデータを収集して使用できるようにしています。OpenTelemetry は基本的にモニタリングの環境を変え、IT チームや DevOps チームがすべての質問とすべてのアクションにデータをもたらすことを可能にしています。これらのワークショップでこれを体験することになります。",
    "description": "OpenTelemetryについて学び、なぜそれが重要なのかを理解しましょう。",
    "tags": [],
    "title": "OpenTelemetryとは何か、なぜ重要なのか？",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/2-opentelemetry/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "OpenTelemetry コレクターのアンインストール EC2 インスタンスには、すでに Splunk Distribution の OpenTelemetry コレクターの古いバージョンが インストールされている可能性があります。先に進む前に、次のコマンドを使用してアンインストールしましょう：\n​ Script Example Output curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; sudo sh /tmp/splunk-otel-collector.sh --uninstall Reading package lists... Done Building dependency tree... Done Reading state information... Done The following packages will be REMOVED: splunk-otel-collector* 0 upgraded, 0 newly installed, 1 to remove and 167 not upgraded. After this operation, 766 MB disk space will be freed. (Reading database ... 157441 files and directories currently installed.) Removing splunk-otel-collector (0.92.0) ... (Reading database ... 147373 files and directories currently installed.) Purging configuration files for splunk-otel-collector (0.92.0) ... Scanning processes... Scanning candidates... Scanning linux images... Running kernel seems to be up-to-date. Restarting services... systemctl restart fail2ban.service falcon-sensor.service Service restarts being deferred: systemctl restart networkd-dispatcher.service systemctl restart unattended-upgrades.service No containers need to be restarted. No user sessions are running outdated binaries. No VM guests are running outdated hypervisor (qemu) binaries on this host. Successfully removed the splunk-otel-collector package OpenTelemetry collector のデプロイ Linux EC2 インスタンスに、Splunk Distribution の OpenTelemetry コレクターの最新バージョンをデプロイしましょう。\nこれはcurlを使用してコレクターバイナリをダウンロードし、特定の引数を指定して実行することで可能です。 これらの引数は、データを送信する realm、使用するアクセストークン、 およびデータを送信するデプロイメント環境をコレクターに指示します。\nSplunk Observability Cloud におけるデプロイメント環境とは、システムまたはアプリケーションの個別のデプロイメントであり、同じアプリケーションの他のデプロイメントの設定と重複しない設定を行うことができます。\n​ Script Example Output curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; \\ sudo sh /tmp/splunk-otel-collector.sh \\ --realm $REALM \\ --mode agent \\ --without-instrumentation \\ --deployment-environment otel-$INSTANCE \\ -- $ACCESS_TOKEN Splunk OpenTelemetry Collector Version: latest Memory Size in MIB: 512 Realm: us1 Ingest Endpoint: https://ingest.us1.signalfx.com API Endpoint: https://api.us1.signalfx.com HEC Endpoint: https://ingest.us1.signalfx.com/v1/log etc. 詳細については、インストーラースクリプトを使用した Linux 用コレクターのインストール を参照してください。\nコレクターが実行中であることを確認 インスタンスでコレクターが正常に実行されていることを確認しましょう。\nステータスコマンドを終了するには、Ctrl + C を押します。\n​ Script Example Output sudo systemctl status splunk-otel-collector ● splunk-otel-collector.service - Splunk OpenTelemetry Collector Loaded: loaded (/lib/systemd/system/splunk-otel-collector.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/splunk-otel-collector.service.d └─service-owner.conf Active: active (running) since Fri 2024-12-20 00:13:14 UTC; 45s ago Main PID: 14465 (otelcol) Tasks: 9 (limit: 19170) Memory: 117.4M CPU: 681ms CGroup: /system.slice/splunk-otel-collector.service └─14465 /usr/bin/otelcol コレクターログの確認方法 journalctlを使用してコレクターログを表示できます：\nログの監視を終了するには、Ctrl + C を押します。\n​ Script Example Output sudo journalctl -u splunk-otel-collector -f -n 100 Dec 20 00:13:14 derek-1 systemd[1]: Started Splunk OpenTelemetry Collector. Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:483: Set config to /etc/otel/collector/agent_config.yaml Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:539: Set memory limit to 460 MiB Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:524: Set soft memory limit set to 460 MiB Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:373: Set garbage collection target percentage (GOGC) to 400 Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:414: set \"SPLUNK_LISTEN_INTERFACE\" to \"127.0.0.1\" etc. コレクターの設定 このコレクターが使用している設定はどこで見つけられるでしょうか？\nその設定は/etc/otel/collectorディレクトリにあります。コレクターをagentモードで インストールしたため、コレクター設定はagent_config.yamlファイルにあります。",
    "description": "OpenTelemetry コレクターのアンインストール EC2 インスタンスには、すでに Splunk Distribution の OpenTelemetry コレクターの古いバージョンが インストールされている可能性があります。先に進む前に、次のコマンドを使用してアンインストールしましょう：\n​ Script Example Output curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; sudo sh /tmp/splunk-otel-collector.sh --uninstall Reading package lists... Done Building dependency tree... Done Reading state information... Done The following packages will be REMOVED: splunk-otel-collector* 0 upgraded, 0 newly installed, 1 to remove and 167 not upgraded. After this operation, 766 MB disk space will be freed. (Reading database ... 157441 files and directories currently installed.) Removing splunk-otel-collector (0.92.0) ... (Reading database ... 147373 files and directories currently installed.) Purging configuration files for splunk-otel-collector (0.92.0) ... Scanning processes... Scanning candidates... Scanning linux images... Running kernel seems to be up-to-date. Restarting services... systemctl restart fail2ban.service falcon-sensor.service Service restarts being deferred: systemctl restart networkd-dispatcher.service systemctl restart unattended-upgrades.service No containers need to be restarted. No user sessions are running outdated binaries. No VM guests are running outdated hypervisor (qemu) binaries on this host. Successfully removed the splunk-otel-collector package OpenTelemetry collector のデプロイ Linux EC2 インスタンスに、Splunk Distribution の OpenTelemetry コレクターの最新バージョンをデプロイしましょう。",
    "tags": [],
    "title": "OpenTelemetryコレクターのデプロイ",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/2-deploy-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic モノリスワークショップ",
    "content": "APM をセットアップするために最初に必要なのは…そう、アプリケーションです。この演習では、Spring PetClinic アプリケーションを使用します。これは、Spring フレームワーク（Springboot）で構築された非常に人気のあるサンプル Java アプリケーションです。\nまず、PetClinic の GitHub リポジトリをクローンし、その後アプリケーションのコンパイル、ビルド、パッケージ化、テストを行います：\ngit clone https://github.com/spring-projects/spring-petclinic spring-petclinic ディレクトリに移動します：\ncd spring-petclinic git checkout b26f235250627a235a2974a22f2317dbef27338d Docker を使用して、PetClinic が使用する MySQL データベースを起動します：\ndocker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/biarms/mysql:5.7 次に、PetClinic アプリケーションにシンプルなトラフィックを生成する Locust を実行する別のコンテナを起動します。Locust は、Web アプリケーションにトラフィックを生成するために使用できるシンプルな負荷テストツールです。\ndocker run --network=\"host\" -d -p 8090:8090 -v ~/workshop/petclinic:/mnt/locust docker.io/locustio/locust -f /mnt/locust/locustfile.py --headless -u 1 -r 1 -H http://127.0.0.1:8083 次に、maven を使用して PetClinic をコンパイル、ビルド、パッケージ化します：\n./mvnw package -Dmaven.test.skip=true 情報 初回実行時は数分かかり、アプリケーションをコンパイルする前に多くの依存関係をダウンロードします。以降のビルドはより高速になります。\nビルドが完了したら、実行しているインスタンスのパブリック IP アドレスを取得する必要があります。以下のコマンドを実行して取得できます：\ncurl http://ifconfig.me IP アドレスが返されます。アプリケーションが実行されていることを確認するために必要になるので、この IP アドレスをメモしておいてください。",
    "description": "APM をセットアップするために最初に必要なのは…そう、アプリケーションです。この演習では、Spring PetClinic アプリケーションを使用します。これは、Spring フレームワーク（Springboot）で構築された非常に人気のあるサンプル Java アプリケーションです。\nまず、PetClinic の GitHub リポジトリをクローンし、その後アプリケーションのコンパイル、ビルド、パッケージ化、テストを行います：\ngit clone https://github.com/spring-projects/spring-petclinic spring-petclinic ディレクトリに移動します：\ncd spring-petclinic git checkout b26f235250627a235a2974a22f2317dbef27338d Docker を使用して、PetClinic が使用する MySQL データベースを起動します：\ndocker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/biarms/mysql:5.7 次に、PetClinic アプリケーションにシンプルなトラフィックを生成する Locust を実行する別のコンテナを起動します。Locust は、Web アプリケーションにトラフィックを生成するために使用できるシンプルな負荷テストツールです。\ndocker run --network=\"host\" -d -p 8090:8090 -v ~/workshop/petclinic:/mnt/locust docker.io/locustio/locust -f /mnt/locust/locustfile.py --headless -u 1 -r 1 -H http://127.0.0.1:8083 次に、maven を使用して PetClinic をコンパイル、ビルド、パッケージ化します：",
    "tags": [],
    "title": "Spring PetClinic アプリケーションのビルド",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/1-petclinic-monolith/2-building-petclinic/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 3. Receivers",
    "content": "Prometheus Receiver prometheus という別の Receiver があることにも気づくでしょう。Prometheus は、OpenTelemetry Collector が使用するオープンソースのツールキットです。この Receiver は、OpenTelemetry Collector 自体からメトリクスをスクレイピングするために使用されます。これらのメトリクスは、Collector の健全性を監視するために使用できます。\nprometheus Receiver を変更して、Collector 自体からメトリクスを収集するためのものであることを明確にしましょう。Receiver の名前を prometheus から prometheus/internal に変更することで、その Receiver が何をしているかがより明確になります。設定ファイルを以下のように更新してください\n​ Prometheus Receiver Configuration prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] ダッシュボード例 - Prometheus メトリクス 以下のスクリーンショットは、Prometheus internal Receiver が OpenTelemetry Collector から収集するメトリクスの一部を表示するダッシュボード例です。ここでは、受け入れられたスパン、メトリクス、ログレコードと送信されたものを確認できます。\nメモ 以下のスクリーンショットは、Splunk Observability Cloud の標準（OOTB）ダッシュボードで、Splunk OpenTelemetry Collector のインストール状況を簡単に監視できます。",
    "description": "Prometheus Receiver prometheus という別の Receiver があることにも気づくでしょう。Prometheus は、OpenTelemetry Collector が使用するオープンソースのツールキットです。この Receiver は、OpenTelemetry Collector 自体からメトリクスをスクレイピングするために使用されます。これらのメトリクスは、Collector の健全性を監視するために使用できます。\nprometheus Receiver を変更して、Collector 自体からメトリクスを収集するためのものであることを明確にしましょう。Receiver の名前を prometheus から prometheus/internal に変更することで、その Receiver が何をしているかがより明確になります。設定ファイルを以下のように更新してください\n​ Prometheus Receiver Configuration prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] ダッシュボード例 - Prometheus メトリクス 以下のスクリーンショットは、Prometheus internal Receiver が OpenTelemetry Collector から収集するメトリクスの一部を表示するダッシュボード例です。ここでは、受け入れられたスパン、メトリクス、ログレコードと送信されたものを確認できます。",
    "tags": [],
    "title": "OpenTelemetry Collector Receivers",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/3-receivers/2-prometheus/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 3. レシーバー",
    "content": "Prometheus レシーバー Prometheus のレシーバーも、もちろんあります。Prometheus は OpenTelemetry Collector で使われているオープンソースのツールキットです。このレシーバーは、OpenTelemetry Collector 自身からメトリクスをスクレイピングするためにも使われます。これらのメトリクスは、コレクタの健全性をモニタリングするために使用できる。\nここでは、prometheus レシーバーを変更して、コレクター自身からメトリクスを収集できるようにしてみます。レシーバーの名前を prometheus から prometheus/internal に変更して、レシーバーが何をしているのかをより明確しましょう。設定ファイルを以下のように更新します：\n​ Prometheus Receiver Configuration prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] 上記の設定では、OpenTelemetry Collector 自身が公開している Prometheus エンドポイントをスクレイピングしています。どのような情報が得られるか、curl コマンドで試すことができます:\ncurl http://localhost:8888/metrics Tips: コンポーネントに名前をつける レシーバー、プロセッサー、エクスポーター、パイプラインなどのコンポーネントは、 otlp や otlp/2 のように、 type[/name] 形式に従った識別子によって定義されます。識別子が一意である限り、与えられたタイプのコンポーネントを複数回定義することができるようになります。\nここでは prometheus/internal という識別子でこのコンポーネントを特定できるようにしたので、別の prometheus レシーバーを追加して、監視対象インスタンスの Prometheus エンドポイントをスクレイピングさせることもできます。\nダッシュボード例 - Prometheus メトリクス このスクリーンショットは、 prometheus/internal レシーバーが OpenTelemetry Collector から収集したメトリクスの、spmeのダッシュボードの例です。ここではスパン・メトリクス・ログの、それぞれの受信および送信の様子を見ることができます。\nメモ このダッシュボードはSplunk Observability Cloud にある組み込みダッシュボードで、Splunk OpenTelemetry Collector のインストールの状況を簡単にモニタリングできます。",
    "description": "Prometheus レシーバー Prometheus のレシーバーも、もちろんあります。Prometheus は OpenTelemetry Collector で使われているオープンソースのツールキットです。このレシーバーは、OpenTelemetry Collector 自身からメトリクスをスクレイピングするためにも使われます。これらのメトリクスは、コレクタの健全性をモニタリングするために使用できる。\nここでは、prometheus レシーバーを変更して、コレクター自身からメトリクスを収集できるようにしてみます。レシーバーの名前を prometheus から prometheus/internal に変更して、レシーバーが何をしているのかをより明確しましょう。設定ファイルを以下のように更新します：\n​ Prometheus Receiver Configuration prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] 上記の設定では、OpenTelemetry Collector 自身が公開している Prometheus エンドポイントをスクレイピングしています。どのような情報が得られるか、curl コマンドで試すことができます:\ncurl http://localhost:8888/metrics Tips: コンポーネントに名前をつける レシーバー、プロセッサー、エクスポーター、パイプラインなどのコンポーネントは、 otlp や otlp/2 のように、 type[/name] 形式に従った識別子によって定義されます。識別子が一意である限り、与えられたタイプのコンポーネントを複数回定義することができるようになります。",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/3-receivers/2-prometheus/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk RUM は業界で唯一のエンドツーエンドのNoSample（サンプリングなし）RUM ソリューションで、すべての Web およびモバイルセッションの完全なユーザーエクスペリエンスに関する可視性を提供し、発生時にすべてのフロントエンドトレースとバックエンドのメトリクス、トレース、ログを独自に組み合わせます。IT オペレーションとエンジニアリングチームは、エラーの範囲を迅速に特定し、優先順位を付け、分離し、パフォーマンスが実際のユーザーにどのように影響するかを測定し、すべてのユーザー操作のビデオ再構築とともにパフォーマンスメトリクスを相関させることでエンドユーザーエクスペリエンスを最適化できます。\n完全なユーザーセッション分析： ストリーミング分析により、シングルページおよびマルチページアプリからの完全なユーザーセッションをキャプチャし、すべてのリソース、画像、ルート変更、API コールの顧客への影響を測定します。\n問題をより迅速に関連付ける： 無限のカーディナリティと完全なトランザクション分析により、複雑な分散システム全体で問題をより迅速に特定し関連付けることができます。\nレイテンシーとエラーの分離： 各コード変更とデプロイメントに対するレイテンシー、エラー、パフォーマンスの低下を簡単に特定します。コンテンツ、画像、サードパーティの依存関係がお客様にどのように影響するかを測定します。\nページパフォーマンスのベンチマークと改善： コアウェブバイタルを活用して、ページ読み込み体験、インタラクティビティ、視覚的安定性を測定し改善します。影響力のある JavaScript エラーを見つけて修正し、最初に改善すべきページを簡単に理解します。\n意味のあるメトリクスの探索： 特定のワークフロー、カスタムタグ、未インデックス化タグの自動提案に関するメトリクスを使用して、顧客への影響を即座に視覚化し、問題の根本原因をすばやく見つけます。\nエンドユーザーエクスペリエンスの最適化： すべてのユーザー操作のビデオ再構築とともにパフォーマンスメトリクスを相関させて、エンドユーザーエクスペリエンスを最適化します。",
    "description": "Splunk RUMについて学び、すべてのWebおよびモバイルセッションの完全なユーザーエクスペリエンスを監視する方法を理解します。",
    "tags": [],
    "title": "Real User Monitoring概要",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/2-rum-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "現在、単一の Synthetic Browser テストの結果を見ています。このテストはビジネストランザクションに分割されています。これは、ビジネス上重要なユーザーフローを表す、論理的に関連する 1 つ以上の操作のグループと考えてください。\n情報 以下のスクリーンショットにはエラーを示す赤いバナーは含まれていませんが、あなたの実行結果には表示されている場合があります。これは、場合によってはテスト実行が失敗することがあり、ワークショップに影響しないため予期されることです。\nフィルムストリップ： サイトのパフォーマンスのスクリーンショットのセットを提供し、ページがリアルタイムでどのように応答するかを確認できます。 ビデオ： 特定のテスト実行の場所とデバイスからあなたのサイトを読み込もうとするユーザーが体験する内容を正確に確認できます。 ブラウザテストメトリクス： ウェブサイトのパフォーマンスの全体像を提供するビューです。 Synthetic トランザクション： サイトとの対話を構成する Synthetic トランザクションのリスト ウォーターフォールチャート ウォーターフォールチャートは、テストランナーとテスト対象サイトの間の対話を視覚的に表現したものです。 デフォルトでは、Splunk Synthetics はテストのスクリーンショットとビデオキャプチャを提供します。これは問題のデバッグに役立ちます。例えば、大きな画像の読み込みが遅い、ページのレンダリングが遅いなどを確認できます。\n演習 マウスを使用してフィルムストリップを左右にスクロールし、テスト実行中にサイトがどのようにレンダリングされていたかを確認します。 ビデオペインで、再生ボタン ▶ を押してテスト再生を見ます。省略記号 ⋮ をクリックすると、再生速度の変更、ピクチャーインピクチャーでの表示、さらにビデオのダウンロードもできます。 Synthetic トランザクションペインのビジネストランザクションヘッダーの下で、最初のボタンHomeをクリックします。 下のウォーターフォールにはページを構成するすべてのオブジェクトが表示されます。最初の行は HTML 自体です。次の行は、ページを構成するオブジェクト（HTML、CSS、JavaScript、画像、フォントなど）です。 ウォーターフォールでGET splunk-otel-web.jsの行を見つけます。 \u003e ボタンをクリックしてメタデータセクションを開き、リクエスト/レスポンスヘッダー情報を確認します。 Synthetic トランザクションペインで、2 番目のビジネストランザクションShopをクリックします。フィルムストリップが調整され、新しいトランザクションの先頭に移動することに注意してください。 他のすべてのトランザクションについても同じことを繰り返し、最後にPlace Orderトランザクションを選択します。",
    "description": "現在、単一の Synthetic Browser テストの結果を見ています。このテストはビジネストランザクションに分割されています。これは、ビジネス上重要なユーザーフローを表す、論理的に関連する 1 つ以上の操作のグループと考えてください。\n情報 以下のスクリーンショットにはエラーを示す赤いバナーは含まれていませんが、あなたの実行結果には表示されている場合があります。これは、場合によってはテスト実行が失敗することがあり、ワークショップに影響しないため予期されることです。\nフィルムストリップ： サイトのパフォーマンスのスクリーンショットのセットを提供し、ページがリアルタイムでどのように応答するかを確認できます。 ビデオ： 特定のテスト実行の場所とデバイスからあなたのサイトを読み込もうとするユーザーが体験する内容を正確に確認できます。 ブラウザテストメトリクス： ウェブサイトのパフォーマンスの全体像を提供するビューです。 Synthetic トランザクション： サイトとの対話を構成する Synthetic トランザクションのリスト ウォーターフォールチャート ウォーターフォールチャートは、テストランナーとテスト対象サイトの間の対話を視覚的に表現したものです。 デフォルトでは、Splunk Synthetics はテストのスクリーンショットとビデオキャプチャを提供します。これは問題のデバッグに役立ちます。例えば、大きな画像の読み込みが遅い、ページのレンダリングが遅いなどを確認できます。\n演習 マウスを使用してフィルムストリップを左右にスクロールし、テスト実行中にサイトがどのようにレンダリングされていたかを確認します。 ビデオペインで、再生ボタン ▶ を押してテスト再生を見ます。省略記号 ⋮ をクリックすると、再生速度の変更、ピクチャーインピクチャーでの表示、さらにビデオのダウンロードもできます。 Synthetic トランザクションペインのビジネストランザクションヘッダーの下で、最初のボタンHomeをクリックします。 下のウォーターフォールにはページを構成するすべてのオブジェクトが表示されます。最初の行は HTML 自体です。次の行は、ページを構成するオブジェクト（HTML、CSS、JavaScript、画像、フォントなど）です。 ウォーターフォールでGET splunk-otel-web.jsの行を見つけます。 \u003e ボタンをクリックしてメタデータセクションを開き、リクエスト/レスポンスヘッダー情報を確認します。 Synthetic トランザクションペインで、2 番目のビジネストランザクションShopをクリックします。フィルムストリップが調整され、新しいトランザクションの先頭に移動することに注意してください。 他のすべてのトランザクションについても同じことを繰り返し、最後にPlace Orderトランザクションを選択します。",
    "tags": [],
    "title": "2. Syntheticsテスト詳細",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/8-synthetics/2-synthetics-detail/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "演習 Custom Eventsタブを選択して、そのタブにいることを確認します。\nCustom Event Latencyチャートを見てください。ここに表示されているメトリクスはアプリケーションのレイテンシーを示しています。横の比較メトリクスは、1 時間前（上部のフィルターバーで選択されています）と比較したレイテンシーを示しています。\nチャートタイトルの下にあるすべて表示リンクをクリックします。\nこのダッシュボードビューでは、RUM データに関連付けられたすべてのタグが表示されます。タグはデータを識別するために使用されるキーと値のペアです。この場合、タグは OpenTelemetry 計装によって自動的に生成されます。タグはデータをフィルタリングし、チャートやテーブルを作成するために使用されます。Tag Spotlight ビューでは、ユーザーセッションを詳しく調べることができます。\n演習 時間枠を過去 1 時間に変更します。 Add filtersをクリックし、OS Versionを選択し、!=をクリックしてSyntheticsとRUMLoadGenを選択し、フィルターを適用ボタンをクリックします。 Custom Events Nameチャートを見つけ、リスト内のPlaceOrderを見つけてクリックし、Add to filterを選択します。 上部のグラフに大きなスパイクがあることに注目してください。 User Sessionタブをクリックします。 Durationの見出しを 2 回クリックして、セッションを期間で並べ替えます（最も長いものが上部に表示されます）。 テーブルの上にあるをクリックし、追加の列のリストからSf Geo Cityを選択し、保存をクリックします。 これで、最も長い期間の降順でソートされたユーザーセッションテーブルができました。このテーブルには、サイトでショッピングしたすべてのユーザーの都市も含まれています。OS バージョン、ブラウザバージョンなど、さらにフィルターを適用してデータを絞り込むこともできます。",
    "description": "演習 Custom Eventsタブを選択して、そのタブにいることを確認します。\nCustom Event Latencyチャートを見てください。ここに表示されているメトリクスはアプリケーションのレイテンシーを示しています。横の比較メトリクスは、1 時間前（上部のフィルターバーで選択されています）と比較したレイテンシーを示しています。\nチャートタイトルの下にあるすべて表示リンクをクリックします。\nこのダッシュボードビューでは、RUM データに関連付けられたすべてのタグが表示されます。タグはデータを識別するために使用されるキーと値のペアです。この場合、タグは OpenTelemetry 計装によって自動的に生成されます。タグはデータをフィルタリングし、チャートやテーブルを作成するために使用されます。Tag Spotlight ビューでは、ユーザーセッションを詳しく調べることができます。\n演習 時間枠を過去 1 時間に変更します。 Add filtersをクリックし、OS Versionを選択し、!=をクリックしてSyntheticsとRUMLoadGenを選択し、フィルターを適用ボタンをクリックします。 Custom Events Nameチャートを見つけ、リスト内のPlaceOrderを見つけてクリックし、Add to filterを選択します。 上部のグラフに大きなスパイクがあることに注目してください。 User Sessionタブをクリックします。 Durationの見出しを 2 回クリックして、セッションを期間で並べ替えます（最も長いものが上部に表示されます）。 テーブルの上にあるをクリックし、追加の列のリストからSf Geo Cityを選択し、保存をクリックします。 これで、最も長い期間の降順でソートされたユーザーセッションテーブルができました。このテーブルには、サイトでショッピングしたすべてのユーザーの都市も含まれています。OS バージョン、ブラウザバージョンなど、さらにフィルターを適用してデータを絞り込むこともできます。",
    "tags": [],
    "title": "2. Tag Spotlight",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/5-rum/2-tag-spotlight/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 6. Advanced Features",
    "content": "APM Waterfall ビューでオリジナルの Trace \u0026 Span (1)（または類似のもの）を選択し、右側のペインから**Memory Stack Traces (2)**を選択してください：\nペインに Memory Stack Trace Flame Graph **(3)**が表示されます。スクロールするか、ペインの右側をドラッグして拡大できます。\nAlwaysOn Profiling は、アプリケーションのコードのスナップショット、つまりスタックトレースを常に取得しています。何千ものスタックトレースを読まなければならないことを想像してみてください！それは現実的ではありません。これを支援するために、AlwaysOn Profiling はプロファイリングデータを集約して要約し、Flame Graphと呼ばれるビューで Call Stacks を探索する便利な方法を提供します。これは、アプリケーションからキャプチャされたすべてのスタックトレースの要約を表します。Flame Graph を使用して、パフォーマンスの問題を引き起こしている可能性のあるコードの行を発見し、コードに加えた変更が意図した効果を持っているかどうかを確認できます。\nAlways-on Profiling をさらに詳しく調べるには、Memory Stack Tracesの下の Profiling Pane で上の画像で参照されている Span **(3)**を選択してください。これにより、Always-on Profiling のメイン画面が開き、Memory ビューがあらかじめ選択されています：\nTime フィルタは、選択したスパンの時間枠に設定されます (1) Java Memory Metric Charts **(2)**では、Heap Memoryのモニター、Memory Allocation RateやGarbage Collecting Metrics などのApplication Activityを確認できます。 スパン **(3)**に関連するメトリクスと Stack Traces のみにフォーカス/表示する機能。これにより、必要に応じて Java アプリケーションで実行されているバックグラウンドアクティビティをフィルタで除外できます。 識別された Java Function calls **(4)**により、その関数から呼び出されたメソッドにドリルダウンできます。 プロファイルされたサービスのスタックトレースに基づく階層の視覚化を持つ Flame Graph (5)。 サービスが複数のバージョンを起動する場合に備えて、Service instance **(6)**を選択する機能。 さらなる調査のために、UI ではスタックトレースをクリックして、呼び出された関数と、フレームチャートから関連する行を確認できます。これを使用して、コーディングプラットフォームで実際のコードの行を表示できます（もちろん、お好みのコーディングプラットフォームによって異なります）。",
    "description": "APM Waterfall ビューでオリジナルの Trace \u0026 Span (1)（または類似のもの）を選択し、右側のペインから**Memory Stack Traces (2)**を選択してください：\nペインに Memory Stack Trace Flame Graph **(3)**が表示されます。スクロールするか、ペインの右側をドラッグして拡大できます。\nAlwaysOn Profiling は、アプリケーションのコードのスナップショット、つまりスタックトレースを常に取得しています。何千ものスタックトレースを読まなければならないことを想像してみてください！それは現実的ではありません。これを支援するために、AlwaysOn Profiling はプロファイリングデータを集約して要約し、Flame Graphと呼ばれるビューで Call Stacks を探索する便利な方法を提供します。これは、アプリケーションからキャプチャされたすべてのスタックトレースの要約を表します。Flame Graph を使用して、パフォーマンスの問題を引き起こしている可能性のあるコードの行を発見し、コードに加えた変更が意図した効果を持っているかどうかを確認できます。\nAlways-on Profiling をさらに詳しく調べるには、Memory Stack Tracesの下の Profiling Pane で上の画像で参照されている Span **(3)**を選択してください。これにより、Always-on Profiling のメイン画面が開き、Memory ビューがあらかじめ選択されています：\nTime フィルタは、選択したスパンの時間枠に設定されます (1) Java Memory Metric Charts **(2)**では、Heap Memoryのモニター、Memory Allocation RateやGarbage Collecting Metrics などのApplication Activityを確認できます。 スパン **(3)**に関連するメトリクスと Stack Traces のみにフォーカス/表示する機能。これにより、必要に応じて Java アプリケーションで実行されているバックグラウンドアクティビティをフィルタで除外できます。 識別された Java Function calls **(4)**により、その関数から呼び出されたメソッドにドリルダウンできます。 プロファイルされたサービスのスタックトレースに基づく階層の視覚化を持つ Flame Graph (5)。 サービスが複数のバージョンを起動する場合に備えて、Service instance **(6)**を選択する機能。 さらなる調査のために、UI ではスタックトレースをクリックして、呼び出された関数と、フレームチャートから関連する行を確認できます。これを使用して、コーディングプラットフォームで実際のコードの行を表示できます（もちろん、お好みのコーディングプラットフォームによって異なります）。",
    "tags": [],
    "title": "Trace Waterfall内のAlways-On Profiling",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/6-profiling-db-query/2-waterfall/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "さて、OpenTelemetry Collector はインストールできました。次は OpenTelemetry Collector のエクステンション（拡張機能）を見てみましょう。エクステンションはオプションで、主にテレメトリーデータの処理を伴わないタスクで使用できます。例としては、ヘルスモニタリング、サービスディスカバリ、データ転送などがあります。\n%%{ init:{ \"theme\": \"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style E fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "さて、OpenTelemetry Collector はインストールできました。次は OpenTelemetry Collector のエクステンション（拡張機能）を見てみましょう。エクステンションはオプションで、主にテレメトリーデータの処理を伴わないタスクで使用できます。例としては、ヘルスモニタリング、サービスディスカバリ、データ転送などがあります。\n%%{ init:{ \"theme\": \"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style E fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/2-extensions/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 9. サービスヘルスダッシュボード",
    "content": "このセクションでは、コピー＆ペースト機能を使用してダッシュボードを拡張します。APM サービスダッシュボードのセクションでいくつかのチャートをコピーしたことを思い出してください。これからそれらのチャートをダッシュボードに追加します。\n演習 ページ上部の 2+ を選択し、チャートの貼り付けを選択します。これにより、カスタムダッシュボードにチャートが作成されます。 現在、チャートはすべてのEnvironmentとServiceのデータを表示しているので、環境とpaymentserviceのフィルターを追加しましょう。 リクエスト率単一値チャートの右上にある 3 つのドット … をクリックします。これにより、チャートが編集モードで開きます。 新しい画面で、画面中央のsf_environment:* xボタン（1）のxをクリックして閉じます。 +をクリックして新しいフィルターを追加し、sf_environmentを選択してからドロップダウンから[ワークショップ名]を選択し、適用を押します。ボタンが**sf_environment:[ワークショップ名]**に変わります。 sf_service.ボタン（2）についても同様に、閉じてsf_serviceの新しいフィルターを作成します。ただし、今回はpaymentserviceに変更します。 保存して閉じるボタン（3）をクリックします。 リクエスト率テキストチャートについても前の 4 つのステップを繰り返します。 2 つのチャートを更新した後、保存をクリックします。 新しく貼り付けられたチャートはダッシュボードの下部に表示されるので、ダッシュボードを再度整理する必要があります。 先ほど学んだドラッグ＆ドロップとリサイズのスキルを使用して、以下の画像のようにダッシュボードを表示させてください。 次に、実行中の Synthetics テストに基づいてカスタムチャートを作成します。",
    "description": "このセクションでは、コピー＆ペースト機能を使用してダッシュボードを拡張します。APM サービスダッシュボードのセクションでいくつかのチャートをコピーしたことを思い出してください。これからそれらのチャートをダッシュボードに追加します。\n演習 ページ上部の 2+ を選択し、チャートの貼り付けを選択します。これにより、カスタムダッシュボードにチャートが作成されます。 現在、チャートはすべてのEnvironmentとServiceのデータを表示しているので、環境とpaymentserviceのフィルターを追加しましょう。 リクエスト率単一値チャートの右上にある 3 つのドット … をクリックします。これにより、チャートが編集モードで開きます。 新しい画面で、画面中央のsf_environment:* xボタン（1）のxをクリックして閉じます。 +をクリックして新しいフィルターを追加し、sf_environmentを選択してからドロップダウンから[ワークショップ名]を選択し、適用を押します。ボタンが**sf_environment:[ワークショップ名]**に変わります。 sf_service.ボタン（2）についても同様に、閉じてsf_serviceの新しいフィルターを作成します。ただし、今回はpaymentserviceに変更します。 保存して閉じるボタン（3）をクリックします。 リクエスト率テキストチャートについても前の 4 つのステップを繰り返します。 2 つのチャートを更新した後、保存をクリックします。 新しく貼り付けられたチャートはダッシュボードの下部に表示されるので、ダッシュボードを再度整理する必要があります。 先ほど学んだドラッグ＆ドロップとリサイズのスキルを使用して、以下の画像のようにダッシュボードを表示させてください。 次に、実行中の Synthetics テストに基づいてカスタムチャートを作成します。",
    "tags": [],
    "title": "コピーしたチャートの追加",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/9-custom-dashboard/2-add-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "特定のログ行を見る前に、これまでに行ったことと、可観測性の 3 本柱に基づいてなぜここにいるのかを簡単に振り返ってみましょう：\nメトリクス トレース ログ 問題がありますか？ 問題はどこですか？ 問題は何ですか？ メトリクスを使用して、アプリケーションに問題があることを特定しました。これはサービスダッシュボードのエラー率が、あるべき値よりも高かったことから明らかでした。 トレースとスパンタグを使用して、問題がどこにあるかを見つけました。paymentserviceにはv350.9とv350.10の 2 つのバージョンがあり、v350.10のエラー率は 100% でした。 paymentserviceのv350.10からのこのエラーが、複数の再試行とオンラインブティックのチェックアウトからの応答の長い遅延を引き起こしたことを確認しました。 トレースから、関連コンテンツの力を使用して、失敗したpaymentserviceバージョンのログエントリに到達しました。これで、問題が何であるかを特定できます。 演習 ログテーブルのエラーエントリをクリックします（リストに別のサービスからのまれなエラーもある場合は、hostname: \"paymentservice-xxxx\"と表示されていることを確認してください）。 ​ 質問 回答 メッセージに基づいて、問題を解決するために開発チームに何を伝えますか？\n開発チームは、有効な API トークンでコンテナを再構築してデプロイするか、v350.9にロールバックする必要があります。\nログメッセージペインのXをクリックして閉じます。 おめでとうございます Splunk Observability Cloud を正常に使用して、オンラインブティックでショッピング中に不良なユーザーエクスペリエンスを体験した理由を理解しました。RUM、APM、ログを使用して、サービス環境で何が起こったかを理解し、その後、可観測性の 3 本柱であるメトリクス、トレース、ログに基づいて根本原因を見つけました。\nまた、アプリケーションの動作パターンを検出するためにTag Spotlightでインテリジェントなタグ付けと分析を使用する方法と、問題のコンテキストを維持しながら異なるコンポーネント間を迅速に移動するために関連コンテンツのフルスタック相関パワーを使用する方法も学びました。\nワークショップの次のパートでは、問題発見モードから緩和、防止、プロセス改善モードに移行します。\n次は、カスタムダッシュボードでのログチャートの作成です。",
    "description": "特定のログ行を見る前に、これまでに行ったことと、可観測性の 3 本柱に基づいてなぜここにいるのかを簡単に振り返ってみましょう：\nメトリクス トレース ログ 問題がありますか？ 問題はどこですか？ 問題は何ですか？ メトリクスを使用して、アプリケーションに問題があることを特定しました。これはサービスダッシュボードのエラー率が、あるべき値よりも高かったことから明らかでした。 トレースとスパンタグを使用して、問題がどこにあるかを見つけました。paymentserviceにはv350.9とv350.10の 2 つのバージョンがあり、v350.10のエラー率は 100% でした。 paymentserviceのv350.10からのこのエラーが、複数の再試行とオンラインブティックのチェックアウトからの応答の長い遅延を引き起こしたことを確認しました。 トレースから、関連コンテンツの力を使用して、失敗したpaymentserviceバージョンのログエントリに到達しました。これで、問題が何であるかを特定できます。 演習 ログテーブルのエラーエントリをクリックします（リストに別のサービスからのまれなエラーもある場合は、hostname: \"paymentservice-xxxx\"と表示されていることを確認してください）。 ​ 質問 回答 メッセージに基づいて、問題を解決するために開発チームに何を伝えますか？\n開発チームは、有効な API トークンでコンテナを再構築してデプロイするか、v350.9にロールバックする必要があります。\nログメッセージペインのXをクリックして閉じます。 おめでとうございます Splunk Observability Cloud を正常に使用して、オンラインブティックでショッピング中に不良なユーザーエクスペリエンスを体験した理由を理解しました。RUM、APM、ログを使用して、サービス環境で何が起こったかを理解し、その後、可観測性の 3 本柱であるメトリクス、トレース、ログに基づいて根本原因を見つけました。",
    "tags": [],
    "title": "2. ログエントリの表示",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/7-log-observer/2-log-entry/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "ワークショップの最初の部分では、OpenTelemetry による自動計装がどのようにして OpenTelemetry Collector に関数がどの言語で書かれているかを自動検出させ、それらの関数のトレースの取得を開始させるかを示します。\n自動計装ワークショップディレクトリとコンテンツ まず、o11y-lambda-workshop/autoディレクトリとそのファイルの一部を見てみましょう。ここにはワークショップの自動計装部分のすべてのコンテンツがあります。\nauto ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/auto ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/auto このディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars 出力には以下のファイルとディレクトリが含まれるはずです：\nget_logs.py main.tf send_message.py handler outputs.tf terraform.tf main.tf ファイル main.tf ファイルをより詳しく見てみましょう：\ncat main.tf ワークショップの質問 このテンプレートによってどの AWS リソースが作成されているか特定できますか？ OpenTelemetry 計装がどこでセットアップされているか特定できますか？ ヒント: Lambda 関数の定義を調べてください 以前に設定した環境変数によってどの計装情報が提供されているか判断できますか？ 各 Lambda 関数の環境変数が設定されているセクションが見つかるはずです。\nenvironment { variables = { SPLUNK_ACCESS_TOKEN = var.o11y_access_token SPLUNK_REALM = var.o11y_realm OTEL_SERVICE_NAME = \"producer-lambda\" OTEL_RESOURCE_ATTRIBUTES = \"deployment.environment=${var.prefix}-lambda-shop\" AWS_LAMBDA_EXEC_WRAPPER = \"/opt/nodejs-otel-handler\" KINESIS_STREAM = aws_kinesis_stream.lambda_streamer.name } } これらの環境変数を使用することで、いくつかの方法で自動計装を構成しています：\n環境変数を設定して、データのエクスポート先となる Splunk Observability Cloud 組織を OpenTelemetry collector に伝えています。\nSPLUNK_ACCESS_TOKEN = var.o11y_access_token SPLUNK_ACCESS_TOKEN = var.o11y_realm また、OpenTelemetry が関数/サービスを識別し、それが属する環境/アプリケーションを認識するのに役立つ変数も設定しています。\nOTEL_SERVICE_NAME = \"producer-lambda\" # consumer関数の場合はconsumer-lambda OTEL_RESOURCE_ATTRIBUTES = \"deployment.environment=${var.prefix}-lambda-shop\" コード言語に基づいて、関数のハンドラーに自動的にトレースデータを取得するために適用する必要があるラッパーを OpenTelemetry に知らせる環境変数を設定しています。\nAWS_LAMBDA_EXEC_WRAPPER - \"/opt/nodejs-otel-handler\" producer-lambda関数の場合、レコードを配置する Kinesis ストリームを関数に知らせるための環境変数を設定しています。\nKINESIS_STREAM = aws_kinesis_stream.lambda_streamer.name これらの値は、「前提条件」セクションで設定した環境変数、および、この Terraform 構成ファイルの一部としてデプロイされるリソースから取得されます。\nまた、各関数に Splunk OpenTelemetry Lambda layer を設定する引数も確認できるはずです\nlayers = var.otel_lambda_layer OpenTelemetry Lambda layer は、Lambda 関数の呼び出し時に計測データを収集、処理、およびエクスポートするために必要なライブラリと依存関係を含むパッケージです。\nすべての OpenTelemetry サポート言語のライブラリと依存関係を持つ一般的な OTel Lambda layer がありますが、関数をさらに軽量化するための言語固有の Lambda layer も存在します。\n各 AWS リージョンの関連する Splunk OpenTelemetry Lambda layer ARN（Amazon Resource Name）と最新バージョンはこちらで確認できます producer.mjs ファイル 次に、producer-lambda関数のコードを見てみましょう：\n以下のコマンドを実行してproducer.mjsファイルの内容を表示します：\ncat ~/o11y-lambda-workshop/auto/handler/producer.mjs この NodeJS モジュールにはプロデューサー関数のコードが含まれています。 基本的に、この関数はメッセージを受け取り、そのメッセージを対象の Kinesis ストリームにレコードとして配置します Lambda 関数のデプロイとトレースデータの生成 autoディレクトリの内容に慣れたところで、ワークショップ用のリソースをデプロイし、Lambda 関数からトレースデータを生成していきます。\nautoディレクトリで Terraform を初期化する main.tfファイルで定義されたリソースをデプロイするには、まず Terraform がそのファイルと同じフォルダで初期化されていることを確認する必要があります。\nauto ディレクトリにいることを確認します:\npwd 予想される出力は ~/o11y-lambda-workshop/auto です auto ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/auto 次のコマンドを実行して、このディレクトリで Terraform を初期化します\nterraform init このコマンドは同じフォルダにいくつかの要素を作成します： .terraform.lock.hcl ファイル：リソースを提供するために使用するプロバイダーを記録します .terraform ディレクトリ：プロバイダーの構成を保存します 上記のファイルに加えて、apply サブコマンドを使用して terraform を実行すると、デプロイされたリソースの状態を追跡するために terraform.tfstate ファイルが作成されます。 これらにより、Terraform は auto ディレクトリの main.tf ファイル内で定義されたとおりに、リソースの作成、状態、破棄を管理できます Lambda 関数とその他の AWS リソースをデプロイする このディレクトリで Terraform を初期化したら、リソースのデプロイに進むことができます。\nまず、terraform plan コマンドを実行して、Terraform が問題なくリソースを作成できることを確認します。\nterraform plan これにより、リソースをデプロイするプランといくつかのデータが出力され、意図したとおりに動作することを確認できます。 プランに表示される値の一部は、作成後に判明するか、セキュリティ上の理由でマスクされていることに注意してください。 次に、terraform apply コマンドを実行して、main.tf ファイルから Lambda 関数とその他のサポートリソースをデプロイします：\nterraform apply Enter a value: プロンプトが表示されたら yes と応答します\nこれにより、以下のような出力が得られます：\nOutputs: base_url = \"https://______.amazonaws.com/serverless_stage/producer\" consumer_function_name = \"_____-consumer\" consumer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-consumer\" consumer_log_group_name = \"/aws/lambda/______-consumer\" environment = \"______-lambda-shop\" lambda_bucket_name = \"lambda-shop-______-______\" producer_function_name = \"______-producer\" producer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-producer\" producer_log_group_name = \"/aws/lambda/______-producer\" Terraform 出力は outputs.tf ファイルで定義されています。 これらの出力は、ワークショップの他の部分でもプログラム的に使用されます。 producer-lambda URL (base_url) にトラフィックを送信する デプロイした Lambda 関数からトレースを取得し始めるには、トラフィックを生成する必要があります。producer-lambda関数のエンドポイントにメッセージを送信し、それを Kinesis ストリームにレコードとして配置し、その後consumer-lambda関数によってストリームから取得されるようにします。\nauto ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/auto です auto ディレクトリにいない場合は、次のコマンドを実行します\ncd ~/o11y-lambda-workshop/auto send_message.py スクリプトは、コマンドラインで入力を受け取り、JSON ディクショナリに追加し、while ループの一部として producer-lambda 関数のエンドポイントに繰り返し送信する Python スクリプトです。\nRun the send_message.py script as a background process\n--name と --superpower 引数が必要です nohup ./send_message.py --name CHANGEME --superpower CHANGEME \u0026 メッセージが成功した場合は、以下のような出力が表示されるはずです\n[1] 79829 user@host manual % appending output to nohup.out ここで重要な情報は 2 つあります: 1 行目のプロセス ID（この例では 79829）、および appending output to nohup.out メッセージ nohup コマンドはスクリプトがバックグラウンドに送られた時に切断されないようにします。また、コマンドからの curl 出力を、現在いるフォルダと同じフォルダにある nohup.out ファイルにキャプチャします。 \u0026 はシェルプロセスにこのプロセスをバックグラウンドで実行するよう指示し、シェルが他のコマンドを実行できるようにします。 次に、response.logs ファイルの内容を確認して、producer-lambda エンドポイントへのリクエストが成功したことを確認します：\ncat response.logs メッセージが成功していれば、画面に印刷された行の中に次の出力が表示されるはずです： {\"message\": \"Message placed in the Event Stream: {prefix}-lambda_stream\"} 失敗した場合は、次のように表示されます： {\"message\": \"Internal server error\"} 重要 この場合は、ワークショップ進行役の一人に支援を求めてください。\nLambda 関数のログを表示する 次に、Lambda 関数のログを確認しましょう。\nproducer-lambda ログを表示するには、producer.logs ファイルを確認します：\ncat producer.logs consumer-lambda ログを表示するには、consumer.logs ファイルを確認します：\ncat consumer.logs ログを注意深く調べてください。\nワークショップの質問 OpenTelemetry が読み込まれているのが見えますか？splunk-extension-wrapperのある行に注目してください splunk-extension-wrapperが読み込まれているのを見るためにhead -n 50 producer.logsまたはhead -n 50 consumer.logsの実行を検討してください。",
    "description": "ワークショップの最初の部分では、OpenTelemetry による自動計装がどのようにして OpenTelemetry Collector に関数がどの言語で書かれているかを自動検出させ、それらの関数のトレースの取得を開始させるかを示します。\n自動計装ワークショップディレクトリとコンテンツ まず、o11y-lambda-workshop/autoディレクトリとそのファイルの一部を見てみましょう。ここにはワークショップの自動計装部分のすべてのコンテンツがあります。\nauto ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/auto ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/auto このディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars 出力には以下のファイルとディレクトリが含まれるはずです：\nget_logs.py main.tf send_message.py handler outputs.tf terraform.tf main.tf ファイル main.tf ファイルをより詳しく見てみましょう：",
    "tags": [],
    "title": "自動計装",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/2-auto-instrumentation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 2. RUM概要",
    "content": "メインメニューのRUMをクリックすると、RUM のメインホームページ（ランディングページ）に移動します。このページの主な概念は、選択したすべての RUM アプリケーションの全体的な状態を、フルダッシュボードまたはコンパクトビューのいずれかで一目で提供することです。\n使用する状態ダッシュボードのタイプに関係なく、RUM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk RUM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。（画面のスペースが必要な場合、このペインを非表示にすることができます。） フィルターペイン: 時間枠、環境、アプリケーション、ソースタイプでフィルタリングします。 アプリケーションサマリーペイン: RUM データを送信するすべてのアプリケーションの概要。 RUM環境とアプリケーション、およびソースタイプ Splunk Observability は、RUM トレースの一部として送信されるEnvironmentタグ（ウェブサイトやモバイルアプリとの各操作で作成される）を使用して、「本番環境」や「開発環境」などの異なる環境からのデータを分離します。 さらに アプリケーション(App) タグによる分離も可能です。これにより、同じ環境で実行されている別々のブラウザ/モバイルアプリケーションを区別することができます。 Splunk RUM はブラウザとモバイルアプリケーションの両方で利用可能です。Source タイプを使用してそれらを区別することも可能ですが、このワークショップではブラウザベースの RUM のみを使用します。 演習 時間ウィンドウが -15m に設定されていることを確認します ドロップダウンボックスからワークショップの環境を選択します。命名規則は [ワークショップ名]-workshop です（これを選択すると、ワークショップ RUM アプリケーションが表示されます） App名を選択します。命名規則は [ワークショップ名]-store で、Sourceはすべてのままにしておきます JavaScript Errorsタイルで、TypeErrorエントリ：Cannot read properties of undefined (reading ‘Prcie’) をクリックして詳細を確認します。ウェブサイトのどの部分でエラーが発生したかを素早く示してくれることに注意してください。これにより、迅速に修正することができます。 ペインを閉じます。 3 番目のタイルはWeb Vitalsを報告します。これはユーザーエクスペリエンスの 3 つの重要な側面である読み込み、対話性、視覚的安定性に焦点を当てたメトリクスです。 ​ 質問 回答 Web Vitals メトリクスに基づいて、現在のウェブサイトのパフォーマンスをどのように評価しますか？\nWeb Vitals メトリクスによれば、サイトの初期読み込みは良好であり、Goodと評価されています\n最後のタイル、Most recent alerts タイルは、アプリケーションに対してアラートが発生しているかどうかを表示します。 アプリケーション名の前にある下向き矢印 ⌵ をクリックして、ビューをコンパクトスタイルに切り替えます。このビューでもすべての主要情報が利用可能であることに注目してください。コンパクトビューの任意の場所をクリックすると、フルビューに戻ります。 次に、Splunk Application Performance Monitoring（APM） を確認しましょう。",
    "description": "メインメニューのRUMをクリックすると、RUM のメインホームページ（ランディングページ）に移動します。このページの主な概念は、選択したすべての RUM アプリケーションの全体的な状態を、フルダッシュボードまたはコンパクトビューのいずれかで一目で提供することです。\n使用する状態ダッシュボードのタイプに関係なく、RUM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk RUM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。（画面のスペースが必要な場合、このペインを非表示にすることができます。） フィルターペイン: 時間枠、環境、アプリケーション、ソースタイプでフィルタリングします。 アプリケーションサマリーペイン: RUM データを送信するすべてのアプリケーションの概要。 RUM環境とアプリケーション、およびソースタイプ Splunk Observability は、RUM トレースの一部として送信されるEnvironmentタグ（ウェブサイトやモバイルアプリとの各操作で作成される）を使用して、「本番環境」や「開発環境」などの異なる環境からのデータを分離します。 さらに アプリケーション(App) タグによる分離も可能です。これにより、同じ環境で実行されている別々のブラウザ/モバイルアプリケーションを区別することができます。 Splunk RUM はブラウザとモバイルアプリケーションの両方で利用可能です。Source タイプを使用してそれらを区別することも可能ですが、このワークショップではブラウザベースの RUM のみを使用します。 演習 時間ウィンドウが -15m に設定されていることを確認します ドロップダウンボックスからワークショップの環境を選択します。命名規則は [ワークショップ名]-workshop です（これを選択すると、ワークショップ RUM アプリケーションが表示されます） App名を選択します。命名規則は [ワークショップ名]-store で、Sourceはすべてのままにしておきます JavaScript Errorsタイルで、TypeErrorエントリ：Cannot read properties of undefined (reading ‘Prcie’) をクリックして詳細を確認します。ウェブサイトのどの部分でエラーが発生したかを素早く示してくれることに注意してください。これにより、迅速に修正することができます。 ペインを閉じます。 3 番目のタイルはWeb Vitalsを報告します。これはユーザーエクスペリエンスの 3 つの重要な側面である読み込み、対話性、視覚的安定性に焦点を当てたメトリクスです。 ​ 質問 回答 Web Vitals メトリクスに基づいて、現在のウェブサイトのパフォーマンスをどのように評価しますか？",
    "tags": [],
    "title": "Real User Monitoring ホームページ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/2-rum-home/1-rum-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 2. Extensions",
    "content": "Performance Profiler Performance Profiler 拡張機能は、golang の net/http/pprof エンドポイントを有効にします。これは通常、開発者がパフォーマンスプロファイルを収集し、サービスの問題を調査するために使用されます。このワークショップではこれを扱いません。",
    "description": "Performance Profiler Performance Profiler 拡張機能は、golang の net/http/pprof エンドポイントを有効にします。これは通常、開発者がパフォーマンスプロファイルを収集し、サービスの問題を調査するために使用されます。このワークショップではこれを扱いません。",
    "tags": [],
    "title": "OpenTelemetry Collector Extensions",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/2-extensions/2-performance/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 2. エクステンション",
    "content": "Performance Profiler エクステンション Performance Profiler エクステンションは、Go の net/http/pprof エンドポイントを有効化します。これは通常、開発者がパフォーマンスプロファイルを収集し、サービスの問題を調査するために使用します。このワークショップでは詳しく紹介はしません。",
    "description": "Performance Profiler エクステンション Performance Profiler エクステンションは、Go の net/http/pprof エンドポイントを有効化します。これは通常、開発者がパフォーマンスプロファイルを収集し、サービスの問題を調査するために使用します。このワークショップでは詳しく紹介はしません。",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/2-extensions/2-performance/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 2. Building Resilience",
    "content": "次に、File Storage 設定をテストする準備として環境を設定します。\nExercise Gateway の起動: Gateway ターミナル ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent の起動: Agent ターミナル ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml 5つのテストスパンを送信: Loadgen ターミナル ウィンドウで以下を実行します\n​ Start Load Generator ../loadgen -count 5 Agent と Gateway の両方がデバッグログを表示し、Gateway が ./gateway-traces.out ファイルを作成するはずです。\nすべてが正常に機能している場合、システムの耐障害性のテストに進むことができます。",
    "description": "次に、File Storage 設定をテストする準備として環境を設定します。\nExercise Gateway の起動: Gateway ターミナル ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent の起動: Agent ターミナル ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml 5つのテストスパンを送信: Loadgen ターミナル ウィンドウで以下を実行します\n​ Start Load Generator ../loadgen -count 5 Agent と Gateway の両方がデバッグログを表示し、Gateway が ./gateway-traces.out ファイルを作成するはずです。",
    "tags": [],
    "title": "2.2 耐障害性テスト用の環境セットアップ",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/2-building-resilience/2-2-test-environment/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 3. APM概要",
    "content": "メインメニューのAPMをクリックすると、APM ホームページが表示されます。APM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk APM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 APM 概要ペイン: トップサービスとトップビジネスワークフローのリアルタイムメトリクス。 機能ペイン: サービス、タグ、トレース、データベースクエリパフォーマンス、コードプロファイリングの詳細分析へのリンク。 APM 概要ペインは、アプリケーションの健全性の高レベルの概要を提供します。これにはアプリケーション内のサービス、レイテンシー、エラーの概要が含まれます。また、エラー率別のトップサービスとエラー率別のトップビジネスワークフローのリストも含まれています（ビジネスワークフローは、特定のアクティビティやトランザクションに関連するトレースコレクションの開始から終了までの旅程であり、エンドツーエンドの KPI の監視やルート原因とボトルネックの特定を可能にします）。\n環境について 複数のアプリケーションを簡単に区別するために、Splunk は Environment を使用します。ワークショップ環境の命名規則は [ワークショップ名]-workshop です。インストラクターが選択する正しい環境を提供します。\n演習 作業している時間ウィンドウが過去 15 分（-15m）に設定されていることを確認します。 ドロップダウンボックスからワークショップ名を選択して、環境をワークショップ用に変更し、それのみが選択されていることを確認します。 ​ 質問 回答 エラー率別のトップサービスチャートから何を結論づけることができますか？\npaymentserviceはエラー率が高い\n概要ページを下にスクロールすると、一部のサービスの横にInferred Serviceと表示されていることに気づくでしょう。\nSplunk APM は、リモートサービスを呼び出すスパンが必要な情報を持っている場合、リモートサービスまたは推測されたサービスの存在を推測できます。推測されるサービスの例としては、データベース、HTTP エンドポイント、メッセージキューなどがあります。推測されたサービスは計装されていませんが、サービスマップとサービスリストに表示されます。\n次に、Splunk ログオブザーバー（LO） を確認しましょう。",
    "description": "メインメニューのAPMをクリックすると、APM ホームページが表示されます。APM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk APM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 APM 概要ペイン: トップサービスとトップビジネスワークフローのリアルタイムメトリクス。 機能ペイン: サービス、タグ、トレース、データベースクエリパフォーマンス、コードプロファイリングの詳細分析へのリンク。 APM 概要ペインは、アプリケーションの健全性の高レベルの概要を提供します。これにはアプリケーション内のサービス、レイテンシー、エラーの概要が含まれます。また、エラー率別のトップサービスとエラー率別のトップビジネスワークフローのリストも含まれています（ビジネスワークフローは、特定のアクティビティやトランザクションに関連するトレースコレクションの開始から終了までの旅程であり、エンドツーエンドの KPI の監視やルート原因とボトルネックの特定を可能にします）。\n環境について 複数のアプリケーションを簡単に区別するために、Splunk は Environment を使用します。ワークショップ環境の命名規則は [ワークショップ名]-workshop です。インストラクターが選択する正しい環境を提供します。\n演習 作業している時間ウィンドウが過去 15 分（-15m）に設定されていることを確認します。 ドロップダウンボックスからワークショップ名を選択して、環境をワークショップ用に変更し、それのみが選択されていることを確認します。 ​ 質問 回答 エラー率別のトップサービスチャートから何を結論づけることができますか？\npaymentserviceはエラー率が高い",
    "tags": [],
    "title": "Application Performance Monitoring ホームページ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/3-apm-home/1-apm-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 3. Spanのドロップ",
    "content": "設定をテストするには、\"/_healthz\" という名前のSpanを含むトレースデータを生成する必要があります。\nExercise Gatewayを起動する：Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config ./gateway.yaml Agentを起動する：Agent terminal ウィンドウで Agent を起動します。\n../otelcol --config ./agent.yaml Loadgenを起動する：Loadgen terminal ウィンドウで、次のコマンドを実行してヘルスチェックSpanを有効にした状態でロードジェネレーターを起動します\n../loadgen -health -count 5 Agent terminal のデバッグ出力に _healthz Spanが表示されます\nInstrumentationScope healthz 1.0.0 Span #0 Trace ID : 0cce8759b5921c8f40b346b2f6e2f4b6 Parent ID : ID : bc32bd0e4ddcb174 Name : /_healthz Kind : Server Start time : 2025-07-11 08:47:50.938703979 +0000 UTC End time : 2025-07-11 08:47:51.938704091 +0000 UTC Status code : Ok Status message : Success これらは、先ほど設定したFilter Processorによってドロップされるため、Gateway のデバッグ出力には表示されません。\nagent.out を確認する：Test terminal で jq を使用して、Agent が受信したSpanの名前を確認します\n​ Check spans in agent.out Example output jq -c '.resourceSpans[].scopeSpans[].spans[] | \"Span \\(input_line_number) found with name \\(.name)\"' ./agent.out \"Span 1 found with name /movie-validator\" \"Span 2 found with name /_healthz\" \"Span 3 found with name /movie-validator\" \"Span 4 found with name /_healthz\" \"Span 5 found with name /movie-validator\" \"Span 6 found with name /_healthz\" \"Span 7 found with name /movie-validator\" \"Span 8 found with name /_healthz\" \"Span 9 found with name /movie-validator\" \"Span 10 found with name /_healthz\" Gateway のデバッグ出力を確認する：jq を使用して、Gateway が受信したSpanの名前を確認します\n​ Check spans in gateway-traces.out Example output jq -c '.resourceSpans[].scopeSpans[].spans[] | \"Span \\(input_line_number) found with name \\(.name)\"' ./gateway-traces.out gateway-metrics.out ファイルには /_healthz という名前のSpanは含まれません。\n\"Span 1 found with name /movie-validator\" \"Span 2 found with name /movie-validator\" \"Span 3 found with name /movie-validator\" \"Span 4 found with name /movie-validator\" \"Span 5 found with name /movie-validator\" Tip Filter Processorで最適なパフォーマンスを確保するには、受信データの形式を十分に理解し、設定を厳密にテストしてください。できるだけ具体的なフィルタリング条件を使用して、重要なデータを誤ってドロップするリスクを最小限に抑えてください。\nこの設定は、さまざまな属性、タグ、またはカスタム条件に基づいてSpanをフィルタリングするように拡張でき、特定のオブザーバビリティ要件に合わせて OpenTelemetry Collector の柔軟性と効率を向上させることができます。\n重要 Agent と Gateway プロセスを、それぞれのターミナルで Ctrl-C を押して停止してください。",
    "description": "設定をテストするには、\"/_healthz\" という名前のSpanを含むトレースデータを生成する必要があります。\nExercise Gatewayを起動する：Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config ./gateway.yaml Agentを起動する：Agent terminal ウィンドウで Agent を起動します。\n../otelcol --config ./agent.yaml Loadgenを起動する：Loadgen terminal ウィンドウで、次のコマンドを実行してヘルスチェックSpanを有効にした状態でロードジェネレーターを起動します\n../loadgen -health -count 5 Agent terminal のデバッグ出力に _healthz Spanが表示されます\nInstrumentationScope healthz 1.0.0 Span #0 Trace ID : 0cce8759b5921c8f40b346b2f6e2f4b6 Parent ID : ID : bc32bd0e4ddcb174 Name : /_healthz Kind : Server Start time : 2025-07-11 08:47:50.938703979 +0000 UTC End time : 2025-07-11 08:47:51.938704091 +0000 UTC Status code : Ok Status message : Success これらは、先ほど設定したFilter Processorによってドロップされるため、Gateway のデバッグ出力には表示されません。",
    "tags": [],
    "title": "3.2 Filter Processorのテスト",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/3-dropping-spans/3-2-test-filter/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 4. Log Observer概要",
    "content": "メインメニューのLog Observerをクリックすると、Log Observer ホームページが表示されます。Log Observer ホームページは 4 つの明確なセクションで構成されています：\nオンボーディングペイン: SplunkLog Observer の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 フィルターバー: 時間、インデックス、フィールドでフィルタリングし、クエリを保存することもできます。 ログテーブルペイン: 現在のフィルター条件に一致するログエントリのリスト。 フィールドペイン: 現在選択されているインデックスで利用可能なフィールドのリスト。 Splunk Index 一般的に、Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk 内のデータは、検索や分析が容易になるように整理され構造化されています。特定のタイプのデータを保存するために異なるインデックスを作成できます。たとえば、Web サーバーログ用のインデックス、アプリケーションログ用の別のインデックスなどがあります。\nヒント 以前に Splunk Enterprise または Splunk Cloud を使用したことがある場合は、おそらくログから調査を開始することに慣れているでしょう。以下の演習で見るように、Splunk Observability Cloud でも同様のことができます。ただし、このワークショップでは、調査にOpenTelemetryのすべてのシグナルを使用します。\n簡単な検索演習を行いましょう：\n演習 時間枠を -15m に設定します。\nフィルターバーでAdd Filterをクリックし、ダイアログでFieldをクリックします。\ncardTypeと入力して選択します。\nトップ値の下でvisaをクリックし、次に = をクリックしてフィルターに追加します。\nログテーブルのログエントリの 1 つをクリックして、エントリにcardType: \"visa\"が含まれていることを確認します。\n出荷されたすべての注文を見つけましょう。フィルターバーのClear Allをクリックして、前のフィルターを削除します。\nフィルターバーで再びAdd Filterをクリックし、キーワードを選択します。次に**キーワードを入力…**ボックスにorder:と入力し、Enter キーを押します。\nこれで「order:」という単語を含むログ行のみが表示されるはずです。まだたくさんのログ行があるので、さらにフィルタリングしましょう。\n別のフィルターを追加します。今回はFieldボックスを選択し、Find a field … 検索ボックスにseverityと入力して選択します。 注文ログ行には重要度が割り当てられていないため、ダイアログボックスの下部にあるExclude all logs with this fieldをクリックしてください。これにより、他のログが削除されます。\n上部にオンボーディングコンテンツがまだ表示されている場合は、Exclude all logs with this fieldボタンを見るためにページを下にスクロールする必要があるかもしれません。\nこれで、過去 15 分間に販売された注文のリストが表示されるはずです。\n次に、Splunk Syntheticsを確認しましょう。",
    "description": "メインメニューのLog Observerをクリックすると、Log Observer ホームページが表示されます。Log Observer ホームページは 4 つの明確なセクションで構成されています：\nオンボーディングペイン: SplunkLog Observer の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 フィルターバー: 時間、インデックス、フィールドでフィルタリングし、クエリを保存することもできます。 ログテーブルペイン: 現在のフィルター条件に一致するログエントリのリスト。 フィールドペイン: 現在選択されているインデックスで利用可能なフィールドのリスト。 Splunk Index 一般的に、Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk 内のデータは、検索や分析が容易になるように整理され構造化されています。特定のタイプのデータを保存するために異なるインデックスを作成できます。たとえば、Web サーバーログ用のインデックス、アプリケーションログ用の別のインデックスなどがあります。\nヒント 以前に Splunk Enterprise または Splunk Cloud を使用したことがある場合は、おそらくログから調査を開始することに慣れているでしょう。以下の演習で見るように、Splunk Observability Cloud でも同様のことができます。ただし、このワークショップでは、調査にOpenTelemetryのすべてのシグナルを使用します。\n簡単な検索演習を行いましょう：\n演習 時間枠を -15m に設定します。\nフィルターバーでAdd Filterをクリックし、ダイアログでFieldをクリックします。",
    "tags": [],
    "title": "Log Observerホームページ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/4-log-observer-home/1-log-observer-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 4. 機密データ",
    "content": "この演習では、Agent がエクスポートする前に、Spanデータから user.account_password を削除し、user.phone_number 属性を更新し、user.email をハッシュ化します。\nExercise Gatewayを起動する：Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config=gateway.yaml Agentを起動する：Agent terminal ウィンドウで Agent を起動します。\n../otelcol --config=agent.yaml Load Generatorを起動する：Loadgen terminal ウィンドウで loadgen を起動します\n../loadgen -count 1 デバッグ出力を確認する：Agent と Gateway の両方で、user.account_password が削除され、user.phone_number と user.email が更新されていることを確認します\n​ New Debug Output Original Debug Output -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(UNKNOWN NUMBER) -\u003e user.email: Str(62d5e03d8fd5808e77aee5ebbd90cf7627a470ae0be9ffd10e8025a4ad0e1287) -\u003e payment.amount: Double(51.71) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(+1555-867-5309) -\u003e user.email: Str(george@deathstar.email) -\u003e user.password: Str(LOTR\u003eStarWars1-2-3) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) -\u003e payment.amount: Double(95.22) ファイル出力を確認する：jq を使用して、gateway-traces.out で user.account_password が削除され、user.phone_number と user.email が更新されていることを検証します\n​ Validate attribute changes Output jq '.resourceSpans[].scopeSpans[].spans[].attributes[] | select(.key == \"user.password\" or .key == \"user.phone_number\" or .key == \"user.email\") | {key: .key, value: .value.stringValue}' ./gateway-traces.out user.account_password が削除され、user.phone_number と user.email が更新されていることに注目してください\n{ \"key\": \"user.phone_number\", \"value\": \"UNKNOWN NUMBER\" } { \"key\": \"user.email\", \"value\": \"62d5e03d8fd5808e77aee5ebbd90cf7627a470ae0be9ffd10e8025a4ad0e1287\" } 重要 Agent と Gateway プロセスを、それぞれのターミナルで Ctrl-C を押して停止してください。",
    "description": "この演習では、Agent がエクスポートする前に、Spanデータから user.account_password を削除し、user.phone_number 属性を更新し、user.email をハッシュ化します。\nExercise Gatewayを起動する：Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config=gateway.yaml Agentを起動する：Agent terminal ウィンドウで Agent を起動します。\n../otelcol --config=agent.yaml Load Generatorを起動する：Loadgen terminal ウィンドウで loadgen を起動します\n../loadgen -count 1 デバッグ出力を確認する：Agent と Gateway の両方で、user.account_password が削除され、user.phone_number と user.email が更新されていることを確認します\n​ New Debug Output Original Debug Output -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(UNKNOWN NUMBER) -\u003e user.email: Str(62d5e03d8fd5808e77aee5ebbd90cf7627a470ae0be9ffd10e8025a4ad0e1287) -\u003e payment.amount: Double(51.71) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(+1555-867-5309) -\u003e user.email: Str(george@deathstar.email) -\u003e user.password: Str(LOTR\u003eStarWars1-2-3) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) -\u003e payment.amount: Double(95.22) ファイル出力を確認する：jq を使用して、gateway-traces.out で user.account_password が削除され、user.phone_number と user.email が更新されていることを検証します",
    "tags": [],
    "title": "4.2 Attribute Processorのテスト",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/4-sensitive-data/4-2-test-delete-tag/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 4. Processors",
    "content": "Resource Detection Processor resourcedetection processor は、ホストからリソース情報を検出し、テレメトリデータのリソース値にこの情報を追加または上書きするために使用できます。\nデフォルトでは、ホスト名は可能であれば FQDN に設定され、それ以外の場合は OS が提供するホスト名がフォールバックとして使用されます。このロジックは hostname_sources 設定オプションを使用して変更できます。FQDN を取得せずに OS が提供するホスト名を使用するには、hostname_sources を os に設定します。\n​ System Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] ワークショップインスタンスが AWS/EC2 インスタンスで実行されている場合、EC2 メタデータ API から以下のタグを収集できます（これは他のプラットフォームでは利用できません）。\ncloud.provider (\"aws\") cloud.platform (\"aws_ec2\") cloud.account.id cloud.region cloud.availability_zone host.id host.image.id host.name host.type これらのタグをメトリクスに追加するために、別の processor を作成します。\n​ EC2 Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2]",
    "description": "Resource Detection Processor resourcedetection processor は、ホストからリソース情報を検出し、テレメトリデータのリソース値にこの情報を追加または上書きするために使用できます。\nデフォルトでは、ホスト名は可能であれば FQDN に設定され、それ以外の場合は OS が提供するホスト名がフォールバックとして使用されます。このロジックは hostname_sources 設定オプションを使用して変更できます。FQDN を取得せずに OS が提供するホスト名を使用するには、hostname_sources を os に設定します。\n​ System Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] ワークショップインスタンスが AWS/EC2 インスタンスで実行されている場合、EC2 メタデータ API から以下のタグを収集できます（これは他のプラットフォームでは利用できません）。",
    "tags": [],
    "title": "OpenTelemetry Collector Processors",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/4-processors/2-resource-detection/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 4. プロセッサー",
    "content": "Resource Detection プロセッサー resourcedetection プロセッサーは、ホストからリソース情報を検出して、テレメトリーデータ内のリソース値をこの情報で追加または上書きすることができます。\nデフォルトでは、可能であればホスト名を FQDN に設定し、そうでなければ OS が提供するホスト名になります。このロジックは hostname_sources オプションを使って変更できます。FQDN を取得せず、OSが提供するホスト名を使用するには、hostname_sourcesをosに設定します。\n​ System Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] If the workshop instance is running on an AWS/EC2 instance we can gather the following tags from the EC2 metadata API (this is not available on other platforms). ワークショップのインスタンスが AWS/EC2 インスタンスで実行されている場合、EC2 のメタデータ API から以下のタグを収集します（これは他のプラットフォームでは利用できないものもあります）。\ncloud.provider (\"aws\") cloud.platform (\"aws_ec2\") cloud.account.id cloud.region cloud.availability_zone host.id host.image.id host.name host.type これらのタグをメトリクスに追加するために、別のプロセッサーとして定義してみましょう。\n​ EC2 Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2]",
    "description": "Resource Detection プロセッサー resourcedetection プロセッサーは、ホストからリソース情報を検出して、テレメトリーデータ内のリソース値をこの情報で追加または上書きすることができます。\nデフォルトでは、可能であればホスト名を FQDN に設定し、そうでなければ OS が提供するホスト名になります。このロジックは hostname_sources オプションを使って変更できます。FQDN を取得せず、OSが提供するホスト名を使用するには、hostname_sourcesをosに設定します。\n​ System Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] If the workshop instance is running on an AWS/EC2 instance we can gather the following tags from the EC2 metadata API (this is not available on other platforms). ワークショップのインスタンスが AWS/EC2 インスタンスで実行されている場合、EC2 のメタデータ API から以下のタグを収集します（これは他のプラットフォームでは利用できないものもあります）。",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/4-processors/2-resource-detection/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 5. Synthetics概要",
    "content": "メインメニューのSyntheticsをクリックします。これにより、Synthetics ホームページに移動します。このページには、役立つ情報を提供するか、Synthetic テストを選択または作成できる 3 つの明確なセクションがあります。\nオンボーディングペイン: SplunkSynthetics の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 テストペイン: 設定されているすべてのテスト（ブラウザ、API、稼働時間）のリスト。 テスト作成ペイン: 新しい Synthetic テストを作成するためのドロップダウン。 情報 ワークショップの一環として、実行しているアプリケーションに対するデフォルトのブラウザテストを作成しています。テストペイン（2）でそれを見つけることができます。名前はWorkshop Browser Test forで、その後にワークショップの名前が続きます（インストラクターがそれを提供しているはずです）。\nツアーを続けるために、ワークショップの自動ブラウザテストの結果を見てみましょう。\n演習 テストペインで、ワークショップの名前を含む行をクリックします。結果は次のようになります： 注意：Synthetic テストページでは、最初のペインに過去 1 日、8 日、30 日間のサイトのパフォーマンスが表示されます。上のスクリーンショットに示すように、テストが過去に十分遡って開始された場合のみ、対応するチャートに有効なデータが含まれます。ワークショップでは、これはワークショップが作成された時期によって異なります。 パフォーマンス KPI ドロップダウンで、デフォルトの 4 時間から過去 1 時間に時間を変更します。 ​ 質問 回答 テストはどのくらいの頻度で、どこから実行されていますか？\nテストは1 分間隔でラウンドロビン方式によりフランクフルト、ロンドン、パリから実行されています\n次に、Splunk インフラストラクチャモニタリング（IM） を使用して、アプリケーションが実行されているインフラストラクチャを調べてみましょう。",
    "description": "メインメニューのSyntheticsをクリックします。これにより、Synthetics ホームページに移動します。このページには、役立つ情報を提供するか、Synthetic テストを選択または作成できる 3 つの明確なセクションがあります。\nオンボーディングペイン: SplunkSynthetics の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 テストペイン: 設定されているすべてのテスト（ブラウザ、API、稼働時間）のリスト。 テスト作成ペイン: 新しい Synthetic テストを作成するためのドロップダウン。 情報 ワークショップの一環として、実行しているアプリケーションに対するデフォルトのブラウザテストを作成しています。テストペイン（2）でそれを見つけることができます。名前はWorkshop Browser Test forで、その後にワークショップの名前が続きます（インストラクターがそれを提供しているはずです）。\nツアーを続けるために、ワークショップの自動ブラウザテストの結果を見てみましょう。\n演習 テストペインで、ワークショップの名前を含む行をクリックします。結果は次のようになります： 注意：Synthetic テストページでは、最初のペインに過去 1 日、8 日、30 日間のサイトのパフォーマンスが表示されます。上のスクリーンショットに示すように、テストが過去に十分遡って開始された場合のみ、対応するチャートに有効なデータが含まれます。ワークショップでは、これはワークショップが作成された時期によって異なります。 パフォーマンス KPI ドロップダウンで、デフォルトの 4 時間から過去 1 時間に時間を変更します。 ​ 質問 回答 テストはどのくらいの頻度で、どこから実行されていますか？",
    "tags": [],
    "title": "Syntheticsホームページ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/5-synthetics-home/1-synthetics-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 5. Transform Data",
    "content": "Exercise Gateway を起動する: Gateway terminal で以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent を起動する: Agent terminal で以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Load Generator を起動する: Loadgen terminal ウィンドウで、次のコマンドを実行して JSON を有効にした Load Generator を起動します\n​ Log Generator ../loadgen -logs -json -count 5 loadgen は JSON 形式で 5 行のログを ./quotes.log に書き込みます。",
    "description": "Exercise Gateway を起動する: Gateway terminal で以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent を起動する: Agent terminal で以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Load Generator を起動する: Loadgen terminal ウィンドウで、次のコマンドを実行して JSON を有効にした Load Generator を起動します\n​ Log Generator ../loadgen -logs -json -count 5 loadgen は JSON 形式で 5 行のログを ./quotes.log に書き込みます。",
    "tags": [],
    "title": "5.2 Setup Environment",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/5-transform-data/5-2-setup/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 6. インフラストラクチャ概要",
    "content": "メインメニューのInfrastructureをクリックすると、Infrastructure ホームページが表示されます。このページは 4 つの異なるセクションで構成されています。\nオンボーディングペイン: SplunkInfrastructure モニタリングの使用を開始するためのトレーニングビデオとドキュメントへのリンク。 時間とフィルターペイン: 時間ウィンドウ（トップレベルでは設定できません） インテグレーションペイン: Splunk Observability Cloud にメトリクスを送信しているすべてのテクノロジーのリスト。 タイルペイン: インテグレーション別に分類された、監視されているサービスの総数。 Infrastructure ペインを使用して、関心のある Infrastructure/テクノロジーを選択できます。早速試してみましょう。\n演習 インテグレーションペイン（3）のコンテナセクションで、調査したいテクノロジーとしてKubernetesを選択します。\nすると、K8s ノードとK8s ワークロードの 2 つのタイルが表示されます。\n各タイルの下部には履歴グラフが表示され、上部にはアラートが発生した通知が表示されます。すべてのタイルで、各タイルのこの追加情報により、Infrastructure の健全性の良い概要が得られます。\nK8s ノードタイルをクリックします。\nKubernetes クラスターの表示が一つ以上表示されます。\nフィルターを追加ボタンをクリックします。k8s.cluster.nameと入力し、検索結果をクリックします。\nリストから**[ワークショップ名]-k3s-cluster**を選択し、フィルターを適用ボタンをクリックします。\nKubernetes ナビゲーターは色を使用して健全性を示します。ご覧のように、失敗状態（1）にある 2 つの不健全なポッドまたはサービスがあります。残りは健全で実行中です。これは共有 Kubernetes 環境では珍しくないため、ワークショップ用にこの状況を再現しました。\n側面のタイル、特にノード依存関係（2）の下の MySQL と Redis のタイルに注目してください。これらは私たちの E コマースアプリケーションで使用されている 2 つのデータベースです。\nノード依存関係 UI では、OpenTelemetry コレクターによって監視するよう設定されている場合、選択したノードで実行されているサービスが表示されます。\n演習 Redisタイルをクリックすると、Redis インスタンスナビゲーターに移動します。REDIS インスタンスの下で**redis-[ワークショップ名]**をクリックします。 これによりRedis インスタンスに移動します。このナビゲーターでは、E コマースサイトのアクティブな Redis インスタンスからのメトリクスデータのチャートが表示されます。 ​ 質問 回答 このビューでインスタンス依存関係タイルの名前を言えますか？\nはい、Kubernetes のものがあります。\nタイルをクリックすると、Kubernetes ナビゲーターに戻りますが、今回は Redis サービスを実行している Pod を表示する Pod レベルになります。 クラスターレベルに戻るには、画面上部のクラスターリンク（1）をクリックするだけです。 これでSplunk Observability Cloudのツアーは終了です。\n仮想の 💶 を持って、私たちの E コマースサイト「Online Boutique」を見て、ショッピングをしましょう。",
    "description": "メインメニューのInfrastructureをクリックすると、Infrastructure ホームページが表示されます。このページは 4 つの異なるセクションで構成されています。\nオンボーディングペイン: SplunkInfrastructure モニタリングの使用を開始するためのトレーニングビデオとドキュメントへのリンク。 時間とフィルターペイン: 時間ウィンドウ（トップレベルでは設定できません） インテグレーションペイン: Splunk Observability Cloud にメトリクスを送信しているすべてのテクノロジーのリスト。 タイルペイン: インテグレーション別に分類された、監視されているサービスの総数。 Infrastructure ペインを使用して、関心のある Infrastructure/テクノロジーを選択できます。早速試してみましょう。\n演習 インテグレーションペイン（3）のコンテナセクションで、調査したいテクノロジーとしてKubernetesを選択します。\nすると、K8s ノードとK8s ワークロードの 2 つのタイルが表示されます。\n各タイルの下部には履歴グラフが表示され、上部にはアラートが発生した通知が表示されます。すべてのタイルで、各タイルのこの追加情報により、Infrastructure の健全性の良い概要が得られます。\nK8s ノードタイルをクリックします。\nKubernetes クラスターの表示が一つ以上表示されます。\nフィルターを追加ボタンをクリックします。k8s.cluster.nameと入力し、検索結果をクリックします。\nリストから**[ワークショップ名]-k3s-cluster**を選択し、フィルターを適用ボタンをクリックします。\nKubernetes ナビゲーターは色を使用して健全性を示します。ご覧のように、失敗状態（1）にある 2 つの不健全なポッドまたはサービスがあります。残りは健全で実行中です。これは共有 Kubernetes 環境では珍しくないため、ワークショップ用にこの状況を再現しました。\n側面のタイル、特にノード依存関係（2）の下の MySQL と Redis のタイルに注目してください。これらは私たちの E コマースアプリケーションで使用されている 2 つのデータベースです。",
    "tags": [],
    "title": "Infrastructureナビゲーター",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/6-infrastructure-home/1-infrastructure-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 6. Routing Data",
    "content": "Exercise 元の traces パイプラインをルーティングを使用するように更新する:\nrouting を有効にするには、元の traces パイプラインを更新して、routing のみをエクスポーターとして使用します。これにより、すべてのスパンデータが Routing Connector を経由して評価され、接続されたパイプラインに転送されます。また、すべての プロセッサーを削除し、空の配列（[]）に置き換えます。これは、traces/route1-regular と traces/route2-security パイプラインで処理されるようになり、各ルートに対してカスタム動作が可能になるためです。traces: の設定は次のようになります\ntraces: # Traces pipeline receivers: - otlp # OTLP receiver processors: [] # Processors for traces exporters: - routing 既存の traces パイプラインの下に route1-regular と route2-security の両方のトレースパイプラインを追加する:\nRoute1-regular パイプラインを設定する: このパイプラインは、コネクターのルーティングテーブルに一致しないすべてのスパンを処理します。 これは唯一のレシーバーとして routing を使用し、元の traces パイプラインからの connection を通じてデータを受信することに注意してください。\ntraces/route1-regular: # Default pipeline for unmatched spans receivers: - routing # Receive data from the routing connector processors: - memory_limiter # Memory Limiter Processor - resource/add_mode # Adds collector mode metadata - batch exporters: - debug # Debug Exporter - file/traces/route1-regular # File Exporter for unmatched spans route2-security パイプラインを追加する: このパイプラインは、ルーティングルールの \"[deployment.environment\"] == \"security-applications\" ルールに一致するすべてのスパンを処理します。このパイプラインもレシーバーとして routing を使用しています。このパイプラインを traces/route1-regular の下に追加します。\ntraces/route2-security: # Default pipeline for unmatched spans receivers: - routing # Receive data from the routing connector processors: - memory_limiter # Memory Limiter Processor - resource/add_mode # Adds collector mode metadata - batch exporters: - debug # Debug exporter - file/traces/route2-security # File exporter for unmatched spans otelbin.io を使用して Agent の設定を検証します。参考として、パイプラインの traces: セクションは次のようになります\n%%{init:{\"fontFamily\":\"monospace\"}}%% graph LR %% Nodes REC1(\u0026nbsp;\u0026nbsp;\u0026nbsp;otlp\u0026nbsp;\u0026nbsp;\u0026nbsp;\u003cbr\u003efa:fa-download):::receiver PRO1(memory_limiter\u003cbr\u003efa:fa-microchip):::processor PRO2(memory_limiter\u003cbr\u003efa:fa-microchip):::processor PRO3(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO4(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO5(batch\u003cbr\u003efa:fa-microchip):::processor PRO6(batch\u003cbr\u003efa:fa-microchip):::processor EXP1(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter EXP2(\u0026emsp;\u0026emsp;file\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003etraces):::exporter EXP3(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter EXP4(\u0026emsp;\u0026emsp;file\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003etraces):::exporter ROUTE1(\u0026nbsp;routing\u0026nbsp;\u003cbr\u003efa:fa-route):::con-export ROUTE2(\u0026nbsp;routing\u0026nbsp;\u003cbr\u003efa:fa-route):::con-receive ROUTE3(\u0026nbsp;routing\u0026nbsp;\u003cbr\u003efa:fa-route):::con-receive %% Links subID1:::sub-traces subID2:::sub-traces subID3:::sub-traces subgraph \" \" direction LR subgraph subID1[**Traces**] REC1 --\u003e ROUTE1 end subgraph subID2[**Traces/route2-security**] ROUTE1 --\u003e ROUTE2 ROUTE2 --\u003e PRO1 PRO1 --\u003e PRO3 PRO3 --\u003e PRO5 PRO5 --\u003e EXP1 PRO5 --\u003e EXP2 end subgraph subID3[**Traces/route1-regular**] ROUTE1 --\u003e ROUTE3 ROUTE3 --\u003e PRO2 PRO2 --\u003e PRO4 PRO4 --\u003e PRO6 PRO6 --\u003e EXP3 PRO6 --\u003e EXP4 end end classDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff; classDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff; classDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff; classDef sub-traces stroke:#fbbf24,stroke-width:1px, color:#fbbf24,stroke-dasharray: 3 3;",
    "description": "Exercise 元の traces パイプラインをルーティングを使用するように更新する:\nrouting を有効にするには、元の traces パイプラインを更新して、routing のみをエクスポーターとして使用します。これにより、すべてのスパンデータが Routing Connector を経由して評価され、接続されたパイプラインに転送されます。また、すべての プロセッサーを削除し、空の配列（[]）に置き換えます。これは、traces/route1-regular と traces/route2-security パイプラインで処理されるようになり、各ルートに対してカスタム動作が可能になるためです。traces: の設定は次のようになります\ntraces: # Traces pipeline receivers: - otlp # OTLP receiver processors: [] # Processors for traces exporters: - routing 既存の traces パイプラインの下に route1-regular と route2-security の両方のトレースパイプラインを追加する:\nRoute1-regular パイプラインを設定する: このパイプラインは、コネクターのルーティングテーブルに一致しないすべてのスパンを処理します。 これは唯一のレシーバーとして routing を使用し、元の traces パイプラインからの connection を通じてデータを受信することに注意してください。\ntraces/route1-regular: # Default pipeline for unmatched spans receivers: - routing # Receive data from the routing connector processors: - memory_limiter # Memory Limiter Processor - resource/add_mode # Adds collector mode metadata - batch exporters: - debug # Debug Exporter - file/traces/route1-regular # File Exporter for unmatched spans route2-security パイプラインを追加する: このパイプラインは、ルーティングルールの \"[deployment.environment\"] == \"security-applications\" ルールに一致するすべてのスパンを処理します。このパイプラインもレシーバーとして routing を使用しています。このパイプラインを traces/route1-regular の下に追加します。",
    "tags": [],
    "title": "6.2 Configuring the Pipelines",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/6-routing-data/6-2-pipelines/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 6. Service",
    "content": "Prometheus Internal Receiver ワークショップの前半で、Collector 内部のメトリクスを収集していることを反映するために prometheus receiver の名前を prometheus/internal に変更しました。\nここで、metrics パイプラインで prometheus/internal receiver を有効にする必要があります。metrics パイプラインの receivers セクションに prometheus/internal を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch] exporters: [debug]",
    "description": "Prometheus Internal Receiver ワークショップの前半で、Collector 内部のメトリクスを収集していることを反映するために prometheus receiver の名前を prometheus/internal に変更しました。\nここで、metrics パイプラインで prometheus/internal receiver を有効にする必要があります。metrics パイプラインの receivers セクションに prometheus/internal を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch] exporters: [debug]",
    "tags": [],
    "title": "OpenTelemetry Collector Service",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/6-service/2-prometheus/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Prometheus Internal レシーバー ワークショップの前半で、prometheus レシーバーの名前を変更し、コレクター内部のメトリクスを収集していることを反映して、prometheus/internal という名前にしました。\n現在、メトリクスパイプラインの下で prometheus/internal レシーバーを有効にする必要があります。metrics パイプラインの下の receivers セクションを更新して、prometheus/internal を含めます：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch] exporters: [logging]",
    "description": "Prometheus Internal レシーバー ワークショップの前半で、prometheus レシーバーの名前を変更し、コレクター内部のメトリクスを収集していることを反映して、prometheus/internal という名前にしました。\n現在、メトリクスパイプラインの下で prometheus/internal レシーバーを有効にする必要があります。metrics パイプラインの下の receivers セクションを更新して、prometheus/internal を含めます：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/6-service/2-prometheus/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 7. Count \u0026 Sum Connector",
    "content": "このセクションでは、Sum Connector がスパンから値を抽出してメトリクスに変換する方法を説明します。\n具体的には、ベーススパンからクレジットカードの請求額を取得し、Sum Connector を活用して合計請求額をメトリクスとして取得します。\nこの connector は、スパン、スパンイベント、メトリクス、データポイント、およびログレコードから属性値を収集（sum）するために使用できます。各個別の値をキャプチャし、メトリクスに変換して転送します。ただし、これらのメトリクスと属性を使用して計算やさらなる処理を行うのはバックエンドの役割です。\nExercise Agent terminal ウィンドウに切り替えて、エディターで agent.yaml ファイルを開きます。\nSum Connector を追加する 設定の connectors セクションに Sum Connector を追加し、メトリクスカウンターを定義します sum: spans: user.card-charge: source_attribute: payment.amount conditions: - attributes[\"payment.amount\"] != \"NULL\" attributes: - key: user.name 上記の例では、スパン内の payment.amount 属性をチェックしています。有効な値がある場合、Sum connector は user.card-charge というメトリクスを生成し、user.name を属性として含めます。これにより、バックエンドは請求サイクルなどの長期間にわたってユーザーの合計請求額を追跡して表示できます。\n以下のパイプライン設定では、connector exporter が traces セクションに追加され、connector receiver が metrics セクションに追加されています。\nExercise パイプラインで Count Connector を設定する pipelines: traces: receivers: - otlp processors: - memory_limiter - attributes/update # Update, hash, and remove attributes - redaction/redact # Redact sensitive fields using regex - resourcedetection - resource/add_mode - batch exporters: - debug - file - otlphttp - sum # Sum connector which aggregates payment.amount from spans and sends to metrics pipeline metrics: receivers: - sum # Receives metrics from the sum exporter in the traces pipeline - count # Receives count metric from logs count exporter in logs pipeline. - otlp #- hostmetrics # Host Metrics Receiver processors: - memory_limiter - resourcedetection - resource/add_mode - batch exporters: - debug - otlphttp logs: receivers: - otlp - filelog/quotes processors: - memory_limiter - resourcedetection - resource/add_mode - transform/logs # Transform logs processor - batch exporters: - count # Count Connector that exports count as a metric to metrics pipeline. - debug - otlphttp otelbin.io を使用して agent 設定を検証してください。参考として、パイプラインの traces と metrics: セクションは以下のようになります %%{init:{\"fontFamily\":\"monospace\"}}%% graph LR %% Nodes REC1(otlp\u003cbr\u003efa:fa-download\u003cbr\u003e ):::receiver REC3(otlp\u003cbr\u003efa:fa-download\u003cbr\u003e ):::receiver PRO1(memory_limiter\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO2(memory_limiter\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO3(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO4(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO5(batch\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO6(batch\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO7(resourcedetection\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO8(resourcedetection\u003cbr\u003efa:fa-microchip\u003cbr\u003e):::processor PROA(attributes\u003cbr\u003efa:fa-microchip\u003cbr\u003eredact):::processor PROB(redaction\u003cbr\u003efa:fa-microchip\u003cbr\u003eupdate):::processor EXP1(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP2(\u0026emsp;\u0026emsp;file\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP3(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP4(\u0026emsp;\u0026emsp;otlphttp\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP5(\u0026emsp;\u0026emsp;otlphttp\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter ROUTE1(\u0026nbsp;sum\u0026nbsp;\u003cbr\u003efa:fa-route\u003cbr\u003e ):::con-export ROUTE2(\u0026nbsp;count\u0026nbsp;\u003cbr\u003efa:fa-route\u003cbr\u003e ):::con-receive ROUTE3(\u0026nbsp;sum\u0026nbsp;\u003cbr\u003efa:fa-route\u003cbr\u003e ):::con-receive %% Links subID1:::sub-traces subID2:::sub-metrics subgraph \" \" direction LR subgraph subID1[**Traces**] direction LR REC1 --\u003e PRO1 PRO1 --\u003e PROA PROA --\u003e PROB PROB --\u003e PRO7 PRO7 --\u003e PRO3 PRO3 --\u003e PRO5 PRO5 --\u003e EXP1 PRO5 --\u003e EXP2 PRO5 --\u003e EXP5 PRO5 --\u003e ROUTE1 end subgraph subID2[**Metrics**] direction LR ROUTE1 --\u003e ROUTE3 ROUTE3 --\u003e PRO2 ROUTE2 --\u003e PRO2 REC3 --\u003e PRO2 PRO2 --\u003e PRO8 PRO8 --\u003e PRO4 PRO4 --\u003e PRO6 PRO6 --\u003e EXP3 PRO6 --\u003e EXP4 end end classDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff; classDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff; classDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff; classDef sub-logs stroke:#34d399,stroke-width:1px, color:#34d399,stroke-dasharray: 3 3; classDef sub-traces stroke:#fbbf24,stroke-width:1px, color:#fbbf24,stroke-dasharray: 3 3; classDef sub-metrics stroke:#38bdf8,stroke-width:1px, color:#38bdf8,stroke-dasharray: 3 3;",
    "description": "このセクションでは、Sum Connector がスパンから値を抽出してメトリクスに変換する方法を説明します。\n具体的には、ベーススパンからクレジットカードの請求額を取得し、Sum Connector を活用して合計請求額をメトリクスとして取得します。\nこの connector は、スパン、スパンイベント、メトリクス、データポイント、およびログレコードから属性値を収集（sum）するために使用できます。各個別の値をキャプチャし、メトリクスに変換して転送します。ただし、これらのメトリクスと属性を使用して計算やさらなる処理を行うのはバックエンドの役割です。\nExercise Agent terminal ウィンドウに切り替えて、エディターで agent.yaml ファイルを開きます。\nSum Connector を追加する 設定の connectors セクションに Sum Connector を追加し、メトリクスカウンターを定義します sum: spans: user.card-charge: source_attribute: payment.amount conditions: - attributes[\"payment.amount\"] != \"NULL\" attributes: - key: user.name 上記の例では、スパン内の payment.amount 属性をチェックしています。有効な値がある場合、Sum connector は user.card-charge というメトリクスを生成し、user.name を属性として含めます。これにより、バックエンドは請求サイクルなどの長期間にわたってユーザーの合計請求額を追跡して表示できます。\n以下のパイプライン設定では、connector exporter が traces セクションに追加され、connector receiver が metrics セクションに追加されています。\nExercise パイプラインで Count Connector を設定する pipelines: traces: receivers: - otlp processors: - memory_limiter - attributes/update # Update, hash, and remove attributes - redaction/redact # Redact sensitive fields using regex - resourcedetection - resource/add_mode - batch exporters: - debug - file - otlphttp - sum # Sum connector which aggregates payment.amount from spans and sends to metrics pipeline metrics: receivers: - sum # Receives metrics from the sum exporter in the traces pipeline - count # Receives count metric from logs count exporter in logs pipeline. - otlp #- hostmetrics # Host Metrics Receiver processors: - memory_limiter - resourcedetection - resource/add_mode - batch exporters: - debug - otlphttp logs: receivers: - otlp - filelog/quotes processors: - memory_limiter - resourcedetection - resource/add_mode - transform/logs # Transform logs processor - batch exporters: - count # Count Connector that exports count as a metric to metrics pipeline. - debug - otlphttp otelbin.io を使用して agent 設定を検証してください。参考として、パイプラインの traces と metrics: セクションは以下のようになります %%{init:{\"fontFamily\":\"monospace\"}}%% graph LR %% Nodes REC1(otlp\u003cbr\u003efa:fa-download\u003cbr\u003e ):::receiver REC3(otlp\u003cbr\u003efa:fa-download\u003cbr\u003e ):::receiver PRO1(memory_limiter\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO2(memory_limiter\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO3(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO4(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO5(batch\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO6(batch\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO7(resourcedetection\u003cbr\u003efa:fa-microchip\u003cbr\u003e ):::processor PRO8(resourcedetection\u003cbr\u003efa:fa-microchip\u003cbr\u003e):::processor PROA(attributes\u003cbr\u003efa:fa-microchip\u003cbr\u003eredact):::processor PROB(redaction\u003cbr\u003efa:fa-microchip\u003cbr\u003eupdate):::processor EXP1(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP2(\u0026emsp;\u0026emsp;file\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP3(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP4(\u0026emsp;\u0026emsp;otlphttp\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter EXP5(\u0026emsp;\u0026emsp;otlphttp\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload\u003cbr\u003e ):::exporter ROUTE1(\u0026nbsp;sum\u0026nbsp;\u003cbr\u003efa:fa-route\u003cbr\u003e ):::con-export ROUTE2(\u0026nbsp;count\u0026nbsp;\u003cbr\u003efa:fa-route\u003cbr\u003e ):::con-receive ROUTE3(\u0026nbsp;sum\u0026nbsp;\u003cbr\u003efa:fa-route\u003cbr\u003e ):::con-receive %% Links subID1:::sub-traces subID2:::sub-metrics subgraph \" \" direction LR subgraph subID1[**Traces**] direction LR REC1 --\u003e PRO1 PRO1 --\u003e PROA PROA --\u003e PROB PROB --\u003e PRO7 PRO7 --\u003e PRO3 PRO3 --\u003e PRO5 PRO5 --\u003e EXP1 PRO5 --\u003e EXP2 PRO5 --\u003e EXP5 PRO5 --\u003e ROUTE1 end subgraph subID2[**Metrics**] direction LR ROUTE1 --\u003e ROUTE3 ROUTE3 --\u003e PRO2 ROUTE2 --\u003e PRO2 REC3 --\u003e PRO2 PRO2 --\u003e PRO8 PRO8 --\u003e PRO4 PRO4 --\u003e PRO6 PRO6 --\u003e EXP3 PRO6 --\u003e EXP4 end end classDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff; classDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff; classDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff; classDef sub-logs stroke:#34d399,stroke-width:1px, color:#34d399,stroke-dasharray: 3 3; classDef sub-traces stroke:#fbbf24,stroke-width:1px, color:#fbbf24,stroke-dasharray: 3 3; classDef sub-metrics stroke:#38bdf8,stroke-width:1px, color:#38bdf8,stroke-dasharray: 3 3;",
    "tags": [],
    "title": "7.2 Sum Connector でメトリクスを作成する",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/7-sum-count/7-2-sum/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ",
    "content": "このワークショップの目的は、OpenTelemetry Collector の設定ファイルを作成・変更する際の自信を深めることです。最小限の agent.yaml と gateway.yaml ファイルから始め、いくつかの高度な実際のシナリオに対応できるよう段階的に構築していきます。\nこのワークショップの重要なポイントは、テレメトリーデータをサードパーティベンダーのバックエンドに送信するのではなく、ローカルに保存するよう OpenTelemetry Collector を設定する方法を学ぶことです。このアプローチはデバッグやトラブルシューティングを簡素化するだけでなく、本番システムへのデータ送信を避けたいテストや開発環境にも最適です。\nこのワークショップを最大限に活用するために、以下の知識が必要です\nOpenTelemetry Collector とその設定ファイル構造の基本的な理解 YAML ファイルの編集スキル このワークショップのすべての内容はローカルで実行できるよう設計されており、実践的でアクセスしやすい学習体験を提供します。それでは、構築を始めましょう！\nワークショップの概要 このワークショップでは、以下のトピックを取り上げます\nAgent と Gateway をローカルでセットアップ: メトリクス、トレース、ログが Agent 経由で Gateway に送られることをテストします。 Agent の耐障害性を強化: フォールトトレランスのための基本設定を行います。 Processor の設定: 特定のスパン（例：ヘルスチェック）をドロップしてノイズをフィルタリングします。 不要なタグを削除し、機密データを処理します。 エクスポート前にパイプラインで OTTL（OpenTelemetry Transformation Language）を使用してデータを変換します。 Connector の設定: 受信した値に基づいて、データを異なるエンドポイントにルーティングします。 このワークショップを終了すると、さまざまな実際のユースケースに対応する OpenTelemetry Collector の設定に精通しているでしょう。",
    "description": "OpenTelemetry Collector の設定をゼロから行う練習を行い、いくつかの高度な設定シナリオを体験します。",
    "tags": [],
    "title": "Advanced OpenTelemetry Collector",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6.2 Optional Exercise",
    "content": "This is Part 2, of the Infrastructure Monitoring exercise, you should now have a single cluster visible.\nIn the Kubernetes Navigator, the cluster is represented by the square with the black line around it. It will contain one or more blue squares representing the node(s) or compute engines. Each of them containing one or more colored boxes that represent Pods. (this is where your services run in). And as you can guess, green means healthy and red means that there is a problem. Given there are two red boxes or tiles, let’s see what is going on and if this will affect our Online Boutique site.\nExercise First, set the time window we are working with to the last 15 minutes. You do this by changing the the Time picker in the filter pane from -4h to Last 15 minutes. Hover with your mouse over the Cluster, Node and pods, both green and red ones. The resulting information pane that appears will tell you the state of the object. Note, That the red Pods show that they are in Pod Phase: Failed. This means they have crashed and are not working. Examine the Cluster Metric charts that provide information on your cluster. (The charts below the cluster image). They provide general information about the health of your cluster like Memory consumption and the number of pods per node. Nothing flags for the red pods, as crashed pods do not affect the performance of Kubernetes. Let’s check if the Spunk Kubernetes Analyzer can tell us something more useful, so click on K8s Analyzer. Spunk Kubernetes Analyzer The Splunk Kubernetes Analyzer is a smart process that runs in the background in Splunk Observability Cloud and is designed to detect relations between anomalies.\nThe K8s Analyzer should have detected that the two red pods are similar, indicated by the 2 after each line, and running in the same Namespace. In the K8s analyzer view can you find what namespace? (hint, look for k8s.namespace.name). Next, we want to check this on the node level as well, so drill down to the node, first by hovering your mouse over the cluster until you see a blue line appear around the node with a in the left top, inside the black Cluster Line. Click on the triangle . Your view should now show little boxes in each pod, these represent the containers that run the actual code. The K8s Analyzer should confirm that this issue is also occurring on the node level. Click on K8s node. This will show the node metrics, and if you examine the charts, you can see that there are only two pods in the development namespace. It is easier to see if you filter on the k8s.namespace.name=development in the Filter Pane. The # Total Pods chart shows only two pods and in the Node Workload chart there is only the test-job and it has failed. Spunk Kubernetes Analyzer The above scenario is common in a shared Kubernetes environment, where teams deploy applications in different stages. Kubernetes is designed to keep these environments completely separate.\nNone of the Pods that make up our Online Boutique site run in the development namespace and all the other pods are green, we can safely assume these pods do not affect us, so let’s move on to look at a few more things.",
    "description": "This is Part 2, of the Infrastructure Monitoring exercise, you should now have a single cluster visible.\nIn the Kubernetes Navigator, the cluster is represented by the square with the black line around it. It will contain one or more blue squares representing the node(s) or compute engines. Each of them containing one or more colored boxes that represent Pods. (this is where your services run in). And as you can guess, green means healthy and red means that there is a problem. Given there are two red boxes or tiles, let’s see what is going on and if this will affect our Online Boutique site.",
    "tags": [],
    "title": "Infrastructure Exercise - Part 2",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/30-im-exercise/2-im-exercise/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ",
    "content": "このワークショップの目的は、Java 向けの Splunk 自動ディスカバリーおよび設定機能を紹介することです。\nワークショップのシナリオは、Kubernetes にシンプルな（計装されていない）Java マイクロサービスアプリケーションをインストールすることで作成されます。\n既存の Java ベースのデプロイメント向けに自動ディスカバリー機能付きの Splunk OpenTelemetry Collector をインストールする簡単な手順に従うことで、メトリクス、トレース、ログを Splunk Observability Cloud に送信することがいかに簡単かを確認できます。\n前提条件 ポート 2222 へのアウトバウンド SSH アクセス ポート 81 へのアウトバウンド HTTP アクセス Linux コマンドラインの基本的な知識 このワークショップでは、以下のコンポーネントをカバーします：\nSplunk Infrastructure Monitoring (IM) Splunk automatic discovery and configuration for Java (APM) Database Query Performance AlwaysOn Profiling Splunk Log Observer (LO) Splunk Real User Monitoring (RUM) Splunk Synthetics は少し寂しそうですが、他のワークショップでカバーしています",
    "description": "Kubernetes で実行される Java ベースのアプリケーション向けの自動ディスカバリーおよび設定を有効にする方法を学びます。リアルタイムモニタリングを体験し、エンドツーエンドの可視性でアプリケーションの動作を最大限に活用しましょう。",
    "tags": [],
    "title": "Kubernetes 上の Spring PetClinic SpringBoot ベースのマイクロサービス",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "自動ディスカバリーワークショップ\rJava アプリケーション向けの Splunk 自動ディスカバリーおよび設定機能の活用方法を学びます。これらのワークショップでは、ゼロコード計装を使用して、モノリスおよび Kubernetes デプロイメント全体でメトリクス、トレース、ログを即座に生成し、包括的なオブザーバビリティを実現する方法をデモンストレーションします。\rOpenTelemetry Collector ワークショップ\rOpenTelemetry Collector の基本概念\rOpenTelemetry Collector の概念と、Splunk Observability Cloud へデータを送信する方法を学びます。\rAdvanced OpenTelemetry Collector\rOpenTelemetry Collector の設定をゼロから行う練習を行い、いくつかの高度な設定シナリオを体験します。\rSplunk Synthetic Scripting\rユーザーフロー、ビジネストランザクション、API 全体のパフォーマンス問題をプロアクティブに検出・修正し、より優れたデジタルエクスペリエンスを提供します。\rLambdaトレーシング\rこのワークショップでは、AWS Lambdaで実行される小規模なサーバーレスアプリケーションの分散トレースを構築し、AWS Kinesisを介してメッセージをproduceおよびconsumeする方法を学びます\rOpenTelemetry、Docker、K8sを実践で学ぶ\rこのワークショップでは、これらの概念を説明するためにシンプルな.NETアプリケーションを使用します。さあ、始めましょう！ワークショップの終わりまでに、OpenTelemetryを使用した.NETアプリケーションの計装の実践経験を積み、そのアプリケーションのDocker化およびKubernetesへのデプロイを行います。また、Helmを使用したOpenTelemetryコレクターのデプロイ、コレクター設定のカスタマイズ、コレクター設定の問題のトラブルシューティングの経験も得られます。",
    "description": "The following workshops require Ninja skills, wax on, wax off.",
    "tags": [],
    "title": "Splunk4Ninjas Workshops",
    "uri": "/observability-workshop/ja/ninja-workshops/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e リソース",
    "content": "メトリクスにコンテキストを与える ディメンションとプロパティの違いや、どちらを使うべきかというのは、よく話題にされます。それぞれの説明から始めるのではなく、私たちがどのように使い、どのように似ているのかを理解してから、それぞれの違いや、なぜどちらかを使うのかの例を見ていくことにしましょう。\nディメンションとプロパティの類似点 最も単純な答えは、ディメンションとプロパティはともに、メトリクスにコンテキスト（状況）を追加するメタデータの key:value ペアであるということです。メトリクス自体は、cpu.utilization のような標準的なインフラストラクチャメトリクスであろうと、API呼び出しの回数のようなカスタムメトリクスであろうと、実際に測定しているものなら全てに当てはまります。\ncpu.utilization メトリクスの値が50%であっても、それがどこから来たのかなどのコンテキストを知らなければ、それは単なる数字であり、私たちにとって有用ではありません。少なくとも、どのホストから来たのかを知る必要があります。\n現在では、個々のホストのパフォーマンスや利用率よりも、クラスターやデータセンター全体のパフォーマンスや利用率をより気にすることが多く、ホストのクラスター全体の平均 cpu.utilization、あるホストの cpu.utilization が同じサービスを実行する他のホストと比べて外れ値である場合、あるいは環境間での平均 cpu.utilization を比較することに興味を持っています。\nこのように cpu.utilization メトリクスをスライス、集約、またはグループ化するためには、受け取る cpu.utilization メトリクスのメタデータに、ホストが属するクラスター、ホスト上で実行されているサービス、およびそれが属する環境などの情報が必要です。このメタデータは、ディメンションまたはプロパティの key:value ペアの形で存在することができます。\n例えば、ダッシュボードでフィルターを適用したり、分析関数を実行する際にグループ化機能を使用したりするとき、プロパティまたはディメンションを使用することができます。\nでは、ディメンションとプロパティはどう違うの？ ディメンションはメトリクスと共に取り込み時に送信されるのに対し、プロパティは取り込み後にメトリクスやディメンションに適用されます。これは、`cpu.utilization`` の値がどのホストから来ているかのような、データポイント（メトリクスの単一の報告値）をユニークにするために必要なメタデータはディメンションでなければならないことを意味します。メトリクス名 + ディメンションは MTS（メトリクスの時間系列）をユニークに定義します。\n例：特定のホスト（server1）によって送信される cpu.utilization メトリクスで、ディメンション host:server1 があれば、それはユニークな時間系列と見なされます。もし 10 台のサーバーがそのメトリクスを送信していれば、メトリクス名 cpu.utilization を共有し、ディメンションのキー値ペア（host:server1, host:server2…host:server10）でユニークに識別される 10 の時間系列があります。\nしかし、サーバー名がデータセンター内でのみユニークである場合、データセンターの場所を示す 2 番目のディメンション dc を追加する必要があります。これにより、可能な MTS の数は倍になります。受信された cpu.utilization メトリクスは、2 組のディメンションのキー値ペアによってユニークに識別されます。\ncpu.utilization に dc:east と host:server1 を加えたものは、cpu.utilization に dc:west と host:server1 を加えたものとは異なる時間系列を作り出します。\nディメンションは不変だが、プロパティは可変である 上記で述べたように、メトリクス名 + ディメンションの組み合わせで、ユニークな MTS を作ります。したがって、ディメンションの値が変わると、メトリクス名 + ディメンション値の新しいユニークな組み合わせが生まれ、新しい MTS が作成されます。\n一方、プロパティはメトリクス（またはディメンション）が取り込まれた後に適用されます。メトリクスにプロパティを適用すると、そのメトリクスが属するすべての MTS に伝播して適用されます。または、ディメンションにプロパティを適用する場合、例えば host:server1 とすると、そのホストからのすべてのメトリクスにそのプロパティが添付されます。プロパティの値を変更すると、そのプロパティが添付されているすべての MTS のプロパティ値が更新されます。これが重要な理由は何でしょうか？ プロパティの歴史的な値にこだわる場合、それをディメンションにする必要があることを意味しています。\n例：私たちはアプリケーションに関するカスタムメトリクスを収集しています。1つのメトリクスは latency で、アプリケーションへのリクエストのレイテンシーをカウントします。顧客ごとにレイテンシーを分類して比較できるように customer ディメンションを持っています。私たちは、顧客が使用しているバージョン別にアプリケーションの latency を分類して比較したいと考え、プロパティ version を customer ディメンションに添付しました。最初はすべての顧客がアプリケーションバージョン1を使用しているので、version:1 です。\n現在、いくつかの顧客がアプリケーションのバージョン2を使用しているため、それらの顧客に対してプロパティを version:2 に更新します。これらの顧客の version プロパティの値を更新すると、その顧客に関連するすべての MTS に伝播します。これにより、これらの顧客が以前に version:1 を使用していたという歴史が失われるため、歴史的な期間にわたって version:1 と version:2 の latency を比較する場合、正確なデータを得ることはできません。この場合、メトリクスの時間系列をユニークにするためにアプリケーションの version が必要ではないかもしれませんが、歴史的な値にこだわるために version をディメンションにする必要があります。\n結局、いつ、ディメンションじゃなくてプロパティを使うの？ メトリクスに添付したいメタデータがあるが、取り込み時にはそれを知らない場合が第一の理由です。第二の理由は、ベストプラクティスとして、ディメンションである必要がなければ、それをプロパティにすることです。なぜでしょうか？\n一つの理由は、現在、分析ジョブやチャートレンダリングあたりの MTS の上限が 5K であり、ディメンションが多いほど多くの MTS を生成することです。プロパティは完全に自由形式であり、MTS の数を増やすことなく、メトリクスやディメンションに必要な情報を追加することができます。\nディメンションは各データポイントと共に送信されるため、ディメンションが多いほど、より多くのデータを送信することになります。これは、クラウドプロバイダーがデータ転送に料金を請求する場合、コストが高くなる可能性があります。\nプロパティを使う良い例としては、ホスト情報の追加などがあります。 machine_type, processor, os などの情報を確認することが重要ですが、これらをディメンションとして設定し、各ホストからのすべてのメトリクスと共に送信するのではなく、プロパティとして設定し、ホストディメンションに添付することができます。\n例えば host:server1 では、プロパティ machine_type:ucs, processor:xeon-5560, os:rhel71 を設定します。host:server1 というディメンションを持つメトリクスが入ってくるたびに、上記のすべてのプロパティが自動的に適用されます。\nプロパティの使用例としては、各サービスのエスカレーション連絡先や、各顧客の SLA レベルを知りたい場合があります。これらの項目は、メトリクスをユニークに識別するために必要ではなく、歴史的な値にも関心がないため、プロパティにすることができます。プロパティはサービスディメンションや顧客ディメンションに追加され、これらのディメンションを持つすべてのメトリクスや MTS に適用されます。\nタグについてはどうですか？ タグは、メトリクスにコンテキストを与えたり整理するのに使われる、メタデータの 3 番目のタイプです。ディメンションやプロパティとは異なり、タグは key:value ペアではありません。タグはラベルやキーワードとして考えることができます。プロパティと同様に、タグは取り込み後に UI の Catalog や API を通じてプログラム的にデータに適用されます。タグはメトリクス、ディメンション、ディテクターなどの他のオブジェクトに適用することができます。\nタグを使う場面はどこですか？ タグが必要とされるのは、タグとオブジェクトの間に多対一の関係がある場合や、タグとそれに適用されるオブジェクト間に一対多の関係がある場合です。本質的に関連していないメトリクスをまとめるのに役立ちます。\n例として、複数のアプリケーションを実行しているホストがある場合です。各アプリケーションに対してタグ（ラベル）を作成し、それぞれのホストに複数のタグを適用して、その上で実行されているアプリケーションをラベル付けします。\n例：Server1 は 3 つのアプリケーションを実行しています。タグ app1, app2, app3 を作成し、ディメンション host:server1 にこれら 3 つのタグをすべて適用します。\n上記の例を拡張すると、アプリケーションからのメトリクスも収集しているとします。作成したタグを、アプリケーション自体から来るメトリクスに適用することができます。タグに基づいてフィルタリングすることで、アプリケーションに基づいてフィルタリングしながら、アプリケーションと関連するホストメトリクスの全体像を得ることができます。\n例：App1 は service:application1 というディメンションでメトリクスを送信します。service:application1 のディメンションにタグ app1 を適用します。その後、チャートやダッシュボードでタグ app1 でフィルタリングすることができます。\nタグの他の使用例には、単一の可能な値を持つ二進状態があります。例として、カナリアテストを行い、カナリアデプロイを行った際に新しいコードを受け取ったホストをマークして、新しいコードを受け取らなかったホストとのパフォーマンスを比較しやすくすることがあります。単一の値 canary しかないため、key:value ペアは必要ありません。\nただし、タグでフィルタリングはできますが、groupBy 関数では使用できないことに注意してください。groupBy 関数は key:value ペアのキー部分を指定して実行され、そのキーの値に基づいて結果がグループ化されます。\nさらなる情報 カスタムメトリクスのディメンションを送信する方法に関する情報については、お使いのライブラリに関するクライアントライブラリのドキュメントをご覧ください。\nAPI を通じてメトリクスやディメンションにプロパティやタグを適用する方法については、 /metric/:name、/dimension/:key/:value に関する API ドキュメントを参照してください。\nUI のメタデータカタログでプロパティやタグを追加または編集する方法については、Search the Metric Finder and Metadata catalogで、​Add or edit metadata セクションをご覧ください。",
    "description": "ディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。",
    "tags": [],
    "title": "ディメンション、プロパティ、タグ",
    "uri": "/observability-workshop/ja/resources/dimensions_properties_tags/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "前提条件 vi、vim、nano、またはお好みのテキストエディタを使用して YAML ファイルを編集するスキル サポートされている環境 提供される Splunk Workshop インスタンス（推奨）。ssh アクセス用にポート 2222 への外部アクセスが必要です。 Apple Mac（Apple Silicon）。jq のインストールが必要です - https://jqlang.org/download/ Exercise ディレクトリの作成: 環境内で新しいディレクトリを作成し、そのディレクトリに移動します\nmkdir advanced-otel-workshop \u0026\u0026 \\ cd advanced-otel-workshop このワークショップの残りの部分では、このディレクトリを [WORKSHOP] と呼びます。\n既存の OpenTelemetry Collector を削除してください Splunk IM ワークショップを完了している場合は、続行する前に Kubernetes で実行中の Collector を削除してください。以下のコマンドを実行して削除できます\nhelm delete splunk-otel-collector その場合、EC2 インスタンスでこのワークショップと干渉する可能性のあるサービスが実行されている場合があるため、以下のコマンドを実行してそれらが存在する場合は停止してください\nkubectl delete ~/workshop/apm/deployment.yaml ワークショップバイナリのダウンロード: [WORKSHOP] ディレクトリに移動し、OpenTelemetry Collector、Load Generator バイナリ、およびセットアップスクリプトをダウンロードします\n​ Splunk Workshop Instance Apple Silicon curl -L https://github.com/signalfx/splunk-otel-collector/releases/download/v0.136.0/otelcol_linux_amd64 -o otelcol \u0026\u0026 \\ curl -L https://github.com/splunk/observability-workshop/raw/refs/heads/main/workshop/ninja/advanced-otel/loadgen/build/loadgen-linux-amd64 -o loadgen \u0026\u0026 \\ curl -L https://github.com/splunk/observability-workshop/raw/refs/heads/main/workshop/ninja/advanced-otel/setup-workshop.sh -o setup-workshop.sh \u0026\u0026 \\ chmod +x setup-workshop.sh curl -L https://github.com/signalfx/splunk-otel-collector/releases/download/v0.136.0/otelcol_darwin_arm64 -o otelcol \u0026\u0026 \\ curl -L https://github.com/splunk/observability-workshop/raw/refs/heads/main/workshop/ninja/advanced-otel/loadgen/build/loadgen-darwin-arm64 -o loadgen \u0026\u0026 \\ curl -L https://github.com/splunk/observability-workshop/raw/refs/heads/main/workshop/ninja/advanced-otel/setup-workshop.sh -o setup-workshop.sh \u0026\u0026 \\ chmod +x setup-workshop.sh setup-workshop.sh スクリプトを実行します。このスクリプトは正しい権限を設定し、Agent と Gateway の初期設定も作成します\n​ Setup Workshop Verify Setup ./setup-workshop.sh ███████╗██████╗ ██╗ ██╗ ██╗███╗ ██╗██╗ ██╗ ██╗ ██╔════╝██╔══██╗██║ ██║ ██║████╗ ██║██║ ██╔╝ ╚██╗ ███████╗██████╔╝██║ ██║ ██║██╔██╗ ██║█████╔╝ ╚██╗ ╚════██║██╔═══╝ ██║ ██║ ██║██║╚██╗██║██╔═██╗ ██╔╝ ███████║██║ ███████╗╚██████╔╝██║ ╚████║██║ ██╗ ██╔╝ ╚══════╝╚═╝ ╚══════╝ ╚═════╝ ╚═╝ ╚═══╝╚═╝ ╚═╝ ╚═╝ Welcome to the Splunk Advanced OpenTelemetry Workshop! ====================================================== macOS detected. Removing quarantine attributes... otelcol version v0.126.0 Usage: loadgen [OPTIONS] Options: -base Send base traces (enabled by default) -health Send health traces -security Send security traces -logs Enable logging of random quotes to quotes.log -json Output logs in JSON format (only applicable with -logs) -count Number of traces or logs to send (default: infinite) -h, --help Display this help message Example: loadgen -health -security -count 10 Send 10 health and security traces loadgen -logs -json -count 5 Write 5 random quotes in JSON format to quotes.log Creating workshop directories... ✓ Created subdirectories: ├── 1-agent-gateway ├── 2-building-resilience ├── 3-dropping-spans ├── 4-sensitive-data ├── 5-transform-data ├── 6-routing-data └── 7-sum-count Creating configuration files for 1-agent-gateway... Creating OpenTelemetry Collector agent configuration file: 1-agent-gateway/agent.yaml ✓ Configuration file created successfully: 1-agent-gateway/agent.yaml ✓ File size: 4355 bytes Creating OpenTelemetry Collector gateway configuration file: 1-agent-gateway/gateway.yaml ✓ Configuration file created successfully: 1-agent-gateway/gateway.yaml ✓ File size: 3376 bytes ✓ Completed configuration files for 1-agent-gateway Creating configuration files for 2-building-resilience... Creating OpenTelemetry Collector agent configuration file: 2-building-resilience/agent.yaml ✓ Configuration file created successfully: 2-building-resilience/agent.yaml ✓ File size: 4355 bytes Creating OpenTelemetry Collector gateway configuration file: 2-building-resilience/gateway.yaml ✓ Configuration file created successfully: 2-building-resilience/gateway.yaml ✓ File size: 3376 bytes ✓ Completed configuration files for 2-building-resilience Workshop environment setup complete! Configuration files created in the following directories: 1-agent-gateway/ ├── agent.yaml └── gateway.yaml 2-building-resilience/ ├── agent.yaml └── gateway.yaml ​ Initial Directory Structure [WORKSHOP] ├── 1-agent-gateway ├── 2-building-resilience ├── 3-dropping-spans ├── 4-sensitive-data ├── 5-transform-data ├── 6-routing-data ├── 7-sum-count ├── loadgen ├── otelcol └── setup-workshop.sh",
    "description": "前提条件 vi、vim、nano、またはお好みのテキストエディタを使用して YAML ファイルを編集するスキル サポートされている環境 提供される Splunk Workshop インスタンス（推奨）。ssh アクセス用にポート 2222 への外部アクセスが必要です。 Apple Mac（Apple Silicon）。jq のインストールが必要です - https://jqlang.org/download/ Exercise ディレクトリの作成: 環境内で新しいディレクトリを作成し、そのディレクトリに移動します\nmkdir advanced-otel-workshop \u0026\u0026 \\ cd advanced-otel-workshop このワークショップの残りの部分では、このディレクトリを [WORKSHOP] と呼びます。\n既存の OpenTelemetry Collector を削除してください Splunk IM ワークショップを完了している場合は、続行する前に Kubernetes で実行中の Collector を削除してください。以下のコマンドを実行して削除できます\nhelm delete splunk-otel-collector その場合、EC2 インスタンスでこのワークショップと干渉する可能性のあるサービスが実行されている場合があるため、以下のコマンドを実行してそれらが存在する場合は停止してください",
    "tags": [],
    "title": "前提条件",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/prerequisites/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "ようこそ！このセクションでは、Agent と Gateway の両方を含む完全に機能する OpenTelemetry セットアップから始めます。\nまず、設定ファイルを簡単に確認して、全体的な構造に慣れ、テレメトリーパイプラインを制御する重要なセクションを確認します。\nTip ワークショップを通じて、複数のターミナルウィンドウを使用します。整理しやすくするために、各ターミナルに固有の名前または色を付けてください。これにより、演習中にターミナルを簡単に識別して切り替えることができます。\nこれらのターミナルを Agent、Gateway、Loadgen、Test と呼びます。\nExercise 最初のターミナルウィンドウを作成し、Agent と名前を付けます。最初の演習用ディレクトリ [WORKSHOP]/1-agent-gateway に移動し、必要なファイルが生成されていることを確認します\ncd 1-agent-gateway ls -l ディレクトリに以下のファイルが表示されるはずです。表示されない場合は、前提条件 セクションで説明されている setup-workshop.sh スクリプトを再実行してください\n​ Directory Structure . ├── agent.yaml └── gateway.yaml Agent 設定の理解 このワークショップで使用する agent.yaml ファイルの主要なコンポーネントを確認しましょう。メトリクス、トレース、ログをサポートするために重要な追加が行われています。\nReceiver receivers セクションは、Agent がテレメトリーデータを取り込む方法を定義します。このセットアップでは、3種類の Receiver が設定されています\nHost Metrics Receiver\nhostmetrics: # Host Metrics Receiver collection_interval: 3600s # Collection Interval (1hr) scrapers: cpu: # CPU Scraper ローカルシステムから1時間ごとに CPU 使用率を収集します。これを使用してサンプルメトリクスデータを生成します。\nOTLP Receiver（HTTP プロトコル）\notlp: # OTLP Receiver protocols: http: # Configure HTTP protocol endpoint: \"0.0.0.0:4318\" # Endpoint to bind to Agent がポート 4318 で HTTP 経由でメトリクス、トレース、ログを受信できるようにします。これは、今後の演習で Collector にデータを送信するために使用されます。\nFileLog Receiver\nfilelog/quotes: # Receiver Type/Name include: ./quotes.log # The file to read log data from include_file_path: true # Include file path in the log data include_file_name: false # Exclude file name from the log data resource: # Add custom resource attributes com.splunk.source: ./quotes.log # Source of the log data com.splunk.sourcetype: quotes # Source type of the log data Agent がローカルログファイル（quotes.log）を tail し、source や sourceType などのメタデータで強化された構造化ログイベントに変換できるようにします。\nExporter Debug Exporter\ndebug: # Exporter Type verbosity: detailed # Enabled detailed debug output OTLPHTTP Exporter\notlphttp: # Exporter Type endpoint: \"http://localhost:5318\" # Gateway OTLP endpoint debug Exporter はワークショップ中の可視性とデバッグのためにデータをコンソールに送信し、otlphttp Exporter はすべてのテレメトリーをローカルの Gateway インスタンスに転送します。\nこのデュアルエクスポート戦略により、生データをローカルで確認しながら、さらなる処理とエクスポートのためにダウンストリームに送信することができます。",
    "description": "ようこそ！このセクションでは、Agent と Gateway の両方を含む完全に機能する OpenTelemetry セットアップから始めます。\nまず、設定ファイルを簡単に確認して、全体的な構造に慣れ、テレメトリーパイプラインを制御する重要なセクションを確認します。\nTip ワークショップを通じて、複数のターミナルウィンドウを使用します。整理しやすくするために、各ターミナルに固有の名前または色を付けてください。これにより、演習中にターミナルを簡単に識別して切り替えることができます。\nこれらのターミナルを Agent、Gateway、Loadgen、Test と呼びます。\nExercise 最初のターミナルウィンドウを作成し、Agent と名前を付けます。最初の演習用ディレクトリ [WORKSHOP]/1-agent-gateway に移動し、必要なファイルが生成されていることを確認します\ncd 1-agent-gateway ls -l ディレクトリに以下のファイルが表示されるはずです。表示されない場合は、前提条件 セクションで説明されている setup-workshop.sh スクリプトを再実行してください\n​ Directory Structure . ├── agent.yaml └── gateway.yaml Agent 設定の理解 このワークショップで使用する agent.yaml ファイルの主要なコンポーネントを確認しましょう。メトリクス、トレース、ログをサポートするために重要な追加が行われています。",
    "tags": [],
    "title": "1. Agent 設定の確認",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/1-agent-gateway/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 1. Agent Configuration",
    "content": "次に、Gateway と Agent を起動します。Agent は起動時に自動的に Host Metrics を送信するよう設定されています。これにより、データが Agent から Gateway に正しくルーティングされることを確認します。\nExercise Gateway: Gateway ターミナル ウィンドウで、以下のコマンドを実行して Gateway を起動します\n​ Start the Gateway ../otelcol --config=gateway.yaml すべてが正しく設定されている場合、Collector が起動し、出力に Everything is ready. Begin running and processing data. と表示されます。以下のような出力になります\n2025-06-09T09:22:11.944+0100 info service@v0.126.0/service.go:289 Everything is ready. Begin running and processing data. {\"resource\": {}} Gateway が実行されると、ポート 5318 で受信データをリッスンし、受信したデータを以下のファイルにエクスポートします\ngateway-traces.out gateway-metrics.out gateway-logs.out Agent の起動: Agent ターミナル ウィンドウで、Agent 設定を使用して Agent を起動します\n​ Start the Agent ../otelcol --config=agent.yaml CPU メトリクスの確認:\nAgent が起動すると、すぐに CPU メトリクスの送信を開始することを確認します。 Agent と Gateway の両方がデバッグ出力にこのアクティビティを表示します。出力は以下のスニペットのようになります \u003csnip\u003e NumberDataPoints #31 Data point attributes: -\u003e cpu: Str(cpu3) -\u003e state: Str(wait) StartTimestamp: 2025-07-07 16:49:42 +0000 UTC Timestamp: 2025-07-09 09:36:21.190226459 +0000 UTC Value: 77.380000 {\"resource\": {}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"metrics\"} この段階で、Agent は1時間ごとまたは再起動ごとに CPU メトリクスを収集し、Gateway に送信し続けます。Gateway はこれらのメトリクスを処理し、gateway-metrics.out という名前のファイルにエクスポートします。このファイルは、パイプラインサービスの一部としてエクスポートされたメトリクスを保存します。\nGateway にデータが到着したことの確認: CPU メトリクス（特に cpu0）が Gateway に正常に到達したことを確認するために、jq コマンドを使用して gateway-metrics.out ファイルを検査します。\n以下のコマンドは、system.cpu.time メトリクスをフィルタリングして抽出し、cpu0 に焦点を当てます。メトリクスの状態（例：user、system、idle、interrupt）と対応する値を表示します。\n3つ目のターミナルウィンドウを開くか作成し、Tests と名前を付けます。Tests ターミナル で以下のコマンドを実行して system.cpu.time メトリクスを確認します\n​ Check CPU Metrics Example Output jq '.resourceMetrics[].scopeMetrics[].metrics[] | select(.name == \"system.cpu.time\") | .sum.dataPoints[] | select(.attributes[0].value.stringValue == \"cpu0\") | {cpu: .attributes[0].value.stringValue, state: .attributes[1].value.stringValue, value: .asDouble}' gateway-metrics.out { \"cpu\": \"cpu0\", \"state\": \"user\", \"value\": 123407.02 } { \"cpu\": \"cpu0\", \"state\": \"system\", \"value\": 64866.6 } { \"cpu\": \"cpu0\", \"state\": \"idle\", \"value\": 216427.87 } { \"cpu\": \"cpu0\", \"state\": \"interrupt\", \"value\": 0 } 重要 Agent と Gateway のプロセスを、それぞれのターミナルで Ctrl-C を押して停止してください。",
    "description": "次に、Gateway と Agent を起動します。Agent は起動時に自動的に Host Metrics を送信するよう設定されています。これにより、データが Agent から Gateway に正しくルーティングされることを確認します。\nExercise Gateway: Gateway ターミナル ウィンドウで、以下のコマンドを実行して Gateway を起動します\n​ Start the Gateway ../otelcol --config=gateway.yaml すべてが正しく設定されている場合、Collector が起動し、出力に Everything is ready. Begin running and processing data. と表示されます。以下のような出力になります\n2025-06-09T09:22:11.944+0100 info service@v0.126.0/service.go:289 Everything is ready. Begin running and processing data. {\"resource\": {}} Gateway が実行されると、ポート 5318 で受信データをリッスンし、受信したデータを以下のファイルにエクスポートします",
    "tags": [],
    "title": "1.2 設定の検証とテスト",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/1-agent-gateway/1-2-send-metrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 2. API Test",
    "content": "認証リクエストの追加 + Add requests をクリックし、リクエストステップ名を入力します（例: Authenticate with Spotify API）。\nRequest セクションを展開し、ドロップダウンからリクエストメソッドを POST に変更して、以下の URL を入力します:\nhttps://accounts.spotify.com/api/token Payload body セクションに以下を入力します:\ngrant_type=client_credentials 次に、以下のキー/値のペアで2つのリクエストヘッダーを追加します:\nCONTENT-TYPE: application/x-www-form-urlencoded AUTHORIZATION: Basic {{env.encoded_auth}} Validation セクションを展開し、以下の抽出を追加します:\nExtract from Response body JSON $.access_token as access_token これにより、Spotify API から受信した JSON ペイロードを解析し、アクセストークンを抽出してカスタム変数として保存します。",
    "description": "認証リクエストの追加 + Add requests をクリックし、リクエストステップ名を入力します（例: Authenticate with Spotify API）。\nRequest セクションを展開し、ドロップダウンからリクエストメソッドを POST に変更して、以下の URL を入力します:\nhttps://accounts.spotify.com/api/token Payload body セクションに以下を入力します:\ngrant_type=client_credentials 次に、以下のキー/値のペアで2つのリクエストヘッダーを追加します:\nCONTENT-TYPE: application/x-www-form-urlencoded AUTHORIZATION: Basic {{env.encoded_auth}} Validation セクションを展開し、以下の抽出を追加します:\nExtract from Response body JSON $.access_token as access_token これにより、Spotify API から受信した JSON ペイロードを解析し、アクセストークンを抽出してカスタム変数として保存します。",
    "tags": [],
    "title": "認証リクエスト",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/2-api-test/3-authentication-request/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 1. Real Browser Test",
    "content": "テストの設定を開始するには、Chrome DevTools Recorder からエクスポートした JSON をインポートする必要があります。Import ボタンを有効にするには、まずテストに名前を付ける必要があります（例: \u003cyour initials\u003e - Online Boutique）。\nImport ボタンが有効になったら、クリックして Chrome DevTools Recorder からエクスポートした JSON ファイルをドロップするか、ファイルをアップロードします。\nJSON ファイルがアップロードされたら、Continue to edit steps をクリックします。\nテストを編集する前に、まず設定を構成します。\u003c Return to test をクリックします。",
    "description": "テストの設定を開始するには、Chrome DevTools Recorder からエクスポートした JSON をインポートする必要があります。Import ボタンを有効にするには、まずテストに名前を付ける必要があります（例: \u003cyour initials\u003e - Online Boutique）。\nImport ボタンが有効になったら、クリックして Chrome DevTools Recorder からエクスポートした JSON ファイルをドロップするか、ファイルをアップロードします。\nJSON ファイルがアップロードされたら、Continue to edit steps をクリックします。",
    "tags": [],
    "title": "1.3 JSON のインポート",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/3-import-json/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 2. 準備",
    "content": "アプリケーションの最初のデプロイメントでは、ビルド済みのコンテナを使用して、観測を開始したい Kubernetes で実行される通常の Java マイクロサービスベースのアプリケーションという基本シナリオを作成します。それでは、アプリケーションをデプロイしましょう：\n​ kubectl apply Output kubectl apply -f ~/workshop/petclinic/deployment.yaml deployment.apps/config-server created service/config-server created deployment.apps/discovery-server created service/discovery-server created deployment.apps/api-gateway created service/api-gateway created service/api-gateway-external created deployment.apps/customers-service created service/customers-service created deployment.apps/vets-service created service/vets-service created deployment.apps/visits-service created service/visits-service created deployment.apps/admin-server created service/admin-server created service/petclinic-db created deployment.apps/petclinic-db created configmap/petclinic-db-initdb-config created deployment.apps/petclinic-loadgen-deployment created configmap/scriptfile created この時点で、Pod が実行されていることを確認してデプロイメントを検証できます。コンテナのダウンロードと起動が必要なため、数分かかる場合があります。\n​ kubectl get pods Output kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-k8s-cluster-receiver-655dcd9b6b-dcvkb 1/1 Running 0 114s splunk-otel-collector-agent-dg2vj 1/1 Running 0 114s splunk-otel-collector-operator-57cbb8d7b4-dk5wf 2/2 Running 0 114s petclinic-db-64d998bb66-2vzpn 1/1 Running 0 58s api-gateway-d88bc765-jd5lg 1/1 Running 0 58s visits-service-7f97b6c579-bh9zj 1/1 Running 0 58s admin-server-76d8b956c5-mb2zv 1/1 Running 0 58s customers-service-847db99f79-mzlg2 1/1 Running 0 58s vets-service-7bdcd7dd6d-2tcfd 1/1 Running 0 58s petclinic-loadgen-deployment-5d69d7f4dd-xxkn4 1/1 Running 0 58s config-server-67f7876d48-qrsr5 1/1 Running 0 58s discovery-server-554b45cfb-bqhgt 1/1 Running 0 58s kubectl get pods の出力が、上記の Output タブに示されている出力と一致することを確認してください。すべてのサービスが Running と表示されていることを確認してください（または k9s を使用してステータスを継続的に監視できます）。\nアプリケーションをテストするには、インスタンスのパブリック IP アドレスを取得する必要があります。以下のコマンドを実行して取得できます：\ncurl http://ifconfig.me http://\u003cIP_ADDRESS\u003e:81（\u003cIP_ADDRESS\u003e を上記で取得した IP アドレスに置き換えてください）にアクセスして、アプリケーションが実行されていることを確認してください。PetClinic アプリケーションが実行されているのが確認できるはずです。アプリケーションはポート 80 と 443 でも実行されているので、これらを使用するか、ポート 81 に到達できない場合はそちらを使用してください。\nAll Owners (1) タブと Veterinarians (2) タブにアクセスして、各ページに名前のリストが表示されることを確認し、アプリケーションが正しく動作していることを確認してください。",
    "description": "アプリケーションの最初のデプロイメントでは、ビルド済みのコンテナを使用して、観測を開始したい Kubernetes で実行される通常の Java マイクロサービスベースのアプリケーションという基本シナリオを作成します。それでは、アプリケーションをデプロイしましょう：\n​ kubectl apply Output kubectl apply -f ~/workshop/petclinic/deployment.yaml deployment.apps/config-server created service/config-server created deployment.apps/discovery-server created service/discovery-server created deployment.apps/api-gateway created service/api-gateway created service/api-gateway-external created deployment.apps/customers-service created service/customers-service created deployment.apps/vets-service created service/vets-service created deployment.apps/visits-service created service/visits-service created deployment.apps/admin-server created service/admin-server created service/petclinic-db created deployment.apps/petclinic-db created configmap/petclinic-db-initdb-config created deployment.apps/petclinic-loadgen-deployment created configmap/scriptfile created この時点で、Pod が実行されていることを確認してデプロイメントを検証できます。コンテナのダウンロードと起動が必要なため、数分かかる場合があります。",
    "tags": [],
    "title": "PetClinic アプリケーションのデプロイ",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/2-preparation/2-petclinic/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 7. Log Observer",
    "content": "下部のペインには、関連するコンテンツが表示されます。以下のスクリーンショットでは、APM がこのログ行に関連するトレースを見つけたことがわかります (1):\nTrace for 960432ac9f16b98be84618778905af50 (2) をクリックすると、このログ行が生成された特定のトレースの APM ウォーターフォールに移動します:\nログに関する Related Content ペーンが表示されていることに注意してください (1)。これをクリックすると、Log Observer に戻り、このトレースの一部であるすべてのログ行が表示されます。",
    "description": "下部のペインには、関連するコンテンツが表示されます。以下のスクリーンショットでは、APM がこのログ行に関連するトレースを見つけたことがわかります (1):\nTrace for 960432ac9f16b98be84618778905af50 (2) をクリックすると、このログ行が生成された特定のトレースの APM ウォーターフォールに移動します:\nログに関する Related Content ペーンが表示されていることに注意してください (1)。これをクリックすると、Log Observer に戻り、このトレースの一部であるすべてのログ行が表示されます。",
    "tags": [],
    "title": "Related Content",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/7-log-observer-connect/2-related-content/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 9. サービスヘルスダッシュボード",
    "content": "ワークショップのこのパートでは、ダッシュボードに追加するチャートを作成し、また以前に構築したディテクターにリンクします。これにより、テストの動作を確認し、1 つ以上のテスト実行が SLA を違反した場合にアラートを受け取ることができます。\n演習 ダッシュボードの上部にある + をクリックし、チャートを選択します。 まず、Untitled Chart入力フィールドを使用して、チャートに全体テスト所要時間という名前を付けます。 この演習では棒グラフまたは柱状グラフが必要なので、チャートオプションボックスの 3 番目のアイコンをクリックします。 Plot editorのSignalボックスにsynthetics.run.duration.time.ms（これはテストの実行時間です）と入力し、Enter キーを押します。 現在、異なる色の棒が表示されています。テストが実行される各リージョンごとに異なる色になっています。これは必要ないので、分析を追加することでその動作を変更できます。 Add Analyticsボタンをクリックします。 ドロップダウンからMeanオプションを選択し、mean:aggregationを選択してダイアログボックスの外をクリックします。メトリクスが集計されるため、チャートが単色に変わることに注目してください。 x 軸は現在、時間を表していません。これを変更するには、プロットラインの最後にある設定アイコンをクリックします。次のダイアログが開きます： ドロップダウンボックスのDisplay Units（2）をnoneから Time (autoscaling)/Milliseconds(ms) に変更します。ドロップダウンがMillisecondに変わり、チャートの x 軸がテスト所要時間を表すようになります。 設定アイコンをクリックするか、Closeボタンをクリックして、ダイアログを閉じます。 Link Detectirボタンをクリックし、以前に作成したディテクターの名前の入力を開始して、ディテクターを追加します。 ディテクター名をクリックして選択します。 チャートの周りに色付きの枠が表示され、アラートのステータスが示されます。また、以下のようにダッシュボードの上部にベルアイコンが表示されることに注目してください： Save and Closeボタンをクリックします。 ダッシュボードで、チャートを移動して以下のスクリーンショットのように表示させます： 最後のタスクとして、ページ上部（Event Overlayの横）にある 3 つのドット … をクリックし、View fullscreenをクリックします。これは壁掛けテレビモニターで使用するビューです（元に戻るには Esc キーを押します）。 ヒント 時間があれば、RUM メトリクスを使用してダッシュボードにもう 1 つのカスタムチャートを追加してみてください。既製のRUM アプリケーションダッシュボードグループからチャートをコピーすることができます。または、RUM メトリクスrum.client_error.countを使用して、アプリケーションのクライアントエラー数を表示するチャートを作成することもできます。\n最後に、ワークショップのまとめを行います。",
    "description": "ワークショップのこのパートでは、ダッシュボードに追加するチャートを作成し、また以前に構築したディテクターにリンクします。これにより、テストの動作を確認し、1 つ以上のテスト実行が SLA を違反した場合にアラートを受け取ることができます。\n演習 ダッシュボードの上部にある + をクリックし、チャートを選択します。 まず、Untitled Chart入力フィールドを使用して、チャートに全体テスト所要時間という名前を付けます。 この演習では棒グラフまたは柱状グラフが必要なので、チャートオプションボックスの 3 番目のアイコンをクリックします。 Plot editorのSignalボックスにsynthetics.run.duration.time.ms（これはテストの実行時間です）と入力し、Enter キーを押します。 現在、異なる色の棒が表示されています。テストが実行される各リージョンごとに異なる色になっています。これは必要ないので、分析を追加することでその動作を変更できます。 Add Analyticsボタンをクリックします。 ドロップダウンからMeanオプションを選択し、mean:aggregationを選択してダイアログボックスの外をクリックします。メトリクスが集計されるため、チャートが単色に変わることに注目してください。 x 軸は現在、時間を表していません。これを変更するには、プロットラインの最後にある設定アイコンをクリックします。次のダイアログが開きます： ドロップダウンボックスのDisplay Units（2）をnoneから Time (autoscaling)/Milliseconds(ms) に変更します。ドロップダウンがMillisecondに変わり、チャートの x 軸がテスト所要時間を表すようになります。 設定アイコンをクリックするか、Closeボタンをクリックして、ダイアログを閉じます。 Link Detectirボタンをクリックし、以前に作成したディテクターの名前の入力を開始して、ディテクターを追加します。 ディテクター名をクリックして選択します。 チャートの周りに色付きの枠が表示され、アラートのステータスが示されます。また、以下のようにダッシュボードの上部にベルアイコンが表示されることに注目してください： Save and Closeボタンをクリックします。 ダッシュボードで、チャートを移動して以下のスクリーンショットのように表示させます： 最後のタスクとして、ページ上部（Event Overlayの横）にある 3 つのドット … をクリックし、View fullscreenをクリックします。これは壁掛けテレビモニターで使用するビューです（元に戻るには Esc キーを押します）。 ヒント 時間があれば、RUM メトリクスを使用してダッシュボードにもう 1 つのカスタムチャートを追加してみてください。既製のRUM アプリケーションダッシュボードグループからチャートをコピーすることができます。または、RUM メトリクスrum.client_error.countを使用して、アプリケーションのクライアントエラー数を表示するチャートを作成することもできます。",
    "tags": [],
    "title": "カスタムチャートの追加",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/9-custom-dashboard/3-custom-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "インストラクターが、このワークショップで使用するインスタンスのログイン情報を提供します。\nインスタンスに初めてログインすると、以下のような Splunk ロゴが表示されます。ワークショップインスタンスへの接続に問題がある場合は、インストラクターにお問い合わせください。\n$ ssh -p 2222 splunk@\u003cIP-ADDRESS\u003e ███████╗██████╗ ██╗ ██╗ ██╗███╗ ██╗██╗ ██╗ ██╗ ██╔════╝██╔══██╗██║ ██║ ██║████╗ ██║██║ ██╔╝ ╚██╗ ███████╗██████╔╝██║ ██║ ██║██╔██╗ ██║█████╔╝ ╚██╗ ╚════██║██╔═══╝ ██║ ██║ ██║██║╚██╗██║██╔═██╗ ██╔╝ ███████║██║ ███████╗╚██████╔╝██║ ╚████║██║ ██╗ ██╔╝ ╚══════╝╚═╝ ╚══════╝ ╚═════╝ ╚═╝ ╚═══╝╚═╝ ╚═╝ ╚═╝ Last login: Mon Feb 5 11:04:54 2024 from [Redacted] splunk@show-no-config-i-0d1b29d967cb2e6ff ~ $ インスタンスが正しく設定されていることを確認するために、このワークショップに必要な環境変数が正しく設定されているか確認する必要があります。ターミナルで以下のスクリプトを実行し、環境変数が存在し、実際の有効な値が設定されていることを確認してください：\n​ Script Example Output . ~/workshop/petclinic/scripts/check_env.sh ACCESS_TOKEN = \u003credacted\u003e REALM = \u003ce.g. eu0, us1, us2, jp0, au0 etc.\u003e RUM_TOKEN = \u003credacted\u003e HEC_TOKEN = \u003credacted\u003e HEC_URL = https://\u003c...\u003e/services/collector/event INSTANCE = \u003cinstance_name\u003e INSTANCE 環境変数の値をメモしておいてください。後で Splunk Observability Cloud でデータをフィルタリングする際に使用します。\nこのワークショップでは、上記の環境変数がすべて必要です。値が不足しているものがある場合は、インストラクターに連絡してください。\n既存の OpenTelemetry Collector の削除 この EC2 インスタンスを使用して以前に Splunk Observability ワークショップを完了している場合は、 既存の Splunk OpenTelemetry Collector のインストールが削除されていることを確認する必要があります。 これは以下のコマンドを実行することで行えます：\nhelm delete splunk-otel-collector",
    "description": "インストラクターが、このワークショップで使用するインスタンスのログイン情報を提供します。\nインスタンスに初めてログインすると、以下のような Splunk ロゴが表示されます。ワークショップインスタンスへの接続に問題がある場合は、インストラクターにお問い合わせください。\n$ ssh -p 2222 splunk@\u003cIP-ADDRESS\u003e ███████╗██████╗ ██╗ ██╗ ██╗███╗ ██╗██╗ ██╗ ██╗ ██╔════╝██╔══██╗██║ ██║ ██║████╗ ██║██║ ██╔╝ ╚██╗ ███████╗██████╔╝██║ ██║ ██║██╔██╗ ██║█████╔╝ ╚██╗ ╚════██║██╔═══╝ ██║ ██║ ██║██║╚██╗██║██╔═██╗ ██╔╝ ███████║██║ ███████╗╚██████╔╝██║ ╚████║██║ ██╗ ██╔╝ ╚══════╝╚═╝ ╚══════╝ ╚═════╝ ╚═╝ ╚═══╝╚═╝ ╚═╝ ╚═╝ Last login: Mon Feb 5 11:04:54 2024 from [Redacted] splunk@show-no-config-i-0d1b29d967cb2e6ff ~ $ インスタンスが正しく設定されていることを確認するために、このワークショップに必要な環境変数が正しく設定されているか確認する必要があります。ターミナルで以下のスクリプトを実行し、環境変数が存在し、実際の有効な値が設定されていることを確認してください：\n​ Script Example Output . ~/workshop/petclinic/scripts/check_env.sh ACCESS_TOKEN = \u003credacted\u003e REALM = \u003ce.g. eu0, us1, us2, jp0, au0 etc.\u003e RUM_TOKEN = \u003credacted\u003e HEC_TOKEN = \u003credacted\u003e HEC_URL = https://\u003c...\u003e/services/collector/event INSTANCE = \u003cinstance_name\u003e INSTANCE 環境変数の値をメモしておいてください。後で Splunk Observability Cloud でデータをフィルタリングする際に使用します。",
    "tags": [],
    "title": "ワークショップインスタンスの準備",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/2-preparation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 2. Building Resilience",
    "content": "Agent の耐障害性を評価するために、一時的な Gateway の停止をシミュレートし、Agent がそれをどのように処理するかを観察します\nExercise ネットワーク障害のシミュレーション: Gateway ターミナル で Ctrl-C を使用して Gateway を停止し、Gateway のコンソールが停止したことを示すまで待ちます。Agent は引き続き実行されますが、Gateway にデータを送信できません。Gateway ターミナル の出力は以下のようになります\n2025-07-09T10:22:37.941Z info service@v0.126.0/service.go:345 Shutdown complete. {\"resource\": {}} トレースの送信: Loadgen ターミナル ウィンドウで、loadgen を使用してさらに5つのトレースを送信します。\n​ Start Load Generator ../loadgen -count 5 Agent のリトライメカニズムが有効になり、データを再送信しようと継続的に試みていることに注目してください。Agent のコンソール出力には、以下のようなメッセージが繰り返し表示されます\n2025-01-28T14:22:47.020+0100 info internal/retry_sender.go:126 Exporting failed. Will retry the request after interval. {\"kind\": \"exporter\", \"data_type\": \"traces\", \"name\": \"otlphttp\", \"error\": \"failed to make an HTTP request: Post \\\"http://localhost:5318/v1/traces\\\": dial tcp 127.0.0.1:5318: connect: connection refused\", \"interval\": \"9.471474933s\"} Agent の停止: Agent ターミナル ウィンドウで、Ctrl-C を使用して Agent を停止します。Agent のコンソールが停止を確認するまで待ちます\n2025-07-09T10:25:59.344Z info service@v0.126.0/service.go:345 Shutdown complete. {\"resource\": {}} 重要 Agent を停止すると、リトライ用にメモリに保持されているメトリクス、トレース、ログは失われます。ただし、FileStorage Extension を設定しているため、ターゲットエンドポイントでまだ受け入れられていないすべてのテレメトリーはディスクに安全にチェックポイントされています。\nAgent の停止は、Agent が再起動されたときにシステムがどのように復旧するかを明確に示すための重要なステップです。",
    "description": "Agent の耐障害性を評価するために、一時的な Gateway の停止をシミュレートし、Agent がそれをどのように処理するかを観察します\nExercise ネットワーク障害のシミュレーション: Gateway ターミナル で Ctrl-C を使用して Gateway を停止し、Gateway のコンソールが停止したことを示すまで待ちます。Agent は引き続き実行されますが、Gateway にデータを送信できません。Gateway ターミナル の出力は以下のようになります\n2025-07-09T10:22:37.941Z info service@v0.126.0/service.go:345 Shutdown complete. {\"resource\": {}} トレースの送信: Loadgen ターミナル ウィンドウで、loadgen を使用してさらに5つのトレースを送信します。\n​ Start Load Generator ../loadgen -count 5 Agent のリトライメカニズムが有効になり、データを再送信しようと継続的に試みていることに注目してください。Agent のコンソール出力には、以下のようなメッセージが繰り返し表示されます\n2025-01-28T14:22:47.020+0100 info internal/retry_sender.go:126 Exporting failed. Will retry the request after interval. {\"kind\": \"exporter\", \"data_type\": \"traces\", \"name\": \"otlphttp\", \"error\": \"failed to make an HTTP request: Post \\\"http://localhost:5318/v1/traces\\\": dial tcp 127.0.0.1:5318: connect: connection refused\", \"interval\": \"9.471474933s\"} Agent の停止: Agent ターミナル ウィンドウで、Ctrl-C を使用して Agent を停止します。Agent のコンソールが停止を確認するまで待ちます",
    "tags": [],
    "title": "2.3 障害のシミュレーション",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/2-building-resilience/2-3-failure/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 2. Extensions",
    "content": "zPages zPages は、外部エクスポーターの代わりにインプロセスで使用できる機能です。組み込まれると、バックグラウンドでトレースとメトリクス情報を収集・集約し、リクエストされたときにウェブページでこのデータを提供します。zPages は、Collector が期待どおりに動作していることを確認するための非常に便利な診断機能です。\n​ ServiceZ PipelineZ ExtensionZ ServiceZ は、Collector サービスの概要と、pipelinez、extensionz、featurez の各 zPages へのクイックアクセスを提供します。このページには、ビルド情報とランタイム情報も表示されます。\nサンプル URL: http://localhost:55679/debug/servicez（localhost をご自身の環境に合わせて変更してください）。\nPipelineZ は、Collector で実行されているパイプラインに関する洞察を提供します。タイプ、データが変更されるかどうかの情報を確認でき、各パイプラインで使用されているレシーバー、プロセッサー、エクスポーターの情報も確認できます。\nサンプル URL: http://localhost:55679/debug/pipelinez（localhost をご自身の環境に合わせて変更してください）。\nExtensionZ は、Collector でアクティブな拡張機能を表示します。\nサンプル URL: http://localhost:55679/debug/extensionz（localhost をご自身の環境に合わせて変更してください）。\nNinja: storage 拡張機能でデータの耐久性を向上させる このためには、使用しているディストリビューションに file_storage 拡張機能がインストールされていることを確認する必要があります。これは、otelcol-contrib components コマンドを実行することで確認でき、以下のような結果が表示されるはずです\n​ Truncated Output Full Output # ... truncated for clarity extensions: - file_storage buildinfo: command: otelcol-contrib description: OpenTelemetry Collector Contrib version: 0.80.0 receivers: - prometheus_simple - apache - influxdb - purefa - purefb - receiver_creator - mongodbatlas - vcenter - snmp - expvar - jmx - kafka - skywalking - udplog - carbon - kafkametrics - memcached - prometheus - windowseventlog - zookeeper - otlp - awsecscontainermetrics - iis - mysql - nsxt - aerospike - elasticsearch - httpcheck - k8sobjects - mongodb - hostmetrics - signalfx - statsd - awsxray - cloudfoundry - collectd - couchdb - kubeletstats - jaeger - journald - riak - splunk_hec - active_directory_ds - awscloudwatch - sqlquery - windowsperfcounters - flinkmetrics - googlecloudpubsub - podman_stats - wavefront - k8s_events - postgresql - rabbitmq - sapm - sqlserver - redis - solace - tcplog - awscontainerinsightreceiver - awsfirehose - bigip - filelog - googlecloudspanner - cloudflare - docker_stats - k8s_cluster - pulsar - zipkin - nginx - opencensus - azureeventhub - datadog - fluentforward - otlpjsonfile - syslog processors: - resource - batch - cumulativetodelta - groupbyattrs - groupbytrace - k8sattributes - experimental_metricsgeneration - metricstransform - routing - attributes - datadog - deltatorate - spanmetrics - span - memory_limiter - redaction - resourcedetection - servicegraph - transform - filter - probabilistic_sampler - tail_sampling exporters: - otlp - carbon - datadog - f5cloud - kafka - mezmo - skywalking - awsxray - dynatrace - loki - prometheus - logging - azuredataexplorer - azuremonitor - instana - jaeger - loadbalancing - sentry - splunk_hec - tanzuobservability - zipkin - alibabacloud_logservice - clickhouse - file - googlecloud - prometheusremotewrite - awscloudwatchlogs - googlecloudpubsub - jaeger_thrift - logzio - sapm - sumologic - otlphttp - googlemanagedprometheus - opencensus - awskinesis - coralogix - influxdb - logicmonitor - signalfx - tencentcloud_logservice - awsemf - elasticsearch - pulsar extensions: - zpages - bearertokenauth - oidc - host_observer - sigv4auth - file_storage - memory_ballast - health_check - oauth2client - awsproxy - http_forwarder - jaegerremotesampling - k8s_observer - pprof - asapclient - basicauth - headers_setter この拡張機能は、エクスポーターが設定されたエンドポイントにデータを送信できない場合に、エクスポーターがデータをディスクにキューイングする機能を提供します。\n拡張機能を設定するには、以下の情報を含めるように設定を更新する必要があります。まず、/tmp/otel-data ディレクトリを作成し、読み書き権限を付与してください\nextensions: ... file_storage: directory: /tmp/otel-data timeout: 10s compaction: directory: /tmp/otel-data on_start: true on_rebound: true rebound_needed_threshold_mib: 5 rebound_trigger_threshold_mib: 3 # ... truncated for clarity service: extensions: [health_check, pprof, zpages, file_storage] なぜデータをディスクにキューイングするのか？ これにより、Collector はネットワークの中断（さらには Collector の再起動）を乗り越えて、データがアップストリームプロバイダーに送信されることを保証できます。\nデータをディスクにキューイングする際の考慮事項 ディスクのパフォーマンスにより、データスループットのパフォーマンスに影響を与える可能性があります。\n参考資料 https://community.splunk.com/t5/Community-Blog/Data-Persistence-in-the-OpenTelemetry-Collector/ba-p/624583 https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/storage/filestorage 設定の確認 拡張機能について学んだので、設定の変更を確認しましょう。\nCheck-in設定を確認する ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # See https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md#safeguards-against-denial-of-service-attacks extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 opencensus: endpoint: 0.0.0.0:55678 # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_binary: endpoint: 0.0.0.0:6832 thrift_compact: endpoint: 0.0.0.0:6831 thrift_http: endpoint: 0.0.0.0:14268 zipkin: endpoint: 0.0.0.0:9411 processors: batch: exporters: debug: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [debug] logs: receivers: [otlp] processors: [batch] exporters: [debug] extensions: [health_check, pprof, zpages] 拡張機能について確認したので、次はワークショップのデータパイプライン部分に進みましょう。パイプラインは、Collector 内でデータが辿る経路を定義し、受信から始まり、さらなる処理や変更を経て、最終的にエクスポーターを通じて Collector を出ていきます。\nOpenTelemetry Collector のデータパイプラインは、レシーバー、プロセッサー、エクスポーターで構成されています。まずはレシーバーから始めます。",
    "description": "zPages zPages は、外部エクスポーターの代わりにインプロセスで使用できる機能です。組み込まれると、バックグラウンドでトレースとメトリクス情報を収集・集約し、リクエストされたときにウェブページでこのデータを提供します。zPages は、Collector が期待どおりに動作していることを確認するための非常に便利な診断機能です。\n​ ServiceZ PipelineZ ExtensionZ ServiceZ は、Collector サービスの概要と、pipelinez、extensionz、featurez の各 zPages へのクイックアクセスを提供します。このページには、ビルド情報とランタイム情報も表示されます。\nサンプル URL: http://localhost:55679/debug/servicez（localhost をご自身の環境に合わせて変更してください）。\nPipelineZ は、Collector で実行されているパイプラインに関する洞察を提供します。タイプ、データが変更されるかどうかの情報を確認でき、各パイプラインで使用されているレシーバー、プロセッサー、エクスポーターの情報も確認できます。\nサンプル URL: http://localhost:55679/debug/pipelinez（localhost をご自身の環境に合わせて変更してください）。",
    "tags": [],
    "title": "OpenTelemetry Collector Extensions",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/2-extensions/3-zpages/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 2. エクステンション",
    "content": "zPages エクステンション zPages は、外部エクスポータに代わるプロセス内部の機能です。有効化すると、バックグラウンドでトレースとメトリクス情報を収集し、集計し、どのようなデータを扱ったかの Web ページを公開します。zpages は、コレクターが期待どおりに動作していることを確認するための非常に便利な診断機能です。\n​ ServiceZ PipelineZ ExtensionZ ServiceZ は、コレクターサービスの概要と、pipelinez、extensionz、featurez zPages へのクイックアクセスを提供します。このページでは、ビルドとランタイムの情報も提供します。\nURL: http://localhost:55679/debug/servicez (localhost は、適切なホスト名に切り替えてください)\nPipelineZ は、コレクターで実行中のパイプラインに関する情報を提供します。タイプ、データが変更されているか、各パイプラインで使用されているレシーバー、プロセッサー、エクスポーターの情報を見ることができます。\nURL: http://localhost:55679/debug/pipelinez (localhost は、適切なホスト名に切り替えてください)\nExtensionZ は、コレクターで有効化されたエクステンションを確認できます。\nExample URL: http://localhost:55679/debug/extensionz (localhost は、適切なホスト名に切り替えてください)\nNinja: storage エクステンションでデータの耐久性を向上させる これをこなうには、ディストリビューションに file_storage エクステンションモジュールがインストールされていることを確認する必要があります。確認するには、otelcol-contrib components コマンドを実行します:\n​ Command Truncated Output Full Output otelcol-contrib components # ... truncated for clarity extensions: - file_storage buildinfo: command: otelcol-contrib description: OpenTelemetry Collector Contrib version: 0.80.0 receivers: - prometheus_simple - apache - influxdb - purefa - purefb - receiver_creator - mongodbatlas - vcenter - snmp - expvar - jmx - kafka - skywalking - udplog - carbon - kafkametrics - memcached - prometheus - windowseventlog - zookeeper - otlp - awsecscontainermetrics - iis - mysql - nsxt - aerospike - elasticsearch - httpcheck - k8sobjects - mongodb - hostmetrics - signalfx - statsd - awsxray - cloudfoundry - collectd - couchdb - kubeletstats - jaeger - journald - riak - splunk_hec - active_directory_ds - awscloudwatch - sqlquery - windowsperfcounters - flinkmetrics - googlecloudpubsub - podman_stats - wavefront - k8s_events - postgresql - rabbitmq - sapm - sqlserver - redis - solace - tcplog - awscontainerinsightreceiver - awsfirehose - bigip - filelog - googlecloudspanner - cloudflare - docker_stats - k8s_cluster - pulsar - zipkin - nginx - opencensus - azureeventhub - datadog - fluentforward - otlpjsonfile - syslog processors: - resource - batch - cumulativetodelta - groupbyattrs - groupbytrace - k8sattributes - experimental_metricsgeneration - metricstransform - routing - attributes - datadog - deltatorate - spanmetrics - span - memory_limiter - redaction - resourcedetection - servicegraph - transform - filter - probabilistic_sampler - tail_sampling exporters: - otlp - carbon - datadog - f5cloud - kafka - mezmo - skywalking - awsxray - dynatrace - loki - prometheus - logging - azuredataexplorer - azuremonitor - instana - jaeger - loadbalancing - sentry - splunk_hec - tanzuobservability - zipkin - alibabacloud_logservice - clickhouse - file - googlecloud - prometheusremotewrite - awscloudwatchlogs - googlecloudpubsub - jaeger_thrift - logzio - sapm - sumologic - otlphttp - googlemanagedprometheus - opencensus - awskinesis - coralogix - influxdb - logicmonitor - signalfx - tencentcloud_logservice - awsemf - elasticsearch - pulsar extensions: - zpages - bearertokenauth - oidc - host_observer - sigv4auth - file_storage - memory_ballast - health_check - oauth2client - awsproxy - http_forwarder - jaegerremotesampling - k8s_observer - pprof - asapclient - basicauth - headers_setter このエクステンションは、エクスポーターが設定されたエンドポイントにデータを送信できない事象が発生したときに、データをディスクにキューイングする機能をエクスポーターに提供します。\nこのエクステンションを設定するには、以下の情報を含むように設定を更新する必要があります。まず、 /tmp/otel-data ディレクトリを作成し、読み取り/書き込み権限を与えてください：\nextensions: ... file_storage: directory: /tmp/otel-data timeout: 10s compaction: directory: /tmp/otel-data on_start: true on_rebound: true rebound_needed_threshold_mib: 5 rebound_trigger_threshold_mib: 3 # ... truncated for clarity service: extensions: [health_check, pprof, zpages, file_storage] なぜキューデータをディスクに書くの？ コレクターはネットワークの不調（および、コレクターの再起動）を乗り切って、アップストリームプロバイダーに確実にデータを送信できるようになります。\nキューデータをディスクに書く時の注意事項は？ ディスクの性能により、データスループットの性能に影響を与える可能性があります\n参照 https://community.splunk.com/t5/Community-Blog/Data-Persistence-in-the-OpenTelemetry-Collector/ba-p/624583 https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/storage/filestorage 設定を確認しましょう さて、エクステンションについて説明したので、設定の変更箇所を確認していきましょう。\nCheck-in設定ファイルを確認してください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] さて、エクステンションについて復習したところで、ワークショップのデータパイプラインの部分に飛び込んでみましょう。パイプラインとは、コレクター内でデータがたどる経路を定義するもので、レシーバーから始まり、追加の処理や変更をし、最終的にエクスポーターを経由してコレクターを出ます。\nOpenTelemetry Collector のデータパイプラインは、レシーバー、プロセッサー、エクスポーターで構成されています。まずは、レシーバーから見ていきましょう。",
    "description": "zPages エクステンション zPages は、外部エクスポータに代わるプロセス内部の機能です。有効化すると、バックグラウンドでトレースとメトリクス情報を収集し、集計し、どのようなデータを扱ったかの Web ページを公開します。zpages は、コレクターが期待どおりに動作していることを確認するための非常に便利な診断機能です。\n​ ServiceZ PipelineZ ExtensionZ ServiceZ は、コレクターサービスの概要と、pipelinez、extensionz、featurez zPages へのクイックアクセスを提供します。このページでは、ビルドとランタイムの情報も提供します。\nURL: http://localhost:55679/debug/servicez (localhost は、適切なホスト名に切り替えてください)\nPipelineZ は、コレクターで実行中のパイプラインに関する情報を提供します。タイプ、データが変更されているか、各パイプラインで使用されているレシーバー、プロセッサー、エクスポーターの情報を見ることができます。\nURL: http://localhost:55679/debug/pipelinez (localhost は、適切なホスト名に切り替えてください)",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/2-extensions/3-zpages/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "前提条件 アプリケーションをデプロイする前に、インスタンスに.NET 8 SDK をインストールする必要があります。\n​ Script Example Output sudo apt-get update \u0026\u0026 \\ sudo apt-get install -y dotnet-sdk-8.0 Hit:1 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy InRelease Hit:2 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease Hit:3 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-backports InRelease Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease Ign:5 https://splunk.jfrog.io/splunk/otel-collector-deb release InRelease Hit:6 https://splunk.jfrog.io/splunk/otel-collector-deb release Release Reading package lists... Done Reading package lists... Done Building dependency tree... Done Reading state information... Done The following additional packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 The following NEW packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-sdk-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 0 upgraded, 13 newly installed, 0 to remove and 0 not upgraded. Need to get 138 MB of archives. After this operation, 495 MB of additional disk space will be used. etc. 詳細については、Ubuntu に.NET SDK または.NET Runtime をインストールする を参照してください。\n.NET アプリケーションの確認 ターミナルで、アプリケーションディレクトリに移動します：\ncd ~/workshop/docker-k8s-otel/helloworld このワークショップでは、シンプルな「Hello World」.NET アプリケーションを使用します。主要なロジックは HelloWorldController.cs ファイルにあります：\npublic class HelloWorldController : ControllerBase { private ILogger\u003cHelloWorldController\u003e logger; public HelloWorldController(ILogger\u003cHelloWorldController\u003e logger) { this.logger = logger; } [HttpGet(\"/hello/{name?}\")] public string Hello(string name) { if (string.IsNullOrEmpty(name)) { logger.LogInformation(\"/hello endpoint invoked anonymously\"); return \"Hello, World!\"; } else { logger.LogInformation(\"/hello endpoint invoked by {name}\", name); return String.Format(\"Hello, {0}!\", name); } } } .NET アプリケーションのビルドと実行 以下のコマンドを使用してアプリケーションをビルドできます：\n​ Script Example Output dotnet build MSBuild version 17.8.5+b5265ef37 for .NET Determining projects to restore... All projects are up-to-date for restore. helloworld -\u003e /home/splunk/workshop/docker-k8s-otel/helloworld/bin/Debug/net8.0/helloworld.dll Build succeeded. 0 Warning(s) 0 Error(s) Time Elapsed 00:00:02.04 ビルドが成功したら、次のように実行できます：\n​ Script Example Output dotnet run Building... info: Microsoft.Hosting.Lifetime[14] Now listening on: http://localhost:8080 info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down. info: Microsoft.Hosting.Lifetime[0] Hosting environment: Development info: Microsoft.Hosting.Lifetime[0] Content root path: /home/splunk/workshop/docker-k8s-otel/helloworld 実行したら、Ubuntu インスタンスへの SSH 接続を 2 つ目のターミナルで開き、curl を使用してアプリケーションにアクセスします：\n​ Script Example Output curl http://localhost:8080/hello Hello, World! 名前を渡すこともできます：\n​ Script Example Output curl http://localhost:8080/hello/Tom Hello, Tom! 次のステップに進む前に、Ctrl + C を押して Helloworld アプリを終了してください。\n次のステップ アプリケーションを OpenTelemetry で計装するために使用できる 3 つの方法は何でしょうか？\nオプションの詳細については、Splunk Observability Cloud 用の.NET アプリケーションの計装 を参照してください。",
    "description": "前提条件 アプリケーションをデプロイする前に、インスタンスに.NET 8 SDK をインストールする必要があります。\n​ Script Example Output sudo apt-get update \u0026\u0026 \\ sudo apt-get install -y dotnet-sdk-8.0 Hit:1 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy InRelease Hit:2 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease Hit:3 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-backports InRelease Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease Ign:5 https://splunk.jfrog.io/splunk/otel-collector-deb release InRelease Hit:6 https://splunk.jfrog.io/splunk/otel-collector-deb release Release Reading package lists... Done Reading package lists... Done Building dependency tree... Done Reading state information... Done The following additional packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 The following NEW packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-sdk-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 0 upgraded, 13 newly installed, 0 to remove and 0 not upgraded. Need to get 138 MB of archives. After this operation, 495 MB of additional disk space will be used. etc. 詳細については、Ubuntu に.NET SDK または.NET Runtime をインストールする を参照してください。",
    "tags": [],
    "title": ".NETアプリケーションのデプロイ",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/3-deploy-dotnet-app/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 5. APM Features",
    "content": "スパンを調べる際、トレーシングの上で自動検出と設定を使用すると、コード変更なしで得られるいくつかの標準機能を見てみましょう：\nまず、Waterfall Paneで、以下のスクリーンショットに示すようにcustomers-service:SELECT petclinicまたは類似のスパンが選択されていることを確認してください：\n基本的なレイテンシ情報は、インストルメントされた関数または呼び出しのバーとして表示されます。上記の例では、17.8ミリ秒かかりました。 いくつかの類似したスパン**(1)**は、スパンが複数回繰り返される場合にのみ表示されます。この場合、例では10回の繰り返しがあります。10xをクリックすると、すべてのスパンが順番に表示されるように表示/非表示を切り替えることができます。 Inferred Services：インストルメントされていない外部システムへの呼び出しは、グレーの「推測された」スパンとして表示されます。この例のInferred Serviceまたはスパンは、上記に示すようにMysqlデータベース mysql:petclinic SELECT petclinic **(2)**への呼び出しです。 Span Tags：Tag Paneには、自動検出と設定によって生成された標準タグが表示されます。この場合、スパンはデータベースを呼び出しているため、db.statementタグ**(3)**が含まれています。このタグは、このスパン中に実行されたデータベース呼び出しで使用されるDBクエリステートメントを保持します。これはDB-Query Performance機能で使用されます。DB-Query Performanceについては次のセクションで見ていきます。 Always-on Profiling：システムがスパンのライフサイクル中にプロファイリングデータをキャプチャするように設定されている場合、スパンのタイムラインでキャプチャされたコールスタックの数が表示されます。上記の例では、customer-service:GET /ownersスパンに対して18個のコールスタックがあることがわかります。(4) 次のセクションでプロファイリングを見ていきます。",
    "description": "スパンを調べる際、トレーシングの上で自動検出と設定を使用すると、コード変更なしで得られるいくつかの標準機能を見てみましょう：\nまず、Waterfall Paneで、以下のスクリーンショットに示すようにcustomers-service:SELECT petclinicまたは類似のスパンが選択されていることを確認してください：\n基本的なレイテンシ情報は、インストルメントされた関数または呼び出しのバーとして表示されます。上記の例では、17.8ミリ秒かかりました。 いくつかの類似したスパン**(1)**は、スパンが複数回繰り返される場合にのみ表示されます。この場合、例では10回の繰り返しがあります。10xをクリックすると、すべてのスパンが順番に表示されるように表示/非表示を切り替えることができます。 Inferred Services：インストルメントされていない外部システムへの呼び出しは、グレーの「推測された」スパンとして表示されます。この例のInferred Serviceまたはスパンは、上記に示すようにMysqlデータベース mysql:petclinic SELECT petclinic **(2)**への呼び出しです。 Span Tags：Tag Paneには、自動検出と設定によって生成された標準タグが表示されます。この場合、スパンはデータベースを呼び出しているため、db.statementタグ**(3)**が含まれています。このタグは、このスパン中に実行されたデータベース呼び出しで使用されるDBクエリステートメントを保持します。これはDB-Query Performance機能で使用されます。DB-Query Performanceについては次のセクションで見ていきます。 Always-on Profiling：システムがスパンのライフサイクル中にプロファイリングデータをキャプチャするように設定されている場合、スパンのタイムラインでキャプチャされたコールスタックの数が表示されます。上記の例では、customer-service:GET /ownersスパンに対して18個のコールスタックがあることがわかります。(4) 次のセクションでプロファイリングを見ていきます。",
    "tags": [],
    "title": "APM Span",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/5-traces/3-spans/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "演習 paymentserviceのタグを表示するには、paymentserviceをクリックし、右側の機能ペインのTag Spotlightをクリックします（画面の解像度によっては下にスクロールする必要があるかもしれません）。 Tag Spotlightに入ったら、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。 Tag Spotlightのビューは、チャートとカードの両方で設定可能です。デフォルトではリクエストとエラーに設定されています。\nまた、カードに表示されるタグメトリクスを設定することも可能です。以下の任意の組み合わせを選択できます：\nRequests Errors Root Cause errors P50 Latency P90 Latency P99 Latency 改めて、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。\n演習 ​ 質問 回答 どのカードが問題を特定するタグを明らかにしていますか？\n「Version」カードです。v350.10に対するリクエスト数がエラー数と一致しています（つまり 100%）\npaymentserviceの問題を引き起こしているバージョンを特定したので、エラーについてさらに詳しい情報が見つかるか確認してみましょう。ページ上部の ← Tag Spotlight をクリックして、サービスマップに戻ります。",
    "description": "演習 paymentserviceのタグを表示するには、paymentserviceをクリックし、右側の機能ペインのTag Spotlightをクリックします（画面の解像度によっては下にスクロールする必要があるかもしれません）。 Tag Spotlightに入ったら、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。 Tag Spotlightのビューは、チャートとカードの両方で設定可能です。デフォルトではリクエストとエラーに設定されています。\nまた、カードに表示されるタグメトリクスを設定することも可能です。以下の任意の組み合わせを選択できます：\nRequests Errors Root Cause errors P50 Latency P90 Latency P99 Latency 改めて、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。\n演習 ​ 質問 回答 どのカードが問題を特定するタグを明らかにしていますか？",
    "tags": [],
    "title": "3. APM Tag Spotlight",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/6-apm/3-apm-tag-spotlight/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk APM は、モノリスとマイクロサービス全体で問題をより迅速に解決するために、すべてのサービスとその依存関係のNoSample（サンプリングなし）エンドツーエンドの可視性を提供します。チームは新しいデプロイメントからの問題をすぐに検出し、問題の原因の範囲を特定して分離することで自信を持ってトラブルシューティングを行い、バックエンドサービスがエンドユーザーとビジネスワークフローにどのように影響するかを理解することでサービスのパフォーマンスを最適化できます。\nリアルタイム監視とアラート： Splunk は標準でサービスダッシュボードを提供し、急激な変化があった場合に RED メトリクス（レート、エラー、期間）を自動的に検出してアラートを発します。 動的テレメトリマップ： 現代の本番環境でのサービスパフォーマンスをリアルタイムで簡単に視覚化できます。インフラストラクチャ、アプリケーション、エンドユーザー、およびすべての依存関係からのサービスパフォーマンスのエンドツーエンドの可視性により、新しい問題の範囲をすばやく特定し、より効果的にトラブルシューティングを行うことができます。\nインテリジェントなタグ付けと分析： ビジネス、インフラストラクチャ、アプリケーションからのすべてのタグを 1 か所で表示し、レイテンシーやエラーの新しい傾向を特定のタグ値と簡単に比較できます。\nAI によるトラブルシューティングが最も影響の大きい問題を特定： 個々のダッシュボードを手動で掘り下げる代わりに、より効率的に問題を分離します。サービスと顧客に最も影響を与える異常とエラーの原因を自動的に特定します。\n完全な分散トレースがすべてのトランザクションを分析： クラウドネイティブ環境の問題をより効果的に特定します。Splunk 分散トレースは、バックエンドとフロントエンドからのすべてのトランザクションをインフラストラクチャ、ビジネスワークフロー、アプリケーションのコンテキストで視覚化し相関付けます。\nフルスタック相関： Splunk Observability 内では、APM がトレース、メトリクス、ログ、プロファイリングをリンクし、スタック全体のすべてのコンポーネントとその依存関係のパフォーマンスを簡単に理解できるようにします。\nデータベースクエリパフォーマンスの監視： SQL および NoSQL データベースからの遅いクエリと高実行クエリがサービス、エンドポイント、ビジネスワークフローにどのように影響するかを簡単に特定できます — 計装は不要です。",
    "description": "Splunk APM は、モノリスとマイクロサービス全体で問題をより迅速に解決するために、すべてのサービスとその依存関係のNoSample（サンプリングなし）エンドツーエンドの可視性を提供します。チームは新しいデプロイメントからの問題をすぐに検出し、問題の原因の範囲を特定して分離することで自信を持ってトラブルシューティングを行い、バックエンドサービスがエンドユーザーとビジネスワークフローにどのように影響するかを理解することでサービスのパフォーマンスを最適化できます。\nリアルタイム監視とアラート： Splunk は標準でサービスダッシュボードを提供し、急激な変化があった場合に RED メトリクス（レート、エラー、期間）を自動的に検出してアラートを発します。 動的テレメトリマップ： 現代の本番環境でのサービスパフォーマンスをリアルタイムで簡単に視覚化できます。インフラストラクチャ、アプリケーション、エンドユーザー、およびすべての依存関係からのサービスパフォーマンスのエンドツーエンドの可視性により、新しい問題の範囲をすばやく特定し、より効果的にトラブルシューティングを行うことができます。\nインテリジェントなタグ付けと分析： ビジネス、インフラストラクチャ、アプリケーションからのすべてのタグを 1 か所で表示し、レイテンシーやエラーの新しい傾向を特定のタグ値と簡単に比較できます。\nAI によるトラブルシューティングが最も影響の大きい問題を特定： 個々のダッシュボードを手動で掘り下げる代わりに、より効率的に問題を分離します。サービスと顧客に最も影響を与える異常とエラーの原因を自動的に特定します。\n完全な分散トレースがすべてのトランザクションを分析： クラウドネイティブ環境の問題をより効果的に特定します。Splunk 分散トレースは、バックエンドとフロントエンドからのすべてのトランザクションをインフラストラクチャ、ビジネスワークフロー、アプリケーションのコンテキストで視覚化し相関付けます。\nフルスタック相関： Splunk Observability 内では、APM がトレース、メトリクス、ログ、プロファイリングをリンクし、スタック全体のすべてのコンポーネントとその依存関係のパフォーマンスを簡単に理解できるようにします。\nデータベースクエリパフォーマンスの監視： SQL および NoSQL データベースからの遅いクエリと高実行クエリがサービス、エンドポイント、ビジネスワークフローにどのように影響するかを簡単に特定できます — 計装は不要です。",
    "tags": [],
    "title": "Application Performance Monitoring概要",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/3-apm-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 6. Advanced Features",
    "content": "Database Query Performanceを使用すると、Splunk APMで直接、データベースクエリがサービスの可用性に与える影響をモニターできます。これにより、データベースをインストルメントすることなく、長時間実行されるクエリ、最適化されていないクエリ、または重いクエリを迅速に特定し、それらが引き起こしている可能性のある問題を軽減できます。\nデータベースクエリのパフォーマンスを確認するには、ブラウザで戻るか、メニューバーのAPMセクションに移動してAPMのService Mapページに移動し、Service Mapタイルをクリックします。\nDependency mapで推論されたデータベースサービス mysql:petclinic Inferred Database serverを選択し (1)、次に右側のペインをスクロールしてDatabase Query Performance Pane **(2)**を見つけます。\nマップで選択したサービスが実際に（推論された）データベースサーバーである場合、このペインには期間に基づく上位90%（P90）のデータベースコールが表示されます。db-queryパフォーマンス機能をさらに詳しく調べるには、ペインの上部にあるDatabase Query Performanceという単語のどこかをクリックします。\nこれにより、DB-query Performanceの概要画面が表示されます：\nDatabase Query Normalization デフォルトでは、Splunk APMインストルメンテーションはデータベースクエリをサニタイズして、db.statementsからシークレットや個人を特定できる情報（PII）などの機密データを削除またはマスクします。データベースクエリの正規化をオフにする方法はこちらで確認できます。\nこの画面には、Splunk Observability Cloudに送信されたTraces \u0026 Spansに基づいて、アプリケーションからデータベースに対して実行されたすべてのDatabase queries **(1)**が表示されます。時間ブロック間で比較したり、Total Time、P90 Latency \u0026 Requests **(2)**でソートしたりできることに注意してください。\nリスト内の各Database queryについて、時間ウィンドウ中の最高レイテンシ、コールの総数、および1秒あたりのリクエスト数 **(3)**が表示されます。これにより、クエリを最適化できる場所を特定できます。\n右側のペイン **(5)**の2つのチャートを使用して、Database Callsを含むトレースを選択できます。Tag Spotlightペイン **(6)**を使用して、エンドポイントやタグに基づいて、データベースコールに関連するタグを確認します。\nクエリの詳細ビューを表示する必要がある場合：\n特定のQuery **(1)**をクリックします。これにより、Query Details pane **(2)**が開き、より詳細な調査に使用できます。",
    "description": "Database Query Performanceを使用すると、Splunk APMで直接、データベースクエリがサービスの可用性に与える影響をモニターできます。これにより、データベースをインストルメントすることなく、長時間実行されるクエリ、最適化されていないクエリ、または重いクエリを迅速に特定し、それらが引き起こしている可能性のある問題を軽減できます。\nデータベースクエリのパフォーマンスを確認するには、ブラウザで戻るか、メニューバーのAPMセクションに移動してAPMのService Mapページに移動し、Service Mapタイルをクリックします。\nDependency mapで推論されたデータベースサービス mysql:petclinic Inferred Database serverを選択し (1)、次に右側のペインをスクロールしてDatabase Query Performance Pane **(2)**を見つけます。\nマップで選択したサービスが実際に（推論された）データベースサーバーである場合、このペインには期間に基づく上位90%（P90）のデータベースコールが表示されます。db-queryパフォーマンス機能をさらに詳しく調べるには、ペインの上部にあるDatabase Query Performanceという単語のどこかをクリックします。\nこれにより、DB-query Performanceの概要画面が表示されます：\nDatabase Query Normalization デフォルトでは、Splunk APMインストルメンテーションはデータベースクエリをサニタイズして、db.statementsからシークレットや個人を特定できる情報（PII）などの機密データを削除またはマスクします。データベースクエリの正規化をオフにする方法はこちらで確認できます。\nこの画面には、Splunk Observability Cloudに送信されたTraces \u0026 Spansに基づいて、アプリケーションからデータベースに対して実行されたすべてのDatabase queries **(1)**が表示されます。時間ブロック間で比較したり、Total Time、P90 Latency \u0026 Requests **(2)**でソートしたりできることに注意してください。\nリスト内の各Database queryについて、時間ウィンドウ中の最高レイテンシ、コールの総数、および1秒あたりのリクエスト数 **(3)**が表示されます。これにより、クエリを最適化できる場所を特定できます。\n右側のペイン **(5)**の2つのチャートを使用して、Database Callsを含むトレースを選択できます。Tag Spotlightペイン **(6)**を使用して、エンドポイントやタグに基づいて、データベースコールに関連するタグを確認します。",
    "tags": [],
    "title": "Database Query Performance",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/6-profiling-db-query/3-dbquery/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 3. Receivers",
    "content": "その他の Receiver デフォルト設定には、otlp、opencensus、jaeger、zipkin などの他の Receiver があることに気づくでしょう。これらは他のソースからテレメトリデータを受信するために使用されます。このワークショップではこれらの Receiver については取り上げませんので、そのままにしておいてください。\nNinja: Receiver を動的に作成する Docker コンテナ、Kubernetes Pod、SSH セッションなどの短期間のタスクを監視するために、receiver creator と observer extensions を使用して、これらのサービスが起動するときに新しい Receiver を作成できます。\n何が必要ですか？ receiver creator とそれに関連する observer extension を使い始めるには、それらが Collector のビルドマニフェストに含まれている必要があります。\n詳細は installation を参照してください。\n考慮すべき事項 一部の短期間のタスクでは、username や password などの追加設定が必要な場合があります。 これらの値は 環境変数 で参照するか、 ${file:./path/to/database/password} のようなスキーム展開構文を使用できます。 この方法を採用する場合は、組織のシークレット管理のベストプラクティスに従ってください。\nNinja ゾーン この Ninja ゾーンに必要なことは2つだけです\nビルダーマニフェストに receiver creator と observer extension が追加されていることを確認します。 検出されたエンドポイントとマッチングするために使用できる設定を作成します。 テンプレート化された設定を作成するには、以下のようにします\nreceiver_creator: watch_observers: [host_observer] receivers: redis: rule: type == \"port\" \u0026\u0026 port == 6379 config: password: ${env:HOST_REDIS_PASSWORD} その他の例については、receiver creator の例 を参照してください。\n設定の確認 Receiver について説明しましたので、設定の変更を確認しましょう。\nCheck-in設定を確認する ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 # To limit exposure to denial of service attacks, change the host in endpoints below from 0.0.0.0 to a specific network interface. # See https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md#safeguards-against-denial-of-service-attacks extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 opencensus: endpoint: 0.0.0.0:55678 # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_binary: endpoint: 0.0.0.0:6832 thrift_compact: endpoint: 0.0.0.0:6831 thrift_http: endpoint: 0.0.0.0:14268 zipkin: endpoint: 0.0.0.0:9411 processors: batch: exporters: debug: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [debug] logs: receivers: [otlp] processors: [batch] exporters: [debug] extensions: [health_check, pprof, zpages] Receiver を通じてデータが OpenTelemetry Collector にどのように取り込まれるかを確認しました。次は、Collector が受信したデータをどのように処理するかを見ていきましょう。\n警告 /etc/otelcol-contrib/config.yaml はまだ完成していないため、この時点では Collector を再起動しないでください。",
    "description": "その他の Receiver デフォルト設定には、otlp、opencensus、jaeger、zipkin などの他の Receiver があることに気づくでしょう。これらは他のソースからテレメトリデータを受信するために使用されます。このワークショップではこれらの Receiver については取り上げませんので、そのままにしておいてください。\nNinja: Receiver を動的に作成する Docker コンテナ、Kubernetes Pod、SSH セッションなどの短期間のタスクを監視するために、receiver creator と observer extensions を使用して、これらのサービスが起動するときに新しい Receiver を作成できます。\n何が必要ですか？ receiver creator とそれに関連する observer extension を使い始めるには、それらが Collector のビルドマニフェストに含まれている必要があります。\n詳細は installation を参照してください。\n考慮すべき事項 一部の短期間のタスクでは、username や password などの追加設定が必要な場合があります。 これらの値は 環境変数 で参照するか、 ${file:./path/to/database/password} のようなスキーム展開構文を使用できます。 この方法を採用する場合は、組織のシークレット管理のベストプラクティスに従ってください。",
    "tags": [],
    "title": "OpenTelemetry Collector Receivers",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/3-receivers/3-other-receivers/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic モノリスワークショップ",
    "content": "Real User Monitoring (RUM) の計装では、ページに OpenTelemetry Javascript スニペット https://github.com/signalfx/splunk-otel-js-web を追加します。ウィザードを使用して Data Management → Add Integration → RUM Instrumentation → Browser Instrumentation の順に進みます。\nインストラクターがドロップダウンから使用するトークンを指示します。Next をクリックしてください。以下の形式で App name と Environment を入力します：\n\u003cINSTANCE\u003e-petclinic-service - \u003cINSTANCE\u003e を先ほどメモした値に置き換えてください。 \u003cINSTANCE\u003e-petclinic-env - \u003cINSTANCE\u003e を先ほどメモした値に置き換えてください。 ウィザードは、ページの \u003chead\u003e セクションの先頭に配置する必要がある HTML コードスニペットを表示します。以下は例です（このスニペットは使用せず、ウィザードが生成したものを使用してください）：\n/* IMPORTANT: Replace the \u003cversion\u003e placeholder in the src URL with a version from https://github.com/signalfx/splunk-otel-js-web/releases */ \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ realm: \"eu0\", rumAccessToken: \"\u003credacted\u003e\", applicationName: \"petclinic-1be0-petclinic-service\", deploymentEnvironment: \"petclinic-1be0-petclinic-env\" }); \u003c/script\u003e Spring PetClinic アプリケーションは、アプリケーションのすべてのページで再利用される単一の HTML ページを「レイアウト」ページとして使用しています。Splunk RUM 計装ライブラリを挿入するには、すべてのページで自動的に読み込まれるため、この場所が最適です。\nそれでは、レイアウトページを編集しましょう：\nvi src/main/resources/templates/fragments/layout.html 次に、上記で生成したスニペットをページの \u003chead\u003e セクションに挿入します。コメントは含めず、ソース URL の \u003cversion\u003e を latest に置き換えてください：\n\u003c!doctype html\u003e \u003chtml th:fragment=\"layout (template, menu)\"\u003e \u003chead\u003e \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ realm: \"eu0\", rumAccessToken: \"\u003credacted\u003e\", applicationName: \"petclinic-1be0-petclinic-service\", deploymentEnvironment: \"petclinic-1be0-petclinic-env\" }); \u003c/script\u003e ... コード変更が完了したら、アプリケーションを再ビルドして再度実行する必要があります。maven コマンドを実行して PetClinic をコンパイル/ビルド/パッケージ化します：\n./mvnw package -Dmaven.test.skip=true java \\ -Dserver.port=8083 \\ -Dotel.service.name=$INSTANCE-petclinic-service \\ -Dotel.resource.attributes=deployment.environment=$INSTANCE-petclinic-env,version=0.314 \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql 次に、ブラウザを使用してアプリケーション http://\u003cIP_ADDRESS\u003e:8083 にアクセスし、実際のユーザートラフィックを生成します。\nRUM で、上記の RUM スニペットで定義された環境にフィルタリングし、ダッシュボードをクリックして開きます。\nRUM トレースをドリルダウンすると、スパン内に APM へのリンクが表示されます。トレース ID をクリックすると、現在の RUM トレースに対応する APM トレースに移動します。",
    "description": "Real User Monitoring (RUM) の計装では、ページに OpenTelemetry Javascript スニペット https://github.com/signalfx/splunk-otel-js-web を追加します。ウィザードを使用して Data Management → Add Integration → RUM Instrumentation → Browser Instrumentation の順に進みます。\nインストラクターがドロップダウンから使用するトークンを指示します。Next をクリックしてください。以下の形式で App name と Environment を入力します：\n\u003cINSTANCE\u003e-petclinic-service - \u003cINSTANCE\u003e を先ほどメモした値に置き換えてください。 \u003cINSTANCE\u003e-petclinic-env - \u003cINSTANCE\u003e を先ほどメモした値に置き換えてください。 ウィザードは、ページの \u003chead\u003e セクションの先頭に配置する必要がある HTML コードスニペットを表示します。以下は例です（このスニペットは使用せず、ウィザードが生成したものを使用してください）：\n/* IMPORTANT: Replace the \u003cversion\u003e placeholder in the src URL with a version from https://github.com/signalfx/splunk-otel-js-web/releases */ \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ realm: \"eu0\", rumAccessToken: \"\u003credacted\u003e\", applicationName: \"petclinic-1be0-petclinic-service\", deploymentEnvironment: \"petclinic-1be0-petclinic-env\" }); \u003c/script\u003e Spring PetClinic アプリケーションは、アプリケーションのすべてのページで再利用される単一の HTML ページを「レイアウト」ページとして使用しています。Splunk RUM 計装ライブラリを挿入するには、すべてのページで自動的に読み込まれるため、この場所が最適です。",
    "tags": [],
    "title": "3. Real User Monitoring",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/1-petclinic-monolith/4-rum/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "ワークショップの Receiver セクションへようこそ！ここは OpenTelemetry Collector のデータパイプラインの出発点です。早速始めましょう。\nReceiver は、プッシュベースまたはプルベースであり、データを Collector に取り込む方法です。Receiver は1つ以上のデータソースをサポートできます。一般的に、Receiver は指定された形式でデータを受け取り、内部形式に変換してから、該当するパイプラインで定義された Processor と Exporter に渡します。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style M fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "ワークショップの Receiver セクションへようこそ！ここは OpenTelemetry Collector のデータパイプラインの出発点です。早速始めましょう。\nReceiver は、プッシュベースまたはプルベースであり、データを Collector に取り込む方法です。Receiver は1つ以上のデータソースをサポートできます。一般的に、Receiver は指定された形式でデータを受け取り、内部形式に変換してから、該当するパイプラインで定義された Processor と Exporter に渡します。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style M fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector Receivers",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/3-receivers/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 8. Real User Monitoring",
    "content": "RUM トレースウォーターフォールを見ています。これは、ユーザーが petclinic アプリケーションのページにアクセスしたときに、ユーザーデバイス上で何が起こったかを示します。\nウォーターフォールを下にスクロールして、右側の #!/owners/details セグメント (1) を見つけてクリックすると、Vets リクエストの処理中に発生したアクションのリストが表示されます。HTTP リクエストには、リターンコードの前に青い APM リンクがあることに注意してください。1 つを選択し、APM リンクをクリックします。これにより、Kubernetes でホストされているこのバックエンドサービスコールの APM 情報が表示されます。\nリクエストで何が起こったかを確認するためにドリルダウンしたい場合は、Trace ID の URL をクリックしてください。\nこれにより、RUM からのリクエストに関連するトレースが表示されます:\nサービスへのエントリーポイントに RUM (1) 関連コンテンツリンクが追加されており、バックエンドサービスで何が起こったかを確認した後、RUM セッションに戻ることができるようになっていることがわかります。",
    "description": "RUM トレースウォーターフォールを見ています。これは、ユーザーが petclinic アプリケーションのページにアクセスしたときに、ユーザーデバイス上で何が起こったかを示します。\nウォーターフォールを下にスクロールして、右側の #!/owners/details セグメント (1) を見つけてクリックすると、Vets リクエストの処理中に発生したアクションのリストが表示されます。HTTP リクエストには、リターンコードの前に青い APM リンクがあることに注意してください。1 つを選択し、APM リンクをクリックします。これにより、Kubernetes でホストされているこのバックエンドサービスコールの APM 情報が表示されます。\nリクエストで何が起こったかを確認するためにドリルダウンしたい場合は、Trace ID の URL をクリックしてください。\nこれにより、RUM からのリクエストに関連するトレースが表示されます:\nサービスへのエントリーポイントに RUM (1) 関連コンテンツリンクが追加されており、バックエンドサービスで何が起こったかを確認した後、RUM セッションに戻ることができるようになっていることがわかります。",
    "tags": [],
    "title": "RUM trace Waterfall view \u0026 linking to APM",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/8-rum/3-rum-tour/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "Lambda 関数は相当量のトレースデータを生成しているはずで、それを確認する必要があります。Lambda 関数のリソース定義で構成された環境変数と OpenTelemetry Lambda layer の組み合わせにより、Splunk APM で関数とトレースを表示する準備が整いました。\nSplunk APM 概要で環境名を確認する まず、Splunk APM が受信しているトレースデータからEnvironmentを認識していることを確認しましょう。これはmain.tfの Lambda 関数定義で設定したOTEL_RESOURCE_ATTRIBUTES変数の一部として設定したdeployment.nameです。これは先ほど実行したterraform applyコマンドの出力の 1 つでもありました。\nSplunk Observability Cloud で：\n左側のメインメニューからAPMボタンをクリックします。これにより Splunk APM 概要に移動します。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 環境はPREFIX-lambda-shop形式になっているはずです。PREFIXは前提条件セクションで設定した環境変数から取得されます メモ トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください\n環境のサービスマップを表示する Environment ドロップダウンから環境名を選択したら、Lambda 関数のサービスマップを確認できます。\nAPM 概要ページの右側にあるService Mapボタンをクリックします。これによりサービスマップビューに移動します。 producer-lambda関数とそのレコードを配置するために Kinesis ストリームに対して行っている呼び出しが表示されるはずです。\nワークショップの質問 あなたのconsumer-lambda関数はどうなっていますか？\nLambda 関数からのトレースを調査する Tracesボタンをクリックしてトレースアナライザーを表示します。 このページでは、producer-lambda関数の OpenTelemetry Lambda layer から取り込まれたトレースを確認できます。\nリストからハイパーリンクされたTrace IDをクリックして、調査するトレースを選択します。 producer-lambda関数が Kinesis ストリームにレコードを配置しているのが確認できます。しかし、consumer-lambda関数のアクションが見当たりません！\nこれはトレースコンテキストが伝播されていないためです。このワークショップの時点では、Kinesis サービスはトレースコンテキスト伝播をすぐには対応していません。分散トレースは Kinesis サービスで止まっており、そのコンテキストがストリームを通じて自動的に伝播されないため、それ以上先を見ることができません。\n少なくとも、今はまだ…\n次のセクションでこの問題にどう対処するか見ていきましょう。しかしその前に、後片付けをしましょう！\nクリーンアップ この自動計装演習の一部としてデプロイしたリソースはクリーンアップする必要があります。同様に、producer-lambdaエンドポイントに対してトラフィックを生成していたスクリプトも、まだ実行中であれば停止する必要があります。以下の手順に従ってクリーンアップを行ってください。\nsend_messageの停止 send_message.pyスクリプトがまだ実行中の場合は、次のコマンドで停止します：\nfg これによりバックグラウンドプロセスがフォアグラウンドに移動します。 次に[CONTROL-C]を押してプロセスを終了できます。 全ての AWS リソースを破棄する Terraform は個々のリソースの状態をデプロイメントとして管理するのに優れています。定義に変更があっても、デプロイされたリソースを更新することもできます。しかし、一からやり直すために、リソースを破棄し、このワークショップの手動計装部分の一部として再デプロイします。\n以下の手順に従ってリソースを破棄してください：\nautoディレクトリにいることを確認します：\npwd 期待される出力は ~/o11y-lambda-workshop/auto です autoディレクトリにいない場合は、以下のコマンドを実行します：\ncd ~/o11y-lambda-workshop/auto 先ほどデプロイした Lambda 関数とその他の AWS リソースを破棄します：\nterraform destroy Enter a value:プロンプトが表示されたらyesと応答します これによりリソースが破棄され、クリーンな環境が残ります このプロセスにより、私たちの活動の結果として作成されたファイルとディレクトリは残ります。それらについては心配する必要はありません。",
    "description": "Lambda 関数は相当量のトレースデータを生成しているはずで、それを確認する必要があります。Lambda 関数のリソース定義で構成された環境変数と OpenTelemetry Lambda layer の組み合わせにより、Splunk APM で関数とトレースを表示する準備が整いました。\nSplunk APM 概要で環境名を確認する まず、Splunk APM が受信しているトレースデータからEnvironmentを認識していることを確認しましょう。これはmain.tfの Lambda 関数定義で設定したOTEL_RESOURCE_ATTRIBUTES変数の一部として設定したdeployment.nameです。これは先ほど実行したterraform applyコマンドの出力の 1 つでもありました。\nSplunk Observability Cloud で：\n左側のメインメニューからAPMボタンをクリックします。これにより Splunk APM 概要に移動します。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 環境はPREFIX-lambda-shop形式になっているはずです。PREFIXは前提条件セクションで設定した環境変数から取得されます メモ トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください\n環境のサービスマップを表示する Environment ドロップダウンから環境名を選択したら、Lambda 関数のサービスマップを確認できます。",
    "tags": [],
    "title": "Splunk APM、Lambda関数およびトレース",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/3-lambdas-in-splunk/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "今、以下のような表示が見えているはずです。\n演習 ウォーターフォールでPOST checkoutで始まるエントリを見つけます。 その前にある \u003e ボタンをクリックして、メタデータセクションを展開します。収集されたメタデータを観察し、Server-Timingヘッダーに注目してください。このヘッダーにより、テスト実行をバックエンドトレースに関連付けることができます。 ウォーターフォールのPOST checkout行にある青い APMリンクをクリックします。 演習 paymentserviceに対して 1 つ以上のエラーが表示されていることを確認します（1）。 同じエラーであることを確認するには、ログの関連コンテンツをクリックします（2）。 前回の演習を繰り返して、エラーのみにフィルタリングします。 エラーログを表示して、無効なトークンによる支払い失敗を確認します。",
    "description": "今、以下のような表示が見えているはずです。\n演習 ウォーターフォールでPOST checkoutで始まるエントリを見つけます。 その前にある \u003e ボタンをクリックして、メタデータセクションを展開します。収集されたメタデータを観察し、Server-Timingヘッダーに注目してください。このヘッダーにより、テスト実行をバックエンドトレースに関連付けることができます。 ウォーターフォールのPOST checkout行にある青い APMリンクをクリックします。 演習 paymentserviceに対して 1 つ以上のエラーが表示されていることを確認します（1）。 同じエラーであることを確認するには、ログの関連コンテンツをクリックします（2）。 前回の演習を繰り返して、エラーのみにフィルタリングします。 エラーログを表示して、無効なトークンによる支払い失敗を確認します。",
    "tags": [],
    "title": "3. SyntheticsからAPMへ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/8-synthetics/3-synthetics-to-apm/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "Splunk Observability Cloud の様々なコンポーネントについて簡単な説明から始めます。これは UI に慣れてもらうことを目的としています。\nSplunk Observability Cloud へのサインイン Real User Monitoring (RUM) Application Performance Monitoring (APM) Log Observer Synthetics Infrastructure Monitoring（IM） ヒント このワークショップを進める最も簡単な方法は以下を使用することです:\nこのページの右上にある左右の矢印（\u003c | \u003e） キーボードの左（◀️）と右（▶️）のカーソルキー",
    "description": "Splunk Observability Cloud UIのクイックツアー",
    "tags": [],
    "title": "UI - クイックツアー 🚌",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "セッション セッションは、ユーザーがアプリケーションと対話する際に実行するアクションに対応するトレースの集まりです。デフォルトでは、セッションはセッションでキャプチャされた最後のイベントから 15 分経過するまで続きます。最大セッション時間は 4 時間です。\n演習 User Sessionテーブルで、最も長いDuration（20 秒以上）の上位のSession IDをクリックすると、RUM セッションビューに移動します。 演習 RUM セッションリプレイ Replayボタンをクリックします。RUM セッションリプレイでは、ユーザーセッションを再生して確認することができます。これはユーザーが体験した内容を正確に確認するための優れた方法です。 ボタンをクリックしてリプレイを開始します。 RUM セッションリプレイでは情報を編集することができます。デフォルトではテキストが編集されます。画像も編集することができます（このワークショップ例では実施済み）。これは、機密情報が含まれるセッションを再生する場合に役立ちます。また、再生速度を変更したり、再生を一時停止したりすることもできます。\nヒント セッションを再生する際、マウスの動きがキャプチャされていることに注目してください。これは、ユーザーがどこに注意を向けているかを確認するのに役立ちます。",
    "description": "セッション セッションは、ユーザーがアプリケーションと対話する際に実行するアクションに対応するトレースの集まりです。デフォルトでは、セッションはセッションでキャプチャされた最後のイベントから 15 分経過するまで続きます。最大セッション時間は 4 時間です。\n演習 User Sessionテーブルで、最も長いDuration（20 秒以上）の上位のSession IDをクリックすると、RUM セッションビューに移動します。 演習 RUM セッションリプレイ Replayボタンをクリックします。RUM セッションリプレイでは、ユーザーセッションを再生して確認することができます。これはユーザーが体験した内容を正確に確認するための優れた方法です。 ボタンをクリックしてリプレイを開始します。 RUM セッションリプレイでは情報を編集することができます。デフォルトではテキストが編集されます。画像も編集することができます（このワークショップ例では実施済み）。これは、機密情報が含まれるセッションを再生する場合に役立ちます。また、再生速度を変更したり、再生を一時停止したりすることもできます。\nヒント セッションを再生する際、マウスの動きがキャプチャされていることに注目してください。これは、ユーザーがどこに注意を向けているかを確認するのに役立ちます。",
    "tags": [],
    "title": "3. セッションリプレイ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/5-rum/3-session-replay/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 3. レシーバー",
    "content": "その他のレシーバー デフォルトの設定には、他のレシーバーがあることに気づくはずです。 otlp、opencensus、jaeger、zipkin が定義されています。これらは他のソースからテレメトリーデータを受信するために使われます。このワークショップでは、これらのレシーバーについては取り上げませんので、そのままにしておきましょう。\nNinja: レシーバーを動的に生成する dockerコンテナ、kubernetesポッド、sshセッションのような短時間のタスクを観測するために、receiver creator レシーバーと observer エクステンションを使って、対象のサービスが起動するタイミングで新しいレシーバーを作成することができます。\n何が必要なの？ receiver creator とそれに関連する observer エクステンションの使用を開始するには、collector build manifest に追加する必要があります。\n詳細は installation を参照してください。\n注意事項はある？ 短命なタスクの中には、username や password のような追加設定を必要とするものがあります。それらの値は環境変数 を参照したり、 ${file:./path/to/database/password} のようなスキーム展開構文を使うこともできます。\n組織における機密情報の取り扱い規定に従って、どのような方法を取るかを検討してください。\nNinja ゾーン この Ninja ゾーンに必要なものは2つだけです:\nbuilder manifestに、 receiver creator レシーバーと observer エクステンションを追加する 検出されたエンドポイントを検出するように、設定を作成する 次のようにすると、設定をテンプレート化できます:\nreceiver_creator: watch_observers: [host_observer] receivers: redis: rule: type == \"port\" \u0026\u0026 port == 6379 config: password: ${env:HOST_REDIS_PASSWORD} 他の例は receiver creator’s examples にあります。\n設定を確認しましょう これで、レシーバーをカバーできました。ここで、設定のの変更内容をチェックしてみましょう。\nCheck-in設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus/internal] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] これで、レシーバーを通して OpenTelemetry Collector にデータがどのように取り込まれるかを確認しました。次に、コレクターが受信したデータをどのように処理するかを見てみましょう。\n警告 ここではコレクターを再起動しないでください！ /etc/otelcol-contrib/config.yaml の変更はまだ完了していません。",
    "description": "その他のレシーバー デフォルトの設定には、他のレシーバーがあることに気づくはずです。 otlp、opencensus、jaeger、zipkin が定義されています。これらは他のソースからテレメトリーデータを受信するために使われます。このワークショップでは、これらのレシーバーについては取り上げませんので、そのままにしておきましょう。\nNinja: レシーバーを動的に生成する dockerコンテナ、kubernetesポッド、sshセッションのような短時間のタスクを観測するために、receiver creator レシーバーと observer エクステンションを使って、対象のサービスが起動するタイミングで新しいレシーバーを作成することができます。\n何が必要なの？ receiver creator とそれに関連する observer エクステンションの使用を開始するには、collector build manifest に追加する必要があります。\n詳細は installation を参照してください。\n注意事項はある？ 短命なタスクの中には、username や password のような追加設定を必要とするものがあります。それらの値は環境変数 を参照したり、 ${file:./path/to/database/password} のようなスキーム展開構文を使うこともできます。",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/3-receivers/3-other-receivers/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. 依存ライブラリを追加する 前のセクション足したような、プロセス全体に渡る属性は便利なのですが、ときにはさらに、リクエストの内容に応じた状況を知りたくなるかもしれません。 心配ありません、OpenTelemetryのAPIを通じてそれらを計装し、データを送り、Splunk Observabilityで分析できるようになります。\n最初に、JavaアプリケーションがOpenTelemetryのAPIを使えるように、ライブラリの依存を追加していきます。 もちろん、vimなどのお好みのエディタをお使い頂いても大丈夫です！\nアプリケーションが起動中であれば、一旦停止しましょう。ターミナルで Ctrl-c を押すと、停止することができます。\nnano pom.xml そして、\u003cdependencies\u003e セクションの中（33行目）に↓を追加してください。 ファイル修正後、 ctrl-O のあとに Enter で、ファイルを保存します。次に ctrl-X で、nanoを終了します。\n\u003cdependency\u003e \u003cgroupId\u003eio.opentelemetry\u003c/groupId\u003e \u003cartifactId\u003eopentelemetry-api\u003c/artifactId\u003e \u003c/dependency\u003e 念のため、コンパイルできるか確かめてみましょう:\n./mvnw package -Dmaven.test.skip=true Tips: nanoの使い方と壊れたファイルの直し方 nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nAlt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 もしファイルをどうしようもなく壊してしまって元に戻したい場合は、gitを使って次のようにするとよいでしょう。\ngit checkout pom.xml これで、JavaのアプリケーションでOpenTelemetryのAPIが使う準備ができました。\n2. Javaのコードにマニュアル計装を追加する では、アプリケーションコードをちょっと変更して、リクエストのコンテキストのデータをスパン属性に追加してみましょう。\nここでは Pet Clinic アプリケーションの中で Find Owners が使われたときに、どのような検索文字列が指定されたのかを調査できるようにしていきます。 検索条件によってパフォーマンスが劣化してしまうケース、よくありませんか？そんなときは OwnerController に計装を追加していきましょう！\nnano src/main/java/org/springframework/samples/petclinic/owner/OwnerController.java このコードを 変更するのは2箇所 です。\nまず、import jakarta.validation.Valid; の下、37行目付近に↓を足します:\nimport io.opentelemetry.api.trace.Span; 次に、 // find owners by last name のコメントがある箇所（おそらく95行目付近にあります）の下に、次のコードを足していきましょう:\nSpan span = Span.current(); span.setAttribute(\"lastName\", owner.getLastName()); このコードで、Last Nameとして指定された検索条件が、スパン属性 lastName としてSplunk Observabilityに伝えるようになりました。\nアプリケーションをコンパイルし直ししますが、Javaコードを多少汚してしまったかもしれません。 spring-javaformat:apply を指定しながらコンパイルしてみましょう。\n./mvnw spring-javaformat:apply package -Dmaven.test.skip=true アプリケーションを起動します。せっかくなので、バージョンを一つあげて version=0.315 としましょう。\njava -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.315 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスして、オーナー検索をいくつか試してましょう。そしてSplunk APM UIからExploreを開き、アプリケーションのトレースを見ていきます。\nさらなる情報: マニュアル計装について マニュアル計装で何ができるか、他の言語でのやり方などは、OpenTelemetryの公式ウェブサイトにある Instrumentation ページをご覧ください。\n検証が完了したら、ターミナルで Ctrl-c を押すと、アプリケーションを停止することができます。\n次のセクションでは、RUMを使ってブラウザ上のパフォーマンスデータを収集してみましょう。",
    "description": "1. 依存ライブラリを追加する 前のセクション足したような、プロセス全体に渡る属性は便利なのですが、ときにはさらに、リクエストの内容に応じた状況を知りたくなるかもしれません。 心配ありません、OpenTelemetryのAPIを通じてそれらを計装し、データを送り、Splunk Observabilityで分析できるようになります。\n最初に、JavaアプリケーションがOpenTelemetryのAPIを使えるように、ライブラリの依存を追加していきます。 もちろん、vimなどのお好みのエディタをお使い頂いても大丈夫です！\nアプリケーションが起動中であれば、一旦停止しましょう。ターミナルで Ctrl-c を押すと、停止することができます。\nnano pom.xml そして、\u003cdependencies\u003e セクションの中（33行目）に↓を追加してください。 ファイル修正後、 ctrl-O のあとに Enter で、ファイルを保存します。次に ctrl-X で、nanoを終了します。\n\u003cdependency\u003e \u003cgroupId\u003eio.opentelemetry\u003c/groupId\u003e \u003cartifactId\u003eopentelemetry-api\u003c/artifactId\u003e \u003c/dependency\u003e 念のため、コンパイルできるか確かめてみましょう:\n./mvnw package -Dmaven.test.skip=true Tips: nanoの使い方と壊れたファイルの直し方 nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nAlt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 もしファイルをどうしようもなく壊してしまって元に戻したい場合は、gitを使って次のようにするとよいでしょう。\ngit checkout pom.xml これで、JavaのアプリケーションでOpenTelemetryのAPIが使う準備ができました。",
    "tags": [],
    "title": "マニュアル計装",
    "uri": "/observability-workshop/ja/other/pet-clinic/docs/manual_instrumentation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "レシーバーワークショップへようこそ！OpenTelemetry Collectorのデータパイプラインのスタート地点です。さあ、始めましょう。\nレシーバーはデータをCollectorに取り込む方法で、プッシュベースとプルベースのものがあります。レシーバーは1つ以上のデータソースをサポートします。一般的に、レシーバーは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサやエクスポータにデータを渡します。\nプッシュまたはプルベースのレシーバは、データをCollectorに取り込む方法です。レシーバは 1 つまたは複数のデータソースをサポートします。通常、レシーバは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサーや エクスポーターにデータを渡します。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style M fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "レシーバーワークショップへようこそ！OpenTelemetry Collectorのデータパイプラインのスタート地点です。さあ、始めましょう。\nレシーバーはデータをCollectorに取り込む方法で、プッシュベースとプルベースのものがあります。レシーバーは1つ以上のデータソースをサポートします。一般的に、レシーバーは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサやエクスポータにデータを渡します。\nプッシュまたはプルベースのレシーバは、データをCollectorに取り込む方法です。レシーバは 1 つまたは複数のデータソースをサポートします。通常、レシーバは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサーや エクスポーターにデータを渡します。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style M fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/3-receivers/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "Log Observer で特定のビューを持った後、そのビューをダッシュボードで使用できると、将来的に問題の検出や解決にかかる時間を短縮するのに非常に役立ちます。ワークショップの一環として、これらのチャートを使用する例示的なカスタムダッシュボードを作成します。\nログタイムラインチャートの作成を見ていきましょう。ログタイムラインチャートは、時間経過に伴うログメッセージを視覚化するために使用されます。ログメッセージの頻度を確認し、パターンを特定するための優れた方法です。また、環境全体でのログメッセージの分布を確認するための素晴らしい方法でもあります。これらのチャートはカスタムダッシュボードに保存できます。\n演習 まず、関心のある列のみに情報量を減らします：\nログテーブルの上にあるテーブル設定アイコンをクリックしてTable Settingを開き、_rawのチェックを外し、次のフィールドが選択されていることを確認します：k8s.pod.name、message、version。 時間選択から固定時間を削除し、過去 15 分に設定します。 すべてのトレースでこれを機能させるには、フィルターからtrace_idを削除し、フィールドsf_service=paymentserviceとsf_environment=[WORKSHOPNAME]を追加します。 Saveをクリックし、Save to Dashboardを選択します。 表示されるチャート作成ダイアログボックスで、Chart nameとしてログタイムラインを使用します。 Select Dashboardをクリックし、ダッシュボード選択ダイアログボックスでNew Dashboardをクリックします。 New Dashboardダイアログボックスに、新しいダッシュボードの名前を入力します（説明を入力する必要はありません）。次の形式を使用します：イニシャル - サービスヘルスダッシュボード、そしてSaveをクリックします。 リスト内で新しいダッシュボードが強調表示されていることを確認し（1）、OK（2）をクリックします。 Chart TypeとしてLog timelineが選択されていることを確認します。 Saveボタンをクリックします（この時点ではSave and go to dashboardをクリックしないでください）。 次に、ログビューチャートを作成します。",
    "description": "Log Observer で特定のビューを持った後、そのビューをダッシュボードで使用できると、将来的に問題の検出や解決にかかる時間を短縮するのに非常に役立ちます。ワークショップの一環として、これらのチャートを使用する例示的なカスタムダッシュボードを作成します。\nログタイムラインチャートの作成を見ていきましょう。ログタイムラインチャートは、時間経過に伴うログメッセージを視覚化するために使用されます。ログメッセージの頻度を確認し、パターンを特定するための優れた方法です。また、環境全体でのログメッセージの分布を確認するための素晴らしい方法でもあります。これらのチャートはカスタムダッシュボードに保存できます。\n演習 まず、関心のある列のみに情報量を減らします：\nログテーブルの上にあるテーブル設定アイコンをクリックしてTable Settingを開き、_rawのチェックを外し、次のフィールドが選択されていることを確認します：k8s.pod.name、message、version。 時間選択から固定時間を削除し、過去 15 分に設定します。 すべてのトレースでこれを機能させるには、フィルターからtrace_idを削除し、フィールドsf_service=paymentserviceとsf_environment=[WORKSHOPNAME]を追加します。 Saveをクリックし、Save to Dashboardを選択します。 表示されるチャート作成ダイアログボックスで、Chart nameとしてログタイムラインを使用します。 Select Dashboardをクリックし、ダッシュボード選択ダイアログボックスでNew Dashboardをクリックします。 New Dashboardダイアログボックスに、新しいダッシュボードの名前を入力します（説明を入力する必要はありません）。次の形式を使用します：イニシャル - サービスヘルスダッシュボード、そしてSaveをクリックします。 リスト内で新しいダッシュボードが強調表示されていることを確認し（1）、OK（2）をクリックします。 Chart TypeとしてLog timelineが選択されていることを確認します。 Saveボタンをクリックします（この時点ではSave and go to dashboardをクリックしないでください）。 次に、ログビューチャートを作成します。",
    "tags": [],
    "title": "3. ログタイムラインチャート",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/7-log-observer/3-log-timeline-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic モノリスワークショップ",
    "content": "以下のコマンドでアプリケーションを起動できます。mysql プロファイルをアプリケーションに渡していることに注目してください。これにより、先ほど起動した MySQL データベースを使用するようアプリケーションに指示します。また、otel.service.name と otel.resource.attributes をインスタンス名を使用した論理名に設定しています。これらは UI でのフィルタリングにも使用されます：\njava \\ -Dserver.port=8083 \\ -Dotel.service.name=$INSTANCE-petclinic-service \\ -Dotel.resource.attributes=deployment.environment=$INSTANCE-petclinic-env \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql http://\u003cIP_ADDRESS\u003e:8083（\u003cIP_ADDRESS\u003e を先ほど取得した IP アドレスに置き換えてください）にアクセスして、アプリケーションが実行されていることを確認できます。\nCollector をインストールした際、AlwaysOn Profiling と Metrics を有効にするように設定しました。これにより、Collector はアプリケーションの CPU およびメモリプロファイルを自動的に生成し、Splunk Observability Cloud に送信します。\nPetClinic アプリケーションを起動すると、Collector がアプリケーションを自動的に検出し、トレースとプロファイリングのために計装するのが確認できます。\n​ 出力例 Picked up JAVA_TOOL_OPTIONS: -javaagent:/usr/lib/splunk-instrumentation/splunk-otel-javaagent.jar OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended [otel.javaagent 2024-08-20 11:35:58:970 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: splunk-2.6.0-otel-2.6.0 [otel.javaagent 2024-08-20 11:35:59:730 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-08-20 11:35:59:730 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - Profiler configuration: [otel.javaagent 2024-08-20 11:35:59:730 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.enabled : true [otel.javaagent 2024-08-20 11:35:59:731 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.directory : /tmp [otel.javaagent 2024-08-20 11:35:59:731 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.recording.duration : 20s [otel.javaagent 2024-08-20 11:35:59:731 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.keep-files : false [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.logs-endpoint : null [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - otel.exporter.otlp.endpoint : null [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.enabled : true [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.event.rate : 150/s [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.call.stack.interval : PT10S [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.include.internal.stacks : false [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.tracing.stacks.only : false [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.JfrActivator - Profiler is active. Splunk APM UI にアクセスして、アプリケーションコンポーネント、トレース、プロファイリング、DB Query パフォーマンス、メトリクスを確認できます。左側のメニューから APM をクリックし、Environment ドロップダウンをクリックして、ご自身の環境（例：\u003cINSTANCE\u003e-petclinic、\u003cINSTANCE\u003e は先ほどメモした値に置き換えてください）を選択します。\n検証が完了したら、Ctrl-c を押してアプリケーションを停止できます。\nリソース属性は、報告されるすべてのスパンに追加できます。例えば version=0.314 のように指定します。カンマ区切りのリソース属性リストも定義できます（例：key1=val1,key2=val2）。\n新しいリソース属性を使用して PetClinic を再度起動しましょう。実行コマンドにリソース属性を追加すると、Collector のインストール時に定義された内容が上書きされることに注意してください。新しいリソース属性 version=0.314 を追加しましょう：\njava \\ -Dserver.port=8083 \\ -Dotel.service.name=$INSTANCE-petclinic-service \\ -Dotel.resource.attributes=deployment.environment=$INSTANCE-petclinic-env,version=0.314 \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql Splunk APM UI に戻り、最近のトレースをドリルダウンすると、スパン内に新しい version 属性が表示されます。",
    "description": "以下のコマンドでアプリケーションを起動できます。mysql プロファイルをアプリケーションに渡していることに注目してください。これにより、先ほど起動した MySQL データベースを使用するようアプリケーションに指示します。また、otel.service.name と otel.resource.attributes をインスタンス名を使用した論理名に設定しています。これらは UI でのフィルタリングにも使用されます：\njava \\ -Dserver.port=8083 \\ -Dotel.service.name=$INSTANCE-petclinic-service \\ -Dotel.resource.attributes=deployment.environment=$INSTANCE-petclinic-env \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql http://\u003cIP_ADDRESS\u003e:8083（\u003cIP_ADDRESS\u003e を先ほど取得した IP アドレスに置き換えてください）にアクセスして、アプリケーションが実行されていることを確認できます。\nCollector をインストールした際、AlwaysOn Profiling と Metrics を有効にするように設定しました。これにより、Collector はアプリケーションの CPU およびメモリプロファイルを自動的に生成し、Splunk Observability Cloud に送信します。\nPetClinic アプリケーションを起動すると、Collector がアプリケーションを自動的に検出し、トレースとプロファイリングのために計装するのが確認できます。\n​ 出力例 Picked up JAVA_TOOL_OPTIONS: -javaagent:/usr/lib/splunk-instrumentation/splunk-otel-javaagent.jar OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended [otel.javaagent 2024-08-20 11:35:58:970 +0000] [main] INFO io.opentelemetry.javaagent.tooling.VersionLogger - opentelemetry-javaagent - version: splunk-2.6.0-otel-2.6.0 [otel.javaagent 2024-08-20 11:35:59:730 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-08-20 11:35:59:730 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - Profiler configuration: [otel.javaagent 2024-08-20 11:35:59:730 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.enabled : true [otel.javaagent 2024-08-20 11:35:59:731 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.directory : /tmp [otel.javaagent 2024-08-20 11:35:59:731 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.recording.duration : 20s [otel.javaagent 2024-08-20 11:35:59:731 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.keep-files : false [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.logs-endpoint : null [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - otel.exporter.otlp.endpoint : null [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.enabled : true [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.memory.event.rate : 150/s [otel.javaagent 2024-08-20 11:35:59:732 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.call.stack.interval : PT10S [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.include.internal.stacks : false [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - splunk.profiler.tracing.stacks.only : false [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.ConfigurationLogger - ----------------------- [otel.javaagent 2024-08-20 11:35:59:733 +0000] [main] INFO com.splunk.opentelemetry.profiler.JfrActivator - Profiler is active. Splunk APM UI にアクセスして、アプリケーションコンポーネント、トレース、プロファイリング、DB Query パフォーマンス、メトリクスを確認できます。左側のメニューから APM をクリックし、Environment ドロップダウンをクリックして、ご自身の環境（例：\u003cINSTANCE\u003e-petclinic、\u003cINSTANCE\u003e は先ほどメモした値に置き換えてください）を選択します。",
    "tags": [],
    "title": "Java 向け自動ディスカバリーおよび設定",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/1-petclinic-monolith/3-auto-discovery/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 4. Processors",
    "content": "Attributes Processor attributes processor は、スパン、ログ、またはメトリクスの属性を変更します。この processor は、指定されたアクションに含めるか除外するかを決定するために、入力データをフィルタリングおよびマッチングする機能もサポートしています。\n設定で指定された順序で実行されるアクションのリストを受け取ります。サポートされているアクションは以下の通りです\ninsert：キーがまだ存在しない入力データに新しい属性を挿入します。 update：キーが存在する入力データの属性を更新します。 upsert：insert または update を実行します。キーがまだ存在しない入力データに新しい属性を挿入し、キーが存在する入力データの属性を更新します。 delete：入力データから属性を削除します。 hash：既存の属性値をハッシュ化（SHA1）します。 extract：正規表現ルールを使用して入力キーからルールで指定されたターゲットキーに値を抽出します。ターゲットキーがすでに存在する場合は上書きされます。 すべてのホストメトリクスに participant.name という新しい属性を insert する attributes processor を作成します。値にはあなたの名前（例：marge_simpson）を設定します。\n警告 INSERT_YOUR_NAME_HERE を必ずあなたの名前に置き換えてください。また、名前にスペースを使用しないようにしてください。\nワークショップの後半で、Splunk Observability Cloud でメトリクスをフィルタリングするためにこの属性を使用します。\n​ Attributes Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" Ninja: connector を使用して内部インサイトを取得する Collector への最新の追加機能の1つは connector の概念で、あるパイプラインの出力を別のパイプラインの入力に接続できます。\nこれが有益な例として、一部のサービスはエクスポートされるデータポイントの量、エラーステータスを含むログの数、または特定のデプロイ環境から送信されるデータ量に基づいてメトリクスを出力します。count connector はこれをすぐに使える形で対処するのに役立ちます。\nprocessor の代わりに connector を使用する理由 processor は処理したデータを渡す必要があるため、追加データを生成する点で制限があり、追加情報を公開するのが困難です。connector は受信したデータを出力する必要がないため、求めているインサイトを作成する機会を提供します。\n例えば、デプロイ環境属性を持たないログ、メトリクス、トレースの数をカウントする connector を作成できます。\nデプロイ環境別にデータ使用量を分類できる非常にシンプルな例です。\nconnector に関する考慮事項 connector は、あるパイプラインからエクスポートされ、別のパイプラインで受信されたデータのみを受け入れます。これは、connector を活用するために Collector の設定をどのように構成するかを検討する必要があることを意味します。\n参考資料 https://opentelemetry.io/docs/collector/configuration/#connectors https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/connector/countconnector 設定の確認 processors について説明しました。設定の変更を確認しましょう。\nCheck-in設定を確認する ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 # To limit exposure to denial of service attacks, change the host in endpoints below from 0.0.0.0 to a specific network interface. # See https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md#safeguards-against-denial-of-service-attacks extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 opencensus: endpoint: 0.0.0.0:55678 # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_binary: endpoint: 0.0.0.0:6832 thrift_compact: endpoint: 0.0.0.0:6831 thrift_http: endpoint: 0.0.0.0:14268 zipkin: endpoint: 0.0.0.0:9411 processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: debug: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [debug] logs: receivers: [otlp] processors: [batch] exporters: [debug] extensions: [health_check, pprof, zpages]",
    "description": "Attributes Processor attributes processor は、スパン、ログ、またはメトリクスの属性を変更します。この processor は、指定されたアクションに含めるか除外するかを決定するために、入力データをフィルタリングおよびマッチングする機能もサポートしています。\n設定で指定された順序で実行されるアクションのリストを受け取ります。サポートされているアクションは以下の通りです\ninsert：キーがまだ存在しない入力データに新しい属性を挿入します。 update：キーが存在する入力データの属性を更新します。 upsert：insert または update を実行します。キーがまだ存在しない入力データに新しい属性を挿入し、キーが存在する入力データの属性を更新します。 delete：入力データから属性を削除します。 hash：既存の属性値をハッシュ化（SHA1）します。 extract：正規表現ルールを使用して入力キーからルールで指定されたターゲットキーに値を抽出します。ターゲットキーがすでに存在する場合は上書きされます。 すべてのホストメトリクスに participant.name という新しい属性を insert する attributes processor を作成します。値にはあなたの名前（例：marge_simpson）を設定します。\n警告 INSERT_YOUR_NAME_HERE を必ずあなたの名前に置き換えてください。また、名前にスペースを使用しないようにしてください。\nワークショップの後半で、Splunk Observability Cloud でメトリクスをフィルタリングするためにこの属性を使用します。\n​ Attributes Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" Ninja: connector を使用して内部インサイトを取得する Collector への最新の追加機能の1つは connector の概念で、あるパイプラインの出力を別のパイプラインの入力に接続できます。",
    "tags": [],
    "title": "OpenTelemetry Collector Processors",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/4-processors/3-attributes/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 4. プロセッサー",
    "content": "Attributes プロセッサー attribute プロセッサーを使うと、スパン、ログ、またはメトリクスの属性を変更できます。また、このプロセッサーは、入力データをフィルタリングし、マッチさせ、指定されたアクションに含めるべきか、除外すべきかを決定する機能もサポートしています。\nアクションを設定するには、指定された順序で実行されるアクションのリストを記述します。サポートされるアクションは以下の通りです：\ninsert: その属性がない場合に、新しい属性値を挿入します。 update: その属性がある場合に、その属性値を更新します。 upsert: insert または update を実行します。属性がない場合には新しい属性値を挿入し、属性がある場合にはその値を更新します。 delete: 入力データから属性値を削除します。 hash: 属性値をハッシュ化 (SHA1) します。 extract: 入力キーの値を正規表現ルールを使って抽出し、対象キーの値を更新します。対象キーがすでに存在する場合は、その値は上書きされます。 次の例のように、attribute プロセッサーを使って、キーは participant.name、あたいはあなたの名前（例: marge_simpson）という新しい属性を追加してみましょう。\n警告 INSERT_YOUR_NAME_HERE の箇所は、自分の名前に置き換えてください。また、自分の名前に スペースを使わない ようにしてください。\nこのワークショップの後半では、この属性を使用して Splunk Observability Cloud でメトリクスをフィルタリングします。\n​ Attributes Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" Ninja: コネクターを使って内部への洞察を加速する 最近追加されたものの一つとして、connector というコンセプトがあります。これを使うと、あるパイプラインの出力を別のパイプラインの入力に結合できるようになります。\n利用シーンとして、送信するデータポイントの量、エラーステータスを含むログの数をメトリクスをとして出力するサービスがあります。他には、あるデプロイ環境から送信されるデータ量のメトリクスを生成するサービスがあります。このような場合に、count コネクターですぐに対応できます。\nプロセッサーではなくコネクターなのはなぜ？ プロセッサーは、処理したデータを次に渡すものであり、追加の情報を出力することはできません。コネクターはレシーバーで受け取ったデータを出力せずに、私たちが求める洞察を作り出す機会を提供します。\nたとえば、count コネクターを使うと、環境変数 deployment を持たないログ、メトリクス、トレースの数をカウントすることができます。\nまた、非常にシンプルな例として、deployment 別にデータ使用量を分解して出力することもできます。\nコネクターの注意事項 コネクターは、あるパイプラインからエクスポートされ、別のパイプラインでレシーバーで定義されたデータのみを受け入れます。コレクターをどう構築してどう利用するか、設定を検討する必要があります。\n参照 https://opentelemetry.io/docs/collector/configuration/#connectors https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/connector/countconnector 設定を確認しましょう これで、プロセッサーがカバーできました。ここで、設定のの変更内容をチェックしてみましょう。\nCheck-in設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages]",
    "description": "Attributes プロセッサー attribute プロセッサーを使うと、スパン、ログ、またはメトリクスの属性を変更できます。また、このプロセッサーは、入力データをフィルタリングし、マッチさせ、指定されたアクションに含めるべきか、除外すべきかを決定する機能もサポートしています。\nアクションを設定するには、指定された順序で実行されるアクションのリストを記述します。サポートされるアクションは以下の通りです：\ninsert: その属性がない場合に、新しい属性値を挿入します。 update: その属性がある場合に、その属性値を更新します。 upsert: insert または update を実行します。属性がない場合には新しい属性値を挿入し、属性がある場合にはその値を更新します。 delete: 入力データから属性値を削除します。 hash: 属性値をハッシュ化 (SHA1) します。 extract: 入力キーの値を正規表現ルールを使って抽出し、対象キーの値を更新します。対象キーがすでに存在する場合は、その値は上書きされます。 次の例のように、attribute プロセッサーを使って、キーは participant.name、あたいはあなたの名前（例: marge_simpson）という新しい属性を追加してみましょう。\n警告 INSERT_YOUR_NAME_HERE の箇所は、自分の名前に置き換えてください。また、自分の名前に スペースを使わない ようにしてください。\nこのワークショップの後半では、この属性を使用して Splunk Observability Cloud でメトリクスをフィルタリングします。\n​ Attributes Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" Ninja: コネクターを使って内部への洞察を加速する 最近追加されたものの一つとして、connector というコンセプトがあります。これを使うと、あるパイプラインの出力を別のパイプラインの入力に結合できるようになります。",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/4-processors/3-attributes/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 4. 機密データ",
    "content": "redaction プロセッサは、テレメトリーデータからどの属性と値を許可または削除するかを正確に制御できます。\nこの演習では、Agent がエクスポートする前に、Spanデータの user.visa と user.mastercard の値を秘匿化します。 Exercise Gatewayを起動する：Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config=gateway.yaml redaction/redact プロセッサを有効にする：Agent terminal ウィンドウで、agent.yaml を編集して前の演習で追加した # を削除します。\ntraces: receivers: - otlp processors: - memory_limiter - attributes/update # Update, hash, and remove attributes - redaction/redact # Redact sensitive fields using regex - resourcedetection - resource/add_mode - batch exporters: - debug - file - otlphttp Agentを起動する：Agent terminal ウィンドウで Agent を起動します。\n../otelcol --config=agent.yaml Load Generatorを起動する：Loadgen terminal ウィンドウで loadgen を起動します\n../loadgen -count 1 デバッグ出力を確認する：Agent と Gateway の両方で、user.visa と user.mastercard の値が更新されていることを確認します。user.amex 属性の値は、blocked_values に一致する正規表現パターンが追加されていないため、秘匿化されていないことに注意してください。\n​ New Debug Output Original Debug Output -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(UNKNOWN NUMBER) -\u003e user.email: Str(62d5e03d8fd5808e77aee5ebbd90cf7627a470ae0be9ffd10e8025a4ad0e1287) -\u003e payment.amount: Double(69.71) -\u003e user.visa: Str(****) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(****) -\u003e redaction.masked.keys: Str(user.mastercard,user.visa) -\u003e redaction.masked.count: Int(2) -\u003e user.name: Str(George Lucas) -\u003e user.phone_number: Str(+1555-867-5309) -\u003e user.email: Str(george@deathstar.email) -\u003e user.password: Str(LOTR\u003eStarWars1-2-3) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) -\u003e payment.amount: Double(65.54) メモ redaction プロセッサに summary:debug を含めると、デバッグ出力に、どの一致するキー値が秘匿化されたか、およびマスクされた値の数に関するサマリー情報が含まれます。\n-\u003e redaction.masked.keys: Str(user.mastercard,user.visa) -\u003e redaction.masked.count: Int(2) ファイル出力を確認する：jq を使用して、gateway-traces.out で user.visa と user.mastercard が更新されていることを検証します。\n​ Validate attribute changes Output jq '.resourceSpans[].scopeSpans[].spans[].attributes[] | select(.key == \"user.visa\" or .key == \"user.mastercard\" or .key == \"user.amex\") | {key: .key, value: .value.stringValue}' ./gateway-traces.out blocked_values に一致する正規表現パターンが追加されていないため、user.amex は秘匿化されていないことに注意してください\n{ \"key\": \"user.visa\", \"value\": \"****\" } { \"key\": \"user.amex\", \"value\": \"3782 822463 10005\" } { \"key\": \"user.mastercard\", \"value\": \"****\" } これらは、attributes と redaction プロセッサを設定して機密データを保護する方法のほんの一例です。\n重要 Agent と Gateway プロセスを、それぞれのターミナルで Ctrl-C を押して停止してください。",
    "description": "redaction プロセッサは、テレメトリーデータからどの属性と値を許可または削除するかを正確に制御できます。\nこの演習では、Agent がエクスポートする前に、Spanデータの user.visa と user.mastercard の値を秘匿化します。 Exercise Gatewayを起動する：Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config=gateway.yaml redaction/redact プロセッサを有効にする：Agent terminal ウィンドウで、agent.yaml を編集して前の演習で追加した # を削除します。\ntraces: receivers: - otlp processors: - memory_limiter - attributes/update # Update, hash, and remove attributes - redaction/redact # Redact sensitive fields using regex - resourcedetection - resource/add_mode - batch exporters: - debug - file - otlphttp Agentを起動する：Agent terminal ウィンドウで Agent を起動します。",
    "tags": [],
    "title": "4.3 Redaction Processorのテスト",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/4-sensitive-data/4-3-test-redaction/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 5. Transform Data",
    "content": "このテストでは、Agent によってエクスポートされる前に、com.splunk/source と os.type のメタデータがログリソース属性から 削除 されていることを確認します。さらに、このテストでは以下を確認します\n重大度情報を抽出するためにログ本文がパースされていること SeverityText と SeverityNumber が LogRecord に設定されていること ログ本文の JSON フィールドがログ attributes に昇格していること これにより、エクスポート前に適切なメタデータフィルタリング、重大度マッピング、および構造化ログのエンリッチメントが行われることが保証されます。\nExercise デバッグ出力を確認する: Agent と Gateway の両方で、com.splunk/source と os.type が削除されていることを確認します\n​ Gateway Debug Output Agent Debug Output Resource attributes: -\u003e com.splunk.sourcetype: Str(quotes) -\u003e host.name: Str(workshop-instance) -\u003e otelcol.service.mode: Str(agent) Resource attributes: -\u003e com.splunk.source: Str(./quotes.log) -\u003e com.splunk.sourcetype: Str(quotes) -\u003e host.name: Str(workshop-instance) -\u003e os.type: Str(linux) -\u003e otelcol.service.mode: Str(agent) Agent と Gateway の両方で、LogRecord の SeverityText と SeverityNumber がログ本文の重大度 level で定義されていることを確認します。また、本文の JSON フィールドがトップレベルのログ Attributes としてアクセスできることを確認します\n​ Gateway Debug Output Agemt Debug Output \u003csnip\u003e SeverityText: WARN SeverityNumber: Warn(13) Body: Str({\"level\":\"WARN\",\"message\":\"Your focus determines your reality.\",\"movie\":\"SW\",\"timestamp\":\"2025-03-07 11:17:26\"}) Attributes: -\u003e log.file.path: Str(quotes.log) -\u003e level: Str(WARN) -\u003e message: Str(Your focus determines your reality.) -\u003e movie: Str(SW) -\u003e timestamp: Str(2025-03-07 11:17:26) \u003c/snip\u003e \u003csnip\u003e SeverityText: SeverityNumber: Unspecified(0) Body: Str({\"level\":\"WARN\",\"message\":\"Your focus determines your reality.\",\"movie\":\"SW\",\"timestamp\":\"2025-03-07 11:17:26\"}) Attributes: -\u003e log.file.path: Str(quotes.log) \u003c/snip\u003e ファイル出力を確認する: 新しい gateway-logs.out ファイルでデータが変換されていることを確認します\n​ jq Query Example Output jq '[.resourceLogs[].scopeLogs[].logRecords[] | {severityText, severityNumber, body: .body.stringValue}]' gateway-logs.out [ { \"severityText\": \"DEBUG\", \"severityNumber\": 5, \"body\": \"{\\\"level\\\":\\\"DEBUG\\\",\\\"message\\\":\\\"All we have to decide is what to do with the time that is given us.\\\",\\\"movie\\\":\\\"LOTR\\\",\\\"timestamp\\\":\\\"2025-03-07 11:56:29\\\"}\" }, { \"severityText\": \"WARN\", \"severityNumber\": 13, \"body\": \"{\\\"level\\\":\\\"WARN\\\",\\\"message\\\":\\\"The Force will be with you. Always.\\\",\\\"movie\\\":\\\"SW\\\",\\\"timestamp\\\":\\\"2025-03-07 11:56:29\\\"}\" }, { \"severityText\": \"ERROR\", \"severityNumber\": 17, \"body\": \"{\\\"level\\\":\\\"ERROR\\\",\\\"message\\\":\\\"One does not simply walk into Mordor.\\\",\\\"movie\\\":\\\"LOTR\\\",\\\"timestamp\\\":\\\"2025-03-07 11:56:29\\\"}\" }, { \"severityText\": \"DEBUG\", \"severityNumber\": 5, \"body\": \"{\\\"level\\\":\\\"DEBUG\\\",\\\"message\\\":\\\"Do or do not, there is no try.\\\",\\\"movie\\\":\\\"SW\\\",\\\"timestamp\\\":\\\"2025-03-07 11:56:29\\\"}\" } ] [ { \"severityText\": \"ERROR\", \"severityNumber\": 17, \"body\": \"{\\\"level\\\":\\\"ERROR\\\",\\\"message\\\":\\\"There is some good in this world, and it's worth fighting for.\\\",\\\"movie\\\":\\\"LOTR\\\",\\\"timestamp\\\":\\\"2025-03-07 11:56:29\\\"}\" } ] 重要 それぞれのターミナルで Ctrl-C を押して、Agent と Gateway のプロセスを停止してください。",
    "description": "このテストでは、Agent によってエクスポートされる前に、com.splunk/source と os.type のメタデータがログリソース属性から 削除 されていることを確認します。さらに、このテストでは以下を確認します\n重大度情報を抽出するためにログ本文がパースされていること SeverityText と SeverityNumber が LogRecord に設定されていること ログ本文の JSON フィールドがログ attributes に昇格していること これにより、エクスポート前に適切なメタデータフィルタリング、重大度マッピング、および構造化ログのエンリッチメントが行われることが保証されます。\nExercise デバッグ出力を確認する: Agent と Gateway の両方で、com.splunk/source と os.type が削除されていることを確認します\n​ Gateway Debug Output Agent Debug Output Resource attributes: -\u003e com.splunk.sourcetype: Str(quotes) -\u003e host.name: Str(workshop-instance) -\u003e otelcol.service.mode: Str(agent) Resource attributes: -\u003e com.splunk.source: Str(./quotes.log) -\u003e com.splunk.sourcetype: Str(quotes) -\u003e host.name: Str(workshop-instance) -\u003e os.type: Str(linux) -\u003e otelcol.service.mode: Str(agent) Agent と Gateway の両方で、LogRecord の SeverityText と SeverityNumber がログ本文の重大度 level で定義されていることを確認します。また、本文の JSON フィールドがトップレベルのログ Attributes としてアクセスできることを確認します",
    "tags": [],
    "title": "5.3 Test Transform Processor",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/5-transform-data/5-3-test-transform/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 6. Service",
    "content": "Resource Detection Processor また、Collector がインスタンスのホスト名と AWS/EC2 メタデータをキャプチャできるように、resourcedetection/system と resourcedetection/ec2 processor を追加しました。ここで、metrics パイプラインでこれら2つの processor を有効にする必要があります。\nmetrics パイプラインの processors セクションに resourcedetection/system と resourcedetection/ec2 を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2] exporters: [debug]",
    "description": "Resource Detection Processor また、Collector がインスタンスのホスト名と AWS/EC2 メタデータをキャプチャできるように、resourcedetection/system と resourcedetection/ec2 processor を追加しました。ここで、metrics パイプラインでこれら2つの processor を有効にする必要があります。\nmetrics パイプラインの processors セクションに resourcedetection/system と resourcedetection/ec2 を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2] exporters: [debug]",
    "tags": [],
    "title": "OpenTelemetry Collector Service",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/6-service/3-resourcedetection/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Resource Detection プロセッサー また、コレクターがインスタンスのホスト名やAWS/EC2のメタデータを取得できるように、resourcedetection/system および resourcedetection/ec2 プロセッサーを追加しました。これらのプロセッサーをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、resourcedetection/system および resourcedetection/ec2 を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2] exporters: [logging]",
    "description": "Resource Detection プロセッサー また、コレクターがインスタンスのホスト名やAWS/EC2のメタデータを取得できるように、resourcedetection/system および resourcedetection/ec2 プロセッサーを追加しました。これらのプロセッサーをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、resourcedetection/system および resourcedetection/ec2 を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/6-service/3-resourcedetection/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 6. Routing Data",
    "content": "Exercise このセクションでは、Gateway 用に設定した routing ルールをテストします。期待される結果は、\"[deployment.environment\"] == \"security-applications\" ルールに一致する loadgen によって生成された span が gateway-traces-route2-security.out ファイルに送信されることです。\nGateway を起動する: Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config gateway.yaml Agent を起動する: Agent terminal ウィンドウで Agent を起動します。\n../otelcol --config agent.yaml 通常のスパンを送信する: Loadgen terminal ウィンドウで loadgen を使用して通常のスパンを送信します\n../loadgen -count 1 Agent と Gateway の両方でデバッグ情報が表示されます。Gateway は新しい gateway-traces-route1-regular.out ファイルも生成します。これが通常のスパンの指定された宛先になりました。\nTip gateway-traces-route1-regular.out を確認すると、loadgen によって送信された span が含まれています。また、空の gateway-traces-route2-security..out ファイルも表示されます。これは、ルーティング設定が、一致するスパンがまだ処理されていなくても、すぐに出力ファイルを作成するためです。\nセキュリティスパンを送信する: Loadgen terminal ウィンドウで security フラグを使用してセキュリティスパンを送信します\n../loadgen -security -count 1 再び、Agent と Gateway の両方で、送信したスパンを含むデバッグ情報が表示されるはずです。今回は、Gateway が gateway-traces-route2-security.out ファイルに行を書き込みます。これは、deployment.environment リソース属性が \"security-applications\" に一致するスパン用に指定されたファイルです。\n​ Validate resource attribute matches Output jq -c '.resourceSpans[] as $resource | $resource.scopeSpans[].spans[] | {spanId: .spanId, deploymentEnvironment: ($resource.resource.attributes[] | select(.key == \"deployment.environment\") | .value.stringValue)}' gateway-traces-route2-security.out {\"spanId\":\"cb799e92e26d5782\",\"deploymentEnvironment\":\"security-applications\"} このシナリオを複数回繰り返すことができ、各トレースは対応する出力ファイルに書き込まれます。\n重要 それぞれのターミナルで Ctrl-C を押して、Agent と Gateway のプロセスを停止してください。\nまとめ このセクションでは、異なるスパンを送信し、その宛先を確認することで、Gateway のルーティングコネクターを正常にテストしました。\n通常のスパン は gateway-traces-route1-regular.out に正しくルーティングされ、一致する deployment.environment 属性を持たないスパンがデフォルトパイプラインに従うことが確認されました。\nセキュリティ関連のスパン は gateway-traces-route2-security.out にルーティングされ、\"deployment.environment\": \"security-applications\" に基づくルーティングルールが期待どおりに機能することが実証されました。\n出力ファイルを検査することで、OpenTelemetry Collector が スパン属性を正しく評価し、適切な宛先にルーティングしている ことを確認しました。これにより、ルーティングルールが異なるユースケース向けにテレメトリデータを効果的に分離して振り分けることができることが検証されました。\n追加のルーティングルールを定義して、異なる属性に基づいてスパン、メトリクス、ログをさらに分類することで、このアプローチを拡張できます。",
    "description": "Exercise このセクションでは、Gateway 用に設定した routing ルールをテストします。期待される結果は、\"[deployment.environment\"] == \"security-applications\" ルールに一致する loadgen によって生成された span が gateway-traces-route2-security.out ファイルに送信されることです。\nGateway を起動する: Gateway terminal ウィンドウで Gateway を起動します。\n../otelcol --config gateway.yaml Agent を起動する: Agent terminal ウィンドウで Agent を起動します。\n../otelcol --config agent.yaml 通常のスパンを送信する: Loadgen terminal ウィンドウで loadgen を使用して通常のスパンを送信します\n../loadgen -count 1 Agent と Gateway の両方でデバッグ情報が表示されます。Gateway は新しい gateway-traces-route1-regular.out ファイルも生成します。これが通常のスパンの指定された宛先になりました。\nTip gateway-traces-route1-regular.out を確認すると、loadgen によって送信された span が含まれています。また、空の gateway-traces-route2-security..out ファイルも表示されます。これは、ルーティング設定が、一致するスパンがまだ処理されていなくても、すぐに出力ファイルを作成するためです。",
    "tags": [],
    "title": "6.3 Test Routing Connector",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/6-routing-data/6-3-test-routing/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 7. Count \u0026 Sum Connector",
    "content": "Exercise Gateway を起動する Gateway terminal ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent を起動する Agent terminal ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Loadgen を起動する Spans terminal ウィンドウで、以下の loadgen コマンドを使用して8つのスパンを送信します\n​ Loadgen ../loadgen -count 8 Agent と Gateway の両方がデバッグ情報を表示し、データを処理していることを示します。loadgen が完了するまで待ちます。\nメトリクスを確認する スパンを処理する際、Agent はメトリクスを生成して Gateway に転送します。Gateway はそれらを gateway-metrics.out に書き込みます。\nメトリクス出力に user.card-charge が存在し、それぞれに user.name 属性があることを確認するには、以下の jq クエリを実行します\n​ jq query command jq example output jq -r '.resourceMetrics[].scopeMetrics[].metrics[] | select(.name == \"user.card-charge\") | .sum.dataPoints[] | \"\\(.attributes[] | select(.key == \"user.name\").value.stringValue)\\t\\(.asDouble)\"' gateway-metrics.out | while IFS=$'\\t' read -r name charge; do printf \"%-20s %s\\n\" \"$name\" \"$charge\" done George Lucas 67.49 Frodo Baggins 87.14 Thorin Oakenshield 90.98 Luke Skywalker 51.37 Luke Skywalker 65.56 Thorin Oakenshield 67.5 Thorin Oakenshield 66.66 Peter Jackson 94.39 重要 それぞれのターミナルで Ctrl-C を押して Agent と Gateway のプロセスを停止してください。",
    "description": "Exercise Gateway を起動する Gateway terminal ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent を起動する Agent terminal ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Loadgen を起動する Spans terminal ウィンドウで、以下の loadgen コマンドを使用して8つのスパンを送信します\n​ Loadgen ../loadgen -count 8 Agent と Gateway の両方がデバッグ情報を表示し、データを処理していることを示します。loadgen が完了するまで待ちます。",
    "tags": [],
    "title": "7.3 Sum Connector のテスト",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/7-sum-count/7-3-sum-test/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops",
    "content": "OpenTelemetry Collector の基本概念\rOpenTelemetry Collector の概念と、Splunk Observability Cloud へデータを送信する方法を学びます。\rAdvanced OpenTelemetry Collector\rOpenTelemetry Collector の設定をゼロから行う練習を行い、いくつかの高度な設定シナリオを体験します。",
    "description": "OpenTelemetry Collector の基本概念\rOpenTelemetry Collector の概念と、Splunk Observability Cloud へデータを送信する方法を学びます。\rAdvanced OpenTelemetry Collector\rOpenTelemetry Collector の設定をゼロから行う練習を行い、いくつかの高度な設定シナリオを体験します。",
    "tags": [],
    "title": "OpenTelemetry Collector ワークショップ",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e リソース",
    "content": "はじめに 大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、その規則が遵守されるようにガバナンスプロセスを設定することが非常に重要です。\nこれにより、OpenTelemetry を通じて収集される MELT データ（メトリクス、イベント、ログ、トレース）を、アラート、ダッシュボード作成、トラブルシューティングの目的で効率的に活用することが可能になります。また、Splunk Observability Cloud のユーザーが探しているデータを迅速に見つけることができます。\n命名規則はまた、データを効果的に集約するためにも重要です。例えば、環境ごとのユニークなホストの数を数えたい場合、ホスト名と環境名を捉えるための標準化された規則を使用する必要があります。\n属性 vs タグ 先に進む前に、用語についての注意をしておきましょう。OpenTelemetry の「タグ」は「属性（attribute）」と呼ばれます。属性は、手動または自動の計装を通じて、メトリクス、ログ、トレースに添付することができます。\n属性はまた、Resource Detection processorなどのさまざまなプロセッサを使用して、OpenTelemetry コレクターレベルでメトリクス、ログ、トレースに添付することもできます。\nSplunk Observability Cloud に属性付きのトレースが取り込まれると、それらは「タグ」として利用可能になります。オプションとして、トレースの一部として収集された属性は、Troubleshooting Metric Setsの作成に使用され、Tag Spotlightなどのさまざまな機能と共に使用することができます。\nまた、属性はMonitoring Metric Setsの作成に使用され、アラートのトリガーとして使用することもできます。\nリソースに関するセマンティック規約 OpenTelemetry リソースセマンティック規約は、組織が標準化すべき属性を決定する際の出発点として使用できます。以下のセクションでは、よく使用される属性のいくつか見ていきましょう。\nサービス属性 監視されるサービスを記述するために多くの属性が使用されます。\nservice.name はサービスの論理名を定義する必須の属性です。OpenTelemetry SDK によって自動的に追加されますが、カスタマイズすることができます。これはシンプルに保つことが最善です（例えば、inventoryservice は inventoryservice-prod-hostxyz よりも良いでしょう。他の属性を使用してサービスの他の側面を捉えることができます）。\n以下のサービス属性が推奨されます：\nservice.namespace はサービスを所有するチームを識別するために使用されます service.instance.id はサービスのユニークなインスタンスを識別するために使用されます service.version はサービスのバージョンを識別するために使用されます テレメトリSDK これらの属性はSDKによって自動的に設定され、使用されている計測ライブラリに関する情報を記録します：\ntelemetry.sdk.name は通常 opentelemetry に設定されます。 telemetry.sdk.language は SDK の言語で、例えば java です。 telemetry.sdk.version は使用されている SDK のバージョンを識別します。 コンテナ コンテナで実行されるサービスには、container.id、container.name、container.image.name など、コンテナのランタイムを記述するための多くの属性が使用されます。完全なリストはこちらで確認できます。\nホスト これらの属性は、サービスが実行されているホストを記述し、host.id、host.name、host.arch などの属性を含みます。完全なリストはこちらで確認できます。\nデプロイ環境 deployment.environment 属性は、サービスがデプロイされている環境（ staging や production など）を識別するために使用されます。\nSplunk Observability Cloud は、この属性を使用して関連コンテンツを有効する（詳細はこちら）ため、この属性を含めることが重要です。\nクラウド AWS などのパブリッククラウド環境で実行されるサービスに関する情報を捉えるための属性もあります。これには、cloud.provider、cloud.account.id、cloud.region が含まれます。\n属性の完全なリストはこちらで確認できます。\n一部のクラウドプロバイダー、例えば GCP は、独自のセマンティック規則を定義しています。\nKubernetes Kubernetesで実行されるアプリケーションにも、いくつかの標準化された属性があります。これらの多くは、Splunk の OpenTelemetry コレクター配布によって自動的に追加されます（詳細はこちら）。\n属性は、例えば k8s.cluster.name、k8s.node.name、k8s.pod.name、k8s.namespace.name、kubernetes.workload.name などがあります。\nカスタム属性のベストプラクティス 多くの組織では、OpenTelemetryのリソースセマンティック規約で定義されているもの以上の属性が欲しくなります。\nこの場合、セマンティック規約にすでに含まれている属性名との命名競合を避けることが重要です。つまり、特定の属性名を命名規則に決定する前に、セマンティック規約をチェックすると良いでしょう。\n属性名の命名規則に加えて、属性値も考慮する必要があります。例えば、アプリケーションが属する特定のビジネスユニットをキャプチャしたい場合、簡単にかつ効果的にフィルタリングするために、標準化されたビジネスユニット値のリストも持ちたいでしょう。\nOpenTelemetryコミュニティでは、属性の命名に従うべきガイドラインも提供しています。こちらで見つけることができます。\nRecommendations for Application Developersは、私たちの議論に最も関連しています。\nそこでは、以下を推奨しています：\ncom.acme.shopname のように、会社のドメイン名で属性名を接頭辞として付けること（属性が社内だけでなく外部で使用される可能性がある場合） 属性が特定のアプリケーションに固有であり、組織内でのみ使用される場合は、アプリケーション名で属性名に接頭辞を付けること 既存の OpenTelemetry セマンティック規約の名前を属性名の接頭辞として使用しないこと 異なる組織や業界全体で一般的なニーズがある場合は、あなたの属性名を OpenTelemetry 仕様に追加する提案を検討すること otel.* で始まる属性名は避けること。これは OpenTelemetry 仕様の使用に予約されています カーディナリティに関する考慮事項 属性名と値の命名基準を決定する際に考慮すべき最後の点は、メトリクスのカーディナリティに関連しています。\nのカーディナリティは、メトリクス名とそれに関連する次元の組み合わせによって生成されるユニークなメトリクス時系列（MTS: Metric Time Series）の数として定義されます。\nメトリクスは、ディメンションの数とそれらのディメンションが持つユニークな値の数が多い場合に、高いカーディナリティを持つことになります。\n例えば、あなたのアプリケーションが custom.metric という名前のメトリクスのデータを送信するとします。属性がない場合、custom.metric は単一のメトリクス時系列（MTS）を生成します。\n一方で、custom.metricが customer.id という属性を含み、数千の顧客ID値がある場合、これは数千のメトリクス時系列を生成し、コストやクエリ性能に影響を与える可能性があります。\nSplunk Observability Cloud は、メトリクスの使用量を管理するためのレポートを提供しています。そして、望ましくないディメンションを削除するルールを作成することができます。しかし、最初の防衛線は、属性名と値の組み合わせがどのようにメトリクスのカーディナリティを増加させるかを理解することです。\nまとめ このドキュメントでは、大規模な OpenTelemetry 計装の展開を開始する前に、OpenTelemetry タグの命名規則を定義することの重要性を強調しました。\nOpenTelemetry のリソースセマンティック規約がいくつかの属性の命名規則を定義し、多くの属性が OpenTelemetry SDKや OpenTelemetry コレクター内で動作するプロセッサーを通じて自動的に収集される方法について説明しました。\n最後に、リソースセマンティック規約が組織のニーズに十分でない場合に、属性名を作成するためのベストプラクティスを共有しました。",
    "description": "大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "tags": [],
    "title": "OpenTelemetryとSplunkにおける、タグ付けのための命名規則",
    "uri": "/observability-workshop/ja/resources/otel_tagging/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6.2 Optional Exercise",
    "content": "Let’s look at some other parts of the UI like the Information Pane on the right of the navigator or the Related Content Pane at the bottom.\nFirst, let’s look at the Information Pane, this pane provides alert and detected services information and the metadata related to the object you’re looking at.\nMeta Data is sent along with the metrics and is very useful for identifying trends when looking into issues. An example could be a pod failing when deployed on a specific Operating System.\nExercise Can you identify the Operating System and Architecture of the node from the metadata? As we have seen in the previous exercise, these fields are very useful for filtering the view in charts and Navigators down to a specific subset of metrics we are interested in.\nAnother feature in the UI is Related content.\nRelated Content The Splunk Observability User Interface will attempt to show you additional information that is related to what you’re actively looking at. A good example of this is the Kubernetes Navigator showing you related Content tiles in the information Pane for the services found running on this node.\nIn the Information Pane, you should see two tiles for services detected, the two databases used by our e-commerce application. Let’s use this Related Content.\nExercise First, make sure you no longer have a filter for the development namespace active. (Simply click on the x to remove it from the Filter Pane) as there are no databases in the Development Namespace. Hoover on the Redis tile, and click on the Goto all my Redis instances button The Navigator view should change to the overall Redis instances view. Select the the instance running on your cluster. (Click on the blue link, named redis-[the name of your workshop], in the Redis Instances pane). We should now see just the information for your Redis Instance \u0026 there should also be an Information Pane. Again we see Meta Data, but we also see that UI is showing in the Related Content tiles that this Redis Server runs in a Container running on Kubernetes. Let’s verify that by clicking on the Kubernetes Tile. We should be back in the Kubernetes Navigator, at the container level. Confirm that the names of our cluster and node are all visible at the top of the page and we are back looking at our K8s Cluster, where we started. This completes the tour of Splunk Observability Cloud. Let’s go and look at our e-commerce site and do some shopping.",
    "description": "Let’s look at some other parts of the UI like the Information Pane on the right of the navigator or the Related Content Pane at the bottom.\nFirst, let’s look at the Information Pane, this pane provides alert and detected services information and the metadata related to the object you’re looking at.\nMeta Data is sent along with the metrics and is very useful for identifying trends when looking into issues. An example could be a pod failing when deployed on a specific Operating System.",
    "tags": [],
    "title": "Infrastructure Exercise - Part 3",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/30-im-exercise/3-im-exercise/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 2. API Test",
    "content": "検索リクエストの追加 + Add Request をクリックして次のステップを追加します。ステップ名を Search for Tracks named “Up around the bend” とします。\nRequest セクションを展開し、リクエストメソッドを GET に変更して、以下の URL を入力します:\nhttps://api.spotify.com/v1/search?q=Up%20around%20the%20bend\u0026type=track\u0026offset=0\u0026limit=5 次に、以下のキー/値のペアで2つのリクエストヘッダーを追加します:\nCONTENT-TYPE: application/json AUTHORIZATION: Bearer {{custom.access_token}} Validation セクションを展開し、以下の抽出を追加します:\nExtract from Response body JSON $.tracks.items[0].id as track.id \u003c Return to test をクリックしてテスト設定ページに戻ります。次に Save をクリックして API テストを保存します。",
    "description": "検索リクエストの追加 + Add Request をクリックして次のステップを追加します。ステップ名を Search for Tracks named “Up around the bend” とします。\nRequest セクションを展開し、リクエストメソッドを GET に変更して、以下の URL を入力します:\nhttps://api.spotify.com/v1/search?q=Up%20around%20the%20bend\u0026type=track\u0026offset=0\u0026limit=5 次に、以下のキー/値のペアで2つのリクエストヘッダーを追加します:\nCONTENT-TYPE: application/json AUTHORIZATION: Bearer {{custom.access_token}} Validation セクションを展開し、以下の抽出を追加します:\nExtract from Response body JSON $.tracks.items[0].id as track.id",
    "tags": [],
    "title": "検索リクエスト",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/2-api-test/4-search-request/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 1. Real Browser Test",
    "content": "シンプル設定では、テストの基本を構成できます:\nName: テストの名前（例: RWC - Online Boutique） Details: Locations: テストを実行するロケーション Device: 異なるデバイスと接続速度をエミュレート。選択したデバイスに合わせてビューポートも調整されます Frequency: テストの実行頻度 Round-robin: 複数のロケーションを選択した場合、すべてのロケーションで同時に実行するのではなく、一度に1つのロケーションからテストを実行します Active: テストをアクティブまたは非アクティブに設定 ![Return to Test]このワークショップでは、モニタリングを行うロケーションを設定します。Locations フィールドをクリックすると、グローバルロケーションのリスト（合計50以上）が表示されます。\n以下のロケーションを選択します:\nAWS - N. Virginia AWS - London AWS - Melbourne 完了したら、下にスクロールして Submit をクリックしてテストを保存します。\nこれで、選択した3つのロケーションから5分ごとにテストが実行されるようスケジュールされます。スケジュールの作成には数分かかります。\nテストのスケジュール作成を待つ間、Edit test をクリックして Advanced 設定を確認しましょう。",
    "description": "シンプル設定では、テストの基本を構成できます:\nName: テストの名前（例: RWC - Online Boutique） Details: Locations: テストを実行するロケーション Device: 異なるデバイスと接続速度をエミュレート。選択したデバイスに合わせてビューポートも調整されます Frequency: テストの実行頻度 Round-robin: 複数のロケーションを選択した場合、すべてのロケーションで同時に実行するのではなく、一度に1つのロケーションからテストを実行します Active: テストをアクティブまたは非アクティブに設定 ![Return to Test]このワークショップでは、モニタリングを行うロケーションを設定します。Locations フィールドをクリックすると、グローバルロケーションのリスト（合計50以上）が表示されます。\n以下のロケーションを選択します:\nAWS - N. Virginia AWS - London AWS - Melbourne 完了したら、下にスクロールして Submit をクリックしてテストを保存します。\nこれで、選択した3つのロケーションから5分ごとにテストが実行されるようスケジュールされます。スケジュールの作成には数分かかります。\nテストのスケジュール作成を待つ間、Edit test をクリックして Advanced 設定を確認しましょう。",
    "tags": [],
    "title": "1.4 設定",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/4-edit-test-settings/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "OpenTelemetry Collector の FileStorage Extension は、より耐障害性の高いテレメトリーパイプラインを構築するための重要なコンポーネントです。これにより、Collector は処理中のデータを確実にチェックポイントし、リトライを効率的に管理し、貴重なテレメトリーを失うことなく一時的な障害を適切に処理できます。\nFileStorage を有効にすると、Collector は中間状態をディスクに永続化できるため、ネットワークの中断、バックエンドの停止、または Collector の再起動時にもトレース、メトリクス、ログが失われないことが保証されます。つまり、ネットワーク接続が切断されたり、バックエンドが一時的に利用できなくなったりしても、Collector はテレメトリーの受信とバッファリングを継続し、接続が復旧すると配信をシームレスに再開します。\nFileStorage Extension をパイプラインに統合することで、オブザーバビリティスタックの耐久性を強化し、接続が不安定な環境でも高品質なテレメトリー取り込みを維持できます。 メモ このソリューションは、接続ダウンタイムが短い場合（最大15分）のメトリクスに対して機能します。ダウンタイムがこれを超えると、Splunk Observability Cloud はデータポイントの順序が乱れないようにデータをドロップする可能性があります。\nログについては、今後の Splunk OpenTelemetry Collector リリースで完全なエンタープライズ対応ソリューションを実装する計画があります。",
    "description": "OpenTelemetry Collector の FileStorage Extension は、より耐障害性の高いテレメトリーパイプラインを構築するための重要なコンポーネントです。これにより、Collector は処理中のデータを確実にチェックポイントし、リトライを効率的に管理し、貴重なテレメトリーを失うことなく一時的な障害を適切に処理できます。\nFileStorage を有効にすると、Collector は中間状態をディスクに永続化できるため、ネットワークの中断、バックエンドの停止、または Collector の再起動時にもトレース、メトリクス、ログが失われないことが保証されます。つまり、ネットワーク接続が切断されたり、バックエンドが一時的に利用できなくなったりしても、Collector はテレメトリーの受信とバッファリングを継続し、接続が復旧すると配信をシームレスに再開します。\nFileStorage Extension をパイプラインに統合することで、オブザーバビリティスタックの耐久性を強化し、接続が不安定な環境でも高品質なテレメトリー取り込みを維持できます。 メモ このソリューションは、接続ダウンタイムが短い場合（最大15分）のメトリクスに対して機能します。ダウンタイムがこれを超えると、Splunk Observability Cloud はデータポイントの順序が乱れないようにデータをドロップする可能性があります。\nログについては、今後の Splunk OpenTelemetry Collector リリースで完全なエンタープライズ対応ソリューションを実装する計画があります。",
    "tags": [],
    "title": "2. 耐障害性の構築",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/2-building-resilience/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector \u003e 2. Building Resilience",
    "content": "この演習では、Gateway Collector を再起動することで、OpenTelemetry Collector がネットワーク障害からどのように復旧するかをテストします。Gateway が再び利用可能になると、Agent は最後にチェックポイントされた状態からデータの送信を再開し、データ損失がないことを保証します。\nExercise Gateway の再起動: Gateway ターミナル ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent の再起動: Agent ターミナル ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Agent が起動して実行されると、File_Storage Extension がチェックポイントフォルダー内のバッファされたデータを検出します。最後のチェックポイントフォルダーから保存されたスパンをデキューし始め、データが失われないことを保証します。\nAgent デバッグ出力の確認: Agent のデバッグ出力は変化せず、以下の行を表示し続け、新しいデータがエクスポートされていないことを示していることに注意してください\n2025-07-11T08:31:58.176Z info service@v0.126.0/service.go:289 Everything is ready. Begin running and processing data. {\"resource\": {}} Gateway デバッグ出力の確認 Gateway のデバッグ画面から、以前見逃されていたトレースを追加のアクションなしで受信し始めていることが確認できるはずです。例\nAttributes: -\u003e user.name: Str(Luke Skywalker) -\u003e user.phone_number: Str(+1555-867-5309) -\u003e user.email: Str(george@deathstar.email) -\u003e user.password: Str(LOTR\u003eStarWars1-2-3) -\u003e user.visa: Str(4111 1111 1111 1111) -\u003e user.amex: Str(3782 822463 10005) -\u003e user.mastercard: Str(5555 5555 5555 4444) -\u003e payment.amount: Double(75.75) {\"resource\": {}, \"otelcol.component.id\": \"debug\", \"otelcol.component.kind\": \"exporter\", \"otelcol.signal\": \"traces\"} gateway-traces.out ファイルの確認: jq を使用して、再作成された gateway-traces.out 内のトレース数をカウントします。Gateway がダウンしていたときに送信した数と一致するはずです。\n​ Check Gateway Traces Out File Example output jq '.resourceSpans | length | \"\\(.) resourceSpans found\"' gateway-traces.out \"5 resourceSpans found\" 重要 Agent と Gateway のプロセスを、それぞれのターミナルで Ctrl-C を押して停止してください。\nまとめ この演習では、file_storage Extension の設定、otlp Exporter のリトライメカニズムの有効化、および一時的なデータ保存用のファイルベースのキューの使用により、OpenTelemetry Collector の耐障害性を強化する方法を示しました。\nファイルベースのチェックポイントとキューの永続化を実装することで、テレメトリーパイプラインが一時的な中断から適切に復旧できることを保証し、本番環境でより堅牢で信頼性の高いものにします。",
    "description": "この演習では、Gateway Collector を再起動することで、OpenTelemetry Collector がネットワーク障害からどのように復旧するかをテストします。Gateway が再び利用可能になると、Agent は最後にチェックポイントされた状態からデータの送信を再開し、データ損失がないことを保証します。\nExercise Gateway の再起動: Gateway ターミナル ウィンドウで以下を実行します\n​ Start the Gateway ../otelcol --config=gateway.yaml Agent の再起動: Agent ターミナル ウィンドウで以下を実行します\n​ Start the Agent ../otelcol --config=agent.yaml Agent が起動して実行されると、File_Storage Extension がチェックポイントフォルダー内のバッファされたデータを検出します。最後のチェックポイントフォルダーから保存されたスパンをデキューし始め、データが失われないことを保証します。\nAgent デバッグ出力の確認: Agent のデバッグ出力は変化せず、以下の行を表示し続け、新しいデータがエクスポートされていないことを示していることに注意してください",
    "tags": [],
    "title": "2.4 復旧",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/2-building-resilience/2-4-recovery/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "インストールが完了したら、Splunk Observability Cloud にログインして、Kubernetes クラスターからメトリクスが流れてきていることを確認できます。\n左側のメニューから Infrastructure をクリックし、Kubernetes を選択してから、Kubernetes nodes タイルを選択します。\nKubernetes nodes の概要画面に入ったら、Time フィルタを -1h から過去15分 (-15m) に変更して最新のデータに焦点を当て、次に Table を選択してメトリクスを報告しているすべてのノードをリスト表示します。\n次に、Refine by: パネルで Cluster name を選択し、リストからご自身のクラスターを選択します。\nTip 特定のクラスターを識別するには、セットアップ中に実行したシェルスクリプト出力の INSTANCE 値を使用してください。この一意の識別子により、リスト内の他のノードの中からワークショップクラスターを見つけることができます。\nこれにより、ご自身のクラスターのノードのみを表示するようにリストがフィルタリングされます。\nK8s node logs ビューに切り替えて、ノードからのログを確認します。",
    "description": "インストールが完了したら、Splunk Observability Cloud にログインして、Kubernetes クラスターからメトリクスが流れてきていることを確認できます。\n左側のメニューから Infrastructure をクリックし、Kubernetes を選択してから、Kubernetes nodes タイルを選択します。\nKubernetes nodes の概要画面に入ったら、Time フィルタを -1h から過去15分 (-15m) に変更して最新のデータに焦点を当て、次に Table を選択してメトリクスを報告しているすべてのノードをリスト表示します。\n次に、Refine by: パネルで Cluster name を選択し、リストからご自身のクラスターを選択します。\nTip 特定のクラスターを識別するには、セットアップ中に実行したシェルスクリプト出力の INSTANCE 値を使用してください。この一意の識別子により、リスト内の他のノードの中からワークショップクラスターを見つけることができます。\nこれにより、ご自身のクラスターのノードのみを表示するようにリストがフィルタリングされます。\nK8s node logs ビューに切り替えて、ノードからのログを確認します。",
    "tags": [],
    "title": "Kubernetes クラスターメトリクスの確認",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/3-verify-setup/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "演習 サービスマップでpaymentserviceを選択します。 右側のペインでBreakdownをクリックします。 リストからtenant.levelを選択します。 サービスマップに戻り、goldをクリックします。 Breakdownをクリックしてversionを選択します。これはサービスバージョンを表示するタグです。 これをsilverとbronzeについても繰り返します。 ​ 質問 回答 表示されている内容からどのような結論が導き出せますか？\nすべてのtenant.levelがv350.10の影響を受けています\nこれでpaymentserviceがgold、silver、bronzeの 3 つのサービスに分解されているのが確認できます。各テナントは 2 つのサービスに分解されており、それぞれのバージョン（v350.10とv350.9）に対応しています。\nスパンタグ スパンタグを使用してサービスを分解することは非常に強力な機能です。これにより、異なる顧客、異なるバージョン、異なる地域などに対して、サービスがどのようにパフォーマンスを発揮しているかを確認できます。この演習では、paymentserviceのv350.10がすべての顧客に問題を引き起こしていることを特定しました。\n次に、何が起きているかを確認するためにトレースを詳しく調べる必要があります。",
    "description": "演習 サービスマップでpaymentserviceを選択します。 右側のペインでBreakdownをクリックします。 リストからtenant.levelを選択します。 サービスマップに戻り、goldをクリックします。 Breakdownをクリックしてversionを選択します。これはサービスバージョンを表示するタグです。 これをsilverとbronzeについても繰り返します。 ​ 質問 回答 表示されている内容からどのような結論が導き出せますか？\nすべてのtenant.levelがv350.10の影響を受けています\nこれでpaymentserviceがgold、silver、bronzeの 3 つのサービスに分解されているのが確認できます。各テナントは 2 つのサービスに分解されており、それぞれのバージョン（v350.10とv350.9）に対応しています。\nスパンタグ スパンタグを使用してサービスを分解することは非常に強力な機能です。これにより、異なる顧客、異なるバージョン、異なる地域などに対して、サービスがどのようにパフォーマンスを発揮しているかを確認できます。この演習では、paymentserviceのv350.10がすべての顧客に問題を引き起こしていることを特定しました。\n次に、何が起きているかを確認するためにトレースを詳しく調べる必要があります。",
    "tags": [],
    "title": "4. APMサービスブレイクダウン",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/6-apm/4-apm-service-breakdown/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic モノリスワークショップ",
    "content": "Splunk Log Observer コンポーネントでは、Splunk OpenTelemetry Collector が Spring PetClinic アプリケーションからログを自動的に収集し、OTLP エクスポーターを使用して Splunk Observability Cloud に送信します。その際、ログイベントに trace_id、span_id、トレースフラグを付与します。\nLog Observer は、アプリケーションとインフラストラクチャからのログをリアルタイムで表示します。ログの検索、フィルタリング、分析を行って、問題のトラブルシューティングや環境の監視が可能です。\nPetClinic Web アプリケーションに戻り、Error リンクを数回クリックしてください。これにより、PetClinic アプリケーションログにいくつかのログメッセージが生成されます。\n左側のメニューから Log Observer をクリックし、Index が splunk4rookies-workshop に設定されていることを確認してください。\n次に、Add Filter をクリックし、フィールド service.name を検索して、値 \u003cINSTANCE\u003e-petclinic-service を選択し、=（include）をクリックします。これで、PetClinic アプリケーションからのログメッセージのみが表示されるはずです。\nPetClinic アプリケーションの Error リンクをクリックして生成されたログエントリの1つを選択してください。ログメッセージと、ログメッセージに自動的にインジェクションされたトレースメタデータが表示されます。また、APM と Infrastructure の Related Content が利用可能であることにも注目してください。\nこれでワークショップは終了です。多くの内容をカバーしました。この時点で、メトリクス、トレース（APM と RUM）、ログ、データベースクエリパフォーマンス、コードプロファイリングが Splunk Observability Cloud に報告されているはずです。しかも、PetClinic アプリケーションのコードを変更することなく実現できました（RUM を除く）。\nおめでとうございます！",
    "description": "Splunk Log Observer コンポーネントでは、Splunk OpenTelemetry Collector が Spring PetClinic アプリケーションからログを自動的に収集し、OTLP エクスポーターを使用して Splunk Observability Cloud に送信します。その際、ログイベントに trace_id、span_id、トレースフラグを付与します。\nLog Observer は、アプリケーションとインフラストラクチャからのログをリアルタイムで表示します。ログの検索、フィルタリング、分析を行って、問題のトラブルシューティングや環境の監視が可能です。\nPetClinic Web アプリケーションに戻り、Error リンクを数回クリックしてください。これにより、PetClinic アプリケーションログにいくつかのログメッセージが生成されます。\n左側のメニューから Log Observer をクリックし、Index が splunk4rookies-workshop に設定されていることを確認してください。\n次に、Add Filter をクリックし、フィールド service.name を検索して、値 \u003cINSTANCE\u003e-petclinic-service を選択し、=（include）をクリックします。これで、PetClinic アプリケーションからのログメッセージのみが表示されるはずです。\nPetClinic アプリケーションの Error リンクをクリックして生成されたログエントリの1つを選択してください。ログメッセージと、ログメッセージに自動的にインジェクションされたトレースメタデータが表示されます。また、APM と Infrastructure の Related Content が利用可能であることにも注目してください。\nこれでワークショップは終了です。多くの内容をカバーしました。この時点で、メトリクス、トレース（APM と RUM）、ログ、データベースクエリパフォーマンス、コードプロファイリングが Splunk Observability Cloud に報告されているはずです。しかも、PetClinic アプリケーションのコードを変更することなく実現できました（RUM を除く）。",
    "tags": [],
    "title": "4. Log Observer",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/1-petclinic-monolith/5-log-observer/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Log Observer Connect を使用すると、Splunk プラットフォームからの同じログデータをシームレスに直感的でコード不要のインターフェースに取り込み、問題を迅速に見つけて修正するのに役立ちます。ログベースの分析を簡単に実行し、Splunk Infrastructure Monitoring のリアルタイムメトリクスと Splunk APM トレースを 1 か所でシームレスに関連付けることができます。\nエンドツーエンドの可視性： Splunk プラットフォームの強力なロギング機能と Splunk Observability Cloud のトレースおよびリアルタイムメトリクスを組み合わせることで、ハイブリッド環境のより深い洞察とより多くのコンテキストを得ることができます。\n迅速かつ簡単なログベースの調査を実行： すでに Splunk Cloud Platform または Enterprise に取り込まれているログを、シンプルで直感的なインターフェース（SPL を知る必要はありません！）でカスタマイズ可能な標準搭載のダッシュボードとともに再利用することによって実現します。\nより高いスケールの経済性と運用効率を実現： チーム間でログ管理を一元化し、データとチームのサイロを壊し、全体的により良いサポートを得ることによって実現します。",
    "description": "Log Observer Connect を使用すると、Splunk プラットフォームからの同じログデータをシームレスに直感的でコード不要のインターフェースに取り込み、問題を迅速に見つけて修正するのに役立ちます。ログベースの分析を簡単に実行し、Splunk Infrastructure Monitoring のリアルタイムメトリクスと Splunk APM トレースを 1 か所でシームレスに関連付けることができます。\nエンドツーエンドの可視性： Splunk プラットフォームの強力なロギング機能と Splunk Observability Cloud のトレースおよびリアルタイムメトリクスを組み合わせることで、ハイブリッド環境のより深い洞察とより多くのコンテキストを得ることができます。\n迅速かつ簡単なログベースの調査を実行： すでに Splunk Cloud Platform または Enterprise に取り込まれているログを、シンプルで直感的なインターフェース（SPL を知る必要はありません！）でカスタマイズ可能な標準搭載のダッシュボードとともに再利用することによって実現します。\nより高いスケールの経済性と運用効率を実現： チーム間でログ管理を一元化し、データとチームのサイロを壊し、全体的により良いサポートを得ることによって実現します。",
    "tags": [],
    "title": "Log Observer概要",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/4-log-observer-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "Splunk Distribution of OpenTelemetry のダウンロード このワークショップでは、NuGet パッケージを使用せず、Splunk Distribution of OpenTelemetry を 手動でインストールします。\n最新のsplunk-otel-dotnet-install.shファイルをダウンロードすることから始めます。 これを使用して.NET アプリケーションを計装します：\ncd ~/workshop/docker-k8s-otel/helloworld curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O インストールプロセスの詳細については、Splunk Distribution of OpenTelemetry .NET の手動インストール を参照してください。\nディストリビューションのインストール ターミナルで、以下のようにディストリビューションをインストールします\n​ Script Example Output sh ./splunk-otel-dotnet-install.sh Downloading v1.8.0 for linux-glibc (/tmp/tmp.m3tSdtbmge/splunk-opentelemetry-dotnet-linux-glibc-x64.zip)... 注意：上記のコマンドを実行する際には、ARCHITECTURE 環境変数を含める必要がある場合があります：\nARCHITECTURE=x64 sh ./splunk-otel-dotnet-install.sh 計装の有効化 次に、OpenTelemetry 計装を有効化できます：\n. $HOME/.splunk-otel-dotnet/instrument.sh デプロイメント環境の設定 デプロイメント環境を設定して、データが Splunk Observability Cloud 内の独自の 環境に流れるようにしましょう：\nexport OTEL_RESOURCE_ATTRIBUTES=deployment.environment=otel-$INSTANCE 計装を使用したアプリケーションの実行 以下のようにアプリケーションを実行できます：\ndotnet run チャレンジ Linux インスタンスから C#アプリケーションによってエクスポートされているトレースをどのように確認できるでしょうか？\n答えを見るにはここをクリック これを行う方法は 2 つあります：\ndotnet runコマンドの開始時にOTEL_TRACES_EXPORTER=otlp,consoleを追加することで、トレースが OTLP 経由でコレクターに書き込まれるとともに、コンソールにも書き込まれるようになります。 OTEL_TRACES_EXPORTER=otlp,console dotnet run あるいは、コレクター設定にデバッグエクスポーターを追加し、それをトレースパイプラインに追加することで、トレースがコレクターログに書き込まれるようになります。 exporters: debug: verbosity: detailed service: pipelines: traces: receivers: [jaeger, otlp, zipkin] processors: - memory_limiter - batch - resourcedetection exporters: [otlphttp, signalfx, debug] アプリケーションへのアクセス アプリケーションが実行中になったら、2 つ目の SSH ターミナルを使用して curl でアクセスします：\ncurl http://localhost:8080/hello 以前と同様に、Hello, World!が返されるはずです。\nトレースログを有効にした場合は、以下のようなトレースがコンソールまたはコレクターログに書き込まれているのを確認できるはずです：\ninfo: Program[0] /hello endpoint invoked anonymously Activity.TraceId: c7bbf57314e4856447508cd8addd49b0 Activity.SpanId: 1c92ac653c3ece27 Activity.TraceFlags: Recorded Activity.ActivitySourceName: Microsoft.AspNetCore Activity.DisplayName: GET /hello/{name?} Activity.Kind: Server Activity.StartTime: 2024-12-20T00:45:25.6551267Z Activity.Duration: 00:00:00.0006464 Activity.Tags: server.address: localhost server.port: 8080 http.request.method: GET url.scheme: http url.path: /hello network.protocol.version: 1.1 user_agent.original: curl/7.81.0 http.route: /hello/{name?} http.response.status_code: 200 Resource associated with Activity: splunk.distro.version: 1.8.0 telemetry.distro.name: splunk-otel-dotnet telemetry.distro.version: 1.8.0 service.name: helloworld os.type: linux os.description: Ubuntu 22.04.5 LTS os.build_id: 6.8.0-1021-aws os.name: Ubuntu os.version: 22.04 host.name: derek-1 host.id: 20cf15fcc7054b468647b73b8f87c556 process.owner: splunk process.pid: 16997 process.runtime.description: .NET 8.0.11 process.runtime.name: .NET process.runtime.version: 8.0.11 container.id: 2 telemetry.sdk.name: opentelemetry telemetry.sdk.language: dotnet telemetry.sdk.version: 1.9.0 deployment.environment: otel-derek-1 Splunk Observability Cloud でのアプリケーションの確認 セットアップが完了したので、トレースがSplunk Observability Cloudに送信されていることを確認しましょう。アプリケーションが初回デプロイされた場合、データが表示されるまでに数分かかる場合があることに注意してください。\nAPM にナビゲートし、Environment ドロップダウンを使用してあなたの環境（つまりotel-instancename）を選択します。\nすべてが正しくデプロイされている場合、サービスのリストにhelloworldが表示されるはずです：\n右側のService Mapをクリックしてサービスマップを表示します。\n次に、右側のTracesをクリックして、このアプリケーションでキャプチャされたトレースを確認します。\n個別のトレースは以下のように表示されるはずです：\n次のステップに進む前に、Ctrl + C を押して Helloworld アプリを終了してください。",
    "description": "Splunk Distribution of OpenTelemetry のダウンロード このワークショップでは、NuGet パッケージを使用せず、Splunk Distribution of OpenTelemetry を 手動でインストールします。\n最新のsplunk-otel-dotnet-install.shファイルをダウンロードすることから始めます。 これを使用して.NET アプリケーションを計装します：\ncd ~/workshop/docker-k8s-otel/helloworld curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O インストールプロセスの詳細については、Splunk Distribution of OpenTelemetry .NET の手動インストール を参照してください。\nディストリビューションのインストール ターミナルで、以下のようにディストリビューションをインストールします\n​ Script Example Output sh ./splunk-otel-dotnet-install.sh Downloading v1.8.0 for linux-glibc (/tmp/tmp.m3tSdtbmge/splunk-opentelemetry-dotnet-linux-glibc-x64.zip)... 注意：上記のコマンドを実行する際には、ARCHITECTURE 環境変数を含める必要がある場合があります：",
    "tags": [],
    "title": "OpenTelemetryで.NETアプリケーションを計装する",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/4-instrument-app-with-otel/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "Processors は、データを受信してからエクスポートするまでの間に実行されます。Processors はオプションですが、一部は推奨されています。OpenTelemetry contrib Collector には 多数の Processors が含まれています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Processors fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "Processors は、データを受信してからエクスポートするまでの間に実行されます。Processors はオプションですが、一部は推奨されています。OpenTelemetry contrib Collector には 多数の Processors が含まれています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Processors fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector Processors",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/4-processors/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. RUMを有効にする Real User Monitoring (RUM)計装のために、Open Telemetry Javascript https://github.com/signalfx/splunk-otel-js-web スニペットをページ内に追加します。再度ウィザードを使用します Data Management → Add Integrationボタン → Monitor user experience（画面上部タブ） → Browser Instrumentationを開きます。\nドロップダウンから設定済みの RUM ACCESS TOKEN を選択し、Next をクリックします。以下の構文で App name とEnvironment を入力します：\n次に、ワークショップのRUMトークンを選択し、 App nameとEnvironmentを定義します。ウィザードでは、ページ上部の \u003chead\u003e セクションに配置する必要のある HTML コードの断片が表示されます。この例では、次のように記述していますが、ウィザードでは先程入力した値が反映されてるはずです。\nApplication Name: \u003chostname\u003e-petclinic-service Environment: \u003chostname\u003e-petclinic-env ウィザードで編集済みコードスニペットをコピーするか、以下のスニペットをコピーして適宜編集してください。ただし：\n[hostname]-petclinic-service - [hostname] をお使いのホスト名に書き換えてください [hostname]-petclinic-env - [hostname] をお使いのホスト名に書き換えてください \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ beaconUrl: \"https://rum-ingest.\u003cREALM\u003e.signalfx.com/v1/rum\", rumAuth: \"\u003cRUM_ACCESS_TOKEN\u003e\", app: \"\u003chostname\u003e.service\", environment: \"\u003chostname\u003e\" }); \u003c/script\u003e Spring PetClinicアプリケーションでは、1つのHTMLページを「レイアウト」ページとして使用し、アプリケーションのすべてのページで再利用しています。これは、Splunk RUM計装ライブラリを挿入するのに最適な場所であり、すべてのページで自動的に読み込まれます。\nでは、レイアウトページを編集してみましょう：\nnano src/main/resources/templates/fragments/layout.html そして、上で生成したスニップをページの \u003chead\u003e セクションに挿入してみましょう。さて、アプリケーションを再構築して、再び実行する必要があります。\n2. PetClinicを再ビルドする mavenコマンドを実行して、PetClinicをコンパイル/ビルド/パッケージ化します：\n./mvnw package -Dmaven.test.skip=true そして、アプリケーションを動かしてみましょう。バージョンを version=0.316 とするのをお忘れなく。\njava -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.316 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql versionを自動で設定する ここまできて version を毎回変えるためにコマンドラインを修正するのは大変だと思うことでしょう。実際、修正が漏れた人もいるかもしれません。 本番環境では、環境変数でアプリケーションバージョンを与えたり、コンテナイメージの作成時にビルドIDを与えたりすることになるはずです。\n次に、より多くのトラフィックを生成するために、アプリケーションに再度アクセスしてみましょう。 http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスすると、今度はRUMトレースが報告されるはずです。\nRUMにアクセスして、トレースとメトリクスのいくつかを見てみましょう。左のメニューから RUM を選ぶと、Spring Pet Clinicでのユーザー（あなたです！）が体験したパフォーマンスが表示されます。",
    "description": "1. RUMを有効にする Real User Monitoring (RUM)計装のために、Open Telemetry Javascript https://github.com/signalfx/splunk-otel-js-web スニペットをページ内に追加します。再度ウィザードを使用します Data Management → Add Integrationボタン → Monitor user experience（画面上部タブ） → Browser Instrumentationを開きます。\nドロップダウンから設定済みの RUM ACCESS TOKEN を選択し、Next をクリックします。以下の構文で App name とEnvironment を入力します：\n次に、ワークショップのRUMトークンを選択し、 App nameとEnvironmentを定義します。ウィザードでは、ページ上部の \u003chead\u003e セクションに配置する必要のある HTML コードの断片が表示されます。この例では、次のように記述していますが、ウィザードでは先程入力した値が反映されてるはずです。\nApplication Name: \u003chostname\u003e-petclinic-service Environment: \u003chostname\u003e-petclinic-env ウィザードで編集済みコードスニペットをコピーするか、以下のスニペットをコピーして適宜編集してください。ただし：\n[hostname]-petclinic-service - [hostname] をお使いのホスト名に書き換えてください [hostname]-petclinic-env - [hostname] をお使いのホスト名に書き換えてください \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ beaconUrl: \"https://rum-ingest.\u003cREALM\u003e.signalfx.com/v1/rum\", rumAuth: \"\u003cRUM_ACCESS_TOKEN\u003e\", app: \"\u003chostname\u003e.service\", environment: \"\u003chostname\u003e\" }); \u003c/script\u003e Spring PetClinicアプリケーションでは、1つのHTMLページを「レイアウト」ページとして使用し、アプリケーションのすべてのページで再利用しています。これは、Splunk RUM計装ライブラリを挿入するのに最適な場所であり、すべてのページで自動的に読み込まれます。",
    "tags": [],
    "title": "Real User Monitoring",
    "uri": "/observability-workshop/ja/other/pet-clinic/docs/rum/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ \u003e 5. APM Features",
    "content": "Splunk APMは、エンジニアに1つの集中ビューでサービスパフォーマンスの深い理解を提供するService Centric Viewsを提供します。すべてのサービスにわたって、エンジニアはサービスの基盤となるインフラストラクチャからのエラーやボトルネックを迅速に特定し、新しいデプロイによるパフォーマンス低下を特定し、すべてのサードパーティ依存関係の健全性を可視化できます。\napi-gatewayのこのダッシュボードを表示するには、左側のメニューからAPMをクリックし、リストのapi-gatewayサービスをクリックします。これにより、Service Centric Viewダッシュボードが表示されます：\nインストルメントされた各サービスで利用可能なこのビューは、Service metrics、Error breakdown、Runtime metrics (Java)、Infrastructure metricsの概要を提供します。",
    "description": "Splunk APMは、エンジニアに1つの集中ビューでサービスパフォーマンスの深い理解を提供するService Centric Viewsを提供します。すべてのサービスにわたって、エンジニアはサービスの基盤となるインフラストラクチャからのエラーやボトルネックを迅速に特定し、新しいデプロイによるパフォーマンス低下を特定し、すべてのサードパーティ依存関係の健全性を可視化できます。\napi-gatewayのこのダッシュボードを表示するには、左側のメニューからAPMをクリックし、リストのapi-gatewayサービスをクリックします。これにより、Service Centric Viewダッシュボードが表示されます：\nインストルメントされた各サービスで利用可能なこのビューは、Service metrics、Error breakdown、Runtime metrics (Java)、Infrastructure metricsの概要を提供します。",
    "tags": [],
    "title": "Service Centric View",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/5-traces/4-red-metrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "これらのテストを 24 時間 365 日実行できるため、テストが失敗したり、合意した SLA よりも長く実行され始めた場合に、ソーシャルメディアやアップタイムウェブサイトから通知される前に、早期に警告を受けるための理想的なツールです。\nそのような事態を防ぐために、テストが 1.1 分以上かかっているかどうかを検知しましょう。\n演習 左側のメニューから Synthetics ホームページに戻ります\nワークショップのテストを再度選択し、ページ上部のCreate Detectorボタンをクリックします。\nNew Synthetics Detectorというテキスト（1）を編集し、イニシャル - [ワークショップ名]に置き換えます。\nRun DurationとStatic threasholdが選択されていることを確認します。\nTrigger threasholt（2）を65,000〜68,000に設定し、Enter キーを押してチャートを更新します。上図のように、しきい値ラインを切る複数のスパイクがあることを確認してください（実際のレイテンシーに合わせてしきい値を少し調整する必要があるかもしれません）。\n残りはデフォルトのままにします。\nスパイクの下に赤と白の三角形の列が表示されるようになったことに注意してください（3）。赤い三角形は、テストが指定されたしきい値を超えたことを Detector が検出したことを知らせ、白い三角形は結果がしきい値を下回ったことを示します。各赤い三角形がアラートをトリガーします。\nアラートの重大度（4）は、ドロップダウンを別のレベルに変更することで変更できます。また、アラート方法も変更できます。受信者を追加しないでください。アラートストームの対象になる可能性があります！\nActibateをクリックして、 Detector をデプロイします。\n新しく作成した Detector を見るには、Edit Testボタンをクリックします。\nページの下部にアクティブな Detector のリストがあります。\nあなたの Detector が見つからず、新しい Synthetics Detectorという名前のものが表示されている場合は、あなたの名前で正しく保存されていない可能性があります。新しい Synthetics Detectorのリンクをクリックして、名前の変更をやり直してください。\n閉じるボタンをクリックして編集モードを終了します。",
    "description": "これらのテストを 24 時間 365 日実行できるため、テストが失敗したり、合意した SLA よりも長く実行され始めた場合に、ソーシャルメディアやアップタイムウェブサイトから通知される前に、早期に警告を受けるための理想的なツールです。\nそのような事態を防ぐために、テストが 1.1 分以上かかっているかどうかを検知しましょう。\n演習 左側のメニューから Synthetics ホームページに戻ります\nワークショップのテストを再度選択し、ページ上部のCreate Detectorボタンをクリックします。\nNew Synthetics Detectorというテキスト（1）を編集し、イニシャル - [ワークショップ名]に置き換えます。\nRun DurationとStatic threasholdが選択されていることを確認します。\nTrigger threasholt（2）を65,000〜68,000に設定し、Enter キーを押してチャートを更新します。上図のように、しきい値ラインを切る複数のスパイクがあることを確認してください（実際のレイテンシーに合わせてしきい値を少し調整する必要があるかもしれません）。\n残りはデフォルトのままにします。\nスパイクの下に赤と白の三角形の列が表示されるようになったことに注意してください（3）。赤い三角形は、テストが指定されたしきい値を超えたことを Detector が検出したことを知らせ、白い三角形は結果がしきい値を下回ったことを示します。各赤い三角形がアラートをトリガーします。\nアラートの重大度（4）は、ドロップダウンを別のレベルに変更することで変更できます。また、アラート方法も変更できます。受信者を追加しないでください。アラートストームの対象になる可能性があります！\nActibateをクリックして、 Detector をデプロイします。",
    "tags": [],
    "title": "4. Synthetics Detector",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/8-synthetics/4-synthetics-detector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "演習 右上隅のXをクリックして、RUM セッションリプレイを閉じます。 スパンの長さに注目してください。これは注文を完了するのにかかった時間で、良くありません！ ページを下にスクロールすると、タグメタデータ（Tag Spotlight で使用されるもの）が表示されます。タグの後に、ウォーターフォールが表示され、読み込まれたページオブジェクト（HTML、CSS、画像、JavaScript など）が表示されます。 ページを下にスクロールし続けて、青いAPMリンク（URL の末尾に/cart/checkoutがあるもの）まで移動し、その上にカーソルを置きます。 これにより APM パフォーマンスサマリーが表示されます。このエンドツーエンド（RUM から APM）のビューは、問題のトラブルシューティングを行う際に非常に便利です。\n演習 上のスクリーンショットのように、paymentserviceとcheckoutserviceがエラー状態にあることがわかります。 ワークフロー名の下にあるfront-end:/cart/checkoutをクリックすると、APM サービスマップが表示されます。",
    "description": "演習 右上隅のXをクリックして、RUM セッションリプレイを閉じます。 スパンの長さに注目してください。これは注文を完了するのにかかった時間で、良くありません！ ページを下にスクロールすると、タグメタデータ（Tag Spotlight で使用されるもの）が表示されます。タグの後に、ウォーターフォールが表示され、読み込まれたページオブジェクト（HTML、CSS、画像、JavaScript など）が表示されます。 ページを下にスクロールし続けて、青いAPMリンク（URL の末尾に/cart/checkoutがあるもの）まで移動し、その上にカーソルを置きます。 これにより APM パフォーマンスサマリーが表示されます。このエンドツーエンド（RUM から APM）のビューは、問題のトラブルシューティングを行う際に非常に便利です。\n演習 上のスクリーンショットのように、paymentserviceとcheckoutserviceがエラー状態にあることがわかります。 ワークフロー名の下にあるfront-end:/cart/checkoutをクリックすると、APM サービスマップが表示されます。",
    "tags": [],
    "title": "4. ユーザーセッション",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/5-rum/4-user-sessions/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ あなたは次の目新しいアイテムを有名なオンラインブティックショップで購入したいと思っているおしゃれな都会人です。オンラインブティックはあなたのヒップスターな要求すべてを満たすための場所だと聞いています。\nこの演習の目的は、オンラインブティックウェブアプリケーションと対話することです。これは Splunk Observability Cloud の機能を実演するために使用されるサンプルアプリケーションです。このアプリケーションは簡単な E コマースサイトで、商品の閲覧、カートへの追加、そして精算が可能です。\nこのアプリケーションはすでにデプロイされており、インストラクターがオンラインブティックウェブサイトへのリンクを提供します。例：\nhttp://\u003cs4r-workshop-i-xxx.splunk\u003e.show:81/。アプリケーションは80および443ポートでも実行されているので、そちらを使用するか、ポート81が到達不能な場合はそれらを使用することもできます。 演習 - ショッピングに行きましょう オンラインブティックへのリンクが得られたら、いくつかの商品を閲覧し、カートに追加し、最後に精算を行ってください。 この演習を数回繰り返し、可能であれば異なるブラウザ、モバイルデバイス、またはタブレットを使用してください。これによりより多くのデータが生成され、探索できるようになります。 ヒント ページの読み込みを待っている間は、ページ上でマウスカーソルを動かしてください。これにより、このワークショップの後半で探索するためのより多くのデータが生成されます。\n演習 (続き) 精算プロセスについて何か気づいたことはありますか？完了までに時間がかかったように思えましたが、最終的には完了しましたか？こうした場合は、注文確認 IDをコピーしてローカルに保存してください。後で必要になります。 ショッピングに使用したブラウザセッションを閉じてください。 これは、ユーザーエクスペリエンスが悪い場合の感覚で、これは潜在的な顧客満足度の問題であるため、すぐにトラブルシューティングを行う必要があります。\nSplunk RUMでデータがどのように見えるか確認してみましょう。",
    "description": "オンラインブティックウェブアプリケーションと対話し、Splunk Observability Cloud用のデータを生成します。",
    "tags": [],
    "title": "ショッピングに行きましょう 💶",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/4-online-boutique/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "プロセッサーは、レシーバーとエクスポーターとの間で、データに対して実行される処理です。プロセッサーはオプションですが、いくつかは推奨されています。OpenTelemetry Collector Contrib には多数のプロセッサーが含まれています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Processors fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "プロセッサーは、レシーバーとエクスポーターとの間で、データに対して実行される処理です。プロセッサーはオプションですが、いくつかは推奨されています。OpenTelemetry Collector Contrib には多数のプロセッサーが含まれています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Processors fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/4-processors/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "ログで使用できる次のチャートタイプはログビューチャートタイプです。このチャートでは、事前定義されたフィルターに基づいてログメッセージを確認できます。\n前回のログタイムラインチャートと同様に、このチャートのバージョンをカスタマーヘルスサービスダッシュボードに追加します：\n演習 前回の演習後、まだLog Observerにいることを確認してください。 フィルターは前回の演習と同じで、時間選択が過去 15 分に設定され、severity=error、sf_service=paymentservice、sf_environment=[WORKSHOPNAME]でフィルタリングされている必要があります。 必要なフィールドのみを含むヘッダーがあることを確認してください。 再度Saveをクリックし、Save to Dashvoardをクリックします。 これによりチャート作成ダイアログが再度表示されます。 Chart nameとしてログビューを使用します。 今回はSelect Dashboardをクリックし、前回の演習で作成したダッシュボードを検索します。検索ボックス（1）にあなたのイニシャルを入力することから始めることができます。 あなたのダッシュボード名をクリックして強調表示し（2）、OK（3）をクリックします。 これによりチャート作成ダイアログに戻ります。 Chart typeとしてLog viewが選択されていることを確認します。 ダッシュボードを表示するには、Save and go to dashboardをクリックします。 結果は以下のダッシュボードと同様になるはずです： この演習の最後のステップとして、あなたのダッシュボードをワークショップチームページに追加しましょう。これにより、ワークショップの後半で簡単に見つけることができます。 ページ上部で、あなたのダッシュボード名の左にある … をクリックします。 ドロップダウンからLinks to Teamを選択します。 次のLinks to Teamダイアログボックスで、インストラクターが提供したワークショップチームを見つけてDoneをクリックします。 次のセッションでは、Splunk Synthetics を見て、Web ベースのアプリケーションのテストを自動化する方法を確認します。",
    "description": "ログで使用できる次のチャートタイプはログビューチャートタイプです。このチャートでは、事前定義されたフィルターに基づいてログメッセージを確認できます。\n前回のログタイムラインチャートと同様に、このチャートのバージョンをカスタマーヘルスサービスダッシュボードに追加します：\n演習 前回の演習後、まだLog Observerにいることを確認してください。 フィルターは前回の演習と同じで、時間選択が過去 15 分に設定され、severity=error、sf_service=paymentservice、sf_environment=[WORKSHOPNAME]でフィルタリングされている必要があります。 必要なフィールドのみを含むヘッダーがあることを確認してください。 再度Saveをクリックし、Save to Dashvoardをクリックします。 これによりチャート作成ダイアログが再度表示されます。 Chart nameとしてログビューを使用します。 今回はSelect Dashboardをクリックし、前回の演習で作成したダッシュボードを検索します。検索ボックス（1）にあなたのイニシャルを入力することから始めることができます。 あなたのダッシュボード名をクリックして強調表示し（2）、OK（3）をクリックします。 これによりチャート作成ダイアログに戻ります。 Chart typeとしてLog viewが選択されていることを確認します。 ダッシュボードを表示するには、Save and go to dashboardをクリックします。 結果は以下のダッシュボードと同様になるはずです： この演習の最後のステップとして、あなたのダッシュボードをワークショップチームページに追加しましょう。これにより、ワークショップの後半で簡単に見つけることができます。 ページ上部で、あなたのダッシュボード名の左にある … をクリックします。 ドロップダウンからLinks to Teamを選択します。 次のLinks to Teamダイアログボックスで、インストラクターが提供したワークショップチームを見つけてDoneをクリックします。 次のセッションでは、Splunk Synthetics を見て、Web ベースのアプリケーションのテストを自動化する方法を確認します。",
    "tags": [],
    "title": "4. ログビューチャート",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/7-log-observer/4-log-view-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "ワークショップの第 2 部では、OpenTelemetry による手動計装が計測データ収集を強化する方法を実演することに焦点を当てます。より具体的には、今回のケースでは、producer-lambda関数からconsumer-lambda関数にトレースコンテキストデータを伝播させることができるようになります。これにより、現在は自動コンテキスト伝播をサポートしていない Kinesis ストリームを介しても、2 つの関数間の関係を見ることができるようになります。\n手動計装ワークショップディレクトリとコンテンツ 再度、作業ディレクトリとそのファイルの一部を確認することから始めます。今回は o11y-lambda-workshop/manual ディレクトリです。ここにはワークショップの手動計装部分のすべてのコンテンツがあります。\nmanual ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/manual ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/manual ls コマンドでこのディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars ワークショップの質問 このディレクトリと最初に始めた auto ディレクトリに何か違いがありますか？\nauto と manual のファイルを比較する 見た目が同じように見えるこれらのファイルが実際に同じかどうか確認しましょう。\nauto と manual ディレクトリの main.tf ファイルを比較します：\ndiff ~/o11y-lambda-workshop/auto/main.tf ~/o11y-lambda-workshop/manual/main.tf 違いはありません！(違いがあるはずはありません。もし違いがあれば、ワークショップ進行役に支援を求めてください) 次に、producer.mjs ファイルを比較してみましょう：\ndiff ~/o11y-lambda-workshop/auto/handler/producer.mjs ~/o11y-lambda-workshop/manual/handler/producer.mjs ここにはかなりの違いがあります！ ファイル全体を表示してその内容を調べたい場合は以下を実行します：\ncat ~/o11y-lambda-workshop/handler/producer.mjs 必要な手動計装タスクを処理するために、いくつかの OpenTelemetry オブジェクトを関数に直接インポートしていることに注目してください。 import { context, propagation, trace } from \"@opentelemetry/api\"; プロデューサー関数でコンテキストを伝播するために、@opentelemetry/api から次のオブジェクトをインポートしています： context propagation trace 最後に、consumer.mjs ファイルを比較します：\ndiff ~/o11y-lambda-workshop/auto/handler/consumer.mjs ~/o11y-lambda-workshop/manual/handler/consumer.mjs ここにもいくつかの注目すべき違いがあります。より詳しく見てみましょう：\ncat handler/consumer.mjs このファイルでは、次の @opentelemetry/api オブジェクトをインポートしています： propagation trace ROOT_CONTEXT これらを使用して、プロデューサー関数から伝播されたトレースコンテキストを抽出します その後、抽出したトレースコンテキストに name と superpower に基づいた新しいスパン属性を追加します プロデューサー関数からのトレースコンテキスト伝播 以下のコードはプロデューサー関数内で次のステップを実行します：\nこのトレース用のトレーサーを取得する コンテキストキャリアオブジェクトを初期化する アクティブスパンのコンテキストをキャリアオブジェクトに注入する Kinesis ストリームに配置しようとしているレコードを修正し、アクティブスパンのコンテキストをコンシューマーに運ぶキャリアを含める ... import { context, propagation, trace, } from \"@opentelemetry/api\"; ... const tracer = trace.getTracer('lambda-app'); ... return tracer.startActiveSpan('put-record', async(span) =\u003e { let carrier = {}; propagation.inject(context.active(), carrier); const eventBody = Buffer.from(event.body, 'base64').toString(); const data = \"{\\\"tracecontext\\\": \" + JSON.stringify(carrier) + \", \\\"record\\\": \" + eventBody + \"}\"; console.log( `Record with Trace Context added: ${data}` ); try { await kinesis.send( new PutRecordCommand({ StreamName: streamName, PartitionKey: \"1234\", Data: data, }), message = `Message placed in the Event Stream: ${streamName}` ) ... span.end(); コンシューマー関数でのトレースコンテキスト抽出 以下のコードはコンシューマー関数内で次のステップを実行します：\nproducer-lambdaから取得したコンテキストをキャリアオブジェクトに抽出する 現在のコンテキストからトレーサーを抽出する 抽出したコンテキスト内でトレーサーを使用して新しいスパンを開始する ボーナス：メッセージからの値を含むカスタム属性など、追加の属性をスパンに追加する！ 完了したら、スパンを終了する import { propagation, trace, ROOT_CONTEXT } from \"@opentelemetry/api\"; ... const carrier = JSON.parse( message ).tracecontext; const parentContext = propagation.extract(ROOT_CONTEXT, carrier); const tracer = trace.getTracer(process.env.OTEL_SERVICE_NAME); const span = tracer.startSpan(\"Kinesis.getRecord\", undefined, parentContext); span.setAttribute(\"span.kind\", \"server\"); const body = JSON.parse( message ).record; if (body.name) { span.setAttribute(\"custom.tag.name\", body.name); } if (body.superpower) { span.setAttribute(\"custom.tag.superpower\", body.superpower); } ... span.end(); これでどのような違いが生まれるか見てみましょう！",
    "description": "ワークショップの第 2 部では、OpenTelemetry による手動計装が計測データ収集を強化する方法を実演することに焦点を当てます。より具体的には、今回のケースでは、producer-lambda関数からconsumer-lambda関数にトレースコンテキストデータを伝播させることができるようになります。これにより、現在は自動コンテキスト伝播をサポートしていない Kinesis ストリームを介しても、2 つの関数間の関係を見ることができるようになります。\n手動計装ワークショップディレクトリとコンテンツ 再度、作業ディレクトリとそのファイルの一部を確認することから始めます。今回は o11y-lambda-workshop/manual ディレクトリです。ここにはワークショップの手動計装部分のすべてのコンテンツがあります。\nmanual ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/manual ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/manual ls コマンドでこのディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars ワークショップの質問 このディレクトリと最初に始めた auto ディレクトリに何か違いがありますか？\nauto と manual のファイルを比較する 見た目が同じように見えるこれらのファイルが実際に同じかどうか確認しましょう。",
    "tags": [],
    "title": "手動計装",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/4-manual-instrumentation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 6. Service",
    "content": "Attributes Processor また、このワークショップの Processors セクションで、Collector がすべてのメトリクスに participant.name という新しい属性を挿入するように attributes/conf processor を追加しました。ここで、metrics パイプラインでこれを有効にする必要があります。\nmetrics パイプラインの processors セクションに attributes/conf を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [debug]",
    "description": "Attributes Processor また、このワークショップの Processors セクションで、Collector がすべてのメトリクスに participant.name という新しい属性を挿入するように attributes/conf processor を追加しました。ここで、metrics パイプラインでこれを有効にする必要があります。\nmetrics パイプラインの processors セクションに attributes/conf を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [debug]",
    "tags": [],
    "title": "OpenTelemetry Collector Service",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/6-service/4-attributes/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Attributes プロセッサー また、このワークショップのプロセッサーセクションでは、attributes/conf プロセッサーを追加し、コレクターがすべてのメトリクスに participant.name という新しい属性を挿入するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、attributes/conf を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging]",
    "description": "Attributes プロセッサー また、このワークショップのプロセッサーセクションでは、attributes/conf プロセッサーを追加し、コレクターがすべてのメトリクスに participant.name という新しい属性を挿入するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、attributes/conf を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/6-service/4-attributes/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops",
    "content": "問題がユーザーに影響を与える前に、Web アプリケーションのパフォーマンスをプロアクティブにモニタリングします。Splunk Synthetic Monitoring を使用すると、技術チームとビジネスチームは詳細なテストを作成し、開発サイクルのあらゆる段階で Web サイト、Web アプリケーション、リソースの速度と信頼性を継続的にモニタリングできます。\nSplunk Synthetic Monitoring は、唯一の完全なオブザーバビリティスイートである Splunk Observability Cloud の一部として、稼働時間と Web パフォーマンス最適化のための最も包括的で詳細な機能を提供します。\nAPI、サービスエンドポイント、エンドユーザーエクスペリエンスのモニタリングを簡単にセットアップできます。Splunk Synthetic Monitoring を使用すると、基本的な稼働時間とパフォーマンスモニタリングを超えて、問題のプロアクティブな検出と修正、Web パフォーマンスの最適化、顧客への最高のユーザーエクスペリエンス提供に集中できます。\nSplunk Synthetic Monitoring では以下のことが可能です:\n重要なユーザーフロー、ビジネストランザクション、API エンドポイント全体で問題を迅速に検出・解決 インテリジェントな Web 最適化エンジンにより、Web パフォーマンスの問題が顧客に影響を与える前に防止 すべてのページリソースとサードパーティ依存関係のパフォーマンスを改善",
    "description": "ユーザーフロー、ビジネストランザクション、API 全体のパフォーマンス問題をプロアクティブに検出・修正し、より優れたデジタルエクスペリエンスを提供します。",
    "tags": [],
    "title": "Splunk Synthetic Scripting",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 1. Real Browser Test",
    "content": "Advanced をクリックします。これらの設定はオプションで、テストをさらに詳細に構成するために使用できます。\nメモ このワークショップでは、これらの設定は情報提供のみを目的としており、実際には使用しません。\nSecurity: TLS/SSL validation: 有効にすると、SSL/TLS 証明書の有効期限切れ、無効なホスト名、信頼できない発行者の検証を強制します Authentication: 企業ネットワーク内など、追加のセキュリティプロトコルを必要とするサイトで認証するための資格情報を追加します。Authentication フィールドで concealed global variables を使用することで、資格情報のセキュリティレイヤーを追加し、チェック間で資格情報を共有しやすくなります Custom Content: Custom headers: 各リクエストで送信するカスタムヘッダーを指定します。たとえば、リクエストに特定のヘッダーを送信することで、バックエンドの分析からリクエストを除外するヘッダーを追加できます。カスタムヘッダーを使用して Cookie を設定することもできます Cookies: テスト開始前にブラウザに Cookie を設定します。たとえば、ポップアップモーダルがランダムに表示されてテストに干渉するのを防ぐために Cookie を設定できます。設定された Cookie は、チェックの開始 URL のドメインに適用されます。Splunk Synthetics Monitoring は public suffix list を使用してドメインを判定します Host overrides: あるホストから別のホストにリクエストをリルーティングするホストオーバーライドルールを追加します。たとえば、既存の本番サイトを開発サイトや特定の CDN エッジノードから読み込まれたページリソースに対してテストするホストオーバーライドを作成できます 次に、テストステップを編集して、各ステップにより意味のある名前を付けます。",
    "description": "Advanced をクリックします。これらの設定はオプションで、テストをさらに詳細に構成するために使用できます。\nメモ このワークショップでは、これらの設定は情報提供のみを目的としており、実際には使用しません。\nSecurity: TLS/SSL validation: 有効にすると、SSL/TLS 証明書の有効期限切れ、無効なホスト名、信頼できない発行者の検証を強制します Authentication: 企業ネットワーク内など、追加のセキュリティプロトコルを必要とするサイトで認証するための資格情報を追加します。Authentication フィールドで concealed global variables を使用することで、資格情報のセキュリティレイヤーを追加し、チェック間で資格情報を共有しやすくなります Custom Content: Custom headers: 各リクエストで送信するカスタムヘッダーを指定します。たとえば、リクエストに特定のヘッダーを送信することで、バックエンドの分析からリクエストを除外するヘッダーを追加できます。カスタムヘッダーを使用して Cookie を設定することもできます Cookies: テスト開始前にブラウザに Cookie を設定します。たとえば、ポップアップモーダルがランダムに表示されてテストに干渉するのを防ぐために Cookie を設定できます。設定された Cookie は、チェックの開始 URL のドメインに適用されます。Splunk Synthetics Monitoring は public suffix list を使用してドメインを判定します Host overrides: あるホストから別のホストにリクエストをリルーティングするホストオーバーライドルールを追加します。たとえば、既存の本番サイトを開発サイトや特定の CDN エッジノードから読み込まれたページリソースに対してテストするホストオーバーライドを作成できます 次に、テストステップを編集して、各ステップにより意味のある名前を付けます。",
    "tags": [],
    "title": "1.5 Advanced 設定",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/5-advanced-settings/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 2. API Test",
    "content": "結果の表示 テストがプロビジョニングされて実行されるまで数分待ちます。テストが正常に実行されたら、実行をクリックしてテスト結果を表示します:\n6. リソース API テストの作成方法\nAPI Test 概要",
    "description": "結果の表示 テストがプロビジョニングされて実行されるまで数分待ちます。テストが正常に実行されたら、実行をクリックしてテスト結果を表示します:\n6. リソース API テストの作成方法\nAPI Test 概要",
    "tags": [],
    "title": "結果の表示",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/2-api-test/5-view-results/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "このセクションでは、Filter Processor を使用して、特定の条件に基づいてSpanを選択的にドロップする方法を説明します。\n具体的には、Span名に基づいてトレースをドロップします。これは、ヘルスチェックや内部通信トレースなどの不要なSpanをフィルタリングするためによく使用されます。今回は、ヘルスチェックリクエストに関連付けられることが多く、通常は非常に「ノイジー」な \"/_healthz\" を含むSpanをフィルタリングします。\nExercise 重要 すべてのターミナルウィンドウを 3-dropping-spans ディレクトリに移動し、clear コマンドを実行してください。\n2-building-resilience ディレクトリから *.yaml を 3-dropping-spans にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml 次に、filter processor と対応するパイプラインを設定します。",
    "description": "このセクションでは、Filter Processor を使用して、特定の条件に基づいてSpanを選択的にドロップする方法を説明します。\n具体的には、Span名に基づいてトレースをドロップします。これは、ヘルスチェックや内部通信トレースなどの不要なSpanをフィルタリングするためによく使用されます。今回は、ヘルスチェックリクエストに関連付けられることが多く、通常は非常に「ノイジー」な \"/_healthz\" を含むSpanをフィルタリングします。\nExercise 重要 すべてのターミナルウィンドウを 3-dropping-spans ディレクトリに移動し、clear コマンドを実行してください。\n2-building-resilience ディレクトリから *.yaml を 3-dropping-spans にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml 次に、filter processor と対応するパイプラインを設定します。",
    "tags": [],
    "title": "3. Spanのドロップ",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/3-dropping-spans/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "このセクションでは、Kubernetes 上で実行されている Java サービスに対して自動検出と設定を有効化します。これにより、OpenTelemetry Collector が Pod アノテーションを検索し、Java アプリケーションに Splunk OpenTelemetry Java エージェントで計装を行う必要があることを示します。これにより、クラスター上で実行されている Java サービスからトレース、スパン、およびプロファイリングデータを取得できるようになります。\n自動検出と設定 自動検出と設定は、コード変更や再コンパイルを必要とせずにアプリケーションからトレース、スパン、およびプロファイリングデータを取得するように設計されていることを理解することが重要です。\nこれは APM を始めるための優れた方法ですが、手動計装 の代替ではありません。手動計装では、カスタムスパン、タグ、ログをアプリケーションに追加でき、トレースにより多くのコンテキストと詳細を提供できます。\nJava アプリケーションの場合、OpenTelemetry Collector はinstrumentation.opentelemetry.io/inject-javaというアノテーションを検索します。\nこのアノテーションの値はtrueに設定するか、OpenTelemetry Collector のnamespace/daemonset（例：default/splunk-otel-collector）に設定できます。これにより、名前空間をまたいで動作することができ、このワークショップではこれを使用します。\ndeployment.yamlの使用 Pod が自動的にトレースを送信するようにしたい場合は、以下に示すようにdeployment.yamlにアノテーションを追加できます。これにより、初期デプロイメント時に計装ライブラリが追加されます。時間を節約するために、以下の Pod に対してこれを実施済みです：\nadmin-server config-server discovery-server apiVersion: apps/v1 kind: Deployment metadata: name: admin-server labels: app.kubernetes.io/part-of: spring-petclinic spec: selector: matchLabels: app: admin-server template: metadata: labels: app: admin-server annotations: instrumentation.opentelemetry.io/inject-java: \"default/splunk-otel-collector\"",
    "description": "このセクションでは、Kubernetes 上で実行されている Java サービスに対して自動検出と設定を有効化します。これにより、OpenTelemetry Collector が Pod アノテーションを検索し、Java アプリケーションに Splunk OpenTelemetry Java エージェントで計装を行う必要があることを示します。これにより、クラスター上で実行されている Java サービスからトレース、スパン、およびプロファイリングデータを取得できるようになります。\n自動検出と設定 自動検出と設定は、コード変更や再コンパイルを必要とせずにアプリケーションからトレース、スパン、およびプロファイリングデータを取得するように設計されていることを理解することが重要です。\nこれは APM を始めるための優れた方法ですが、手動計装 の代替ではありません。手動計装では、カスタムスパン、タグ、ログをアプリケーションに追加でき、トレースにより多くのコンテキストと詳細を提供できます。\nJava アプリケーションの場合、OpenTelemetry Collector はinstrumentation.opentelemetry.io/inject-javaというアノテーションを検索します。\nこのアノテーションの値はtrueに設定するか、OpenTelemetry Collector のnamespace/daemonset（例：default/splunk-otel-collector）に設定できます。これにより、名前空間をまたいで動作することができ、このワークショップではこれを使用します。\ndeployment.yamlの使用 Pod が自動的にトレースを送信するようにしたい場合は、以下に示すようにdeployment.yamlにアノテーションを追加できます。これにより、初期デプロイメント時に計装ライブラリが追加されます。時間を節約するために、以下の Pod に対してこれを実施済みです：\nadmin-server config-server discovery-server apiVersion: apps/v1 kind: Deployment metadata: name: admin-server labels: app.kubernetes.io/part-of: spring-petclinic spec: selector: matchLabels: app: admin-server template: metadata: labels: app: admin-server annotations: instrumentation.opentelemetry.io/inject-java: \"default/splunk-otel-collector\"",
    "tags": [],
    "title": "APMの自動検出と設定のセットアップ",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/4-apm/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "Splunk APM はすべてのサービスのNoSample（サンプリングなし）エンドツーエンドの可視性を提供するため、Splunk APM はすべてのトレースをキャプチャします。このワークショップでは、Order Confirmation IDがタグとして利用可能です。これは、ワークショップの前半で遭遇した不良なユーザー体験の正確なトレースを検索するためにこれを使用できることを意味します。\nトレースアナライザー Splunk Observability Cloud は、アプリケーション監視データを探索するためのいくつかのツールを提供しています。Trace Analyzerは、未知または新しい問題を調査するための高カーディナリティ、高粒度の検索と探索が必要なシナリオに適しています。\n演習 paymentserviceの外側のボックスを選択した状態で、右側のペインでTraceをクリックします。 Trace Analyzerを使用していることを確認するため、ク Switch to Classic Viewボタンが表示されていることを確認します。表示されていない場合は、Switch to Trace Analyzerをクリックします。 時間範囲を過去 15 分に設定します。 Sample Ratioが1:10ではなく1:1に設定されていることを確認します。 Trace \u0026 Error countビューは、積み上げ棒グラフで合計トレース数とエラーのあるトレース数を表示します。マウスを使用して、利用可能な時間枠内の特定の期間を選択できます。\n演習 Trace \u0026 Error countと表示されているドロップダウンメニューをクリックし、Trace Durationに変更します Trace Durationビューは、期間ごとのトレースのヒートマップを表示します。ヒートマップは 3 次元のデータを表しています：\nx 軸の時間 y 軸のトレース期間 ヒートマップの色合いで表される 1 秒あたりのトレース（またはリクエスト）数 マウスを使ってヒートマップ上の領域を選択し、特定の時間帯とトレース期間の範囲にフォーカスすることができます。\n演習 Trace DurationからTrace \u0026 Error countに戻します。 時間選択で過去 1 時間を選択します。 ほとんどのトレースにエラー（赤）があり、エラーのないトレース（青）は限られていることに注意してください。 Sample Ratioが1:10ではなく1:1に設定されていることを確認します。 Add filtersをクリックし、orderIdと入力してリストからorderIdを選択します。 ワークショップの前半でショッピングを行った際のOrder Confirmation IDを貼り付けて Enter キーを押します。もし ID を記録していない場合は、インストラクターに確認してください。 これで、非常に長いチェックアウト待ちという不良なユーザーエクスペリエンスに遭遇した正確なトレースまでフィルタリングできました。\nこのトレースを表示することの二次的な利点は、トレースが最大 13 か月間アクセス可能であることです。これにより、開発者は後の段階でこの問題に戻り、このトレースを引き続き表示することができます。\n演習 リスト内のトレースをクリックします。 次に、トレースウォーターフォールを確認していきます。",
    "description": "Splunk APM はすべてのサービスのNoSample（サンプリングなし）エンドツーエンドの可視性を提供するため、Splunk APM はすべてのトレースをキャプチャします。このワークショップでは、Order Confirmation IDがタグとして利用可能です。これは、ワークショップの前半で遭遇した不良なユーザー体験の正確なトレースを検索するためにこれを使用できることを意味します。\nトレースアナライザー Splunk Observability Cloud は、アプリケーション監視データを探索するためのいくつかのツールを提供しています。Trace Analyzerは、未知または新しい問題を調査するための高カーディナリティ、高粒度の検索と探索が必要なシナリオに適しています。\n演習 paymentserviceの外側のボックスを選択した状態で、右側のペインでTraceをクリックします。 Trace Analyzerを使用していることを確認するため、ク Switch to Classic Viewボタンが表示されていることを確認します。表示されていない場合は、Switch to Trace Analyzerをクリックします。 時間範囲を過去 15 分に設定します。 Sample Ratioが1:10ではなく1:1に設定されていることを確認します。 Trace \u0026 Error countビューは、積み上げ棒グラフで合計トレース数とエラーのあるトレース数を表示します。マウスを使用して、利用可能な時間枠内の特定の期間を選択できます。\n演習 Trace \u0026 Error countと表示されているドロップダウンメニューをクリックし、Trace Durationに変更します",
    "tags": [],
    "title": "5. APMトレースアナライザー",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/6-apm/5-apm-trace-analyzer/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "Exporter はプッシュ型またはプル型で、1つ以上のバックエンド/宛先にデータを送信する方法です。Exporter は1つ以上のデータソースをサポートする場合があります。\nこのワークショップでは、otlphttp exporter を使用します。OpenTelemetry Protocol (OTLP) は、テレメトリデータを送信するためのベンダー中立で標準化されたプロトコルです。OTLP exporter は、OTLP プロトコルを実装しているサーバーにデータを送信します。OTLP exporter は gRPC と HTTP/JSON の両方のプロトコルをサポートしています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Exporters fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "Exporter はプッシュ型またはプル型で、1つ以上のバックエンド/宛先にデータを送信する方法です。Exporter は1つ以上のデータソースをサポートする場合があります。\nこのワークショップでは、otlphttp exporter を使用します。OpenTelemetry Protocol (OTLP) は、テレメトリデータを送信するためのベンダー中立で標準化されたプロトコルです。OTLP exporter は、OTLP プロトコルを実装しているサーバーにデータを送信します。OTLP exporter は gRPC と HTTP/JSON の両方のプロトコルをサポートしています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Exporters fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Collector A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector Exporters",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/5-exporters/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "トレースデータを収集したい関数やサービスに手動計装を適用する方法がわかったので、Lambda 関数を再度デプロイして、producer-lambdaエンドポイントに対するトラフィックを生成していきましょう。\nmanual ディレクトリで Terraform を初期化する 新しいディレクトリにいるので、ここでもう一度 Terraform を初期化する必要があります。\nmanual ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manual ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual 次のコマンドを実行して、このディレクトリで Terraform を初期化します：\nterraform init Lambda 関数とその他の AWS リソースをデプロイする それでは、これらのリソースを再度デプロイしましょう！\n問題がないことを確認するために、terraform plan コマンドを実行します。\nterraform plan 続いて、terraform apply コマンドを使用して main.tf ファイルから Lambda 関数とその他のサポートリソースをデプロイします：\nterraform apply Enter a value: プロンプトが表示されたら yes と応答します\nこれにより、以下のような出力が得られます：\nOutputs: base_url = \"https://______.amazonaws.com/serverless_stage/producer\" consumer_function_name = \"_____-consumer\" consumer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-consumer\" consumer_log_group_name = \"/aws/lambda/______-consumer\" environment = \"______-lambda-shop\" lambda_bucket_name = \"lambda-shop-______-______\" producer_function_name = \"______-producer\" producer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-producer\" producer_log_group_name = \"/aws/lambda/______-producer\" 見ての通り、base_url の最初の部分とログループ ARN 以外は、このワークショップの自動計装部分をこの同じ時点まで実行したときと出力は概ね同じはずです。\nproducer-lambda エンドポイント (base_url) にトラフィックを送信する もう一度、name と superpower をメッセージとしてエンドポイントに送信します。これはトレースコンテキストとともに、Kinesis ストリーム内のレコードに追加されます。\nmanual ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manual ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual send_message.py スクリプトをバックグラウンドプロセスとして実行します：\nnohup ./send_message.py --name CHANGEME --superpower CHANGEME \u0026 次に、response.logs ファイルの内容を確認して、producer-lambdaエンドポイントへの呼び出しが成功しているか確認します：\ncat response.logs メッセージが成功していれば、画面に表示される行の中に次の出力が表示されるはずです：\n{\"message\": \"Message placed in the Event Stream: hostname-eventStream\"} 失敗した場合は、次のように表示されます：\n{\"message\": \"Internal server error\"} 重要 これが発生した場合は、ワークショップ進行役の一人に支援を求めてください。\nLambda 関数のログの確認 ログがどのようになっているか見てみましょう。\nproducer.logs ファイルを確認します：\ncat producer.logs そして consumer.logs ファイルを確認します：\ncat consumer.logs ログを注意深く調べてください。\nワークショップの質問 違いに気づきましたか？\nconsumer-lambda ログからのトレース ID のコピー 今回は、consumer-lambda のロググループが、我々が伝播したtracecontextとともに、メッセージをrecordとしてログに記録しているのが確認できます。\nトレース ID をコピーするには：\nKinesis Messageログの 1 つを見てみましょう。その中にはdataディクショナリがあります ネストされたtracecontextディクショナリを見るために、dataをより詳しく見てください tracecontextディクショナリ内には、traceparentというキーと値のペアがあります traceparentキーと値のペアには、私たちが探しているトレース ID が含まれています -で区切られた 4 つの値のグループがあります。トレース ID は 2 番目の文字グループです トレース ID をコピーして保存してください。 このワークショップの後のステップで必要になります",
    "description": "トレースデータを収集したい関数やサービスに手動計装を適用する方法がわかったので、Lambda 関数を再度デプロイして、producer-lambdaエンドポイントに対するトラフィックを生成していきましょう。\nmanual ディレクトリで Terraform を初期化する 新しいディレクトリにいるので、ここでもう一度 Terraform を初期化する必要があります。\nmanual ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manual ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual 次のコマンドを実行して、このディレクトリで Terraform を初期化します：\nterraform init Lambda 関数とその他の AWS リソースをデプロイする それでは、これらのリソースを再度デプロイしましょう！\n問題がないことを確認するために、terraform plan コマンドを実行します。\nterraform plan 続いて、terraform apply コマンドを使用して main.tf ファイルから Lambda 関数とその他のサポートリソースをデプロイします：",
    "tags": [],
    "title": "Lambda関数のデプロイとトレースデータの生成",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/5-redeploy-lambdas/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "このセクションでは、Spring PetClinicアプリケーションをファイルシステムのファイルにログを書き込むように設定し、 Splunk OpenTelemetry Collectorがそのログファイルを読み取り（tail）、Splunk Observability Platformに情報を報告するように設定していきます。\n1. FluentDの設定 Splunk OpenTelemetry Collectorを、Spring PetClinicのログファイルをtailし Splunk Observability Cloudエンドポイントにデータを報告するように設定する必要があります。\nSplunk OpenTelemetry Collectorは、FluentDを使用してログの取得/報告を行い、 Spring PetClinicのログを報告するための適切な設定を行うには、 デフォルトディレクトリ（/etc/otel/collector/fluentd/conf.d/）にFluentDの設定ファイルを追加するだけです。\n以下は、サンプルのFluentD設定ファイル petclinic.conf を新たに作成し、\nsudo nano /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイル /tmp/spring-petclinic.logを読み取るよう設定を記述します。\n\u003csource\u003e @type tail @label @SPLUNK tag petclinic.app path /tmp/spring-petclinic.log pos_file /tmp/spring-petclinic.pos_file read_from_head false \u003cparse\u003e @type none \u003c/parse\u003e \u003c/source\u003e このとき、ファイル petclinic.conf のアクセス権と所有権を変更する必要があります。\nsudo chown td-agent:td-agent /etc/otel/collector/fluentd/conf.d/petclinic.conf sudo chmod 755 /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイルが作成されたら、FluentDプロセスを再起動しましょう。\nsudo systemctl restart td-agent 3. Logbackの設定 Spring Pet Clinicアプリケーションは、いくつかのJavaログライブラリを使用することができます。 このシナリオでは、logbackを使ってみましょう。\nリソースフォルダに logback.xml という名前のファイルを作成して…\nnano src/main/resources/logback.xml 以下の設定を保存しましょう:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE xml\u003e \u003cconfiguration scan=\"true\" scanPeriod=\"30 seconds\"\u003e \u003ccontextListener class=\"ch.qos.logback.classic.jul.LevelChangePropagator\"\u003e \u003cresetJUL\u003etrue\u003c/resetJUL\u003e \u003c/contextListener\u003e \u003clogger name=\"org.springframework.samples.petclinic\" level=\"debug\"/\u003e \u003cappender name=\"file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003cfile\u003e/tmp/spring-petclinic.log\u003c/file\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003cfileNamePattern\u003espringLogFile.%d{yyyy-MM-dd}.log\u003c/fileNamePattern\u003e \u003cmaxHistory\u003e5\u003c/maxHistory\u003e \u003ctotalSizeCap\u003e1GB\u003c/totalSizeCap\u003e \u003c/rollingPolicy\u003e \u003cencoder\u003e \u003cpattern\u003e %d{yyyy-MM-dd HH:mm:ss} - %logger{36} - %msg trace_id=%X{trace_id} span_id=%X{span_id} trace_flags=%X{trace_flags} service.name=%property{otel.resource.service.name}, deployment.environment=%property{otel.resource.deployment.environment} %n \u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003croot level=\"debug\"\u003e \u003cappender-ref ref=\"file\" /\u003e \u003c/root\u003e \u003c/configuration\u003e その後、アプリケーションを再構築して再度実行していきます。\n./mvnw package -Dmaven.test.skip=true java -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.317 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql これまで通り、アプリケーション http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスしてトラフィックを生成すると、ログメッセージが報告されるようになります。\n左側のLog Observerアイコンをクリックして、ホストとSpring PetClinicアプリケーションからのログメッセージのみを選択するためのフィルタを追加できます。\nAdd Filter → Field → host.name → \u003cあなたのホスト名\u003e Add Filter → Field → service.name → \u003cあなたのホスト名\u003e.service 4. まとめ これでワークショップは終了です。 これまでに、Splunk Observability Cloudにメトリクス、トレース、ログ、データベースクエリのパフォーマンス、コードプロファイリングが報告されるようになりました。 おめでとうございます！",
    "description": "このセクションでは、Spring PetClinicアプリケーションをファイルシステムのファイルにログを書き込むように設定し、 Splunk OpenTelemetry Collectorがそのログファイルを読み取り（tail）、Splunk Observability Platformに情報を報告するように設定していきます。\n1. FluentDの設定 Splunk OpenTelemetry Collectorを、Spring PetClinicのログファイルをtailし Splunk Observability Cloudエンドポイントにデータを報告するように設定する必要があります。\nSplunk OpenTelemetry Collectorは、FluentDを使用してログの取得/報告を行い、 Spring PetClinicのログを報告するための適切な設定を行うには、 デフォルトディレクトリ（/etc/otel/collector/fluentd/conf.d/）にFluentDの設定ファイルを追加するだけです。\n以下は、サンプルのFluentD設定ファイル petclinic.conf を新たに作成し、\nsudo nano /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイル /tmp/spring-petclinic.logを読み取るよう設定を記述します。\n\u003csource\u003e @type tail @label @SPLUNK tag petclinic.app path /tmp/spring-petclinic.log pos_file /tmp/spring-petclinic.pos_file read_from_head false \u003cparse\u003e @type none \u003c/parse\u003e \u003c/source\u003e このとき、ファイル petclinic.conf のアクセス権と所有権を変更する必要があります。\nsudo chown td-agent:td-agent /etc/otel/collector/fluentd/conf.d/petclinic.conf sudo chmod 755 /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイルが作成されたら、FluentDプロセスを再起動しましょう。",
    "tags": [],
    "title": "Log Observer",
    "uri": "/observability-workshop/ja/other/pet-clinic/docs/logobserver/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ あなたはフロントエンドエンジニアまたはSREで、パフォーマンス問題の最初のトリアージを行うよう任されています。オンラインブティックアプリケーションに関する潜在的な顧客満足度の問題を調査するよう依頼されました。\nすべての参加者のブラウザセッションから受信したテレメトリによって提供された実際のユーザーデータを調査します。目標は、パフォーマンスの悪かったブラウザ、モバイル、またはタブレットセッションを見つけて、トラブルシューティングプロセスを開始することです。",
    "description": "このセクションでは、エンドユーザーの視点からアプリケーションのパフォーマンスを監視するためにSplunk RUMを使用する方法を理解するのに役立ちます。",
    "tags": [],
    "title": "Splunk RUM",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/5-rum/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk Synthetic Monitoring は、URL、API、重要な Web サービス全体に可視性を提供し、問題をより迅速に解決します。IT オペレーションとエンジニアリングチームは、問題の検出、アラート、優先順位付けを簡単に行い、複数ステップのユーザージャーニーをシミュレートし、新しいコードデプロイメントからのビジネスへの影響を測定し、ステップバイステップのガイド付き推奨事項を使用して Web パフォーマンスを最適化し、より良いデジタルエクスペリエンスを確保できます。\n可用性の確保： ユーザーエクスペリエンスを構成する複数ステップのワークフローをシミュレートするカスタマイズ可能なブラウザテストで、重要なサービス、URL、API の健全性と可用性を事前に監視し、アラートを出します。\nメトリクスの改善： コアウェブバイタルとモダンパフォーマンスメトリクスにより、ユーザーはすべてのパフォーマンス欠陥を 1 か所で表示し、ページ読み込み、インタラクティビティ、視覚的安定性を測定して改善し、JavaScript エラーを見つけて修正してページパフォーマンスを向上させることができます。\nフロントエンドからバックエンドまで： Splunk APM、Infrastructure Monitoring、On-Call、ITSI との統合により、チームはエンドポイントの稼働時間をバックエンドサービス、基盤となるインフラストラクチャ、およびインシデント対応の調整との関連で表示し、単一の UI 内で環境全体をトラブルシューティングできます。\n検出とアラート： エンドユーザー体験を監視してシミュレートし、顧客に影響を与える前に API、サービスエンドポイント、重要なビジネストランザクションの問題を検出、通信、解決します。\nビジネスパフォーマンス： 主要なビジネストランザクションの複数ステップのユーザーフローを簡単に定義し、数分で重要なユーザージャーニーの記録とテストを開始します。稼働時間とパフォーマンスの SLA と SLO を追跡・報告します。\nフィルムストリップとビデオ再生： 画面録画、フィルムストリップ、スクリーンショットを、最新のパフォーマンススコア、競合ベンチマーキング、メトリクスとともに表示して、人工的なエンドユーザー体験を視覚化します。ビジュアルコンテンツを配信する速度を最適化し、ページの安定性とインタラクティビティを向上させて、より良いデジタルエクスペリエンスをデプロイします。",
    "description": "Splunk Synthetic Monitoring は、URL、API、重要な Web サービス全体に可視性を提供し、問題をより迅速に解決します。IT オペレーションとエンジニアリングチームは、問題の検出、アラート、優先順位付けを簡単に行い、複数ステップのユーザージャーニーをシミュレートし、新しいコードデプロイメントからのビジネスへの影響を測定し、ステップバイステップのガイド付き推奨事項を使用して Web パフォーマンスを最適化し、より良いデジタルエクスペリエンスを確保できます。\n可用性の確保： ユーザーエクスペリエンスを構成する複数ステップのワークフローをシミュレートするカスタマイズ可能なブラウザテストで、重要なサービス、URL、API の健全性と可用性を事前に監視し、アラートを出します。\nメトリクスの改善： コアウェブバイタルとモダンパフォーマンスメトリクスにより、ユーザーはすべてのパフォーマンス欠陥を 1 か所で表示し、ページ読み込み、インタラクティビティ、視覚的安定性を測定して改善し、JavaScript エラーを見つけて修正してページパフォーマンスを向上させることができます。\nフロントエンドからバックエンドまで： Splunk APM、Infrastructure Monitoring、On-Call、ITSI との統合により、チームはエンドポイントの稼働時間をバックエンドサービス、基盤となるインフラストラクチャ、およびインシデント対応の調整との関連で表示し、単一の UI 内で環境全体をトラブルシューティングできます。\n検出とアラート： エンドユーザー体験を監視してシミュレートし、顧客に影響を与える前に API、サービスエンドポイント、重要なビジネストランザクションの問題を検出、通信、解決します。\nビジネスパフォーマンス： 主要なビジネストランザクションの複数ステップのユーザーフローを簡単に定義し、数分で重要なユーザージャーニーの記録とテストを開始します。稼働時間とパフォーマンスの SLA と SLO を追跡・報告します。\nフィルムストリップとビデオ再生： 画面録画、フィルムストリップ、スクリーンショットを、最新のパフォーマンススコア、競合ベンチマーキング、メトリクスとともに表示して、人工的なエンドユーザー体験を視覚化します。ビジュアルコンテンツを配信する速度を最適化し、ページの安定性とインタラクティビティを向上させて、より良いデジタルエクスペリエンスをデプロイします。",
    "tags": [],
    "title": "Synthetics概要",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/5-synthetics-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "このワークショップの後半では、.NET アプリケーションを Kubernetes クラスターにデプロイします。\nしかし、どのようにそれを行うのでしょうか？\n最初のステップは、アプリケーション用の Docker イメージを作成することです。これは アプリケーションの「Docker 化」として知られており、プロセスはDockerfileの作成から始まります。\nしかし、まず重要な用語を定義しましょう。\n重要な用語 Docker とは何ですか？ 「Docker は、コンテナと呼ばれる緩い分離環境でアプリケーションをパッケージ化して実行する機能を提供します。分離とセキュリティにより、指定されたホスト上で同時に多くのコンテナを実行できます。コンテナは軽量で、アプリケーションの実行に必要なすべてを含んでいるため、ホストにインストールされているものに依存する必要がありません。」\nソース: https://docs.docker.com/get-started/docker-overview/\nコンテナとは何ですか？ 「コンテナは、アプリのコンポーネントごとの分離されたプロセスです。各コンポーネントは…独自の分離された環境で実行され、マシン上の他のすべてのものから完全に分離されています。」\nソース: https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-a-container/\nコンテナイメージとは何ですか？ 「コンテナイメージは、コンテナを実行するためのすべてのファイル、バイナリ、ライブラリ、および設定を含む標準化されたパッケージです。」\nDockerfile 「Dockerfile は、コンテナイメージを作成するために使用されるテキストベースのドキュメントです。実行するコマンド、コピーするファイル、起動コマンドなどに関するイメージビルダーへの指示を提供します。」\nDockerfile の作成 /home/splunk/workshop/docker-k8s-otel/helloworldディレクトリにDockerfileという名前のファイルを作成しましょう。\ncd /home/splunk/workshop/docker-k8s-otel/helloworld ファイルの作成には vi または nano を使用できます。vi を使用した例を示します：\nvi Dockerfile 新しく開いたファイルに以下の内容をコピー＆ペーストします：\n以下のテキストを貼り付ける前に、vi で「i」を押して挿入モードに入ってください。\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base USER app WORKDIR /app EXPOSE 8080 FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build FROM build AS publish ARG BUILD_CONFIGURATION=Release RUN dotnet publish \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false FROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\"dotnet\", \"helloworld.dll\"] vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\nこれはすべて何を意味するのでしょうか？詳しく見てみましょう。\nDockerfile の詳細解説 この例では、マルチステージ Dockerfile を使用しており、Docker イメージ作成プロセスを以下のステージに分けています：\nBase（ベース） Build（ビルド） Publish（パブリッシュ） Final（最終） マルチステージアプローチはより複雑ですが、デプロイメント用により 軽量なランタイムイメージを作成することができます。以下では、 これらの各ステージの目的を説明します。\nベースステージ ベースステージでは、アプリを実行するユーザー、作業ディレクトリを定義し、 アプリにアクセスするために使用されるポートを公開します。 これは Microsoft のmcr.microsoft.com/dotnet/aspnet:8.0イメージをベースにしています：\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base USER app WORKDIR /app EXPOSE 8080 なお、mcr.microsoft.com/dotnet/aspnet:8.0イメージには.NET runtime のみが含まれており、 SDK は含まれていないため、比較的軽量です。これは Debian 12 Linux distribution がベースになっています。ASP.NET Core Runtime Docker イメージの詳細については GitHubで確認できます。\nBuild ステージ Dockerfile の次のステージは build ステージです。このステージでは、 mcr.microsoft.com/dotnet/sdk:8.0イメージが使用されます。これも Debian 12 がベースになっていますが、 runtime だけでなく完全な.NET SDKが含まれています。\nこのステージでは.csprojファイルを build イメージにコピーし、その後dotnet restoreを使用して アプリケーションが使用する依存関係をダウンロードします。\n次に、アプリケーションコードを build イメージにコピーし、 dotnet buildを使用してプロジェクトとその依存関係を .dllバイナリのセットにビルドします：\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build Publish ステージ 3 番目のステージは publish で、これは Microsoft イメージではなく build ステージイメージをベースにしています。このステージでは、dotnet publishを使用して アプリケーションとその依存関係を deployment 用にパッケージ化します：\nFROM build AS publish ARG BUILD_CONFIGURATION=Release RUN dotnet publish \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false Final ステージ 4 番目のステージは最終ステージで、これは base ステージイメージをベースにしています（build と publish ステージよりも軽量）。publish ステージイメージからの出力をコピーし、 アプリケーションの entry point を定義します：\nFROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\"dotnet\", \"helloworld.dll\"] Docker イメージのビルド Dockerfileができたので、これを使用してアプリケーションを含む Docker イメージを ビルドできます：\n​ Script Example Output docker build -t helloworld:1.0 . DEPRECATED: The legacy builder is deprecated and will be removed in a future release. Install the buildx component to build images with BuildKit: https://docs.docker.com/go/buildx/ Sending build context to Docker daemon 281.1kB Step 1/19 : FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base 8.0: Pulling from dotnet/aspnet af302e5c37e9: Pull complete 91ab5e0aabf0: Pull complete 1c1e4530721e: Pull complete 1f39ca6dcc3a: Pull complete ea20083aa801: Pull complete 64c242a4f561: Pull complete Digest: sha256:587c1dd115e4d6707ff656d30ace5da9f49cec48e627a40bbe5d5b249adc3549 Status: Downloaded newer image for mcr.microsoft.com/dotnet/aspnet:8.0 ---\u003e 0ee5d7ddbc3b Step 2/19 : USER app etc, これは、現在のディレクトリのDockerfileを使用してhelloworld:1.0のタグでイメージをビルドするよう Docker に指示します。\n以下のコマンドで正常に作成されたことを確認できます：\n​ Script Example Output docker images REPOSITORY TAG IMAGE ID CREATED SIZE helloworld 1.0 db19077b9445 20 seconds ago 217MB Docker イメージのテスト 続行する前に、以前に開始したアプリケーションがインスタンス上で実行されていないことを確認してください。\nDocker イメージを使用して以下のようにアプリケーションを実行できます：\ndocker run --name helloworld \\ --detach \\ --expose 8080 \\ --network=host \\ helloworld:1.0 注意：--network=hostパラメータを含めて、Docker コンテナが インスタンス上のリソースにアクセスできるようにしています。これは後でアプリケーションが localhost 上で実行されているコレクターにデータを送信する必要がある場合に重要です。\nDocker コンテナが実行されていることを確認しましょう：\n​ Script Example Output docker ps $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5f5b9cd56ac5 helloworld:1.0 \"dotnet helloworld.d…\" 2 mins ago Up 2 mins helloworld 以前と同様にアプリケーションにアクセスできます：\n​ Script Example Output curl http://localhost:8080/hello/Docker Hello, Docker! おめでとうございます。ここまで到達したということは、.NET アプリケーションの Docker 化に成功したということです。",
    "description": "このワークショップの後半では、.NET アプリケーションを Kubernetes クラスターにデプロイします。\nしかし、どのようにそれを行うのでしょうか？\n最初のステップは、アプリケーション用の Docker イメージを作成することです。これは アプリケーションの「Docker 化」として知られており、プロセスはDockerfileの作成から始まります。\nしかし、まず重要な用語を定義しましょう。\n重要な用語 Docker とは何ですか？ 「Docker は、コンテナと呼ばれる緩い分離環境でアプリケーションをパッケージ化して実行する機能を提供します。分離とセキュリティにより、指定されたホスト上で同時に多くのコンテナを実行できます。コンテナは軽量で、アプリケーションの実行に必要なすべてを含んでいるため、ホストにインストールされているものに依存する必要がありません。」\nソース: https://docs.docker.com/get-started/docker-overview/\nコンテナとは何ですか？ 「コンテナは、アプリのコンポーネントごとの分離されたプロセスです。各コンポーネントは…独自の分離された環境で実行され、マシン上の他のすべてのものから完全に分離されています。」\nソース: https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-a-container/\nコンテナイメージとは何ですか？ 「コンテナイメージは、コンテナを実行するためのすべてのファイル、バイナリ、ライブラリ、および設定を含む標準化されたパッケージです。」\nDockerfile 「Dockerfile は、コンテナイメージを作成するために使用されるテキストベースのドキュメントです。実行するコマンド、コピーするファイル、起動コマンドなどに関するイメージビルダーへの指示を提供します。」",
    "tags": [],
    "title": "アプリケーションのDocker化",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/5-dockerize-app/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "エクスポーターは、プッシュまたはプルベースであり、一つ以上のバックエンド/デスティネーションにデータを送信する方法です。エクスポーターは、一つまたは複数のデータソースをサポートすることがあります。\nこのワークショップでは、otlphttp エクスポーターを使用します。OpenTelemetry Protocol (OTLP) は、テレメトリーデータを伝送するためのベンダーニュートラルで標準化されたプロトコルです。OTLP エクスポーターは、OTLP プロトコルを実装するサーバーにデータを送信します。OTLP エクスポーターは、gRPC および HTTP/JSON プロトコルの両方をサポートします。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Exporters fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "エクスポーターは、プッシュまたはプルベースであり、一つ以上のバックエンド/デスティネーションにデータを送信する方法です。エクスポーターは、一つまたは複数のデータソースをサポートすることがあります。\nこのワークショップでは、otlphttp エクスポーターを使用します。OpenTelemetry Protocol (OTLP) は、テレメトリーデータを伝送するためのベンダーニュートラルで標準化されたプロトコルです。OTLP エクスポーターは、OTLP プロトコルを実装するサーバーにデータを送信します。OTLP エクスポーターは、gRPC および HTTP/JSON プロトコルの両方をサポートします。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Exporters fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector エクスポーター",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/5-exporters/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 6. Service",
    "content": "OTLP HTTP Exporter ワークショップの Exporters セクションで、メトリクスを Splunk Observability Cloud に送信するための otlphttp exporter を設定しました。ここで、metrics パイプラインでこれを有効にする必要があります。\nmetrics パイプラインの exporters セクションに otlphttp/splunk を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [debug, otlphttp/splunk] Ninja: Collector の内部を観察する Collector は、実行中のコンポーネントからの追加シグナルを含む、自身の動作に関する内部シグナルをキャプチャします。 これは、データフローに関する判断を行うコンポーネントが、その情報をメトリクスまたはトレースとして公開する方法を必要とするためです。\nなぜ Collector を監視するのか？ これは「監視者を誰が監視するのか？」という、鶏と卵のような問題ですが、この情報を公開できることは重要です。Collector の歴史において興味深い点は、Go メトリクス SDK が安定版と見なされる前から存在していたため、当面の間、Collector はこの機能を提供するために Prometheus エンドポイントを公開しているということです。\n考慮事項 組織内で実行中の各 Collector の内部使用状況を監視すると、大量の新しい Metric Time Series (MTS) が発生する可能性があります。Splunk ディストリビューションでは、これらのメトリクスが厳選されており、予想される増加を予測するのに役立ちます。\nNinja Zone Collector の内部オブザーバビリティを公開するために、いくつかの追加設定を調整できます\n​ telemetry schema example-config.yml service: telemetry: logs: level: \u003cinfo|warn|error\u003e development: \u003ctrue|false\u003e encoding: \u003cconsole|json\u003e disable_caller: \u003ctrue|false\u003e disable_stacktrace: \u003ctrue|false\u003e output_paths: [\u003cstdout|stderr\u003e, paths...] error_output_paths: [\u003cstdout|stderr\u003e, paths...] initial_fields: key: value metrics: level: \u003cnone|basic|normal|detailed\u003e # Address binds the promethues endpoint to scrape address: \u003chostname:port\u003e service: telemetry: logs: level: info encoding: json disable_stacktrace: true initial_fields: instance.name: ${env:INSTANCE} metrics: address: localhost:8888 参考資料 https://opentelemetry.io/docs/collector/configuration/#service 最終設定 Check-in最終設定を確認する ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 # To limit exposure to denial of service attacks, change the host in endpoints below from 0.0.0.0 to a specific network interface. # See https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md#safeguards-against-denial-of-service-attacks extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 opencensus: endpoint: 0.0.0.0:55678 # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: endpoint: 0.0.0.0:14250 thrift_binary: endpoint: 0.0.0.0:6832 thrift_compact: endpoint: 0.0.0.0:6831 thrift_http: endpoint: 0.0.0.0:14268 zipkin: endpoint: 0.0.0.0:9411 processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: debug: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-Token: ${env:ACCESS_TOKEN} service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [debug, otlphttp/splunk] logs: receivers: [otlp] processors: [batch] exporters: [debug] extensions: [health_check, pprof, zpages] ヒント Collector を再起動する前に、設定ファイルを検証することをお勧めします。config.yaml ファイルの内容を otelbin.io に貼り付けることで検証できます。\nScreenshotOTelBin これで動作する設定ができたので、Collector を起動して zPages が何を報告しているか確認しましょう。\n​ Command otelcol-contrib --config=file:/etc/otelcol-contrib/config.yaml ブラウザで zPages を開きます：http://localhost:55679/debug/pipelinez（localhost を自分の環境に合わせて変更してください）。",
    "description": "OTLP HTTP Exporter ワークショップの Exporters セクションで、メトリクスを Splunk Observability Cloud に送信するための otlphttp exporter を設定しました。ここで、metrics パイプラインでこれを有効にする必要があります。\nmetrics パイプラインの exporters セクションに otlphttp/splunk を含めるように更新します\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [debug] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [debug, otlphttp/splunk] Ninja: Collector の内部を観察する Collector は、実行中のコンポーネントからの追加シグナルを含む、自身の動作に関する内部シグナルをキャプチャします。 これは、データフローに関する判断を行うコンポーネントが、その情報をメトリクスまたはトレースとして公開する方法を必要とするためです。",
    "tags": [],
    "title": "OpenTelemetry Collector Service",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/6-service/5-otlphttp/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "OTLP HTTP エクスポーター ワークショップのエクスポーターセクションでは、otlphttp エクスポーターを設定して、メトリクスを Splunk Observability Cloud に送信するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の exporters セクションを更新して、otlphttp/splunk を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging, otlphttp/splunk] Ninja: コレクターの内部を観測する コレクターは、その動作に関する内部シグナルを捕捉しています。これには実行中のコンポーネントからの追加されるシグナルも含まれます。これは、データの流れに関する決定を行うコンポーネントが、その情報をメトリクスやトレースとして表面化する方法を必要とするためです。\nなぜコレクターを監視するの？ これは「監視者を監視するのは誰か？」という種類の問題ですが、このような情報を表面化できることは重要です。コレクターの歴史の興味深い部分は、GoメトリクスのSDKが安定と考えられる前に存在していたことで、コレクターは当面の間、この機能を提供するために Prometheus エンドポイントを公開しています。\n注意点 組織内で稼働している各コレクターの内部使用状況を監視することは、新しいメトリクス量（MTS）を大幅な増加させる可能性があります。Splunkディストリビューションはこれらのメトリクスをキュレーションしており、増加を予測するのに役立ちます。\nNinja ゾーン コレクターの内部オブザーバビリティを公開するためには、いくつかの設定を追加することがあります：\n​ telemetry schema example-config.yml service: telemetry: logs: level: \u003cinfo|warn|error\u003e development: \u003ctrue|false\u003e encoding: \u003cconsole|json\u003e disable_caller: \u003ctrue|false\u003e disable_stacktrace: \u003ctrue|false\u003e output_paths: [\u003cstdout|stderr\u003e, paths...] error_output_paths: [\u003cstdout|stderr\u003e, paths...] initial_fields: key: value metrics: level: \u003cnone|basic|normal|detailed\u003e # Address binds the promethues endpoint to scrape address: \u003chostname:port\u003e service: telemetry: logs: level: info encoding: json disable_stacktrace: true initial_fields: instance.name: ${env:INSTANCE} metrics: address: localhost:8888 参照 https://opentelemetry.io/docs/collector/configuration/#service 完成した設定 Check-in完成した設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-TOKEN: ${env:ACCESS_TOKEN} service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging, otlphttp/splunk] extensions: [health_check, pprof, zpages] ヒント コレクターを再起動する前に、設定ファイルを検証することをお勧めします。これは、組み込みの validate コマンドを使用して行うことができます：\n​ Command Example error output otelcol-contrib validate --config=file:/etc/otelcol-contrib/config.yaml Error: failed to get config: cannot unmarshal the configuration: 1 error(s) decoding: * error decoding 'processors': error reading configuration for \"attributes/conf\": 1 error(s) decoding: * 'actions[0]' has invalid keys: actions 2023/06/29 09:41:28 collector server run finished with error: failed to get config: cannot unmarshal the configuration: 1 error(s) decoding: * error decoding 'processors': error reading configuration for \"attributes/conf\": 1 error(s) decoding: * 'actions[0]' has invalid keys: actions 動作する設定ができたので、コレクターを起動し、その後 zPages が報告している内容を確認しましょう。\n​ Command sudo systemctl restart otelcol-contrib",
    "description": "OTLP HTTP エクスポーター ワークショップのエクスポーターセクションでは、otlphttp エクスポーターを設定して、メトリクスを Splunk Observability Cloud に送信するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の exporters セクションを更新して、otlphttp/splunk を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging, otlphttp/splunk] Ninja: コレクターの内部を観測する コレクターは、その動作に関する内部シグナルを捕捉しています。これには実行中のコンポーネントからの追加されるシグナルも含まれます。これは、データの流れに関する決定を行うコンポーネントが、その情報をメトリクスやトレースとして表面化する方法を必要とするためです。",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/6-service/5-otlphttp/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 1. Real Browser Test",
    "content": "ステップを編集するには、+ Edit steps or synthetic transactions ボタンをクリックします。ここから、各ステップに意味のある名前を付けていきます。\n4つのステップそれぞれに意味のある名前を付けます。\nStep 1: Go to URL というテキストを HomePage - Online Boutique に置き換えます Step 2: Select Vintage Camera Lens と入力します Step 3: Add to Cart と入力します Step 4: Place Order と入力します \u003c Return to test をクリックしてテスト設定ページに戻り、Save をクリックしてテストを保存します。\nテストダッシュボードに戻り、テスト結果が表示され始めます。\nおめでとうございます！ Splunk Synthetic Monitoring で Real Browser Test の作成に成功しました。次に、テスト結果をより詳しく見ていきます。",
    "description": "ステップを編集するには、+ Edit steps or synthetic transactions ボタンをクリックします。ここから、各ステップに意味のある名前を付けていきます。\n4つのステップそれぞれに意味のある名前を付けます。\nStep 1: Go to URL というテキストを HomePage - Online Boutique に置き換えます Step 2: Select Vintage Camera Lens と入力します Step 3: Add to Cart と入力します Step 4: Place Order と入力します \u003c Return to test をクリックしてテスト設定ページに戻り、Save をクリックしてテストを保存します。",
    "tags": [],
    "title": "1.6 テストステップの編集",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/6-edit-steps/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "このセクションでは、OpenTelemetry Collector を設定して、テレメトリーSpanから特定のタグを削除し、機密データを秘匿化する方法を学びます。これは、クレジットカード番号、個人データ、その他のセキュリティ関連の詳細など、処理またはエクスポートする前に匿名化する必要がある機密情報を保護するために重要です。\nOpenTelemetry Collector の主要なプロセッサの設定について説明します\nAttributes Processor：特定のSpan属性を変更または削除します。 Redaction Processor：機密データが保存または送信される前にサニタイズされることを保証します。 Exercise 重要 すべてのターミナルウィンドウを 4-sensitive-data ディレクトリに移動し、clear コマンドを実行してください。\n3-dropping-spans ディレクトリから *.yaml を 4-sensitive-data にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml",
    "description": "このセクションでは、OpenTelemetry Collector を設定して、テレメトリーSpanから特定のタグを削除し、機密データを秘匿化する方法を学びます。これは、クレジットカード番号、個人データ、その他のセキュリティ関連の詳細など、処理またはエクスポートする前に匿名化する必要がある機密情報を保護するために重要です。\nOpenTelemetry Collector の主要なプロセッサの設定について説明します\nAttributes Processor：特定のSpan属性を変更または削除します。 Redaction Processor：機密データが保存または送信される前にサニタイズされることを保証します。 Exercise 重要 すべてのターミナルウィンドウを 4-sensitive-data ディレクトリに移動し、clear コマンドを実行してください。\n3-dropping-spans ディレクトリから *.yaml を 4-sensitive-data にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml",
    "tags": [],
    "title": "4. 機密データの秘匿化",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/4-sensitive-data/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "前のセクションで見てきたように、サービスで自動検出と設定を有効にすると、トレースがSplunk Observability Cloudに送信されます。\nこれらのトレースにより、Splunkは自動的にService MapsとRED Metricsを生成します。これらは、サービスの動作とサービス間の相互作用を理解するための最初のステップです。\n次のセクションでは、トレース自体と、コードに触れることなくサービスの動作を理解するのに役立つ情報を詳しく見ていきます。",
    "description": "前のセクションで見てきたように、サービスで自動検出と設定を有効にすると、トレースがSplunk Observability Cloudに送信されます。\nこれらのトレースにより、Splunkは自動的にService MapsとRED Metricsを生成します。これらは、サービスの動作とサービス間の相互作用を理解するための最初のステップです。\n次のセクションでは、トレース自体と、コードに触れることなくサービスの動作を理解するのに役立つ情報を詳しく見ていきます。",
    "tags": [],
    "title": "APM Features",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/5-traces/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "トレースアナライザーからトレースウォーターフォールに到達しました。トレースは同じトレース ID を共有するスパンの集まりで、アプリケーションとその構成サービスによって処理される一意のトランザクションを表します。\nSplunk APM の各スパンは、単一の操作をキャプチャします。Splunk APM は、スパンがキャプチャする操作がエラーになった場合、そのスパンをエラースパンとみなします。\n演習 ウォーターフォール内の任意のpaymentservice:grpc.hipstershop.PaymentService/Chargeスパンの横にある!をクリックします。 ​ 質問 回答 スパン詳細で報告されているエラーメッセージとバージョンは何ですか？\nInvalid request（無効なリクエスト）とv350.10です。\n問題を引き起こしているpaymentserviceのバージョンを特定したので、エラーについてさらに詳しい情報が見つかるか確認してみましょう。ここで関連ログの出番です。\n関連コンテンツ(Related Contents)は、APM、インフラストラクチャモニタリング、および Log Observer が可観測性クラウド全体でフィルターを渡すことを可能にする特定のメタデータに依存しています。関連ログが機能するためには、ログに以下のメタデータが必要です：\nservice.name deployment.environment host.name trace_id span_id 演習 トレースウォーターフォールの一番下でLogs (1)をクリックします。これは、このトレースに関連ログがあることを示しています。 ポップアップのLogs for trace xxx（トレース xxx のログ）エントリをクリックすると、Log Observerで完全なトレースのログが開きます。 次に、ログのエラーについてさらに詳しく調べてみましょう。",
    "description": "トレースアナライザーからトレースウォーターフォールに到達しました。トレースは同じトレース ID を共有するスパンの集まりで、アプリケーションとその構成サービスによって処理される一意のトランザクションを表します。\nSplunk APM の各スパンは、単一の操作をキャプチャします。Splunk APM は、スパンがキャプチャする操作がエラーになった場合、そのスパンをエラースパンとみなします。\n演習 ウォーターフォール内の任意のpaymentservice:grpc.hipstershop.PaymentService/Chargeスパンの横にある!をクリックします。 ​ 質問 回答 スパン詳細で報告されているエラーメッセージとバージョンは何ですか？\nInvalid request（無効なリクエスト）とv350.10です。\n問題を引き起こしているpaymentserviceのバージョンを特定したので、エラーについてさらに詳しい情報が見つかるか確認してみましょう。ここで関連ログの出番です。\n関連コンテンツ(Related Contents)は、APM、インフラストラクチャモニタリング、および Log Observer が可観測性クラウド全体でフィルターを渡すことを可能にする特定のメタデータに依存しています。関連ログが機能するためには、ログに以下のメタデータが必要です：\nservice.name deployment.environment host.name trace_id span_id 演習 トレースウォーターフォールの一番下でLogs (1)をクリックします。これは、このトレースに関連ログがあることを示しています。 ポップアップのLogs for trace xxx（トレース xxx のログ）エントリをクリックすると、Log Observerで完全なトレースのログが開きます。",
    "tags": [],
    "title": "6. APMウォーターフォール",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/6-apm/6-apm-waterfall/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "アプリケーションを正常に Docker 化したので、次に OpenTelemetry による計装 を追加しましょう。\nこれは、Linux で実行しているアプリケーションを計装した際の手順と似ていますが、 注意すべきいくつかの重要な違いがあります。\nDockerfile の更新 /home/splunk/workshop/docker-k8s-otel/helloworldディレクトリのDockerfileを更新しましょう。\nDockerfile で.NET アプリケーションがビルドされた後、以下の操作を行いたいと思います：\nsplunk-otel-dotnet-install.shをダウンロードして実行するために必要な依存関係を追加する Splunk OTel .NET インストーラーをダウンロードする ディストリビューションをインストールする Dockerfile のビルドステージに以下を追加できます。vi で Dockerfile を開きましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile vi では「i」キーを押して編集モードに入ります ‘NEW CODE’とマークされている行を Dockerfile のビルドステージセクションに貼り付けてください：\n# CODE ALREADY IN YOUR DOCKERFILE: FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build # NEW CODE: add dependencies for splunk-otel-dotnet-install.sh RUN apt-get update \u0026\u0026 \\ apt-get install -y unzip # NEW CODE: download Splunk OTel .NET installer RUN curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O # NEW CODE: install the distribution RUN sh ./splunk-otel-dotnet-install.sh 次に、以下の変更で Dockerfile の最終ステージを更新します：\nビルドイメージから最終イメージに/root/.splunk-otel-dotnet/をコピーする entrypoint.sh ファイルもコピーする OTEL_SERVICE_NAMEとOTEL_RESOURCE_ATTRIBUTES環境変数を設定する ENTRYPOINTをentrypoint.shに設定する 最も簡単な方法は、最終ステージ全体を以下の内容で置き換えることです：\n重要 Dockerfile の$INSTANCEをあなたのインスタンス名に置き換えてください。 インスタンス名はecho $INSTANCEを実行することで確認できます。\n# CODE ALREADY IN YOUR DOCKERFILE FROM base AS final # NEW CODE: Copy instrumentation file tree WORKDIR \"//home/app/.splunk-otel-dotnet\" COPY --from=build /root/.splunk-otel-dotnet/ . # CODE ALREADY IN YOUR DOCKERFILE WORKDIR /app COPY --from=publish /app/publish . # NEW CODE: copy the entrypoint.sh script COPY entrypoint.sh . # NEW CODE: set OpenTelemetry environment variables ENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' # NEW CODE: replace the prior ENTRYPOINT command with the following two lines ENTRYPOINT [\"sh\", \"entrypoint.sh\"] CMD [\"dotnet\", \"helloworld.dll\"] vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\nこれらすべての変更の後、Dockerfile は以下のようになるはずです：\n重要 このコンテンツを自分の Dockerfile にコピー＆ペーストする場合は、 Dockerfile の$INSTANCEをあなたのインスタンス名に置き換えてください。 インスタンス名はecho $INSTANCEを実行することで確認できます。\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base USER app WORKDIR /app EXPOSE 8080 FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build # NEW CODE: add dependencies for splunk-otel-dotnet-install.sh RUN apt-get update \u0026\u0026 \\ apt-get install -y unzip # NEW CODE: download Splunk OTel .NET installer RUN curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O # NEW CODE: install the distribution RUN sh ./splunk-otel-dotnet-install.sh FROM build AS publish ARG BUILD_CONFIGURATION=Release RUN dotnet publish \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false FROM base AS final # NEW CODE: Copy instrumentation file tree WORKDIR \"//home/app/.splunk-otel-dotnet\" COPY --from=build /root/.splunk-otel-dotnet/ . WORKDIR /app COPY --from=publish /app/publish . # NEW CODE: copy the entrypoint.sh script COPY entrypoint.sh . # NEW CODE: set OpenTelemetry environment variables ENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' # NEW CODE: replace the prior ENTRYPOINT command with the following two lines ENTRYPOINT [\"sh\", \"entrypoint.sh\"] CMD [\"dotnet\", \"helloworld.dll\"] entrypoint.sh ファイルの作成 また、/home/splunk/workshop/docker-k8s-otel/helloworldフォルダにentrypoint.shという名前のファイルを 以下の内容で作成する必要があります：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/entrypoint.sh 次に、新しく作成したファイルに以下のコードを貼り付けます：\n#!/bin/sh # Read in the file of environment settings . /$HOME/.splunk-otel-dotnet/instrument.sh # Then run the CMD exec \"$@\" vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\nentrypoint.shスクリプトは、計装に含まれる instrument.sh スクリプトが環境変数をコンテナ起動時に取得するために必要です。これにより、各プラットフォームに対して環境変数が正しく設定されることが保証されます。\n「なぜ Linux ホスト上で OpenTelemetry .NET instrumentation を有効化したときのように、 Dockerfile に以下のコマンドを含めるだけではだめなのか？」と疑問に思うかもしれません。\nRUN . $HOME/.splunk-otel-dotnet/instrument.sh この方法の問題点は、各 Dockerfile RUN ステップが新しいコンテナと新しいシェルで実行されることです。 あるシェルで環境変数を設定しようとしても、後で見ることはできません。 この問題は、ここで行ったようにエントリポイントスクリプトを使用することで解決されます。 この問題についての詳細は、こちらのStack Overflow の投稿を参照してください。\nDocker イメージのビルド OpenTelemetry .NET instrumentation を含む新しい Docker イメージをビルドしましょう：\ndocker build -t helloworld:1.1 . 注：以前のバージョンと区別するために、異なるバージョン（1.1）を使用しています。 古いバージョンをクリーンアップするには、以下のコマンドでコンテナ ID を取得します：\ndocker ps -a 次に、以下のコマンドでコンテナを削除します：\ndocker rm \u003cold container id\u003e --force 次にコンテナイメージ ID を取得します：\ndocker images | grep 1.0 最後に、以下のコマンドで古いイメージを削除できます：\ndocker image rm \u003cold image id\u003e アプリケーションの実行 新しい Docker イメージを実行しましょう：\ndocker run --name helloworld \\ --detach \\ --expose 8080 \\ --network=host \\ helloworld:1.1 以下を使用してアプリケーションにアクセスできます：\ncurl http://localhost:8080/hello トラフィックを生成するために上記のコマンドを数回実行しましょう。\n1 分ほど経過したら、Splunk Observability Cloud に新しいトレースが表示されることを確認します。\nあなたの特定の環境でトレースを探すことを忘れないでください。\nトラブルシューティング Splunk Observability Cloud にトレースが表示されない場合は、以下のようにトラブルシューティングを行うことができます。\nまず、コレクター設定ファイルを編集用に開きます：\nsudo vi /etc/otel/collector/agent_config.yaml 次に、トレースパイプラインにデバッグエクスポーターを追加します。これにより、トレースがコレクターログに書き込まれるようになります：\nservice: extensions: [health_check, http_forwarder, zpages, smartagent] pipelines: traces: receivers: [jaeger, otlp, zipkin] processors: - memory_limiter - batch - resourcedetection #- resource/add_environment # NEW CODE: デバッグエクスポーターをここに追加 exporters: [otlphttp, signalfx, debug] その後、コレクターを再起動して設定変更を適用します：\nsudo systemctl restart splunk-otel-collector journalctlを使用してコレクターログを表示できます：\nログの追跡を終了するには、Ctrl + C を押します。\nsudo journalctl -u splunk-otel-collector -f -n 100",
    "description": "アプリケーションを正常に Docker 化したので、次に OpenTelemetry による計装 を追加しましょう。\nこれは、Linux で実行しているアプリケーションを計装した際の手順と似ていますが、 注意すべきいくつかの重要な違いがあります。\nDockerfile の更新 /home/splunk/workshop/docker-k8s-otel/helloworldディレクトリのDockerfileを更新しましょう。\nDockerfile で.NET アプリケーションがビルドされた後、以下の操作を行いたいと思います：\nsplunk-otel-dotnet-install.shをダウンロードして実行するために必要な依存関係を追加する Splunk OTel .NET インストーラーをダウンロードする ディストリビューションをインストールする Dockerfile のビルドステージに以下を追加できます。vi で Dockerfile を開きましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile vi では「i」キーを押して編集モードに入ります ‘NEW CODE’とマークされている行を Dockerfile のビルドステージセクションに貼り付けてください：\n# CODE ALREADY IN YOUR DOCKERFILE: FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build # NEW CODE: add dependencies for splunk-otel-dotnet-install.sh RUN apt-get update \u0026\u0026 \\ apt-get install -y unzip # NEW CODE: download Splunk OTel .NET installer RUN curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O # NEW CODE: install the distribution RUN sh ./splunk-otel-dotnet-install.sh 次に、以下の変更で Dockerfile の最終ステージを更新します：",
    "tags": [],
    "title": "Dockerfileに計装を追加する",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/6-add-instrumentation-to-dockerfile/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "Service セクションは、receivers、processors、exporters、extensions セクションで定義された設定に基づいて、Collector でどのコンポーネントを有効にするかを設定するために使用します。\n情報 コンポーネントが設定されていても、Service セクション内で定義されていない場合、そのコンポーネントは有効になりません。\nservice セクションは3つのサブセクションで構成されています\nextensions pipelines telemetry デフォルト設定では、extension セクションは health_check、pprof、zpages を有効にするよう設定されています。これらは先ほど Extensions モジュールで設定しました。\nservice: extensions: [health_check, pprof, zpages] それでは、Metric Pipeline を設定しましょう！",
    "description": "Service セクションは、receivers、processors、exporters、extensions セクションで定義された設定に基づいて、Collector でどのコンポーネントを有効にするかを設定するために使用します。\n情報 コンポーネントが設定されていても、Service セクション内で定義されていない場合、そのコンポーネントは有効になりません。\nservice セクションは3つのサブセクションで構成されています\nextensions pipelines telemetry デフォルト設定では、extension セクションは health_check、pprof、zpages を有効にするよう設定されています。これらは先ほど Extensions モジュールで設定しました。\nservice: extensions: [health_check, pprof, zpages] それでは、Metric Pipeline を設定しましょう！",
    "tags": [],
    "title": "OpenTelemetry Collector Service",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/6-service/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ あなたはバックエンド開発者で、SRE が発見した問題の調査を手伝うよう依頼されました。SRE はユーザーエクスペリエンスの低下を特定し、あなたにその問題を調査するよう依頼しました。\nRUM トレース（フロントエンド）から APM トレース（バックエンド）にジャンプすることで、完全なエンドツーエンドの可視性の力を発見します。すべてのサービスはテレメトリ（トレースとスパン）を送信しており、Splunk Observability Cloud はこれを視覚化、分析し、異常やエラーを検出するために使用できます。\nRUM と APM は同じコインの表と裏です。RUM はアプリケーションのクライアント側からの視点であり、APM はサーバー側からの視点です。このセクションでは、APM を使用して掘り下げ、問題がどこにあるかを特定します。",
    "description": "このセクションでは、APMを使用して掘り下げ、問題がどこにあるかを特定します。",
    "tags": [],
    "title": "Splunk APM",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/6-apm/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "ログの外部でコンテキスト伝播の結果を確認するために、もう一度Splunk APM UIを参照します。\nSplunk APM サービスマップで Lambda 関数を表示する もう一度 APM で環境のサービスマップを確認してみましょう。\nSplunk Observability Cloud で：\nメインメニューのAPMボタンをクリックします。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 概要ページの右側にあるService Mapボタンをクリックします。これによりサービスマップビューに移動します。\n\u003e 注意：トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください ワークショップの質問 違いに気づきましたか？\n今回は、伝播されたコンテキストによってリンクされたproducer-lambdaとconsumer-lambda関数が見えるはずです！ トレース ID で Lambda トレースを調査する 次に、環境に関連するトレースをもう一度確認します。\nコンシューマー関数のログからコピーしたトレース ID を、Traces 下のView Trace ID検索ボックスに貼り付け、Goをクリックします メモ トレース ID は、私たちが伝播したトレースコンテキストの一部でした。\n最も一般的な 2 つの伝播規格について読むことができます：\nW3C B3 ワークショップの質問 私たちはどちらを使用していますか？\n私たちの NodeJS 関数をサポートする Splunk Distribution of Opentelemetry JS は、デフォルトでW3C標準を使用しています ワークショップの質問 ボーナス質問：W3C ヘッダーと B3 ヘッダーを混在させるとどうなりますか？\nconsumer-lambdaスパンをクリックしてください。\nワークショップの質問 あなたのメッセージからの属性を見つけることができますか？\nクリーンアップ いよいよワークショップの最後に来ました。後片付けをしましょう！\nsend_messageの停止 send_message.pyスクリプトがまだ実行中の場合は、次のコマンドで停止します：\nfg これによりバックグラウンドプロセスがフォアグラウンドに移動します。 次に[CONTROL-C]を押してプロセスを終了できます。 すべての AWS リソースを破棄する Terraform は個々のリソースの状態をデプロイメントとして管理するのに優れています。定義に変更があっても、デプロイされたリソースを更新することもできます。しかし、一からやり直すために、リソースを破棄し、このワークショップの手動計装部分の一部として再デプロイします。\n以下の手順に従ってリソースを破棄してください：\nmanualディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manualディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual 以前にデプロイした Lambda 関数とその他の AWS リソースを破棄します：\nterraform destroy Enter a value:プロンプトが表示されたらyesと応答します これにより、リソースが破棄され、クリーンな環境が残ります",
    "description": "ログの外部でコンテキスト伝播の結果を確認するために、もう一度Splunk APM UIを参照します。\nSplunk APM サービスマップで Lambda 関数を表示する もう一度 APM で環境のサービスマップを確認してみましょう。\nSplunk Observability Cloud で：\nメインメニューのAPMボタンをクリックします。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 概要ページの右側にあるService Mapボタンをクリックします。これによりサービスマップビューに移動します。\n\u003e 注意：トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください ワークショップの質問 違いに気づきましたか？\n今回は、伝播されたコンテキストによってリンクされたproducer-lambdaとconsumer-lambda関数が見えるはずです！ トレース ID で Lambda トレースを調査する 次に、環境に関連するトレースをもう一度確認します。",
    "tags": [],
    "title": "Splunk APM、Lambda関数とトレース、再び！",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/6-updated-lambdas/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "Service セクションでは、レシーバー、プロセッサー、エクスポーター、およびエクステンションにある設定に基づいて、コレクターで有効にするコンポーネントを設定していきます。\n情報 コンポーネントが設定されていても、Service セクション内で定義されていない場合、そのコンポーネントは有効化されません。\nサービスのセクションは、以下の3つのサブセクションで構成されています：\nextensions（拡張機能） pipelines（パイプライン） telemetry（テレメトリー） デフォルトの設定では、拡張機能セクションが health_check、pprof、zpages を有効にするように設定されており、これらは以前のエクステンションのモジュールで設定しました。\nservice: extensions: [health_check, pprof, zpages] それでは、メトリックパイプラインを設定していきましょう！",
    "description": "Service セクションでは、レシーバー、プロセッサー、エクスポーター、およびエクステンションにある設定に基づいて、コレクターで有効にするコンポーネントを設定していきます。\n情報 コンポーネントが設定されていても、Service セクション内で定義されていない場合、そのコンポーネントは有効化されません。\nサービスのセクションは、以下の3つのサブセクションで構成されています：\nextensions（拡張機能） pipelines（パイプライン） telemetry（テレメトリー） デフォルトの設定では、拡張機能セクションが health_check、pprof、zpages を有効にするように設定されており、これらは以前のエクステンションのモジュールで設定しました。\nservice: extensions: [health_check, pprof, zpages] それでは、メトリックパイプラインを設定していきましょう！",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/6-service/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk Infrastructure Monitoring（IM）は、ハイブリッドクラウド環境向けの市場をリードする監視および可観測性サービスです。特許取得済みのストリーミングアーキテクチャに基づいて構築されており、従来のソリューションよりもはるかに短時間で、より高い精度でインフラストラクチャ、サービス、アプリケーション全体のパフォーマンスを視覚化および分析するためのリアルタイムソリューションをエンジニアリングチームに提供します。\nOpenTelemetry 標準化： データの完全な制御を提供し、ベンダーロックインから解放し、独自のエージェントの実装から解放します。\nSplunk の OTel コレクター： シームレスなインストールと動的な構成により、スタック全体を数秒で自動検出し、クラウド、サービス、システム全体の可視性を提供します。\n300 以上の使いやすい標準コンテンツ： 事前構築されたナビゲーターとダッシュボードにより、環境全体の即時の視覚化を提供し、すべてのデータとリアルタイムで対話できます。\nKubernetes ナビゲーター： ノード、ポッド、コンテナの包括的な標準的な階層ビューを即座に提供します。わかりやすいインタラクティブなクラスターマップで、最も初心者の Kubernetes ユーザーでもすぐに使いこなせます。\nAutoDetect アラートとディテクター： 最も重要なメトリクスを標準で自動的に識別し、テレメトリデータが取り込まれた瞬間から正確にアラートを出すディテクターのアラート条件を作成し、重要な通知のために数秒でリアルタイムのアラート機能を使用します。\nダッシュボード内のログビュー： 共通のフィルターと時間制御を使用して、ログメッセージとリアルタイムメトリクスを 1 ページに組み合わせ、より迅速なコンテキスト内トラブルシューティングを実現します。\nメトリクスパイプライン管理： 再計装なしに取り込み時点でメトリクスの量を制御し、必要なデータのみを保存して分析するための集約およびデータ削除ルールのセットを使用します。メトリクスの量を削減し、可観測性のコストを最適化します。",
    "description": "Splunk Infrastructure Monitoring（IM）は、ハイブリッドクラウド環境向けの市場をリードする監視および可観測性サービスです。特許取得済みのストリーミングアーキテクチャに基づいて構築されており、従来のソリューションよりもはるかに短時間で、より高い精度でインフラストラクチャ、サービス、アプリケーション全体のパフォーマンスを視覚化および分析するためのリアルタイムソリューションをエンジニアリングチームに提供します。\nOpenTelemetry 標準化： データの完全な制御を提供し、ベンダーロックインから解放し、独自のエージェントの実装から解放します。\nSplunk の OTel コレクター： シームレスなインストールと動的な構成により、スタック全体を数秒で自動検出し、クラウド、サービス、システム全体の可視性を提供します。\n300 以上の使いやすい標準コンテンツ： 事前構築されたナビゲーターとダッシュボードにより、環境全体の即時の視覚化を提供し、すべてのデータとリアルタイムで対話できます。\nKubernetes ナビゲーター： ノード、ポッド、コンテナの包括的な標準的な階層ビューを即座に提供します。わかりやすいインタラクティブなクラスターマップで、最も初心者の Kubernetes ユーザーでもすぐに使いこなせます。\nAutoDetect アラートとディテクター： 最も重要なメトリクスを標準で自動的に識別し、テレメトリデータが取り込まれた瞬間から正確にアラートを出すディテクターのアラート条件を作成し、重要な通知のために数秒でリアルタイムのアラート機能を使用します。\nダッシュボード内のログビュー： 共通のフィルターと時間制御を使用して、ログメッセージとリアルタイムメトリクスを 1 ページに組み合わせ、より迅速なコンテキスト内トラブルシューティングを実現します。\nメトリクスパイプライン管理： 再計装なしに取り込み時点でメトリクスの量を制御し、必要なデータのみを保存して分析するための集約およびデータ削除ルールのセットを使用します。メトリクスの量を削減し、可観測性のコストを最適化します。",
    "tags": [],
    "title": "インフラストラクチャ概要",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/6-infrastructure-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops",
    "content": "このワークショップでは、AWS Lambda で実行される小規模なサーバーレスアプリケーションの分散トレースを構築し、AWS Kinesis を介してメッセージを produce および consume する方法を学びます。\nまず、OpenTelemetry の自動計装がどのようにトレースをキャプチャし、選択した宛先にエクスポートするかを確認します。\n次に、手動計装によってコンテキスト伝播を有効にする方法を見ていきます。\nこのワークショップのために、Splunk は AWS/EC2 上の Ubuntu Linux インスタンスを事前に構成しています。このインスタンスにアクセスするには、ワークショップインストラクターが提供する URL にアクセスしてください。",
    "description": "このワークショップでは、AWS Lambdaで実行される小規模なサーバーレスアプリケーションの分散トレースを構築し、AWS Kinesisを介してメッセージをproduceおよびconsumeする方法を学びます",
    "tags": [],
    "title": "AWS Lambda関数の分散トレーシング",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Splunk Synthetic Scripting \u003e 1. Real Browser Test",
    "content": "前のステップの散布図で、いずれかのドットをクリックしてテスト実行データにドリルダウンします。できれば、最新のテスト実行（最も右側）を選択してください。",
    "description": "前のステップの散布図で、いずれかのドットをクリックしてテスト実行データにドリルダウンします。できれば、最新のテスト実行（最も右側）を選択してください。",
    "tags": [],
    "title": "1.7 テスト結果の表示",
    "uri": "/observability-workshop/ja/ninja-workshops/4-synthetics-scripting/1-real-browser-test/7-view-test-results/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "Transform Processor を使用すると、パイプラインを流れるテレメトリデータ（ログ、メトリクス、トレース）を変更できます。OpenTelemetry Transformation Language (OTTL) を使用して、アプリケーションコードを変更することなく、データのフィルタリング、エンリッチメント、変換をその場で行うことができます。\nこの演習では、gateway.yaml を更新して、次の処理を行う Transform Processor を追加します\nログリソース属性の フィルタリング JSON構造化ログデータの属性への パース ログメッセージ本文に基づくログ重大度レベルの 設定 以前のログで SeverityText や SeverityNumber が未定義だったことにお気づきかもしれません。これは filelog レシーバーの典型的な動作です。ただし、重大度はログ本文内に埋め込まれています。例\nSeverityText: SeverityNumber: Unspecified(0) Body: Str(2025-01-31 15:49:29 [WARN] - Do or do not, there is no try.) ログには、ログ本文内にJSONとしてエンコードされた構造化データが含まれていることがよくあります。これらのフィールドを属性として抽出することで、インデックス作成、フィルタリング、クエリの効率が向上します。下流のシステムで手動でJSONをパースする代わりに、OTTLを使用してテレメトリパイプラインレベルで自動的に変換できます。\nExercise 重要 すべてのターミナルウィンドウを 5-transform-data ディレクトリに移動し、clear コマンドを実行してください。\n4-sensitve-data ディレクトリから *.yaml を 5-transform-data にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml",
    "description": "Transform Processor を使用すると、パイプラインを流れるテレメトリデータ（ログ、メトリクス、トレース）を変更できます。OpenTelemetry Transformation Language (OTTL) を使用して、アプリケーションコードを変更することなく、データのフィルタリング、エンリッチメント、変換をその場で行うことができます。\nこの演習では、gateway.yaml を更新して、次の処理を行う Transform Processor を追加します\nログリソース属性の フィルタリング JSON構造化ログデータの属性への パース ログメッセージ本文に基づくログ重大度レベルの 設定 以前のログで SeverityText や SeverityNumber が未定義だったことにお気づきかもしれません。これは filelog レシーバーの典型的な動作です。ただし、重大度はログ本文内に埋め込まれています。例\nSeverityText: SeverityNumber: Unspecified(0) Body: Str(2025-01-31 15:49:29 [WARN] - Do or do not, there is no try.) ログには、ログ本文内にJSONとしてエンコードされた構造化データが含まれていることがよくあります。これらのフィールドを属性として抽出することで、インデックス作成、フィルタリング、クエリの効率が向上します。下流のシステムで手動でJSONをパースする代わりに、OTTLを使用してテレメトリパイプラインレベルで自動的に変換できます。\nExercise 重要 すべてのターミナルウィンドウを 5-transform-data ディレクトリに移動し、clear コマンドを実行してください。\n4-sensitve-data ディレクトリから *.yaml を 5-transform-data にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml",
    "tags": [],
    "title": "5. Transform Data",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/5-transform-data/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "前の章で見てきたように、APMを使用して、コードに触れることなく、さまざまなサービス間のインタラクションをトレースすることができ、問題をより迅速に特定できます。\nトレーシングに加えて、automatic discovery and configurationは、問題をさらに迅速に発見するのに役立つ追加機能を最初から提供します。このセクションでは、そのうちの2つを見ていきます：\nAlways-on Profiling and Java Metrics Database Query Performance Always-on ProfilingまたはDatabase Query Performanceについてさらに深く学びたい場合は、Debug Problems in Microservicesという別のNinja Workshopがありますので、そちらをご覧ください。",
    "description": "前の章で見てきたように、APMを使用して、コードに触れることなく、さまざまなサービス間のインタラクションをトレースすることができ、問題をより迅速に特定できます。\nトレーシングに加えて、automatic discovery and configurationは、問題をさらに迅速に発見するのに役立つ追加機能を最初から提供します。このセクションでは、そのうちの2つを見ていきます：\nAlways-on Profiling and Java Metrics Database Query Performance Always-on ProfilingまたはDatabase Query Performanceについてさらに深く学びたい場合は、Debug Problems in Microservicesという別のNinja Workshopがありますので、そちらをご覧ください。",
    "tags": [],
    "title": "Always-On Profiling \u0026 DB Query Performance",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/6-profiling-db-query/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "ワークショップパート 1 の振り返り ワークショップのこの時点で、以下を正常に完了しました：\nLinux ホストに Splunk distribution of OpenTelemetry コレクターをデプロイ Splunk Observability Cloud にトレースとメトリクスを送信するよう設定 .NET アプリケーションをデプロイし、OpenTelemetry で計装 .NET アプリケーションを Docker 化し、o11y cloud にトレースが流れることを確認 上記のステップを完了していない場合は、ワークショップの残りの部分に進む前に以下のコマンドを実行してください：\ncp /home/splunk/workshop/docker-k8s-otel/docker/Dockerfile /home/splunk/workshop/docker-k8s-otel/helloworld/ cp /home/splunk/workshop/docker-k8s-otel/docker/entrypoint.sh /home/splunk/workshop/docker-k8s-otel/helloworld/ 重要 これらのファイルがコピーされたら、/home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile を エディターで開き、Dockerfile の $INSTANCE をあなたのインスタンス名に置き換えてください。 インスタンス名は echo $INSTANCE を実行することで確認できます。\nワークショップパート 2 の紹介 ワークショップの次の部分では、Kubernetes でアプリケーションを実行したいと思います。 そのため、Kubernetes クラスターに Splunk distribution of OpenTelemetry コレクターを デプロイする必要があります。\nまず、いくつかの重要な用語を定義しましょう。\n重要な用語 Kubernetes とは何ですか？ 「Kubernetes は、宣言的な設定と自動化の両方を促進する、コンテナ化されたワークロードとサービスを管理するためのポータブルで拡張可能なオープンソースプラットフォームです。」\nSource: https://kubernetes.io/docs/concepts/overview/\nDockerfile に小さな修正を加えた後、アプリケーション用に以前ビルドした Docker イメージを Kubernetes クラスターにデプロイします。\nHelm とは何ですか？ Helm は Kubernetes 用のパッケージマネージャーです。\n「最も複雑な Kubernetes アプリケーションだとしても、定義、インストール、アップグレード役立ちます」\nHelm を使用したコレクターのインストール プロダクト内ウィザードではなくコマンドラインを使用して、コレクターをインストールするための独自の helmコマンドを作成しましょう。\nまず、helm リポジトリを追加する必要があります：ます。」\nSource: https://helm.sh/\nHelm を使用して K8s クラスターに OpenTelemetry コレクターをデプロイします。\nHelm の利点 複雑性の管理 数十のマニフェストファイルではなく、単一の values.yaml ファイルを扱う 簡単な更新 インプレースアップグレード ロールバックサポート helm rollback を使用してリリースの古いバージョンにロールバック ホストコレクターのアンインストール 先に進む前に、Linux ホストに先ほどインストールしたコレクターを削除しましょう： \\\ncurl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; sudo sh /tmp/splunk-otel-collector.sh --uninstall Helm を利用して Collector をインストールする ウィザードの代わりに、コマンドラインを利用して collector をインストールします。\nまず初めに、Helm リポジトリに登録する必要があります\nhelm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart リポジトリが最新であることを確認します：\nhelm repo update helm チャートのデプロイメントを設定するために、/home/splunkディレクトリにvalues.yamlという名前の新しいファイルを作成しましょう：\n# swith to the /home/splunk dir cd /home/splunk # create a values.yaml file in vi vi values.yaml Press ‘i’ to enter into insert mode in vi before pasting the text below.　“i\"を押下すると vi はインサートモードになります。ペースト前に押下してください\nそして、下記のコードをコピーしてください\nlogsEngine: otel agent: config: receivers: hostmetrics: collection_interval: 10s root_path: /hostfs scrapers: cpu: null disk: null filesystem: exclude_mount_points: match_type: regexp mount_points: - /var/* - /snap/* - /boot/* - /boot - /opt/orbstack/* - /mnt/machines/* - /Users/* load: null memory: null network: null paging: null processes: null vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n次のコマンドを使用してコレクターをインストールできます：\n​ Script Example Output helm install splunk-otel-collector --version 0.136.0 \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector NAME: splunk-otel-collector LAST DEPLOYED: Fri Dec 20 01:01:43 2024 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Observability realm us1. コレクターが実行中であることを確認 以下のコマンドでコレクターが実行されているかどうかを確認できます：\n​ Script Example Output kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-agent-8xvk8 1/1 Running 0 49s splunk-otel-collector-k8s-cluster-receiver-d54857c89-tx7qr 1/1 Running 0 49s O11y Cloud で K8s クラスターを確認 Splunk Observability Cloud で、Infrastructure -\u003e Kubernetes -\u003e Kubernetes Clustersにナビゲートし、 クラスター名（$INSTANCE-cluster）を検索します：",
    "description": "ワークショップパート 1 の振り返り ワークショップのこの時点で、以下を正常に完了しました：\nLinux ホストに Splunk distribution of OpenTelemetry コレクターをデプロイ Splunk Observability Cloud にトレースとメトリクスを送信するよう設定 .NET アプリケーションをデプロイし、OpenTelemetry で計装 .NET アプリケーションを Docker 化し、o11y cloud にトレースが流れることを確認 上記のステップを完了していない場合は、ワークショップの残りの部分に進む前に以下のコマンドを実行してください：\ncp /home/splunk/workshop/docker-k8s-otel/docker/Dockerfile /home/splunk/workshop/docker-k8s-otel/helloworld/ cp /home/splunk/workshop/docker-k8s-otel/docker/entrypoint.sh /home/splunk/workshop/docker-k8s-otel/helloworld/ 重要 これらのファイルがコピーされたら、/home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile を エディターで開き、Dockerfile の $INSTANCE をあなたのインスタンス名に置き換えてください。 インスタンス名は echo $INSTANCE を実行することで確認できます。\nワークショップパート 2 の紹介 ワークショップの次の部分では、Kubernetes でアプリケーションを実行したいと思います。 そのため、Kubernetes クラスターに Splunk distribution of OpenTelemetry コレクターを デプロイする必要があります。",
    "tags": [],
    "title": "K8sでOpenTelemetryコレクターをインストール",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/7-install-collector-k8s/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ バックエンド開発者の役割を継続して、アプリケーションのログを調査して問題の根本原因を特定する必要があります。\nAPM トレースに関連するコンテンツ（ログ）を使用して、Splunk Log Observer でさらに掘り下げ、問題が正確に何であるかを理解します。\n関連コンテンツは、あるコンポーネントから別のコンポーネントにジャンプできる強力な機能で、メトリクス、トレース、ログで利用可能です。",
    "description": "このセクションでは、Log Observerを使用して掘り下げ、問題が何かを特定します。",
    "tags": [],
    "title": "Splunk Log Observer",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/7-log-observer/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "Splunk Observability Cloud OpenTelemetry Collector からメトリクスを Splunk Observability Cloud に送信する設定が完了したので、Splunk Observability Cloud でデータを確認してみましょう。Splunk Observability Cloud への招待を受け取っていない場合は、インストラクターがログイン資格情報を提供します。\nその前に、少し面白くするためにインスタンスでストレステストを実行してみましょう。これによりダッシュボードが活性化されます。\nsudo apt install stress while true; do stress -c 2 -t 40; stress -d 5 -t 40; stress -m 20 -t 40; done Splunk Observability Cloud にログインしたら、左側のナビゲーションを使用してメインメニューから Dashboards に移動します。これによりチームビューが表示されます。このビューの上部にある All Dashboards をクリックします\n検索ボックスで OTel Contrib を検索します\n情報 ダッシュボードが存在しない場合は、インストラクターがすぐに追加できます。Splunk 主催のワークショップに参加していない場合は、インポートするダッシュボードグループをこのページの下部で見つけることができます。\nOTel Contrib Dashboard ダッシュボードをクリックして開き、次にダッシュボード上部の Participant Name ボックスをクリックして、config.yaml で participant.name に設定した名前をドロップダウンリストから選択するか、名前を入力して検索します\nこれで、OpenTelemetry Collector を設定したホストのホストメトリクスを確認できます。\nDownload Dashboard Group JSON for importing OpenTelemetry-Contrib-Dashboard-Group.json (40 KB)",
    "description": "Splunk Observability Cloud OpenTelemetry Collector からメトリクスを Splunk Observability Cloud に送信する設定が完了したので、Splunk Observability Cloud でデータを確認してみましょう。Splunk Observability Cloud への招待を受け取っていない場合は、インストラクターがログイン資格情報を提供します。\nその前に、少し面白くするためにインスタンスでストレステストを実行してみましょう。これによりダッシュボードが活性化されます。\nsudo apt install stress while true; do stress -c 2 -t 40; stress -d 5 -t 40; stress -m 20 -t 40; done Splunk Observability Cloud にログインしたら、左側のナビゲーションを使用してメインメニューから Dashboards に移動します。これによりチームビューが表示されます。このビューの上部にある All Dashboards をクリックします\n検索ボックスで OTel Contrib を検索します",
    "tags": [],
    "title": "データの可視化",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/7-visualisation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "Splunk Observability Cloud OpenTelemetry Collector を設定して Splunk Observability Cloud にメトリクスを送信するようにしたので、Splunk Observability Cloud でデータを見てみましょう。Splunk Observability Cloud　への招待を受け取っていない場合は、講師がログイン資格情報を提供します。\nその前に、もう少し興味深くするために、インスタンスでストレステストを実行しましょう。これにより、ダッシュボードが活性化されます。\nsudo apt install stress while true; do stress -c 2 -t 40; stress -d 5 -t 40; stress -m 20 -t 40; done Splunk Observability Cloudにログインしたら、左側のナビゲーションを使用して Dashboards に移動します：\n検索ボックスで OTel Contrib を検索します：\n情報 ダッシュボードが存在しない場合は、講師が迅速に追加します。このワークショップの Splunk 主催版に参加していない場合、インポートするダッシュボードグループはこのページの下部にあります。\nOTel Contrib Dashboard ダッシュボードをクリックして開きます：\nダッシュボードの上部にある Filter 欄に「participant」の途中まで入力し、候補に出る participant.name を選択します：\nparticipant.name で、config.yaml 内で設定したあなたの名前を入力するか、リストから選択することができます：\nこれで、OpenTelemetry Collector を設定したホストの、ホストメトリクスを確認することができます。\nダッシュボードJSONのダウンロード方法 index.files/dashboard_OTel-Contrib-Dashboard.json (40 KB)",
    "description": "Splunk Observability Cloud OpenTelemetry Collector を設定して Splunk Observability Cloud にメトリクスを送信するようにしたので、Splunk Observability Cloud でデータを見てみましょう。Splunk Observability Cloud　への招待を受け取っていない場合は、講師がログイン資格情報を提供します。\nその前に、もう少し興味深くするために、インスタンスでストレステストを実行しましょう。これにより、ダッシュボードが活性化されます。\nsudo apt install stress while true; do stress -c 2 -t 40; stress -d 5 -t 40; stress -m 20 -t 40; done Splunk Observability Cloudにログインしたら、左側のナビゲーションを使用して Dashboards に移動します：\n検索ボックスで OTel Contrib を検索します：",
    "tags": [],
    "title": "データの可視化",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/7-visualisation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "Lambda Tracing ワークショップを終えたことをおめでとうございます！自動計装を手動のステップで補完して、producer-lambda関数のコンテキストを Kinesis ストリーム内のレコードを介してconsumer-lambda関数に送信する方法を見てきました。これにより、期待される分散トレースを構築し、Splunk APM で両方の関数間の関係をコンテキスト化することができました。\nこれで、2 つの異なる関数を手動でリンクしてトレースを構築することができます。これは、自動計装や第三者のシステムがコンテキスト伝播を標準でサポートしていない場合や、より関連性の高いトレース分析のためにカスタム属性をトレースに追加したい場合に役立ちます。",
    "description": "Lambda Tracing ワークショップを終えたことをおめでとうございます！自動計装を手動のステップで補完して、producer-lambda関数のコンテキストを Kinesis ストリーム内のレコードを介してconsumer-lambda関数に送信する方法を見てきました。これにより、期待される分散トレースを構築し、Splunk APM で両方の関数間の関係をコンテキスト化することができました。\nこれで、2 つの異なる関数を手動でリンクしてトレースを構築することができます。これは、自動計装や第三者のシステムがコンテキスト伝播を標準でサポートしていない場合や、より関連性の高いトレース分析のためにカスタム属性をトレースに追加したい場合に役立ちます。",
    "tags": [],
    "title": "結論",
    "uri": "/observability-workshop/ja/ninja-workshops/6-lambda-kinesis/7-summary/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "OpenTelemetry の Routing Connector は、特定の条件に基づいてデータ（traces、metrics、または logs）を異なるパイプライン/宛先に振り分けることができる強力な機能です。これは、テレメトリデータのサブセットに異なる処理やエクスポートロジックを適用したい場合に特に有用です。\n例えば、本番環境 のデータを1つのエクスポーターに送信し、テスト や 開発 のデータを別のエクスポーターに振り分けることができます。同様に、サービス名、環境、スパン名などの属性に基づいて特定のスパンをルーティングし、カスタムの処理やストレージロジックを適用することもできます。\nExercise 重要 すべてのターミナルウィンドウを 6-routing-data ディレクトリに移動し、clear コマンドを実行してください。\n5-transform-data ディレクトリから *.yaml を 6-routing-data にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml 次に、Routing Connector とそれぞれのパイプラインを設定します。",
    "description": "OpenTelemetry の Routing Connector は、特定の条件に基づいてデータ（traces、metrics、または logs）を異なるパイプライン/宛先に振り分けることができる強力な機能です。これは、テレメトリデータのサブセットに異なる処理やエクスポートロジックを適用したい場合に特に有用です。\n例えば、本番環境 のデータを1つのエクスポーターに送信し、テスト や 開発 のデータを別のエクスポーターに振り分けることができます。同様に、サービス名、環境、スパン名などの属性に基づいて特定のスパンをルーティングし、カスタムの処理やストレージロジックを適用することもできます。\nExercise 重要 すべてのターミナルウィンドウを 6-routing-data ディレクトリに移動し、clear コマンドを実行してください。\n5-transform-data ディレクトリから *.yaml を 6-routing-data にコピーします。更新後のディレクトリ構造は次のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml 次に、Routing Connector とそれぞれのパイプラインを設定します。",
    "tags": [],
    "title": "6. Routing Data",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/6-routing-data/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "この時点まで、コード変更は一切なく、トレーシング、プロファイリング、データベースクエリパフォーマンスのデータが Splunk Observability Cloud に送信されています。\n次に、Splunk Log Observer を使用して Spring PetClinic アプリケーションからログデータを取得します。\nSplunk OpenTelemetry Collector は、Spring PetClinic アプリケーションからログを自動的に収集し、OTLP エクスポーターを使用して Splunk Observability Cloud に送信します。その際、ログイベントには trace_id、span_id、トレースフラグが付与されます。\nSplunk Log Observer を使用してログを表示し、ログ情報をサービスやトレースと自動的に関連付けます。\nこの機能は Related Content と呼ばれています。",
    "description": "この時点まで、コード変更は一切なく、トレーシング、プロファイリング、データベースクエリパフォーマンスのデータが Splunk Observability Cloud に送信されています。\n次に、Splunk Log Observer を使用して Spring PetClinic アプリケーションからログデータを取得します。\nSplunk OpenTelemetry Collector は、Spring PetClinic アプリケーションからログを自動的に収集し、OTLP エクスポーターを使用して Splunk Observability Cloud に送信します。その際、ログイベントには trace_id、span_id、トレースフラグが付与されます。\nSplunk Log Observer を使用してログを表示し、ログ情報をサービスやトレースと自動的に関連付けます。\nこの機能は Related Content と呼ばれています。",
    "tags": [],
    "title": "Log Observer",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/7-log-observer-connect/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念",
    "content": "カスタムコンポーネントの開発 OpenTelemetry Collector 用のコンポーネントを構築するには、3つの主要な部分が必要です\nConfiguration - ユーザーに公開される設定値 Factory - 提供された値を使用してコンポーネントを作成する Business Logic - コンポーネントが実行する必要がある処理 ここでは、プロジェクトの重要な DevOps メトリクスを追跡できるように、Jenkins と連携するコンポーネントを構築する例を使用します。\n測定しようとしているメトリクスは以下の通りです\nLead time for changes - “コミットが本番環境にデプロイされるまでにかかる時間” Change failure rate - “本番環境で障害を引き起こすデプロイメントの割合” Deployment frequency - \"[チーム]が本番環境に正常にリリースする頻度\" Mean time to recover - \"[チーム]が本番環境の障害から復旧するまでにかかる時間\" これらの指標は、ソフトウェア開発チームのパフォーマンスを示すために、Google の DevOps Research and Assessment（DORA）[^1] チームによって特定されました。Jenkins CI を選択した理由は、同じオープンソースソフトウェアのエコシステム内にとどまることで、将来ベンダーが管理する CI ツールが採用するための例として機能できるからです。\n計装 vs コンポーネント 組織内のオブザーバビリティのレベルを向上させる際に考慮すべきことがあります。いくつかのトレードオフが生じるためです。\nメリット デメリット （自動）計装 システムを監視するために外部 API を監視する必要がありません。 計装を変更するにはプロジェクトへの変更が必要です。 システムオーナー/開発者がオブザーバビリティを変更する権限を持てます。 追加のランタイム依存関係が必要です。 システムコンテキストを理解し、キャプチャしたデータを Exemplars と関連付けることができます。 システムのパフォーマンスに影響を与える可能性があります。 コンポーネント データ名やセマンティクスへの変更をシステムのリリースサイクルとは独立して展開できます。 API の破壊的な変更には、システムと Collector の間で調整されたリリースが必要です。 収集されるデータの更新/拡張は、ユーザーにとってシームレスな変更です。 キャプチャされたデータのセマンティクスが、新しいシステムリリースと一致しない形で予期せず壊れる可能性があります。 サポートチームがオブザーバビリティの実践について深い理解を持つ必要がありません。 システムから外部に公開された情報のみを表面化できます。",
    "description": "カスタムコンポーネントの開発 OpenTelemetry Collector 用のコンポーネントを構築するには、3つの主要な部分が必要です\nConfiguration - ユーザーに公開される設定値 Factory - 提供された値を使用してコンポーネントを作成する Business Logic - コンポーネントが実行する必要がある処理 ここでは、プロジェクトの重要な DevOps メトリクスを追跡できるように、Jenkins と連携するコンポーネントを構築する例を使用します。\n測定しようとしているメトリクスは以下の通りです\nLead time for changes - “コミットが本番環境にデプロイされるまでにかかる時間” Change failure rate - “本番環境で障害を引き起こすデプロイメントの割合” Deployment frequency - \"[チーム]が本番環境に正常にリリースする頻度\" Mean time to recover - \"[チーム]が本番環境の障害から復旧するまでにかかる時間\" これらの指標は、ソフトウェア開発チームのパフォーマンスを示すために、Google の DevOps Research and Assessment（DORA）[^1] チームによって特定されました。Jenkins CI を選択した理由は、同じオープンソースソフトウェアのエコシステム内にとどまることで、将来ベンダーが管理する CI ツールが採用するための例として機能できるからです。\n計装 vs コンポーネント 組織内のオブザーバビリティのレベルを向上させる際に考慮すべきことがあります。いくつかのトレードオフが生じるためです。",
    "tags": [],
    "title": "OpenTelemetry Collector 開発",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/8-develop/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "カスタムコンポーネントの開発 Open Telemetry Collectorのためのコンポーネントを構築するには、以下の3つの主要な部分が必要です：\nConfiguration - ユーザーが設定できる値は何か Factory - 提供された値を使ってコンポーネントを作成する Business Logic - コンポーネントが実行する必要があること これについて、プロジェクトの重要なDevOpsメトリクスを追跡するためにJenkinsと連携するコンポーネントを構築する例を考えていきます。\n測定しようとしているメトリクスは次のとおりです：\n変更に対するリードタイム - 「コミットが本番環境に入るまでにかかる時間」 変更失敗率 - 「本番環境での障害を引き起こすデプロイの割合」 デプロイ頻度 - 「[チーム]が本番環境に成功してリリースする頻度」 平均復旧時間 - 「[チーム]が本番環境の障害から復旧するのにかかる時間」 これらの指標は Google の DevOps Research and Assessment (DORA) チームによって特定されたもので、ソフトウェア開発チームのパフォーマンスを示すのに役立ちます。Jenkins CI を選択した理由は、私たちが同じオープンソースソフトウェアエコシステムに留まり、将来的にベンダー管理のCIツールが採用する例となることができるためです。\n計装 🆚 コンポーネント 組織内でオブザーバビリティを向上させる際には、トレードオフが発生するため、考慮する点があります。\n長所 短所 （自動）計装1 システムを観測するために外部APIが不要 計装を変更するにはプロジェクトの変更が必要 システム所有者/開発者は可観測性の変更が可能 ランタイムへの追加の依存が必要 システムの文脈を理解し、Exemplar とキャプチャされたデータを関連付けることが可能 システムのパフォーマンスに影響を与える可能性がある コンポーネント データ名や意味の変更をシステムのリリースサイクルから独立した展開が可能 APIの破壊的な変更の可能性があり、システムとコレクター間でリリースの調整が必要 その後の利用に合わせて収集されるデータの更新/拡張が容易 キャプチャされたデータの意味がシステムリリースと一致せず、予期せず壊れる可能性がある 計装（instrument, インストゥルメント）とは、アプリケーションなどのシステムコンポーネントに対して、トレースやメトリクス、ログなどのテレメトリーデータを出力させる実装。計装ライブラリを最低限セットアップするだけで一通りのトレースやメトリクスなどを出力できるような対応を「自動計装」と呼びます。 ↩︎",
    "description": "カスタムコンポーネントの開発 Open Telemetry Collectorのためのコンポーネントを構築するには、以下の3つの主要な部分が必要です：\nConfiguration - ユーザーが設定できる値は何か Factory - 提供された値を使ってコンポーネントを作成する Business Logic - コンポーネントが実行する必要があること これについて、プロジェクトの重要なDevOpsメトリクスを追跡するためにJenkinsと連携するコンポーネントを構築する例を考えていきます。\n測定しようとしているメトリクスは次のとおりです：\n変更に対するリードタイム - 「コミットが本番環境に入るまでにかかる時間」 変更失敗率 - 「本番環境での障害を引き起こすデプロイの割合」 デプロイ頻度 - 「[チーム]が本番環境に成功してリリースする頻度」 平均復旧時間 - 「[チーム]が本番環境の障害から復旧するのにかかる時間」 これらの指標は Google の DevOps Research and Assessment (DORA) チームによって特定されたもので、ソフトウェア開発チームのパフォーマンスを示すのに役立ちます。Jenkins CI を選択した理由は、私たちが同じオープンソースソフトウェアエコシステムに留まり、将来的にベンダー管理のCIツールが採用する例となることができるためです。\n計装 🆚 コンポーネント 組織内でオブザーバビリティを向上させる際には、トレードオフが発生するため、考慮する点があります。\n長所 短所 （自動）計装1 システムを観測するために外部APIが不要 計装を変更するにはプロジェクトの変更が必要 システム所有者/開発者は可観測性の変更が可能 ランタイムへの追加の依存が必要 システムの文脈を理解し、Exemplar とキャプチャされたデータを関連付けることが可能 システムのパフォーマンスに影響を与える可能性がある コンポーネント データ名や意味の変更をシステムのリリースサイクルから独立した展開が可能 APIの破壊的な変更の可能性があり、システムとコレクター間でリリースの調整が必要 その後の利用に合わせて収集されるデータの更新/拡張が容易 キャプチャされたデータの意味がシステムリリースと一致せず、予期せず壊れる可能性がある 計装（instrument, インストゥルメント）とは、アプリケーションなどのシステムコンポーネントに対して、トレースやメトリクス、ログなどのテレメトリーデータを出力させる実装。計装ライブラリを最低限セットアップするだけで一通りのトレースやメトリクスなどを出力できるような対応を「自動計装」と呼びます。 ↩︎",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/8-develop/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ SREの帽子を再び被って、オンラインブティックの監視を設定するよう依頼されました。アプリケーションが 24 時間 365 日、利用可能で良好なパフォーマンスを発揮していることを確認する必要があります。\nアプリケーションを 24 時間 365 日監視し、問題が発生したときにアラートを受け取ることができたらいいと思いませんか？ここで Synthetics の出番です。オンラインブティックを通じて典型的なユーザージャーニーのパフォーマンスと可用性を毎分チェックする簡単なテストを紹介します。",
    "description": "このセクションでは、Splunk Syntheticsを使用してアプリケーションのパフォーマンスと可用性を監視する方法を学びます。",
    "tags": [],
    "title": "Splunk Synthetics",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/8-synthetics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "Dockerfile の更新 Kubernetes では、環境変数は通常、Docker イメージに組み込むのではなく.yamlマニフェストファイルで管理されます。そこで、Dockerfile から以下の 2 つの環境変数を削除しましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile 次に、以下の 2 つの環境変数を削除します：\nENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n新しい Docker イメージのビルド 環境変数を除外した新しい Docker イメージをビルドしましょう：\ncd /home/splunk/workshop/docker-k8s-otel/helloworld docker build -t helloworld:1.2 . Note: we’ve used a different version (1.2) to distinguish the image from our earlier version. To clean up the older versions, run the following command to get the container id:\ndocker ps -a Then run the following command to delete the container:\ndocker rm \u003cold container id\u003e --force Now we can get the container image id:\ndocker images | grep 1.1 Finally, we can run the following command to delete the old image:\ndocker image rm \u003cold image id\u003e Docker イメージを Kubernetes にインポート 通常であれば、Docker イメージを Docker Hub などのリポジトリにプッシュします。 しかし、今回のセッションでは、k3s に直接インポートする回避策を使用します。\ncd /home/splunk # Import the image into k3d sudo k3d image import helloworld:1.2 --cluster $INSTANCE-cluster .NET アプリケーションのデプロイ ヒント：vi で編集モードに入るには「i」キーを押します。変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n.NET アプリケーションを K8s にデプロイするために、/home/splunkにdeployment.yamlという名前のファイルを作成しましょう：\nvi /home/splunk/deployment.yaml そして以下を貼り付けます：\napiVersion: apps/v1 kind: Deployment metadata: name: helloworld spec: selector: matchLabels: app: helloworld replicas: 1 template: metadata: labels: app: helloworld spec: containers: - name: helloworld image: docker.io/library/helloworld:1.2 imagePullPolicy: Never ports: - containerPort: 8080 env: - name: PORT value: \"8080\" Kubernetes における Deployment とは？ deployment.yaml ファイルは、deployment リソースを定義するために使用される kubernetes 設定ファイルです。このファイルは Kubernetes でアプリケーションを管理するための基盤となります！deployment 設定は deployment の 望ましい状態 を定義し、Kubernetes が 実際の状態 がそれと一致するよう保証します。これにより、アプリケーション pod の自己修復が可能になり、アプリケーションの簡単な更新やロールバックも可能になります。\n次に、同じディレクトリにservice.yamlという名前の 2 つ目のファイルを作成します：\nvi /home/splunk/service.yaml そして以下を貼り付けます：\napiVersion: v1 kind: Service metadata: name: helloworld labels: app: helloworld spec: type: ClusterIP selector: app: helloworld ports: - port: 8080 protocol: TCP Kubernetes における Service とは？ Kubernetes の Service は抽象化レイヤーであり、仲介者のような役割を果たします。Pod にアクセスするための固定 IP アドレスや DNS 名を提供し、時間の経過とともに Pod が追加、削除、または交換されても同じままです。\nこれらのマニフェストファイルを使用してアプリケーションをデプロイできます：\n​ Script Example Output # create the deployment kubectl apply -f deployment.yaml # create the service kubectl apply -f service.yaml deployment.apps/helloworld created service/helloworld created アプリケーションのテスト アプリケーションにアクセスするには、まず IP アドレスを取得する必要があります：\n​ Script Example Output kubectl describe svc helloworld | grep IP: IP: 10.43.102.103 その後、前のコマンドから返された Cluster IP を使用してアプリケーションにアクセスできます。 例：\ncurl http://10.43.102.103:8080/hello/Kubernetes OpenTelemetry の設定 .NET OpenTelemetry 計装はすでに Docker イメージに組み込まれています。しかし、データの送信先を指定するためにいくつかの環境変数を設定する必要があります。\n先ほど作成したdeployment.yamlファイルに以下を追加します：\n重要 以下の YAML の$INSTANCEをあなたのインスタンス名に置き換えてください。 インスタンス名はecho $INSTANCEを実行することで確認できます。\nenv: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=otel-$INSTANCE\" 完全なdeployment.yamlファイルは以下のようになります（$INSTANCEではなくあなたのインスタンス名を使用してください）：\napiVersion: apps/v1 kind: Deployment metadata: name: helloworld spec: selector: matchLabels: app: helloworld replicas: 1 template: metadata: labels: app: helloworld spec: containers: - name: helloworld image: docker.io/library/helloworld:1.2 imagePullPolicy: Never ports: - containerPort: 8080 env: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=otel-$INSTANCE\" 以下のコマンドで変更を適用します：\n​ Script Example Output kubectl apply -f deployment.yaml deployment.apps/helloworld configured その後、curlを使用してトラフィックを生成します。\n1 分ほど経過すると、o11y cloud でトレースが流れているのが確認できるはずです。ただし、より早くトレースを確認したい場合は、以下の方法があります…\nチャレンジ 開発者として、トレース ID を素早く取得するか、コンソールフィードバックを見たい場合、deployment.yaml ファイルにどのような環境変数を追加できるでしょうか？\n答えを見るにはここをクリック セクション 4「.NET Application を OpenTelemetry で計装する」のチャレンジで思い出していただければ、OTEL_TRACES_EXPORTER環境変数を使って trace を console に書き込むトリックをお見せしました。この変数を deployment.yaml に追加し、アプリケーションを再 deploy して、helloworld アプリから log を tail することで、trace id を取得して Splunk Observability Cloud で trace を見つけることができます。（ワークショップの次のセクションでは、debug exporter の使用についても説明します。これは K8s 環境でアプリケーションを debug する際の典型的な方法です。）\nまず、vi で deployment.yaml ファイルを開きます：\nvi deployment.yaml 次に、OTEL_TRACES_EXPORTER環境変数を追加します：\nenv: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=YOURINSTANCE\" # NEW VALUE HERE: - name: OTEL_TRACES_EXPORTER value: \"otlp,console\" 変更を保存してからアプリケーションを再 deploy します：\n​ Script Example Output kubectl apply -f deployment.yaml deployment.apps/helloworld configured helloworld の log を tail します：\n​ Script Example Output kubectl logs -l app=helloworld -f info: HelloWorldController[0] /hello endpoint invoked by K8s9 Activity.TraceId: 5bceb747cc7b79a77cfbde285f0f09cb Activity.SpanId: ac67afe500e7ad12 Activity.TraceFlags: Recorded Activity.ActivitySourceName: Microsoft.AspNetCore Activity.DisplayName: GET hello/{name?} Activity.Kind: Server Activity.StartTime: 2025-02-04T15:22:48.2381736Z Activity.Duration: 00:00:00.0027334 Activity.Tags: server.address: 10.43.226.224 server.port: 8080 http.request.method: GET url.scheme: http url.path: /hello/K8s9 network.protocol.version: 1.1 user_agent.original: curl/7.81.0 http.route: hello/{name?} http.response.status_code: 200 Resource associated with Activity: splunk.distro.version: 1.8.0 telemetry.distro.name: splunk-otel-dotnet telemetry.distro.version: 1.8.0 os.type: linux os.description: Debian GNU/Linux 12 (bookworm) os.build_id: 6.2.0-1018-aws os.name: Debian GNU/Linux os.version: 12 host.name: helloworld-69f5c7988b-dxkwh process.owner: app process.pid: 1 process.runtime.description: .NET 8.0.12 process.runtime.name: .NET process.runtime.version: 8.0.12 container.id: 39c2061d7605d8c390b4fe5f8054719f2fe91391a5c32df5684605202ca39ae9 telemetry.sdk.name: opentelemetry telemetry.sdk.language: dotnet telemetry.sdk.version: 1.9.0 service.name: helloworld deployment.environment: otel-jen-tko-1b75 次に、別の terminal window で curl コマンドを使って trace を生成します。log を tail している console で trace id が表示されるはずです。Activity.TraceId:の値をコピーして、APM の Trace 検索フィールドに貼り付けてください。",
    "description": "Dockerfile の更新 Kubernetes では、環境変数は通常、Docker イメージに組み込むのではなく.yamlマニフェストファイルで管理されます。そこで、Dockerfile から以下の 2 つの環境変数を削除しましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile 次に、以下の 2 つの環境変数を削除します：\nENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n新しい Docker イメージのビルド 環境変数を除外した新しい Docker イメージをビルドしましょう：\ncd /home/splunk/workshop/docker-k8s-otel/helloworld docker build -t helloworld:1.2 . Note: we’ve used a different version (1.2) to distinguish the image from our earlier version. To clean up the older versions, run the following command to get the container id:",
    "tags": [],
    "title": "アプリケーションをK8sにデプロイ",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/8-deploy-app-k8s/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops",
    "content": "このワークショップでは、以下の項目について実践経験を積むことができます：\nLinux および Kubernetes 環境で、Splunk ディストリビューションの OpenTelemetry .NET を使用してコレクターのデプロイと.NET アプリケーションの計装を実践します。 .NET アプリケーションの「Docker 化」、Docker での実行、そして Splunk OpenTelemetry 計装の追加を実践します。 Helm を使用した K8s 環境での Splunk ディストロのコレクターのデプロイを実践します。その後、コレクター設定をカスタマイズし、問題のトラブルシューティングを行います。 Tip このワークショップを最も簡単にナビゲートする方法は以下を使用することです：\nこのページの右上にある左右の矢印（\u003c | \u003e） キーボードの左（◀️）と右（▶️）のカーソルキー",
    "description": "このワークショップでは、これらの概念を説明するためにシンプルな.NETアプリケーションを使用します。さあ、始めましょう！ワークショップの終わりまでに、OpenTelemetryを使用した.NETアプリケーションの計装の実践経験を積み、そのアプリケーションのDocker化およびKubernetesへのデプロイを行います。また、Helmを使用したOpenTelemetryコレクターのデプロイ、コレクター設定のカスタマイズ、コレクター設定の問題のトラブルシューティングの経験も得られます。",
    "tags": [],
    "title": "OpenTelemetry、Docker、K8sを実践で学ぶ",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "このセクションでは、Count Connector を使用して、ログから属性値を抽出し、意味のあるメトリクスに変換する方法を説明します。\n具体的には、Count Connector を使用して、ログに出現する「Star Wars」と「Lord of the Rings」の名言の数を追跡し、測定可能なデータポイントに変換します。\nExercise 重要 すべてのターミナルウィンドウを 7-sum-count ディレクトリに変更し、clear コマンドを実行してください。\n6-routing-data ディレクトリから *.yaml を 7-sum-count にコピーしてください。更新後のディレクトリ構造は以下のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml agent.yaml を更新して、ログを読み取る頻度を変更します。 agent.yaml 内の filelog/quotes レシーバーを見つけ、poll_interval 属性を追加してください filelog/quotes: # Receiver Type/Name poll_interval: 10s # Only read every ten seconds 遅延を設定する理由は、OpenTelemetry Collector の Count Connector が各処理インターバル内でのみログをカウントするためです。つまり、データが読み取られるたびに、次のインターバルでカウントがゼロにリセットされます。デフォルトの Filelog receiver インターバル 200ms では、loadgen が書き込むすべての行を読み取り、カウントが1になります。このインターバルを設定することで、複数のエントリをカウントできるようになります。\n以下に示すように、条件を省略することで、Collector は各読み取りインターバルの累計カウントを維持できます。ただし、バックエンドは長期間にわたってカウントを追跡できるため、累計カウントはバックエンドに任せるのがベストプラクティスです。\nExercise Count Connector を追加する 設定の connectors セクションに Count Connector を追加し、使用するメトリクスカウンターを定義します\nconnectors: count: logs: logs.full.count: description: \"Running count of all logs read in interval\" logs.sw.count: description: \"StarWarsCount\" conditions: - attributes[\"movie\"] == \"SW\" logs.lotr.count: description: \"LOTRCount\" conditions: - attributes[\"movie\"] == \"LOTR\" logs.error.count: description: \"ErrorCount\" conditions: - attributes[\"level\"] == \"ERROR\" メトリクスカウンターの説明\nlogs.full.count：各読み取りインターバルで処理されたログの総数を追跡します。 このメトリクスにはフィルタリング条件がないため、システムを通過するすべてのログがカウントに含まれます。 logs.sw.count：Star Wars 映画の名言を含むログをカウントします。 logs.lotr.count：Lord of the Rings 映画の名言を含むログをカウントします。 logs.error.count：読み取りインターバルで重大度レベルが ERROR のログをカウントする、実際のシナリオを表します。 パイプラインで Count Connector を設定する 以下のパイプライン設定では、connector exporter が logs セクションに追加され、connector receiver が metrics セクションに追加されています。\npipelines: traces: receivers: - otlp processors: - memory_limiter - attributes/update # Update, hash, and remove attributes - redaction/redact # Redact sensitive fields using regex - resourcedetection - resource/add_mode - batch exporters: - debug - file - otlphttp metrics: receivers: - count # Count Connector that receives count metric from logs count exporter in logs pipeline. - otlp #- hostmetrics # Host Metrics Receiver processors: - memory_limiter - resourcedetection - resource/add_mode - batch exporters: - debug - otlphttp logs: receivers: - otlp - filelog/quotes processors: - memory_limiter - resourcedetection - resource/add_mode - transform/logs # Transform logs processor - batch exporters: - count # Count Connector that exports count as a metric to metrics pipeline. - debug - otlphttp ログは属性に基づいてカウントされます。ログデータが属性ではなくログボディに格納されている場合は、パイプラインで Transform プロセッサーを使用して、キー/バリューのペアを抽出し、属性として追加する必要があります。\nこのワークショップでは、05-transform-data セクションで既に merge_maps(attributes, cache, \"upsert\") を追加しています。これにより、関連するすべてのデータが処理用のログ属性に含まれるようになります。\n属性を作成するフィールドを選択する際は注意が必要です。すべてのフィールドを無差別に追加することは、本番環境では一般的に理想的ではありません。不要なデータの乱雑さを避けるため、本当に必要なフィールドのみを選択してください。\nExercise otelbin.io を使用して agent 設定を検証してください。参考として、パイプラインの logs と metrics: セクションは以下のようになります %%{init:{\"fontFamily\":\"monospace\"}}%% graph LR %% Nodes REC1(otlp\u003cbr\u003efa:fa-download):::receiver REC2(filelog\u003cbr\u003efa:fa-download\u003cbr\u003equotes):::receiver REC3(otlp\u003cbr\u003efa:fa-download):::receiver PRO1(memory_limiter\u003cbr\u003efa:fa-microchip):::processor PRO2(memory_limiter\u003cbr\u003efa:fa-microchip):::processor PRO3(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO4(resource\u003cbr\u003efa:fa-microchip\u003cbr\u003eadd_mode):::processor PRO5(batch\u003cbr\u003efa:fa-microchip):::processor PRO6(batch\u003cbr\u003efa:fa-microchip):::processor PRO7(resourcedetection\u003cbr\u003efa:fa-microchip):::processor PRO8(resourcedetection\u003cbr\u003efa:fa-microchip):::processor PRO9(transfrom\u003cbr\u003efa:fa-microchip\u003cbr\u003elogs):::processor EXP1(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter EXP2(\u0026emsp;\u0026emsp;otlphttp\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload):::exporter EXP3(\u0026nbsp;\u0026ensp;debug\u0026nbsp;\u0026ensp;\u003cbr\u003efa:fa-upload):::exporter EXP4(\u0026emsp;\u0026emsp;otlphttp\u0026emsp;\u0026emsp;\u003cbr\u003efa:fa-upload):::exporter ROUTE1(\u0026nbsp;count\u0026nbsp;\u003cbr\u003efa:fa-route):::con-export ROUTE2(\u0026nbsp;count\u0026nbsp;\u003cbr\u003efa:fa-route):::con-receive %% Links subID1:::sub-logs subID2:::sub-metrics subgraph \" \" direction LR subgraph subID1[**Logs**] direction LR REC1 --\u003e PRO1 REC2 --\u003e PRO1 PRO1 --\u003e PRO7 PRO7 --\u003e PRO3 PRO3 --\u003e PRO9 PRO9 --\u003e PRO5 PRO5 --\u003e ROUTE1 PRO5 --\u003e EXP1 PRO5 --\u003e EXP2 end subgraph subID2[**Metrics**] direction LR ROUTE1 --\u003e ROUTE2 ROUTE2 --\u003e PRO2 REC3 --\u003e PRO2 PRO2 --\u003e PRO8 PRO8 --\u003e PRO4 PRO4 --\u003e PRO6 PRO6 --\u003e EXP3 PRO6 --\u003e EXP4 end end classDef receiver,exporter fill:#8b5cf6,stroke:#333,stroke-width:1px,color:#fff; classDef processor fill:#6366f1,stroke:#333,stroke-width:1px,color:#fff; classDef con-receive,con-export fill:#45c175,stroke:#333,stroke-width:1px,color:#fff; classDef sub-logs stroke:#34d399,stroke-width:1px, color:#34d399,stroke-dasharray: 3 3; classDef sub-metrics stroke:#38bdf8,stroke-width:1px, color:#38bdf8,stroke-dasharray: 3 3;",
    "description": "このセクションでは、Count Connector を使用して、ログから属性値を抽出し、意味のあるメトリクスに変換する方法を説明します。\n具体的には、Count Connector を使用して、ログに出現する「Star Wars」と「Lord of the Rings」の名言の数を追跡し、測定可能なデータポイントに変換します。\nExercise 重要 すべてのターミナルウィンドウを 7-sum-count ディレクトリに変更し、clear コマンドを実行してください。\n6-routing-data ディレクトリから *.yaml を 7-sum-count にコピーしてください。更新後のディレクトリ構造は以下のようになります\n​ Updated Directory Structure . ├── agent.yaml └── gateway.yaml agent.yaml を更新して、ログを読み取る頻度を変更します。 agent.yaml 内の filelog/quotes レシーバーを見つけ、poll_interval 属性を追加してください filelog/quotes: # Receiver Type/Name poll_interval: 10s # Only read every ten seconds 遅延を設定する理由は、OpenTelemetry Collector の Count Connector が各処理インターバル内でのみログをカウントするためです。つまり、データが読み取られるたびに、次のインターバルでカウントがゼロにリセットされます。デフォルトの Filelog receiver インターバル 200ms では、loadgen が書き込むすべての行を読み取り、カウントが1になります。このインターバルを設定することで、複数のエントリをカウントできるようになります。",
    "tags": [],
    "title": "7. Count Connector でメトリクスを作成する",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/7-sum-count/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "アプリケーションに Real User Monitoring (RUM) インストルメンテーションを有効にするには、コードベースに Open Telemetry Javascript https://github.com/signalfx/splunk-otel-js-web スニペットを追加する必要があります。\nSpring PetClinic アプリケーションは、アプリケーションのすべてのビューで再利用される単一の index HTML ページを使用しています。これは、Splunk RUM インストルメンテーションライブラリを挿入するのに最適な場所です。すべてのページで自動的に読み込まれるためです。\napi-gateway サービスはすでにインストルメンテーションを実行しており、RUM トレースを Splunk Observability Cloud に送信しています。次のセクションでデータを確認します。\nスニペットを確認したい場合は、ブラウザでページを右クリックして View Page Source を選択することで、ページソースを表示できます。\n\u003cscript src=\"/env.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e var realm = env.RUM_REALM; console.log('Realm:', realm); var auth = env.RUM_AUTH; var appName = env.RUM_APP_NAME; var environmentName = env.RUM_ENVIRONMENT if (realm \u0026\u0026 auth) { SplunkRum.init({ realm: realm, rumAccessToken: auth, applicationName: appName, deploymentEnvironment: environmentName, version: '1.0.0', }); SplunkSessionRecorder.init({ applicationName: appName, realm: realm, rumAccessToken: auth, recorder: \"splunk\", features: { video: true, } }); const Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); } else { // Realm or auth is empty, provide default values or skip initialization console.log(\"Realm or auth is empty. Skipping Splunk Rum initialization.\"); } \u003c/script\u003e \u003c!-- Section added for RUM --\u003e",
    "description": "アプリケーションに Real User Monitoring (RUM) インストルメンテーションを有効にするには、コードベースに Open Telemetry Javascript https://github.com/signalfx/splunk-otel-js-web スニペットを追加する必要があります。\nSpring PetClinic アプリケーションは、アプリケーションのすべてのビューで再利用される単一の index HTML ページを使用しています。これは、Splunk RUM インストルメンテーションライブラリを挿入するのに最適な場所です。すべてのページで自動的に読み込まれるためです。\napi-gateway サービスはすでにインストルメンテーションを実行しており、RUM トレースを Splunk Observability Cloud に送信しています。次のセクションでデータを確認します。\nスニペットを確認したい場合は、ブラウザでページを右クリックして View Page Source を選択することで、ページソースを表示できます。\n\u003cscript src=\"/env.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e var realm = env.RUM_REALM; console.log('Realm:', realm); var auth = env.RUM_AUTH; var appName = env.RUM_APP_NAME; var environmentName = env.RUM_ENVIRONMENT if (realm \u0026\u0026 auth) { SplunkRum.init({ realm: realm, rumAccessToken: auth, applicationName: appName, deploymentEnvironment: environmentName, version: '1.0.0', }); SplunkSessionRecorder.init({ applicationName: appName, realm: realm, rumAccessToken: auth, recorder: \"splunk\", features: { video: true, } }); const Provider = SplunkRum.provider; var tracer=Provider.getTracer('appModuleLoader'); } else { // Realm or auth is empty, provide default values or skip initialization console.log(\"Realm or auth is empty. Skipping Splunk Rum initialization.\"); } \u003c/script\u003e \u003c!-- Section added for RUM --\u003e",
    "tags": [],
    "title": "Real User Monitoring",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/8-rum/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 8. Develop",
    "content": "プロジェクトのセットアップ Ninja メモ このワークショップセクションを完了するまでの時間は、経験によって異なります。\n行き詰まった場合やインストラクターに沿って進めたい場合は、こちらに完全なソリューションがあります。\n新しい Jenkins CI レシーバーの開発を始めるには、まず Golang プロジェクトをセットアップする必要があります。 新しい Golang プロジェクトを作成する手順は以下の通りです\n${HOME}/go/src/jenkinscireceiver という名前の新しいディレクトリを作成し、そのディレクトリに移動します 実際のディレクトリ名や場所は厳密ではなく、独自の開発ディレクトリを選択して作成できます。 go mod init splunk.conf/workshop/example/jenkinscireceiver を実行して golang モジュールを初期化します これにより go.mod というファイルが作成され、直接的および間接的な依存関係を追跡するために使用されます 最終的には、インポートされる依存関係のチェックサム値である go.sum が生成されます。 Check-ingo.mod を確認する module splunk.conf/workshop/example/jenkinscireceiver go 1.20",
    "description": "プロジェクトのセットアップ Ninja メモ このワークショップセクションを完了するまでの時間は、経験によって異なります。\n行き詰まった場合やインストラクターに沿って進めたい場合は、こちらに完全なソリューションがあります。\n新しい Jenkins CI レシーバーの開発を始めるには、まず Golang プロジェクトをセットアップする必要があります。 新しい Golang プロジェクトを作成する手順は以下の通りです\n${HOME}/go/src/jenkinscireceiver という名前の新しいディレクトリを作成し、そのディレクトリに移動します 実際のディレクトリ名や場所は厳密ではなく、独自の開発ディレクトリを選択して作成できます。 go mod init splunk.conf/workshop/example/jenkinscireceiver を実行して golang モジュールを初期化します これにより go.mod というファイルが作成され、直接的および間接的な依存関係を追跡するために使用されます 最終的には、インポートされる依存関係のチェックサム値である go.sum が生成されます。 Check-ingo.mod を確認する module splunk.conf/workshop/example/jenkinscireceiver go 1.20",
    "tags": [],
    "title": "OpenTelemetry Collector 開発",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/8-develop/1-project-setup/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "プロジェクトのセットアップ Ninja メモ このワークショップのセクションを完了する時間は経験によって異なる場合があります。\n完成したものはこちらにあります。詰まった場合や講師と一緒に進めたい場合に利用してください。\n新しい Jenkins CI レシーバーの開発を始めるため、まずは Go プロジェクトのセットアップから始めていきます。 新しい Go プロジェクトを作成する手順は以下の通りです：\n${HOME}/go/src/jenkinscireceiver という名前の新しいディレクトリを作成し、そのディレクトリに移動します。 実際のディレクトリ名や場所は厳密ではありません。自分の開発ディレクトリを自由に選ぶことができます。 go mod init splunk.conf/workshop/example/jenkinscireceiver を実行して、Go のモジュールを初期化します。 依存関係を追跡するために使用される go.mod というファイルが作成されます。 インポートされている依存関係のチェックサム値が go.sum として保存されます。 Check-ingo.modをレビューする `` text module splunk.conf/workshop/example/jenkinscireceiver\ngo 1.20",
    "description": "プロジェクトのセットアップ Ninja メモ このワークショップのセクションを完了する時間は経験によって異なる場合があります。\n完成したものはこちらにあります。詰まった場合や講師と一緒に進めたい場合に利用してください。\n新しい Jenkins CI レシーバーの開発を始めるため、まずは Go プロジェクトのセットアップから始めていきます。 新しい Go プロジェクトを作成する手順は以下の通りです：\n${HOME}/go/src/jenkinscireceiver という名前の新しいディレクトリを作成し、そのディレクトリに移動します。 実際のディレクトリ名や場所は厳密ではありません。自分の開発ディレクトリを自由に選ぶことができます。 go mod init splunk.conf/workshop/example/jenkinscireceiver を実行して、Go のモジュールを初期化します。 依存関係を追跡するために使用される go.mod というファイルが作成されます。 インポートされている依存関係のチェックサム値が go.sum として保存されます。 Check-ingo.modをレビューする `` text module splunk.conf/workshop/example/jenkinscireceiver\ngo 1.20",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/8-develop/1-project-setup/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "デフォルト設定を使用して K8s クラスターに Splunk Distribution of OpenTelemetry コレクターを デプロイしました。このセクションでは、コレクター設定をカスタマイズする方法をいくつかの例で 説明します。\nコレクター設定の取得 コレクター設定をカスタマイズする前に、現在の設定がどのようになっているかを どのように確認するのでしょうか？\nKubernetes 環境では、コレクター設定は Config Map を使用して保存されます。\n以下のコマンドで、クラスターに存在する config map を確認できます：\n​ Script Example Output kubectl get cm -l app=splunk-otel-collector NAME DATA AGE splunk-otel-collector-otel-k8s-cluster-receiver 1 3h37m splunk-otel-collector-otel-agent 1 3h37m なぜ 2 つの config map があるのでしょうか？\n次に、以下のようにコレクターエージェントの config map を表示できます：\n​ Script Example Output kubectl describe cm splunk-otel-collector-otel-agent Name: splunk-otel-collector-otel-agent Namespace: default Labels: app=splunk-otel-collector app.kubernetes.io/instance=splunk-otel-collector app.kubernetes.io/managed-by=Helm app.kubernetes.io/name=splunk-otel-collector app.kubernetes.io/version=0.113.0 chart=splunk-otel-collector-0.113.0 helm.sh/chart=splunk-otel-collector-0.113.0 heritage=Helm release=splunk-otel-collector Annotations: meta.helm.sh/release-name: splunk-otel-collector meta.helm.sh/release-namespace: default Data ==== relay: ---- exporters: otlphttp: headers: X-SF-Token: ${SPLUNK_OBSERVABILITY_ACCESS_TOKEN} metrics_endpoint: https://ingest.us1.signalfx.com/v2/datapoint/otlp traces_endpoint: https://ingest.us1.signalfx.com/v2/trace/otlp (followed by the rest of the collector config in yaml format) K8s でコレクター設定を更新する方法 Linux インスタンスでコレクターを実行した以前の例では、コレクター設定は /etc/otel/collector/agent_config.yamlファイルで利用可能でした。その場合にコレクター設定を 変更する必要があれば、単純にこのファイルを編集し、変更を保存してから コレクターを再起動すればよかったのです。\nK8s では、少し異なる動作をします。agent_config.yamlを直接変更する代わりに、 helm チャートをデプロイするために使用されるvalues.yamlファイルを変更することで コレクター設定をカスタマイズします。\nGitHubの values.yaml ファイルには、 利用可能なカスタマイズオプションが記載されています。\n例を見てみましょう。\nInfrastructure Events Monitoring の追加 最初の例として、K8s クラスターの infrastructure events monitoring を有効にしましょう。\nこれにより、charts の Events Feed セクションの一部として Kubernetes イベントを確認できるようになります。 cluster receiver は、kubernetes-events monitor を使用して Smart Agent receiver で設定され、custom イベントを送信します。詳細についてはCollect Kubernetes eventsを参照してください。\nこれはvalues.yamlファイルに以下の行を追加することで実行されます：\nヒント：vi での開き方と保存方法は前のステップにあります。\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: ファイルが保存されたら、以下のコマンドで変更を適用できます：\n​ Script Example Output helm upgrade splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector Release \"splunk-otel-collector\" has been upgraded. Happy Helming! NAME: splunk-otel-collector LAST DEPLOYED: Fri Dec 20 01:17:03 2024 NAMESPACE: default STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Observability realm us1. その後、config map を表示して変更が適用されたことを確認できます：\n​ Script Example Output kubectl describe cm splunk-otel-collector-otel-k8s-cluster-receiver smartagent/kubernetes-eventsが agent config に含まれていることを確認してください：\nsmartagent/kubernetes-events: alwaysClusterReporter: true type: kubernetes-events whitelistedEvents: - involvedObjectKind: Pod reason: Created - involvedObjectKind: Pod reason: Unhealthy - involvedObjectKind: Pod reason: Failed - involvedObjectKind: Job reason: FailedCreate これらの特定の変更が適用されるのは cluster receiver config map なので、そちらを指定していることに注意してください。\nDebug Exporter の追加 collector に送信される trace と log を確認して、 Splunk に送信する前に検査したいとします。この目的のために debug exporter を使用できます。これは OpenTelemetry 関連の問題のトラブルシューティングに役立ちます。\nvalues.yaml ファイルの下部に以下のように debug exporter を追加しましょう：\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: config: receivers: ... exporters: debug: verbosity: detailed service: pipelines: traces: exporters: - debug logs: exporters: - debug ファイルが保存されたら、以下のコマンドで変更を適用できます：\n​ Script Example Output helm upgrade splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector Release \"splunk-otel-collector\" has been upgraded. Happy Helming! NAME: splunk-otel-collector LAST DEPLOYED: Fri Dec 20 01:32:03 2024 NAMESPACE: default STATUS: deployed REVISION: 3 TEST SUITE: None NOTES: Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Observability realm us1. curl を使用してアプリケーションを数回実行してから、以下のコマンドで agent collector の log を tail します：\nkubectl logs -l component=otel-collector-agent -f 以下のような trace が agent collector の log に書き込まれているのが確認できるはずです：\n2024-12-20T01:43:52.929Z info Traces {\"kind\": \"exporter\", \"data_type\": \"traces\", \"name\": \"debug\", \"resource spans\": 1, \"spans\": 2} 2024-12-20T01:43:52.929Z info ResourceSpans #0 Resource SchemaURL: https://opentelemetry.io/schemas/1.6.1 Resource attributes: -\u003e splunk.distro.version: Str(1.8.0) -\u003e telemetry.distro.name: Str(splunk-otel-dotnet) -\u003e telemetry.distro.version: Str(1.8.0) -\u003e os.type: Str(linux) -\u003e os.description: Str(Debian GNU/Linux 12 (bookworm)) -\u003e os.build_id: Str(6.8.0-1021-aws) -\u003e os.name: Str(Debian GNU/Linux) -\u003e os.version: Str(12) -\u003e host.name: Str(derek-1) -\u003e process.owner: Str(app) -\u003e process.pid: Int(1) -\u003e process.runtime.description: Str(.NET 8.0.11) -\u003e process.runtime.name: Str(.NET) -\u003e process.runtime.version: Str(8.0.11) -\u003e container.id: Str(78b452a43bbaa3354a3cb474010efd6ae2367165a1356f4b4000be031b10c5aa) -\u003e telemetry.sdk.name: Str(opentelemetry) -\u003e telemetry.sdk.language: Str(dotnet) -\u003e telemetry.sdk.version: Str(1.9.0) -\u003e service.name: Str(helloworld) -\u003e deployment.environment: Str(otel-derek-1) -\u003e k8s.pod.ip: Str(10.42.0.15) -\u003e k8s.pod.labels.app: Str(helloworld) -\u003e k8s.pod.name: Str(helloworld-84865965d9-nkqsx) -\u003e k8s.namespace.name: Str(default) -\u003e k8s.pod.uid: Str(38d39bc6-1309-4022-a569-8acceef50942) -\u003e k8s.node.name: Str(derek-1) -\u003e k8s.cluster.name: Str(derek-1-cluster) そして以下のような log エントリも確認できます：\n2024-12-20T01:43:53.215Z info Logs {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\", \"resource logs\": 1, \"log records\": 2} 2024-12-20T01:43:53.215Z info ResourceLog #0 Resource SchemaURL: https://opentelemetry.io/schemas/1.6.1 Resource attributes: -\u003e splunk.distro.version: Str(1.8.0) -\u003e telemetry.distro.name: Str(splunk-otel-dotnet) -\u003e telemetry.distro.version: Str(1.8.0) -\u003e os.type: Str(linux) -\u003e os.description: Str(Debian GNU/Linux 12 (bookworm)) -\u003e os.build_id: Str(6.8.0-1021-aws) -\u003e os.name: Str(Debian GNU/Linux) -\u003e os.version: Str(12) -\u003e host.name: Str(derek-1) -\u003e process.owner: Str(app) -\u003e process.pid: Int(1) -\u003e process.runtime.description: Str(.NET 8.0.11) -\u003e process.runtime.name: Str(.NET) -\u003e process.runtime.version: Str(8.0.11) -\u003e container.id: Str(78b452a43bbaa3354a3cb474010efd6ae2367165a1356f4b4000be031b10c5aa) -\u003e telemetry.sdk.name: Str(opentelemetry) -\u003e telemetry.sdk.language: Str(dotnet) -\u003e telemetry.sdk.version: Str(1.9.0) -\u003e service.name: Str(helloworld) -\u003e deployment.environment: Str(otel-derek-1) -\u003e k8s.node.name: Str(derek-1) -\u003e k8s.cluster.name: Str(derek-1-cluster) ただし、Splunk Observability Cloud に戻ると、アプリケーションから trace と log が もはやそこに送信されていないことに気づくでしょう。\nなぜそうなったと思いますか？次のセクションで詳しく説明します。",
    "description": "デフォルト設定を使用して K8s クラスターに Splunk Distribution of OpenTelemetry コレクターを デプロイしました。このセクションでは、コレクター設定をカスタマイズする方法をいくつかの例で 説明します。\nコレクター設定の取得 コレクター設定をカスタマイズする前に、現在の設定がどのようになっているかを どのように確認するのでしょうか？\nKubernetes 環境では、コレクター設定は Config Map を使用して保存されます。\n以下のコマンドで、クラスターに存在する config map を確認できます：\n​ Script Example Output kubectl get cm -l app=splunk-otel-collector NAME DATA AGE splunk-otel-collector-otel-k8s-cluster-receiver 1 3h37m splunk-otel-collector-otel-agent 1 3h37m なぜ 2 つの config map があるのでしょうか？",
    "tags": [],
    "title": "OpenTelemetryコレクター設定のカスタマイズ",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/9-customize-collector-config/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e 自動ディスカバリーワークショップ \u003e PetClinic Kubernetes ワークショップ",
    "content": "おめでとうございます。Get the Most Out of Your Existing Kubernetes Java Applications Using Automatic Discovery and Configuration With OpenTelemetry ワークショップを完了しました。\n今日、既存の Kubernetes 上の Java アプリケーションにトレース、コードプロファイリング、データベースクエリパフォーマンスを追加することがいかに簡単かを学びました。\nAutomatic Discovery and Configuration を使用して、コードや設定に一切触れることなく、アプリケーションとインフラストラクチャの可観測性を即座に向上させました。\nまた、シンプルな設定変更により、さらに多くの可観測性 (logging や RUM) をアプリケーションに追加して、エンドツーエンドの可観測性を提供できることも学びました。",
    "description": "おめでとうございます。OpenTelemetry の自動検出と設定を使用して既存の Kubernetes Java アプリケーションを最大限に活用するワークショップを完了しました。今日、既存の Kubernetes 上の Java アプリケーションにトレース、コードプロファイリング、データベースクエリパフォーマンスを追加することがいかに簡単かを学びました。これにより、アプリケーションとインフラストラクチャの可観測性を即座に向上させることができます。",
    "tags": [],
    "title": "Workshop Wrap-up 🎁",
    "uri": "/observability-workshop/ja/ninja-workshops/1-automatic-discovery/2-petclinic-kubernetes/9-wrap-up/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ SREの帽子が似合っているので、引き続き着用してpaymentservice用のカスタムサービスヘルスダッシュボードの構築を依頼されたと想定します。要件は RED メトリクス、ログ、Synthetic テスト期間の結果を表示することです。\n開発チームと SRE チームが、アプリケーションやサービスの健全性の概要を必要とすることは一般的です。これらは多くの場合、壁に取り付けられた TV に表示されます。Splunk Observability Cloud は、カスタムダッシュボードを作成することでこれに最適なソリューションを提供しています。\nこのセクションでは、チームのモニターや TV に表示するためのサービスヘルスダッシュボードを構築します。",
    "description": "このセクションでは、サービスの健全性を監視するためのカスタムサービスヘルスダッシュボードの構築方法を学びます。",
    "tags": [],
    "title": "カスタムサービスヘルスダッシュボード 🏥",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/9-custom-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "前のセクションでは、debug エクスポーターをコレクターの設定に追加し、 トレースとログのパイプラインの一部にしました。期待通りに、debug 出力が エージェントコレクターのログに書き込まれているのが確認できます。\nしかし、トレースが o11y cloud に送信されなくなっています。なぜなのかを把握して修正しましょう。\nコレクター設定を確認する values.yamlファイルを通じてコレクター設定が変更された場合は、 config map を確認してコレクターに実際に適用された設定を確認することが役立ちます：\nkubectl describe cm splunk-otel-collector-otel-agent エージェントコレクター設定のログとトレースのパイプラインを確認しましょう。次のようになっているはずです：\npipelines: logs: exporters: - debug processors: - memory_limiter - k8sattributes - filter/logs - batch - resourcedetection - resource - resource/logs - resource/add_environment receivers: - filelog - fluentforward - otlp ... traces: exporters: - debug processors: - memory_limiter - k8sattributes - batch - resourcedetection - resource - resource/add_environment receivers: - otlp - jaeger - smartagent/signalfx-forwarder - zipkin 問題がわかりますか？debug エクスポーターのみがトレースとログのパイプラインに含まれています。 以前のトレースパイプライン設定にあったotlphttpとsignalfxエクスポーターがなくなっています。 これが、もう o11y cloud でトレースが見えなくなった理由です。ログパイプラインについても、splunk_hec/platform_logs エクスポーターが削除されています。\nどのような特定のエクスポーターが以前含まれていたかをどのように知ったか？それを見つけるには、 以前のカスタマイズを元に戻してから、config map を確認して トレースパイプラインに元々何が含まれていたかを見ることもできました。あるいは、 splunk-otel-collector-chart の GitHub リポジトリ の例を参照することもでき、これにより Helm チャートで使用されるデフォルトのエージェント設定が分かります。\nこれらのエクスポーターはどのように削除されたのか？ values.yamlファイルに追加したカスタマイズを確認しましょう：\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: config: receivers: ... exporters: debug: verbosity: detailed service: pipelines: traces: exporters: - debug logs: exporters: - debug helm upgradeを使ってコレクターにvalues.yamlファイルを適用したとき、 カスタム設定は以前のコレクター設定とマージされました。 これが発生すると、リストを含むyaml設定のセクション、 例えばパイプラインセクションのエクスポーターのリストは、values.yamlファイルに 含めたもの（debug エクスポーターのみ）で置き換えられます。\n問題を修正しましょう 既存のパイプラインをカスタマイズする場合、設定のその部分を完全に再定義する必要があります。 したがって、values.yamlファイルを次のように更新する必要があります：\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: config: receivers: ... exporters: debug: verbosity: detailed service: pipelines: traces: exporters: - otlphttp - signalfx - debug logs: exporters: - splunk_hec/platform_logs - debug 変更を適用しましょう：\nhelm upgrade splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector それからエージェント config map を確認します：\nkubectl describe cm splunk-otel-collector-otel-agent 今度は、ログとトレースの両方について完全に定義されたエクスポーターパイプラインが表示されるはずです：\npipelines: logs: exporters: - splunk_hec/platform_logs - debug processors: ... traces: exporters: - otlphttp - signalfx - debug processors: ... ログ出力の確認 Splunk Distribution of OpenTelemetry .NETは、ログに使用するアプリケーション （サンプルアプリでも使用している）から、トレースコンテキストで強化されたログを自動的にエクスポートします。\nアプリケーションログはトレースメタデータで強化され、その後 OpenTelemetry Collector のローカルインスタンスに OTLP 形式でエクスポートされます。\ndebug エクスポーターによってキャプチャされたログを詳しく見て、それが発生しているかを確認しましょう。 コレクターログを tail するには、次のコマンドを使用できます：\nkubectl logs -l component=otel-collector-agent -f ログを tail したら、curl を使ってさらにトラフィックを生成できます。そうすると 次のようなものが表示されるはずです：\n2024-12-20T21:56:30.858Z info Logs {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\", \"resource logs\": 1, \"log records\": 1} 2024-12-20T21:56:30.858Z info ResourceLog #0 Resource SchemaURL: https://opentelemetry.io/schemas/1.6.1 Resource attributes: -\u003e splunk.distro.version: Str(1.8.0) -\u003e telemetry.distro.name: Str(splunk-otel-dotnet) -\u003e telemetry.distro.version: Str(1.8.0) -\u003e os.type: Str(linux) -\u003e os.description: Str(Debian GNU/Linux 12 (bookworm)) -\u003e os.build_id: Str(6.8.0-1021-aws) -\u003e os.name: Str(Debian GNU/Linux) -\u003e os.version: Str(12) -\u003e host.name: Str(derek-1) -\u003e process.owner: Str(app) -\u003e process.pid: Int(1) -\u003e process.runtime.description: Str(.NET 8.0.11) -\u003e process.runtime.name: Str(.NET) -\u003e process.runtime.version: Str(8.0.11) -\u003e container.id: Str(5bee5b8f56f4b29f230ffdd183d0367c050872fefd9049822c1ab2aa662ba242) -\u003e telemetry.sdk.name: Str(opentelemetry) -\u003e telemetry.sdk.language: Str(dotnet) -\u003e telemetry.sdk.version: Str(1.9.0) -\u003e service.name: Str(helloworld) -\u003e deployment.environment: Str(otel-derek-1) -\u003e k8s.node.name: Str(derek-1) -\u003e k8s.cluster.name: Str(derek-1-cluster) ScopeLogs #0 ScopeLogs SchemaURL: InstrumentationScope HelloWorldController LogRecord #0 ObservedTimestamp: 2024-12-20 21:56:28.486804 +0000 UTC Timestamp: 2024-12-20 21:56:28.486804 +0000 UTC SeverityText: Information SeverityNumber: Info(9) Body: Str(/hello endpoint invoked by {name}) Attributes: -\u003e name: Str(Kubernetes) Trace ID: 78db97a12b942c0252d7438d6b045447 Span ID: 5e9158aa42f96db3 Flags: 1 {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\"} この例では、Trace ID と Span ID が OpenTelemetry .NET 計装によってログ出力に自動的に書き込まれていることがわかります。これにより、 Splunk Observability Cloud でログとトレースを関連付けることができます。\nただし、Helm を使って K8s クラスターに OpenTelemetry collector をデプロイし、 ログ収集オプションを含める場合、OpenTelemetry collector は File Log receiver を使用して コンテナーログを自動的にキャプチャすることを覚えておいてください。\nこれにより、アプリケーションの重複ログがキャプチャされることになります。例えば、次のスクリーンショットでは サービスへの各リクエストに対して 2 つのログエントリーが表示されています：\nこれをどのように回避しますか？\nK8s での重複ログの回避 重複ログをキャプチャしないようにするには、OTEL_LOGS_EXPORTER環境変数をnoneに設定して、 Splunk Distribution of OpenTelemetry .NET が OTLP を使用してコレクターにログをエクスポートしないようにできます。 これは、deployment.yamlファイルにOTEL_LOGS_EXPORTER環境変数を追加することで実行できます：\nenv: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=otel-$INSTANCE\" - name: OTEL_LOGS_EXPORTER value: \"none\" それから次を実行します：\n# update the deployment kubectl apply -f deployment.yaml OTEL_LOGS_EXPORTER環境変数をnoneに設定するのは簡単です。しかし、Trace ID と Span ID はアプリケーションによって生成された stdout ログに書き込まれないため、 ログとトレースを関連付けることができなくなります。\nこれを解決するには、 /home/splunk/workshop/docker-k8s-otel/helloworld/SplunkTelemetryConfigurator.csで定義されている例のような、カスタムロガーを定義する必要があります。\n次のようにProgram.csファイルを更新することで、これをアプリケーションに含めることができます：\nusing SplunkTelemetry; using Microsoft.Extensions.Logging.Console; var builder = WebApplication.CreateBuilder(args); builder.Services.AddControllers(); SplunkTelemetryConfigurator.ConfigureLogger(builder.Logging); var app = builder.Build(); app.MapControllers(); app.Run(); その後、カスタムログ設定を含む新しい Docker イメージをビルドします：\ncd /home/splunk/workshop/docker-k8s-otel/helloworld docker build -t helloworld:1.3 . それから更新されたイメージを Kubernetes にインポートします：\ncd /home/splunk # Import the image into k3d sudo k3d image import helloworld:1.3 --cluster $INSTANCE-cluster 最後に、deployment.yamlファイルを更新してコンテナーイメージの 1.3 バージョンを使用する必要があります：\nspec: containers: - name: helloworld image: docker.io/library/helloworld:1.3 それから変更を適用します：\n# update the deployment kubectl apply -f deployment.yaml これで重複したログエントリーが排除されたことがわかります。そして 残りのログエントリーは JSON としてフォーマットされ、span と trace ID が含まれています：",
    "description": "前のセクションでは、debug エクスポーターをコレクターの設定に追加し、 トレースとログのパイプラインの一部にしました。期待通りに、debug 出力が エージェントコレクターのログに書き込まれているのが確認できます。\nしかし、トレースが o11y cloud に送信されなくなっています。なぜなのかを把握して修正しましょう。\nコレクター設定を確認する values.yamlファイルを通じてコレクター設定が変更された場合は、 config map を確認してコレクターに実際に適用された設定を確認することが役立ちます：\nkubectl describe cm splunk-otel-collector-otel-agent エージェントコレクター設定のログとトレースのパイプラインを確認しましょう。次のようになっているはずです：\npipelines: logs: exporters: - debug processors: - memory_limiter - k8sattributes - filter/logs - batch - resourcedetection - resource - resource/logs - resource/add_environment receivers: - filelog - fluentforward - otlp ... traces: exporters: - debug processors: - memory_limiter - k8sattributes - batch - resourcedetection - resource - resource/add_environment receivers: - otlp - jaeger - smartagent/signalfx-forwarder - zipkin 問題がわかりますか？debug エクスポーターのみがトレースとログのパイプラインに含まれています。 以前のトレースパイプライン設定にあったotlphttpとsignalfxエクスポーターがなくなっています。 これが、もう o11y cloud でトレースが見えなくなった理由です。ログパイプラインについても、splunk_hec/platform_logs エクスポーターが削除されています。",
    "tags": [],
    "title": "Troubleshoot OpenTelemetry Collector Issues",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/10-troubleshoot-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "おめでとうございます。Splunk4Rookies - Observability Cloud ワークショップを修了しました。今日は Splunk Observability Cloud を使用してアプリケーションとインフラストラクチャを監視する方法に慣れました。\nこの修了証をあなたのLinkedIn プロフィールに追加して成果をアピールしましょう。\n私たちが学んだことと次にできることを振り返ってみましょう。",
    "description": "おめでとうございます。Splunk4Rookies - Observability Cloudワークショップを修了しました。今日はSplunk Observability Cloudを使用してアプリケーションとインフラストラクチャを監視する方法に慣れました。",
    "tags": [],
    "title": "ワークショップ まとめ 🎁",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/10-wrap-up/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e Advanced OpenTelemetry Collector",
    "content": "",
    "description": "",
    "tags": [],
    "title": "8. まとめ",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/2-advanced-collector/8-wrap-up/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 8. Develop",
    "content": "Configuration の構築 コンポーネントの Configuration 部分は、ユーザーがコンポーネントに対して入力を行う方法です。そのため、設定に使用される値は以下の条件を満たす必要があります\nそのフィールドが何を制御するかをユーザーが直感的に理解できること 必須と任意を明確にすること 一般的な名前とフィールドを再利用すること オプションをシンプルに保つこと ​ bad config good config --- jenkins_server_addr: hostname jenkins_server_api_port: 8089 interval: 10m filter_builds_by: - name: my-awesome-build status: amber track: values: example.metric.1: yes example.metric.2: yes example.metric.3: no example.metric.4: no --- # Required Values endpoint: http://my-jenkins-server:8089 auth: authenticator: basicauth/jenkins # Optional Values collection_interval: 10m metrics: example.metric.1: enabled: true example.metric.2: enabled: true example.metric.3: enabled: true example.metric.4: enabled: true 悪い設定例は、設定のベストプラクティスの逆を行うことがコンポーネントの使いやすさにどのように影響するかを示しています。フィールド値が何であるべきかが明確ではなく、既存のプロセッサにプッシュできる機能が含まれており、フィールド名が Collector に存在する他のコンポーネントと一貫していません。\n良い設定例は、必須の値をシンプルに保ち、他のコンポーネントからフィールド名を再利用し、コンポーネントが Jenkins と Collector 間の相互作用のみに焦点を当てることを確保しています。\nコードタブは、私たちが追加する必要がある量と、Collector 内の共有ライブラリによってすでに提供されているものを示しています。これらはビジネスロジックに到達したときにより詳細に説明します。Configuration は小さく始まり、追加機能が必要になるとビジネスロジックが含まれるようになると変更されます。\nコードを書く Configuration に必要なコードを実装するために、以下の内容で config.go という新しいファイルを作成します\npackage jenkinscireceiver import ( \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type Config struct { // HTTPClientSettings contains all the values // that are commonly shared across all HTTP interactions // performed by the collector. confighttp.HTTPClientSettings `mapstructure:\",squash\"` // ScraperControllerSettings will allow us to schedule // how often to check for updates to builds. scraperhelper.ScraperControllerSettings `mapstructure:\",squash\"` // MetricsBuilderConfig contains all the metrics // that can be configured. metadata.MetricsBuilderConfig `mapstructure:\",squash\"` }",
    "description": "Configuration の構築 コンポーネントの Configuration 部分は、ユーザーがコンポーネントに対して入力を行う方法です。そのため、設定に使用される値は以下の条件を満たす必要があります\nそのフィールドが何を制御するかをユーザーが直感的に理解できること 必須と任意を明確にすること 一般的な名前とフィールドを再利用すること オプションをシンプルに保つこと ​ bad config good config --- jenkins_server_addr: hostname jenkins_server_api_port: 8089 interval: 10m filter_builds_by: - name: my-awesome-build status: amber track: values: example.metric.1: yes example.metric.2: yes example.metric.3: no example.metric.4: no --- # Required Values endpoint: http://my-jenkins-server:8089 auth: authenticator: basicauth/jenkins # Optional Values collection_interval: 10m metrics: example.metric.1: enabled: true example.metric.2: enabled: true example.metric.3: enabled: true example.metric.4: enabled: true 悪い設定例は、設定のベストプラクティスの逆を行うことがコンポーネントの使いやすさにどのように影響するかを示しています。フィールド値が何であるべきかが明確ではなく、既存のプロセッサにプッシュできる機能が含まれており、フィールド名が Collector に存在する他のコンポーネントと一貫していません。",
    "tags": [],
    "title": "OpenTelemetry Collector 開発",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/8-develop/2-configuration/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "Configuration の構築 コンポーネントの Configuration 部分は、ユーザーがコンポーネントに対する入力を行う方法であり、設定に使用される値は以下のようである必要があります：\nそのフィールドが何を制御するのか、ユーザーが直感的に理解できる 必須項目とオプション項目が明確である 共通の名前とフィールドを再利用する オプションをシンプルに保つ ​ 良い config 悪い config --- # Required Values endpoint: http://my-jenkins-server:8089 auth: authenticator: basicauth/jenkins # Optional Values collection_interval: 10m metrics: example.metric.1: enabled: true example.metric.2: enabled: true example.metric.3: enabled: true example.metric.4: enabled: true --- jenkins_server_addr: hostname jenkins_server_api_port: 8089 interval: 10m filter_builds_by: - name: my-awesome-build status: amber track: values: example.metric.1: yes example.metric.2: yes example.metric.3: no example.metric.4: no 悪い例では、Configuration のベストプラクティスに反するとコンポーネントが使いにくくなってしまうことが理解できるはずです。 フィールドの値が何であるべきかを明確ではなく、既存のプロセッサーに移譲できる機能を含み、コレクター内の他のコンポーネントと比較してフィールドの命名に一貫性がありません。\n良い例では、必要な値をシンプルに保ち、他のコンポーネントからのフィールド名を再利用し、コンポーネントが Jenkins とコレクター間の相互作用にのみ焦点を当てています。\n設定値の中には、このコンポーネントで独自に追加するものと、コレクター内部の共有ライブラリによって提供されているものがあります。これらはビジネスロジックに取り組む際にさらに詳しく説明します。Configuration は小さく始めるべきで、ビジネスロジックに追加の機能が必要になったら、設定も追加していきましょう。\nコードを書く Configuration に必要なコードを実装するために、config.go という名前の新しいファイルを以下の内容で作成します：\npackage jenkinscireceiver import ( \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type Config struct { // HTTPClientSettings contains all the values // that are commonly shared across all HTTP interactions // performed by the collector. confighttp.HTTPClientSettings `mapstructure:\",squash\"` // ScraperControllerSettings will allow us to schedule // how often to check for updates to builds. scraperhelper.ScraperControllerSettings `mapstructure:\",squash\"` // MetricsBuilderConfig contains all the metrics // that can be configured. metadata.MetricsBuilderConfig `mapstructure:\",squash\"` }",
    "description": "Configuration の構築 コンポーネントの Configuration 部分は、ユーザーがコンポーネントに対する入力を行う方法であり、設定に使用される値は以下のようである必要があります：\nそのフィールドが何を制御するのか、ユーザーが直感的に理解できる 必須項目とオプション項目が明確である 共通の名前とフィールドを再利用する オプションをシンプルに保つ ​ 良い config 悪い config --- # Required Values endpoint: http://my-jenkins-server:8089 auth: authenticator: basicauth/jenkins # Optional Values collection_interval: 10m metrics: example.metric.1: enabled: true example.metric.2: enabled: true example.metric.3: enabled: true example.metric.4: enabled: true --- jenkins_server_addr: hostname jenkins_server_api_port: 8089 interval: 10m filter_builds_by: - name: my-awesome-build status: amber track: values: example.metric.1: yes example.metric.2: yes example.metric.3: no example.metric.4: no 悪い例では、Configuration のベストプラクティスに反するとコンポーネントが使いにくくなってしまうことが理解できるはずです。 フィールドの値が何であるべきかを明確ではなく、既存のプロセッサーに移譲できる機能を含み、コレクター内の他のコンポーネントと比較してフィールドの命名に一貫性がありません。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/8-develop/2-configuration/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ",
    "content": "概要 OpenTelemetry を使い始める場合は、バックエンドに直接データを送ることから始めるかもしれません。最初のステップとしてはよいですが、OpenTelemetry Collector をオブザーバビリティのアーキテクチャとして使用するのは多くの利点があり、本番環境では Collector を使ったデプロイを推奨しています。\nこのワークショップでは、OpenTelemetry Collector を使用することに焦点を当て、Splunk Observability Cloud で使用するためのレシーバー、プロセッサー、エクスポーターを定義し、実際にテレメトリデータを送信するためのパイプラインを設定することで、環境に合わせて Collector を活用を学びます。また、分散プラットフォームのビジネスニーズに対応するための、カスタムコンポーネントを追加できるようになるまでの道のりを進むことになります。\nNinja セクション ワークショップの途中には、展開できる Ninja セクション があります。これらはより実践的で、ワークショップ中、もしくは自分の時間を使って、さらに技術的な詳細に取り組むことができます。\nOpenTelemetry プロジェクトは頻繁に開発されているため、Ninjaセクションの内容が古くなる可能性があることに注意してください。コンテンツが古い場合には更新のリクエストを出すこともできますので、必要なものを見つけた場合はお知らせください。\nNinja: をテストして！ このワークショップを完了すると、正式に OpenTelemetry Collector ニンジャになります！\n対象者 このワークショップは、OpenTelemetry Collector のアーキテクチャとデプロイメントについてさらに学びたいと考えている開発者やシステム管理者を対象としています。\n前提条件 データ収集に関する基本的な理解 コマンドラインとvim/viの経験 Ubuntu 20.04 LTSまたは22.04 LTSが稼働するインスタンス/ホスト/VM 最小要件はAWS/EC2 t2.micro（1 CPU、1GB RAM、8GBストレージ） 学習目標 このセッションの終わりまでに、参加者は以下を行うことができるようになります：\nOpenTelemetry のコンポーネントを理解する レシーバー、プロセッサー、エクスポーターを使用してデータを収集・分析する OpenTelemetry を使用する利点を特定する 自分たちのビジネスニーズに対応するカスタムコンポーネントを構築する OpenTelemetry のアーキテクチャー %%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "OpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。",
    "tags": [],
    "title": "OpenTelemetryでクラウドネイティブ環境のオブザーバビリティを実現する",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "このワークショップでは、以下の概念についてハンズオンで体験しました：\nLinux ホストにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 Splunk Distribution of OpenTelemetry .NETで.NET アプリケーションを計装する方法。 .NET アプリケーションを「Docker 化」し、Splunk Distribution of OpenTelemetry .NETで計装する方法。 Helm を使用して Kubernetes クラスターにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 コレクター設定をカスタマイズして問題をトラブルシューティングする方法。 他の言語と環境で OpenTelemetry がどのように計装されるかを確認するには、 Splunk OpenTelemetry Examples GitHub リポジトリをご覧ください。\n将来このワークショップを独自に実行するには、これらの手順を参照して、Splunk Show のSplunk4Rookies - Observability ワークショップテンプレートを使用して EC2 インスタンスをプロビジョニングしてください。",
    "description": "このワークショップでは、以下の概念についてハンズオンで体験しました：\nLinux ホストにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 Splunk Distribution of OpenTelemetry .NETで.NET アプリケーションを計装する方法。 .NET アプリケーションを「Docker 化」し、Splunk Distribution of OpenTelemetry .NETで計装する方法。 Helm を使用して Kubernetes クラスターにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 コレクター設定をカスタマイズして問題をトラブルシューティングする方法。 他の言語と環境で OpenTelemetry がどのように計装されるかを確認するには、 Splunk OpenTelemetry Examples GitHub リポジトリをご覧ください。\n将来このワークショップを独自に実行するには、これらの手順を参照して、Splunk Show のSplunk4Rookies - Observability ワークショップテンプレートを使用して EC2 インスタンスをプロビジョニングしてください。",
    "tags": [],
    "title": "Summary",
    "uri": "/observability-workshop/ja/ninja-workshops/8-docker-k8s-otel/11-summary/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 8. Develop",
    "content": "コンポーネントのレビュー Jenkins からメトリクスをキャプチャするために必要なコンポーネントの種類を振り返ります\n​ Extension Receiver Processor Exporter Ninja: Connectors Extension が解決するビジネスユースケースは以下の通りです\nランタイム設定が必要な共有機能を持つこと Collector のランタイムを観測することを間接的に支援すること 詳細は Extensions の概要 を参照してください。\nReceiver が解決するビジネスユースケースは以下の通りです\nリモートソースからデータをフェッチする リモートソースからデータを受信する これは一般的に pull 型と push 型のデータ収集と呼ばれ、詳細は Receiver の概要 で読むことができます。\nProcessor が解決するビジネスユースケースは以下の通りです\nデータ、フィールド、または値の追加や削除 データを観測し、意思決定を行う バッファリング、キューイング、並び替え 留意すべき点は、Processor を流れるデータタイプは、下流のコンポーネントに同じデータタイプを転送する必要があるということです。詳細は Processor の概要 をお読みください。\nExporter が解決するビジネスユースケースは以下の通りです\nツール、サービス、またはストレージにデータを送信する OpenTelemetry Collector は「バックエンド」、つまりオールインワンのオブザーバビリティスイートになることを望んでおらず、むしろ OpenTelemetry を創設した原則を維持しています。つまり、すべての人のためのベンダーに依存しないオブザーバビリティです。詳細を再確認するには、Exporter の概要 をお読みください。\nこれはワークショップで見逃されたコンポーネントタイプです。比較的新しい Collector への追加であるためです。Connector を考える最良の方法は、異なるテレメトリタイプとパイプライン間で使用できる Processor のようなものです。つまり、Connector はログとしてデータを受け入れ、メトリクスを出力したり、あるパイプラインからメトリクスを受け入れ、観測したデータに関するメトリクスを提供したりできます。\nConnector が解決するビジネスケースは以下の通りです\n異なるテレメトリタイプ間の変換 ログからメトリクス トレースからメトリクス メトリクスからログ 受信データを観測し、独自のデータを生成する メトリクスを受け入れ、データの分析メトリクスを生成する。 Processor の概要 の Ninja セクションに簡単な概要がありました。新しい Connector コンポーネントの更新についてはプロジェクトを確認してください。\nコンポーネントの概要から、Jenkins 用のプルベースのレシーバーを開発することが明確です。",
    "description": "コンポーネントのレビュー Jenkins からメトリクスをキャプチャするために必要なコンポーネントの種類を振り返ります\n​ Extension Receiver Processor Exporter Ninja: Connectors Extension が解決するビジネスユースケースは以下の通りです\nランタイム設定が必要な共有機能を持つこと Collector のランタイムを観測することを間接的に支援すること 詳細は Extensions の概要 を参照してください。\nReceiver が解決するビジネスユースケースは以下の通りです",
    "tags": [],
    "title": "OpenTelemetry Collector 開発",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/8-develop/3-component/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "コンポーネントを検討する Jenkinsからメトリクスを取得するために必要なコンポーネントの種類をおさらいしましょう：\n​ エクステンション レシーバー プロセッサー エクスポーター Ninja: コネクター エクステンションが解決するビジネスユースケースは以下の通りです：\n実行時の設定が必要な共有機能を持つ コレクターの実行時間の観察に間接的に役立つ 詳細については、エクステンションの概要を参照してください。\nレシーバーが解決するビジネスユースケースは以下の通りです：\nリモートソースからのデータの取得 リモートソースからのデータの受信 これらは一般的に pull 対 push ベースのデータ収集と呼ばれ、詳細についてはレシーバーの概要で読むことができます。\nプロセッサーが解決するビジネスユースケースは以下の通りです：\nデータ、フィールド、または値の追加または削除 データの観察と意思決定 バッファリング、キューイング、および並べ替え プロセッサーを通過するデータタイプは、下流のコンポーネントに同じデータタイプを転送する必要があることを覚えておいてください。 詳細については、プロセッサーの概要をご覧ください。\nエクスポーターが解決するビジネスユースケースは以下の通りです：\nデータをツール、サービス、またはストレージに送信する OpenTelemetryコレクターは「バックエンド」、すべてを一元化した観測可能性スイートを目指すのではなく、OpenTelemetryの創設原則に忠実であり続けることを目指しています。つまり、ベンダーに依存しない全ての人のための観測可能性です。詳細については、エクスポーターの概要をお読みください。\nコネクターは比較的新しいコンポーネントで、このワークショップではあまり触れていません。 コネクターは、異なるテレメトリタイプやパイプラインをまたいで使用できるプロセッサーのようなものだといえます。たとえば、コネクターはログとしてデータを受け取り、メトリクスとして出力したり、あるパイプラインからメトリクスを受け取り、テレメトリーデータに関するメトリクスを提供したりすることができます。\nコネクターが解決するビジネスケースは以下の通りです：\n異なるテレメトリタイプ間の変換 ログからメトリクスへ トレースからメトリクスへ メトリクスからログへ 受信したデータを観察し、自身のデータを生成する メトリクスを受け取り、データの分析メトリクスを生成する。 Ninjaセクションの一部としてプロセッサーの概要内で簡単に概要が説明されています。\nこれらのコンポーネントについて考えると、Jenkins に対応する場合はプルベースのレシーバーを開発する必要があることがわかります。",
    "description": "コンポーネントを検討する Jenkinsからメトリクスを取得するために必要なコンポーネントの種類をおさらいしましょう：\n​ エクステンション レシーバー プロセッサー エクスポーター Ninja: コネクター エクステンションが解決するビジネスユースケースは以下の通りです：\n実行時の設定が必要な共有機能を持つ コレクターの実行時間の観察に間接的に役立つ 詳細については、エクステンションの概要を参照してください。\nレシーバーが解決するビジネスユースケースは以下の通りです：\nリモートソースからのデータの取得 リモートソースからのデータの受信 これらは一般的に pull 対 push ベースのデータ収集と呼ばれ、詳細についてはレシーバーの概要で読むことができます。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/8-develop/3-component/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 8. Develop",
    "content": "メトリクスの設計 レシーバーでキャプチャしたメトリクスを定義およびエクスポートするために、mdatagen を使用します。これは、YAML で定義されたメトリクスをコードに変換する Collector 用に開発されたツールです。\n​ metadata.yaml gen.go --- # Type defines the name to reference the component # in the configuration file type: jenkins # Status defines the component type and the stability level status: class: receiver stability: development: [metrics] # Attributes are the expected fields reported # with the exported values. attributes: job.name: description: The name of the associated Jenkins job type: string job.status: description: Shows if the job had passed, or failed type: string enum: - failed - success - unknown # Metrics defines all the pontentially exported values from this receiver. metrics: jenkins.jobs.count: enabled: true description: Provides a count of the total number of configured jobs unit: \"{Count}\" gauge: value_type: int jenkins.job.duration: enabled: true description: Show the duration of the job unit: \"s\" gauge: value_type: int attributes: - job.name - job.status jenkins.job.commit_delta: enabled: true description: The calculation difference of the time job was finished minus commit timestamp unit: \"s\" gauge: value_type: int attributes: - job.name - job.status // To generate the additional code needed to capture metrics, // the following command to be run from the shell: // go generate -x ./... //go:generate go run github.com/open-telemetry/opentelemetry-collector-contrib/cmd/mdatagen@v0.80.0 metadata.yaml package jenkinscireceiver // There is no code defined within this file. 次のセクションに進む前に、これらのファイルをプロジェクトフォルダー内に作成してください。\nFactory の構築 Factory は、オブジェクト（この場合は jenkinscireceiver）を提供された設定で動的に作成できるようにするソフトウェアデザインパターンです。より現実世界の例を使うと、電話ショップに行き、自分の説明と正確に一致する電話を求め、それを提供してもらうようなものです。\ngo generate -x ./... コマンドを実行すると、定義されたメトリクスをエクスポートするために必要なすべてのコードを含む新しいフォルダー jenkinscireceiver/internal/metadata が作成されます。必要なコードは以下の通りです\n​ factory.go config.go scraper.go build-config.yaml project layout package jenkinscireceiver import ( \"errors\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) func NewFactory() receiver.Factory { return receiver.NewFactory( metadata.Type, newDefaultConfig, receiver.WithMetrics(newMetricsReceiver, metadata.MetricsStability), ) } func newMetricsReceiver(_ context.Context, set receiver.CreateSettings, cfg component.Config, consumer consumer.Metrics) (receiver.Metrics, error) { // Convert the configuration into the expected type conf, ok := cfg.(*Config) if !ok { return nil, errors.New(\"can not convert config\") } sc, err := newScraper(conf, set) if err != nil { return nil, err } return scraperhelper.NewScraperControllerReceiver( \u0026conf.ScraperControllerSettings, set, consumer, scraperhelper.AddScraper(sc), ) } package jenkinscireceiver import ( \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type Config struct { // HTTPClientSettings contains all the values // that are commonly shared across all HTTP interactions // performed by the collector. confighttp.HTTPClientSettings `mapstructure:\",squash\"` // ScraperControllerSettings will allow us to schedule // how often to check for updates to builds. scraperhelper.ScraperControllerSettings `mapstructure:\",squash\"` // MetricsBuilderConfig contains all the metrics // that can be configured. metadata.MetricsBuilderConfig `mapstructure:\",squash\"` } func newDefaultConfig() component.Config { return \u0026Config{ ScraperControllerSettings: scraperhelper.NewDefaultScraperControllerSettings(metadata.Type), HTTPClientSettings: confighttp.NewDefaultHTTPClientSettings(), MetricsBuilderConfig: metadata.DefaultMetricsBuilderConfig(), } } package jenkinscireceiver type scraper struct {} func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { // Create a our scraper with our values s := scraper{ // To be filled in later } return scraperhelper.NewScraper(metadata.Type, s.scrape) } func (scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetrics.NewMetrics(), nil } --- dist: name: otelcol description: \"Conf workshop collector\" output_path: ./dist version: v0.0.0-experimental extensions: - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/basicauthextension v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckextension v0.80.0 receivers: - gomod: go.opentelemetry.io/collector/receiver/otlpreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver v0.80.0 - gomod: splunk.conf/workshop/example/jenkinscireceiver v0.0.0 path: ./jenkinscireceiver processors: - gomod: go.opentelemetry.io/collector/processor/batchprocessor v0.80.0 exporters: - gomod: go.opentelemetry.io/collector/exporter/loggingexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlpexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlphttpexporter v0.80.0 # This replace is a go directive that allows for redefine # where to fetch the code to use since the default would be from a remote project. replaces: - splunk.conf/workshop/example/jenkinscireceiver =\u003e ./jenkinscireceiver ├── build-config.yaml └── jenkinscireceiver ├── go.mod ├── config.go ├── factory.go ├── scraper.go └── internal └── metadata これらのファイルを期待される内容でプロジェクトに書き込んだら、go mod tidy を実行します。これにより、すべてのリモート依存関係がフェッチされ、go.mod が更新され、go.sum ファイルが生成されます。",
    "description": "メトリクスの設計 レシーバーでキャプチャしたメトリクスを定義およびエクスポートするために、mdatagen を使用します。これは、YAML で定義されたメトリクスをコードに変換する Collector 用に開発されたツールです。\n​ metadata.yaml gen.go --- # Type defines the name to reference the component # in the configuration file type: jenkins # Status defines the component type and the stability level status: class: receiver stability: development: [metrics] # Attributes are the expected fields reported # with the exported values. attributes: job.name: description: The name of the associated Jenkins job type: string job.status: description: Shows if the job had passed, or failed type: string enum: - failed - success - unknown # Metrics defines all the pontentially exported values from this receiver. metrics: jenkins.jobs.count: enabled: true description: Provides a count of the total number of configured jobs unit: \"{Count}\" gauge: value_type: int jenkins.job.duration: enabled: true description: Show the duration of the job unit: \"s\" gauge: value_type: int attributes: - job.name - job.status jenkins.job.commit_delta: enabled: true description: The calculation difference of the time job was finished minus commit timestamp unit: \"s\" gauge: value_type: int attributes: - job.name - job.status // To generate the additional code needed to capture metrics, // the following command to be run from the shell: // go generate -x ./... //go:generate go run github.com/open-telemetry/opentelemetry-collector-contrib/cmd/mdatagen@v0.80.0 metadata.yaml package jenkinscireceiver // There is no code defined within this file. 次のセクションに進む前に、これらのファイルをプロジェクトフォルダー内に作成してください。",
    "tags": [],
    "title": "OpenTelemetry Collector 開発",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/8-develop/4-design/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "メトリクスを設計する レシーバーによってキャプチャされるメトリクスを定義し、エクスポートするために、コレクターのために開発された mdatagen を使って、yaml で定義したメトリクスをコードに変換していきます。\n​ metadata.yaml gen.go --- # Type defines the name to reference the component # in the configuration file type: jenkins # Status defines the component type and the stability level status: class: receiver stability: development: [metrics] # Attributes are the expected fields reported # with the exported values. attributes: job.name: description: The name of the associated Jenkins job type: string job.status: description: Shows if the job had passed, or failed type: string enum: - failed - success - unknown # Metrics defines all the pontentially exported values from this receiver. metrics: jenkins.jobs.count: enabled: true description: Provides a count of the total number of configured jobs unit: \"{Count}\" gauge: value_type: int jenkins.job.duration: enabled: true description: Show the duration of the job unit: \"s\" gauge: value_type: int attributes: - job.name - job.status jenkins.job.commit_delta: enabled: true description: The calculation difference of the time job was finished minus commit timestamp unit: \"s\" gauge: value_type: int attributes: - job.name - job.status // To generate the additional code needed to capture metrics, // the following command to be run from the shell: // go generate -x ./... //go:generate go run github.com/open-telemetry/opentelemetry-collector-contrib/cmd/mdatagen@v0.80.0 metadata.yaml package jenkinscireceiver // There is no code defined within this file. 次のセクションに進む前に、これらのファイルをプロジェクトフォルダ内に作成してください。\nFactory の構築 Factory はソフトウェアデザインパターンの一種で、提供された Configuration を使って、動的にオブジェクト（この場合は jenkinscireceiver）を作成するものです。現実的な例では、携帯電話店に行って、あなたの正確な説明に合った携帯電話を求め、それを提供されるようなものです。\nコマンド go generate -x ./... を実行すると、定義されたメトリクスをエクスポートするために必要なすべてのコードを含む新しいフォルダ jenkinscireceiver/internal/metadata が作成されます。生成されるコードは以下の通りです：\n​ factory.go config.go scraper.go build-config.yaml project layout package jenkinscireceiver import ( \"errors\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) func NewFactory() receiver.Factory { return receiver.NewFactory( metadata.Type, newDefaultConfig, receiver.WithMetrics(newMetricsReceiver, metadata.MetricsStability), ) } func newMetricsReceiver(_ context.Context, set receiver.CreateSettings, cfg component.Config, consumer consumer.Metrics) (receiver.Metrics, error) { // Convert the configuration into the expected type conf, ok := cfg.(*Config) if !ok { return nil, errors.New(\"can not convert config\") } sc, err := newScraper(conf, set) if err != nil { return nil, err } return scraperhelper.NewScraperControllerReceiver( \u0026conf.ScraperControllerSettings, set, consumer, scraperhelper.AddScraper(sc), ) } package jenkinscireceiver import ( \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type Config struct { // HTTPClientSettings contains all the values // that are commonly shared across all HTTP interactions // performed by the collector. confighttp.HTTPClientSettings `mapstructure:\",squash\"` // ScraperControllerSettings will allow us to schedule // how often to check for updates to builds. scraperhelper.ScraperControllerSettings `mapstructure:\",squash\"` // MetricsBuilderConfig contains all the metrics // that can be configured. metadata.MetricsBuilderConfig `mapstructure:\",squash\"` } func newDefaultConfig() component.Config { return \u0026Config{ ScraperControllerSettings: scraperhelper.NewDefaultScraperControllerSettings(metadata.Type), HTTPClientSettings: confighttp.NewDefaultHTTPClientSettings(), MetricsBuilderConfig: metadata.DefaultMetricsBuilderConfig(), } } package jenkinscireceiver type scraper struct {} func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { // Create a our scraper with our values s := scraper{ // To be filled in later } return scraperhelper.NewScraper(metadata.Type, s.scrape) } func (scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetrics.NewMetrics(), nil } --- dist: name: otelcol description: \"Conf workshop collector\" output_path: ./dist version: v0.0.0-experimental extensions: - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/basicauthextension v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckextension v0.80.0 receivers: - gomod: go.opentelemetry.io/collector/receiver/otlpreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver v0.80.0 - gomod: splunk.conf/workshop/example/jenkinscireceiver v0.0.0 path: ./jenkinscireceiver processors: - gomod: go.opentelemetry.io/collector/processor/batchprocessor v0.80.0 exporters: - gomod: go.opentelemetry.io/collector/exporter/loggingexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlpexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlphttpexporter v0.80.0 # This replace is a go directive that allows for redefine # where to fetch the code to use since the default would be from a remote project. replaces: - splunk.conf/workshop/example/jenkinscireceiver =\u003e ./jenkinscireceiver ├── build-config.yaml └── jenkinscireceiver ├── go.mod ├── config.go ├── factory.go ├── scraper.go └── internal └── metadata これらのファイルがプロジェクトに作成されたら、go mod tidy を実行します。すると、すべての依存ライブラリが取得され、go.mod が更新されます。",
    "description": "メトリクスを設計する レシーバーによってキャプチャされるメトリクスを定義し、エクスポートするために、コレクターのために開発された mdatagen を使って、yaml で定義したメトリクスをコードに変換していきます。\n​ metadata.yaml gen.go --- # Type defines the name to reference the component # in the configuration file type: jenkins # Status defines the component type and the stability level status: class: receiver stability: development: [metrics] # Attributes are the expected fields reported # with the exported values. attributes: job.name: description: The name of the associated Jenkins job type: string job.status: description: Shows if the job had passed, or failed type: string enum: - failed - success - unknown # Metrics defines all the pontentially exported values from this receiver. metrics: jenkins.jobs.count: enabled: true description: Provides a count of the total number of configured jobs unit: \"{Count}\" gauge: value_type: int jenkins.job.duration: enabled: true description: Show the duration of the job unit: \"s\" gauge: value_type: int attributes: - job.name - job.status jenkins.job.commit_delta: enabled: true description: The calculation difference of the time job was finished minus commit timestamp unit: \"s\" gauge: value_type: int attributes: - job.name - job.status // To generate the additional code needed to capture metrics, // the following command to be run from the shell: // go generate -x ./... //go:generate go run github.com/open-telemetry/opentelemetry-collector-contrib/cmd/mdatagen@v0.80.0 metadata.yaml package jenkinscireceiver // There is no code defined within this file. 次のセクションに進む前に、これらのファイルをプロジェクトフォルダ内に作成してください。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/8-develop/4-design/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry Collector ワークショップ \u003e OpenTelemetry Collector の基本概念 \u003e 8. Develop",
    "content": "ビジネスロジックの構築 この時点で、現在何もしないカスタムコンポーネントがあるため、Jenkins からこのデータをキャプチャするために必要なロジックを追加する必要があります。\nここから、実行する必要があるステップは以下の通りです\nJenkins に接続するクライアントを作成する 設定されたすべてのジョブをキャプチャする 設定されたジョブの最後のビルドのステータスを報告する コミットのタイムスタンプとジョブ完了の時間差を計算する 変更は scraper.go に対して行われます。\n​ Add Jenkins client Capture all configured jobs Report the status of each job Report the delta Jenkins サーバーに接続できるようにするために、“github.com/yosida95/golang-jenkins” パッケージを使用します。このパッケージは、Jenkins サーバーからデータを読み取るために必要な機能を提供します。\n次に、“go.opentelemetry.io/collector/receiver/scraperhelper” ライブラリのヘルパー関数を利用して、コンポーネントの起動が完了した後に Jenkins サーバーに接続できるように start 関数を作成します。\npackage jenkinscireceiver import ( \"context\" jenkins \"github.com/yosida95/golang-jenkins\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/pdata/pmetric\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type scraper struct { mb *metadata.MetricsBuilder client *jenkins.Jenkins } func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { s := \u0026scraper{ mb : metadata.NewMetricsBuilder(cfg.MetricsBuilderConfig, set), } return scraperhelper.NewScraper( metadata.Type, s.scrape, scraperhelper.WithStart(func(ctx context.Context, h component.Host) error { client, err := cfg.ToClient(h, set.TelemetrySettings) if err != nil { return err } // The collector provides a means of injecting authentication // on our behalf, so this will ignore the libraries approach // and use the configured http client with authentication. s.client = jenkins.NewJenkins(nil, cfg.Endpoint) s.client.SetHTTPClient(client) return nil }), ) } func (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetric.NewMetrics(), nil } これで Jenkins レシーバーを初期化するために必要なすべてのセットアップコードが完了しました。\nここからは、入力を待っていた scrape メソッドに焦点を当てます。このメソッドは、設定で構成された間隔（デフォルトでは毎分）で実行されます。\n設定されたジョブの数をキャプチャしたい理由は、Jenkins サーバーの成長を確認し、オンボードしたプロジェクトの数を測定できるようにするためです。これを行うために、Jenkins クライアントを呼び出してすべてのジョブをリストし、エラーが報告された場合はメトリクスなしでそれを返し、そうでなければメトリクスビルダーからデータを出力します。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) // To be filled in return s.mb.Emit(), nil } 前のステップでは、すべてのジョブをキャプチャし、ジョブの数を報告することができました。このステップでは、各ジョブを調べ、報告された値を使用してメトリクスをキャプチャします。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) for _, job := range jobs { // Ensure we have valid results to start off with var ( build = job.LastCompletedBuild status = metadata.AttributeJobStatusUnknown ) // This will check the result of the job, however, // since the only defined attributes are // `success`, `failure`, and `unknown`. // it is assume that anything did not finish // with a success or failure to be an unknown status. switch build.Result { case \"aborted\", \"not_built\", \"unstable\": status = metadata.AttributeJobStatusUnknown case \"success\": status = metadata.AttributeJobStatusSuccess case \"failure\": status = metadata.AttributeJobStatusFailed } s.mb.RecordJenkinsJobDurationDataPoint( now, int64(job.LastCompletedBuild.Duration), job.Name, status, ) } return s.mb.Emit(), nil } 最後のステップは、コミットからジョブ完了までにかかった時間を計算し、DORA メトリクスを推測するのに役立てることです。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) for _, job := range jobs { // Ensure we have valid results to start off with var ( build = job.LastCompletedBuild status = metadata.AttributeJobStatusUnknown ) // Previous step here // Ensure that the `ChangeSet` has values // set so there is a valid value for us to reference if len(build.ChangeSet.Items) == 0 { continue } // Making the assumption that the first changeset // item is the most recent change. change := build.ChangeSet.Items[0] // Record the difference from the build time // compared against the change timestamp. s.mb.RecordJenkinsJobCommitDeltaDataPoint( now, int64(build.Timestamp-change.Timestamp), job.Name, status, ) } return s.mb.Emit(), nil } これらのステップがすべて完了すると、カスタム Jenkins CI レシーバーの構築が完了です！\n次のステップ コンポーネントから欲しい機能がおそらくもっとあるでしょう。例えば\nジョブが使用したブランチ名を含めることはできますか？ ジョブのプロジェクト名を含めることはできますか？ プロジェクトの累積ジョブ期間をどのように計算しますか？ 変更が機能することをどのように検証しますか？ この時間を使って、遊んでみたり、壊してみたり、変更したり、ビルドからログをキャプチャしてみたりしてください。",
    "description": "ビジネスロジックの構築 この時点で、現在何もしないカスタムコンポーネントがあるため、Jenkins からこのデータをキャプチャするために必要なロジックを追加する必要があります。\nここから、実行する必要があるステップは以下の通りです\nJenkins に接続するクライアントを作成する 設定されたすべてのジョブをキャプチャする 設定されたジョブの最後のビルドのステータスを報告する コミットのタイムスタンプとジョブ完了の時間差を計算する 変更は scraper.go に対して行われます。\n​ Add Jenkins client Capture all configured jobs Report the status of each job Report the delta Jenkins サーバーに接続できるようにするために、“github.com/yosida95/golang-jenkins” パッケージを使用します。このパッケージは、Jenkins サーバーからデータを読み取るために必要な機能を提供します。",
    "tags": [],
    "title": "OpenTelemetry Collector 開発",
    "uri": "/observability-workshop/ja/ninja-workshops/3-opentelemetry-collector-workshops/1-opentelemetry-collector/8-develop/5-business-logic/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "ビジネスロジックを作る この時点では、何も行っていないカスタムコンポーネントが作成されています。ここから、Jenkins からデータを取得するための必要なロジックを追加していきましょう。\nここからのステップは以下の通りです：\nJenkinsに接続するクライアントを作成する 設定されたすべてのジョブをキャプチャする 設定されたジョブの最後のビルドのステータスを報告する コミットタイムスタンプとジョブ完了の時間差を計算する 変更を scraper.go に加えていきます。\n​ Jenkins クライアントを追加する ジョブをキャプチャする ジョブの状態を報告する 差分を報告する Jenkinsサーバーに接続するために、パッケージ “github.com/yosida95/golang-jenkins” を使用します。これには、Jenkinsサーバーからデータを読み取るために必要な機能が提供されています。\n次に、“go.opentelemetry.io/collector/receiver/scraperhelper” ライブラリのいくつかのヘルパー関数を利用して、コンポーネントの起動が完了したらJenkinsサーバーに接続できるようにするスタート関数を作成します。\npackage jenkinscireceiver import ( \"context\" jenkins \"github.com/yosida95/golang-jenkins\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/pdata/pmetric\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type scraper struct { mb *metadata.MetricsBuilder client *jenkins.Jenkins } func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { s := \u0026scraper{ mb : metadata.NewMetricsBuilder(cfg.MetricsBuilderConfig, set), } return scraperhelper.NewScraper( metadata.Type, s.scrape, scraperhelper.WithStart(func(ctx context.Context, h component.Host) error { client, err := cfg.ToClient(h, set.TelemetrySettings) if err != nil { return err } // The collector provides a means of injecting authentication // on our behalf, so this will ignore the libraries approach // and use the configured http client with authentication. s.client = jenkins.NewJenkins(nil, cfg.Endpoint) s.client.SetHTTPClient(client) return nil }), ) } func (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetric.NewMetrics(), nil } これで、Jenkinsレシーバーを初期化するために必要なすべてのコードが完成しました。\nここから先は、実装が必要な scrape メソッドに焦点を当てます。このメソッドは、設定された間隔（デフォルトでは1分）ごとに実行されます。\nJenkins サーバーの負荷状況や、どの程度のプロジェクトが実行されているかを測定するために、Jenkins で設定されているジョブの数をキャプチャしたいと考えています。これを行うために、Jenkins クライアントを呼び出してすべてのジョブをリスト化し、エラーが報告された場合はメトリクスなしでそれを返し、そうでなければメトリクスビルダーからのデータを発行します。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) // To be filled in return s.mb.Emit(), nil } 前のステップにより、すべてのジョブをキャプチャしてジョブの数をレポートできるようになりました。 このステップでは、それぞれのジョブを調査し、レポートされた値を使用してメトリクスをキャプチャしていきます。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) for _, job := range jobs { // Ensure we have valid results to start off with var ( build = job.LastCompletedBuild status = metadata.AttributeJobStatusUnknown ) // This will check the result of the job, however, // since the only defined attributes are // `success`, `failure`, and `unknown`. // it is assume that anything did not finish // with a success or failure to be an unknown status. switch build.Result { case \"aborted\", \"not_built\", \"unstable\": status = metadata.AttributeJobStatusUnknown case \"success\": status = metadata.AttributeJobStatusSuccess case \"failure\": status = metadata.AttributeJobStatusFailed } s.mb.RecordJenkinsJobDurationDataPoint( now, int64(job.LastCompletedBuild.Duration), job.Name, status, ) } return s.mb.Emit(), nil } 最後のステップでは、コミットからジョブ完了までにかかった時間を計算して、DORA メトリクス を推測するのに役立てていきます。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) for _, job := range jobs { // Ensure we have valid results to start off with var ( build = job.LastCompletedBuild status = metadata.AttributeJobStatusUnknown ) // Previous step here // Ensure that the `ChangeSet` has values // set so there is a valid value for us to reference if len(build.ChangeSet.Items) == 0 { continue } // Making the assumption that the first changeset // item is the most recent change. change := build.ChangeSet.Items[0] // Record the difference from the build time // compared against the change timestamp. s.mb.RecordJenkinsJobCommitDeltaDataPoint( now, int64(build.Timestamp-change.Timestamp), job.Name, status, ) } return s.mb.Emit(), nil } これらのステップがすべて完了すると、Jenkins CI レシーバーが完成します！\n次は何をするの？ コンポーネントに必要な機能は、おそらく他にもたくさん思いつくでしょう。例えば：\nジョブで使用されたブランチ名を含めることはできますか？ ジョブのプロジェクト名を含めることはできますか？ プロジェクトのジョブの総持続時間をどのように計算しますか？ 変更が機能するかどうかをどのように検証しますか？ この時間を使って遊んでみたり、壊してみたり、変更してみたり、ビルドからのログをキャプチャしてみるなどしてください。",
    "description": "ビジネスロジックを作る この時点では、何も行っていないカスタムコンポーネントが作成されています。ここから、Jenkins からデータを取得するための必要なロジックを追加していきましょう。\nここからのステップは以下の通りです：\nJenkinsに接続するクライアントを作成する 設定されたすべてのジョブをキャプチャする 設定されたジョブの最後のビルドのステータスを報告する コミットタイムスタンプとジョブ完了の時間差を計算する 変更を scraper.go に加えていきます。\n​ Jenkins クライアントを追加する ジョブをキャプチャする ジョブの状態を報告する 差分を報告する Jenkinsサーバーに接続するために、パッケージ “github.com/yosida95/golang-jenkins” を使用します。これには、Jenkinsサーバーからデータを読み取るために必要な機能が提供されています。\n次に、“go.opentelemetry.io/collector/receiver/scraperhelper” ライブラリのいくつかのヘルパー関数を利用して、コンポーネントの起動が完了したらJenkinsサーバーに接続できるようにするスタート関数を作成します。\npackage jenkinscireceiver import ( \"context\" jenkins \"github.com/yosida95/golang-jenkins\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/pdata/pmetric\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type scraper struct { mb *metadata.MetricsBuilder client *jenkins.Jenkins } func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { s := \u0026scraper{ mb : metadata.NewMetricsBuilder(cfg.MetricsBuilderConfig, set), } return scraperhelper.NewScraper( metadata.Type, s.scrape, scraperhelper.WithStart(func(ctx context.Context, h component.Host) error { client, err := cfg.ToClient(h, set.TelemetrySettings) if err != nil { return err } // The collector provides a means of injecting authentication // on our behalf, so this will ignore the libraries approach // and use the configured http client with authentication. s.client = jenkins.NewJenkins(nil, cfg.Endpoint) s.client.SetHTTPClient(client) return nil }), ) } func (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetric.NewMetrics(), nil } これで、Jenkinsレシーバーを初期化するために必要なすべてのコードが完成しました。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/ja/other/opentelemetry-collector/8-develop/5-business-logic/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "Pet Clinic Java ワークショップ\rJavaアプリケーションをつかったSplunk Oservabilityのワークショップです\rOpenTelemetry Collector\rOpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。",
    "description": "Pet Clinic Java ワークショップ\rJavaアプリケーションをつかったSplunk Oservabilityのワークショップです\rOpenTelemetry Collector\rOpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。",
    "tags": [],
    "title": "その他のワークショップ",
    "uri": "/observability-workshop/ja/other/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "よくある質問とその回答\rオブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\rディメンション、プロパティ、タグ\rディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。\rOpenTelemetryでのタグ付け\r大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "description": "よくある質問とその回答\rオブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\rディメンション、プロパティ、タグ\rディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。\rOpenTelemetryでのタグ付け\r大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "tags": [],
    "title": "リソース",
    "uri": "/observability-workshop/ja/resources/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 1. はじめに",
    "content": "この FAQ では、ワークショップへのログイン時に遭遇することの多い一般的な問題について説明します。\n1. 招待メールまたはパスワード更新メールが届かない 最初に行うべき手順は、noreply@signalfx.com からのメールをすべてのメールフォルダで検索することです。これは招待状やパスワード更新メールの送信に使用されるアドレスです。メールが見つからない場合は、スパム/迷惑メールフォルダを確認してください。\nメールが存在しないことが確実な場合は、インストラクターにワークショップに使用されたメールアドレスを確認してもらい、招待状を再送信してもらいましょう。\nこれがうまくいかない場合、別の解決策として、インストラクターに別のメールアドレス（例えばプライベートメールアドレス）を提供し、招待状を再送信してもらうことも可能です。\n2. パスワードが受け付けられない Splunk Observability Cloud でのパスワードの要件は以下の通りです：\n8 文字から 32 文字の間でなければなりません 少なくとも 1 つの大文字を含まなければなりません 少なくとも 1 つの数字を含まなければなりません 少なくとも 1 つの記号（例：!@#$%^\u0026*()_+）を含まなければなりません 3. 無効または不明なパスワード システムがパスワードとユーザー名の組み合わせを認識しない場合は、パスワードリセットリンクをクリックしてパスワードのリセットを試みてください。 パスワードの入力を求められます。そのアカウントが存在する場合は、パスワードをリセットできるようにメールが送信されます。そのメールの指示に従ってください。\nメールが届かない場合やユーザー名が認識されない場合は、インストラクターに連絡して支援を求めてください。\n4. その他のオプション 準備中です。",
    "description": "この FAQ では、ワークショップへのログイン時に遭遇することの多い一般的な問題について説明します。\n1. 招待メールまたはパスワード更新メールが届かない 最初に行うべき手順は、noreply@signalfx.com からのメールをすべてのメールフォルダで検索することです。これは招待状やパスワード更新メールの送信に使用されるアドレスです。メールが見つからない場合は、スパム/迷惑メールフォルダを確認してください。\nメールが存在しないことが確実な場合は、インストラクターにワークショップに使用されたメールアドレスを確認してもらい、招待状を再送信してもらいましょう。\nこれがうまくいかない場合、別の解決策として、インストラクターに別のメールアドレス（例えばプライベートメールアドレス）を提供し、招待状を再送信してもらうことも可能です。\n2. パスワードが受け付けられない Splunk Observability Cloud でのパスワードの要件は以下の通りです：\n8 文字から 32 文字の間でなければなりません 少なくとも 1 つの大文字を含まなければなりません 少なくとも 1 つの数字を含まなければなりません 少なくとも 1 つの記号（例：!@#$%^\u0026*()_+）を含まなければなりません 3. 無効または不明なパスワード システムがパスワードとユーザー名の組み合わせを認識しない場合は、パスワードリセットリンクをクリックしてパスワードのリセットを試みてください。 パスワードの入力を求められます。そのアカウントが存在する場合は、パスワードをリセットできるようにメールが送信されます。そのメールの指示に従ってください。\nメールが届かない場合やユーザー名が認識されない場合は、インストラクターに連絡して支援を求めてください。\n4. その他のオプション 準備中です。",
    "tags": [],
    "title": "ログオンFAQ",
    "uri": "/observability-workshop/ja/splunk4rookies/observability-cloud/3-quick-tour/1-homepage/99-login-faq/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "",
    "description": "",
    "tags": [],
    "title": "カテゴリー",
    "uri": "/observability-workshop/ja/categories/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "",
    "description": "",
    "tags": [],
    "title": "タグ",
    "uri": "/observability-workshop/ja/tags/index.html"
  }
]
