<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=print><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=generator content="Relearn 7.2.1"><meta name=description content="Resources for learning about Splunk Observability Cloud"><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Resources :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="Resources for learning about Splunk Observability Cloud"><meta property="og:url" content="https://splunk.github.io/observability-workshop/v5.88/en/resources/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="Resources :: Splunk Observability Cloud Workshops"><meta property="og:description" content="Resources for learning about Splunk Observability Cloud"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Resources :: Splunk Observability Cloud Workshops"><meta itemprop=description content="Resources for learning about Splunk Observability Cloud"><meta itemprop=dateModified content="2024-09-19T16:47:03+01:00"><meta itemprop=wordCount content="61"><title>Resources :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/v5.88/en/resources/index.html rel=alternate hreflang=x-default><link href=https://splunk.github.io/observability-workshop/v5.88/en/resources/index.html rel=alternate hreflang=en><link href=https://splunk.github.io/observability-workshop/v5.88/ja/resources/index.html rel=alternate hreflang=ja><link href=https://splunk.github.io/observability-workshop/v5.88/en/resources/index.html rel=canonical type=text/html title="Resources :: Splunk Observability Cloud Workshops"><link href=/observability-workshop/v5.88/images/favicon.ico?1742286784 rel=icon type=image/x-icon sizes=any><link href=/observability-workshop/v5.88/css/fontawesome-all.min.css?1742286784 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.88/css/fontawesome-all.min.css?1742286784 rel=stylesheet></noscript><link href=/observability-workshop/v5.88/css/auto-complete.css?1742286784 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.88/css/auto-complete.css?1742286784 rel=stylesheet></noscript><link href=/observability-workshop/v5.88/css/perfect-scrollbar.min.css?1742286784 rel=stylesheet><link href=/observability-workshop/v5.88/css/theme.min.css?1742286784 rel=stylesheet><link href=/observability-workshop/v5.88/css/format-print.min.css?1742286784 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../..",window.relearn.relBaseUri="../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop/v5.88",window.relearn.min=`.min`,window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.themevariants=["auto","splunk-light","splunk-dark"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}}))},window.relearn.markVariant=function(){var t=window.localStorage.getItem(window.relearn.absBaseUri+"/variant"),e=document.querySelector("#R-select-variant");e&&(e.value=t)},window.relearn.initVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({app:"observability-workshop",realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA"})</script></script><style>:root{--MAIN-WIDTH-MAX:130rem;--MENU-WIDTH-L:23rem}p{margin:.75rem 0}.highlight{max-height:500px;overflow-y:auto}pre:not(.mermaid){margin:0}</style></head><body class="mobile-support print disableInlineCopyToClipboard" data-url=/observability-workshop/v5.88/en/resources/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.88/en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Resources</span><meta itemprop=position content="2"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.88/en/resources/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.88/en/scenarios/self_service_observability/2-collect_with_standards/3-reconfigure_collector/index.html title="Reconfigure Collector (ü°ê)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.88/en/resources/dimensions_properties_tags/index.html title="Dimension, Properties and Tags (ü°í)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable resources" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=resources>Resources</h1><div class="children children-h3 children-sort-"><h3><a href=/observability-workshop/v5.88/en/resources/dimensions_properties_tags/index.html>Dimension, Properties and Tags</a></h3><p>One conversation that frequently comes up is Dimensions vs Properties and when you should use one verus the other.</p><h3><a href=/observability-workshop/v5.88/en/resources/otel_tagging/index.html>OpenTelemetry Tagging</a></h3><p>When deploying OpenTelemetry in a large organization, it‚Äôs critical to define a standardized naming convention for tagging, and a governance process to ensure the convention is adhered to.</p><h3><a href=/observability-workshop/v5.88/en/resources/local-hosting/index.html>Local Hosting</a></h3><p>Resources for setting up a locally hosted workshop environment.</p></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Sep 19, 2024</span></span></footer></article><section><h1 class=a11y-only>Subsections of Resources</h1><article class=default><header class=headline></header><h1 id=dimension-properties-and-tags>Dimension, Properties and Tags</h1><h2 id=applying-context-to-your-metrics>Applying context to your metrics</h2><p>One conversation that frequently comes up is Dimensions vs Properties and when you should use one verus the other. Instead of starting off with their descriptions it makes sense to understand how we use them and how they are similar, before diving into their differences and examples of why you would use one or the other.</p><h2 id=how-are-dimensions-and-properties-similar>How are Dimensions and Properties similar?</h2><p>The simplest answer is that they are both metadata <code>key:value</code> pairs that add context to our metrics. Metrics themselves are what we actually want to measure, whether it‚Äôs a standard infrastructure metric like‚Äã ‚Äã<code>cpu.utilization</code> or a custom metric like number of API calls received.</p><p>If we receive a value of 50% for th‚Äãe ‚Äã<code>cpu.utilization</code> metric without knowing where it came from or any other context it is just a number and not useful to us. We would need at least to know what host it comes from.</p><p>These days it is likely we care more about the performance or utilization of a cluster or data center as a whole then that of an individual host and therefore more interested in things like the average <code>cpu.utilization</code> across a cluster of hosts, when a‚Äã host‚Äôs <code>‚Äãcpu.utilization</code> is a outlier when compared to other hosts running the same service or maybe compare the ‚Äãaverage ‚Äã<code>cpu.utilization</code> of one environment to another.</p><p>To be able to slice, aggregate or g‚Äãroup our ‚Äã<code>cpu.utilization</code> metrics in this way we will need additional metad‚Äãata for the <code>‚Äãcpu.utilization</code> metrics we receive to include what cluster a host belongs to, what service is running on the host and what environment it is a part of. This metadata can be in the form of either dimension or property <code>key:value</code> pairs.</p><p>For example, if I go to apply a filter to a dashboard or use the Group by function when running analytics, I can use a property or a dimension.</p><h2 id=so-how-are-dimensions-and-properties-different>So how are Dimensions and Properties different?</h2><p>Dimensions are sent in with metrics at the time of ingest while properties are applied to metrics or dimensions after ingest. This means that any metadata you need to make a datapoint (‚Äãa single reported value of a metric) ‚Äãunique, like what host a value of <code>cpu.utilization</code> is coming from needs to be a dimension. Metric names + dimensions uniquely define an MTS (metric time series).</p><p>Example: the <code>‚Äãcpu.utilization</code> metric sent by a particular host (‚Äãserver1) with a dimension <code>‚Äãhost:server1</code> would be considered a unique time series. If you have 10 servers, each sending that metric, then you would have 10 time series, with each time series sharing the metric name <code>‚Äãcpu.utilization</code> and uniquely identified by the dimension key-value pair (‚Äãhost:server1, host:server2&mldr;host:server10).</p><p>However, if your server names are only unique within a datacenter vs your whole environment you would need to add a 2n‚Äãd‚Äã dimension <code>dc</code> for the datacenter location. You could now have double the number of possible MTSs. cpu.utilization metrics received would now be uniquely identified by 2 sets of dimension key-value pairs.</p><p>cpu.utilization plus ‚Äãdc:east &‚Äã host:server1 would create a different time series then ‚Äãcpu.utilization plus dc:west & ‚Äãhost:server1.</p><h2 id=dimensions-are-immutable-while-properties-are-mutable>Dimensions are immutable while properties are mutable</h2><p>As we mentioned above, Metric name + dimensions make a unique MTS. Therefore, if the dimension value changes we will have a new unique combination of metric name + dimension value and create a new MTS.</p><p>Properties on the other hand are applied to metrics (or dimensions) after they are ingested. If you apply a property to a metric, it propagates and applies to all MTS that the metric is a part of. Or if you apply a property to a dimension, say ‚Äãhost:server1 then all metrics from that host will have those properties attached. If you change the value of a property it will propagate and update the value of the property to all MTSs with that property attached. Why is this important? It means that if you care about the historical value of a property you need to make it a dimension.</p><p>Example: We are collecting custom metrics on our application. One metric is ‚Äãlatency which counts the latency of requests made to our application. We have a dimension ‚Äãcustomer, so we can sort and compare latency by customer. We decide we want to track the ‚Äãapplication version as well so we can sort and compare our application ‚Äãlatency by the version customers are using. We create a property ‚Äãversion that we attach to the customer dimension. Initially all customers are using application version 1, so ‚Äãversion:1.</p><p>We now have some customers using version 2 of our application, for those customers we update the property to ‚Äãversion:2. When we update the value of the ‚Äãversion property for those customers it will propagate down to all MTS for that customer. We lose the history that those customers at some point used ‚Äãversion 1, so if we wanted to compare ‚Äãlatency of ‚Äãversion 1 and ‚Äãversion 2 over a historical period we would not get accurate data. In this case even though we don‚Äôt need application ‚Äãversion to make out metric time series unique we need to make ‚Äãversion a dimension, because we care about the historical value.</p><h2 id=so-when-should-something-be-a-property-instead-of-a-dimension>So when should something be a Property instead of a dimension?</h2><p>The first reason would be if there is any metadata you want attached to metrics, but you don‚Äôt know it at the time of ingest.
The second reason is best practice is if it doesn‚Äôt need to be a dimension, make it a property. Why?
One reason is that today there is a limit of 5K MTSs per analytics job or chart rendering and the more dimensions you have the more MTS you will create. Properties are completely free-form and let you add as much information as you want or need to metrics or dimensions without adding to MTS counts.</p><p>As dimensions are sent in with every datapoint, the more dimensions you have the more data you send to us, which could mean higher costs to you if your cloud provider charges for data transfer.</p><p>A good example of some things that should be properties would be additional host information. You want to be able to see things like machine_type, processor, or os, but instead of making these things dimensions and sending them with every metric from a host you could make them properties and attach the properties to the host dimension.</p><p>Example where ‚Äãhost:server1 you would set properties ‚Äãmachine_type:ucs, processor:xeon-5560, os:rhel71. Anytime a metric comes in with the dimension ‚Äãhost:server1 all the above properties will be applied to it automatically.</p><p>Some other examples of use cases for properties would be if you want to know who is the escalation contact for each service or SLA level for every customer. You do not need these items to make metrics uniquely identifiable and you don‚Äôt care about the historical values, so they can be properties. The properties could be added to the service dimension and customer dimensions and would then apply to all metrics and MTSs with those dimensions.</p><h2 id=what-about-tags>What about Tags?</h2><p>Tags are the 3r‚Äãd‚Äã type of metadata that can be used to give context to or help organize your metrics. Unlike dimensions and properties, tags are NOT key:value pairs. ‚ÄãTags can be thought of as labels or keywords. Similar to Properties, Tags are applied to your data after ingest via the Catalog in the UI or programmatically via the API.‚Äã Tags can be applied to Metrics, Dimensions or other objects such as Detectors.</p><h2 id=where-would-i-use-tags>Where would I use Tags?</h2><p>Tags are used when there is a need for a many-to-one relationship of tags to an object or a one-to-many relationship between the tag and the objects you are applying them to. They are useful for grouping together metrics that may not be intrinsically associated.</p><p>One example is you have hosts that run multiple applications. You can create tags (labels) for each application and then apply multiple tags to each host to label the applications that are running on it.</p><p>Example: Server1 runs 3 applications. You create tags ‚Äãapp1, app2 and app3 and apply all 3 tags to the dimension ‚Äãhost:server1</p><p>To expand on the example above let us say you also collect metrics from your applications.‚Äã You could apply the tags you created to any metrics coming in from the applications themselves. You can filter based on a tag allowing you to filter based on an application, but get the full picture including both application and the relevant host metrics.</p><p>Example: App1 sends in metrics with the dimension ‚Äãservice:application1. You would apply tag ‚Äãapp1 to the dimension ‚Äãservice:application1. You can then filter on the tag ‚Äãapp1 in charts and dashboards.</p><p>Another use case for tags for binary states where there is just one possible value. An example is you do canary testing and when you do a canary deployment you want to be able to mark the hosts that received the new code, so you can easily identify their metrics and compare their performance to those hosts that did not receive the new code. There is no need for a key:value pair as there is just a single value ‚Äúcanary‚Äù.</p><p>Be aware that while you can filter on tags you cannot use the groupBy function on them. The groupBy function is run by supplying the key part of a key:value pair and the results are then grouped by values of that key pair.</p><h2 id=additional-information>Additional information</h2><p>For information on sending dimensions for custom metrics please review the ‚ÄãClient Libraries documentation for your library of choice.</p><p>For information on how to apply properties & tags to metrics or dimensions via the API please see the API documentation for ‚Äã/metric/:name‚Äã ‚Äã/dimension/:key/:value</p><p>For information on how to add or edit properties and tags via the Metadata Catalog in the UI please reference the section <strong>‚ÄãAdd or edit metadata</strong> in <a href=https://docs.splunk.com/Observability/metrics-and-metadata/metrics-finder-metadata-catalog.html#use-the-metadata-catalog rel=external target=_blank>Search the Metric Finder and Metadata catalog</a>.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Apr 2, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=naming-conventions-for-tagging-with-opentelemetry-and-splunk>Naming Conventions for Tagging with OpenTelemetry and Splunk</h1><h2 id=introduction>Introduction</h2><p>When deploying OpenTelemetry in a large organization, it‚Äôs critical to define a standardized naming convention for tagging, and a governance process to ensure the convention is adhered to.</p><p>This ensures that MELT data collected via OpenTelemetry can be efficiently utilized for alerting, dashboarding, and troubleshooting purposes. It also ensures that users of Splunk Observability Cloud can quickly find the data they‚Äôre looking for.</p><p>Naming conventions also ensure that data can be aggregated effectively. For example, if we wanted to count the number of unique hosts by environment, then we must use a standardized convention for capturing the host and environment names.</p><h2 id=attributes-vs-tags>Attributes vs. Tags</h2><p>Before we go further, let‚Äôs make a note regarding terminology. Tags in OpenTelemetry are called ‚Äúattributes‚Äù. Attributes can be attached to metrics, logs, and traces, either via manual instrumentation or automated instrumentation.</p><p>Attributes can also be attached to metrics, logs, and traces at the OpenTelemetry collector level, using various processors such as the <a href=https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/resourcedetectionprocessor rel=external target=_blank>Resource Detection processor</a>.</p><p>Once traces with attributes are ingested into Splunk Observability Cloud, they are available as ‚Äútags‚Äù. Optionally, attributes collected as part of traces can be used to create <a href=https://docs.splunk.com/Observability/apm/span-tags/metricsets.html#troubleshooting-metricsets rel=external target=_blank>Troubleshooting Metric Sets</a>, which can in turn be used with various features such as <a href=https://docs.splunk.com/Observability/apm/span-tags/tag-spotlight.html rel=external target=_blank>Tag Spotlight</a>.</p><p>Alternatively, attributes can be used to create <a href=https://docs.splunk.com/Observability/apm/span-tags/metricsets.html#monitoring-metricsets rel=external target=_blank>Monitoring Metric Sets</a>, which can be used to drive alerting.</p><h2 id=resource-semantic-conventions>Resource Semantic Conventions</h2><p><a href=https://github.com/open-telemetry/semantic-conventions/tree/main rel=external target=_blank>OpenTelemetry resource semantic conventions</a> should be used as a starting point when determining which attributes an organization should standardize on. In the following sections, we‚Äôll review some of the more commonly used attributes.</p><h3 id=service-attributes>Service Attributes</h3><p>A number of attributes are used to describe the service being monitored.</p><p><code>service.name</code> is a required attribute that defines the logical name of the service. It‚Äôs added automatically by the OpenTelemetry SDK but can be customized. It‚Äôs best to keep this simple (i.e. <code>inventoryservice</code> would be better than <code>inventoryservice-prod-hostxyz</code>, as other attributes can be utilized to capture other aspects of the service instead).</p><p>The following service attributes are recommended:</p><ul><li><code>service.namespace</code> this attribute could be utilized to identify the team that owns the service</li><li><code>service.instance.id</code> is used to identify a unique instance of the service</li><li><code>service.version</code> is used to identify the version of the service</li></ul><h3 id=telemetry-sdk>Telemetry SDK</h3><p>These attributes are set automatically by the SDK, to record information about the instrumentation libraries being used:</p><ul><li><code>telemetry.sdk.name</code> is typically set to <code>opentelemetry</code></li><li><code>telemetry.sdk.language</code> is the language of the SDK, such as <code>java</code></li><li><code>telemetry.sdk.version</code> identifies which version of the SDK is utilized</li></ul><h3 id=containers>Containers</h3><p>For services running in containers, there are numerous attributes used to describe the container runtime, such as <code>container.id</code>, <code>container.name</code>, and <code>container.image.name</code>. The full list can be found <a href=https://github.com/open-telemetry/semantic-conventions/blob/main/docs/resource/container.md rel=external target=_blank>here</a>.</p><h3 id=hosts>Hosts</h3><p>These attributes describe the host where the service is running, and include attributes such as <code>host.id</code>, <code>host.name</code>, and <code>host.arch</code>. The full list can be found <a href=https://github.com/open-telemetry/semantic-conventions/blob/main/docs/resource/host.md rel=external target=_blank>here</a>.</p><h3 id=deployment-environment>Deployment Environment</h3><p>The <code>deployment.environment</code> attribute is used to identify the environment where the service is deployed, such as <strong>staging</strong> or <strong>production</strong>.</p><p>Splunk Observability Cloud uses this attribute to enable related content (as described <a href=https://docs.splunk.com/observability/metrics-and-metadata/enablerelatedcontent.html rel=external target=_blank>here</a>), so it‚Äôs important to include it.</p><h3 id=cloud>Cloud</h3><p>There are also attributes to capture information for services running in public cloud environments, such as AWS. Attributes include cloud.provider, <code>cloud.account.id</code>, and <code>cloud.region</code>.</p><p>The full list of attributes can be found <a href=https://github.com/open-telemetry/semantic-conventions/blob/main/docs/resource/cloud.md rel=external target=_blank>here</a>.</p><p>Some cloud providers, such as <a href=https://github.com/open-telemetry/semantic-conventions/tree/main/docs/resource/cloud-provider/gcp rel=external target=_blank>GCP</a>, define semantic conventions specific to their offering.</p><h3 id=kubernetes>Kubernetes</h3><p>There are a number of standardized attributes for applications running in Kubernetes as well. Many of these are added automatically by Splunk‚Äôs distribution of the OpenTelemetry collector, as described <a href=https://docs.splunk.com/observability/metrics-and-metadata/enablerelatedcontent.html#splunk-infrastructure-monitoring rel=external target=_blank>here</a>.</p><p>These attributes include <code>k8s.cluster.name</code>, <code>k8s.node.name</code>, <code>k8s.pod.name</code>, <code>k8s.namespace.name</code>, and <code>kubernetes.workload.name</code>.</p><h2 id=best-practices-for-creating-custom-attributes>Best Practices for Creating Custom Attributes</h2><p>Many organizations require attributes that go beyond what‚Äôs defined in OpenTelemetry‚Äôs resource semantic conventions.</p><p>In this case, it‚Äôs important to avoid naming conflicts with attribute names already included in the semantic conventions. So it‚Äôs a good idea to check the semantic conventions before deciding on a particular attribute name for your naming convention.</p><p>In addition to a naming convention for attribute names, you also need to consider attribute values. For example, if you‚Äôd like to capture the particular business unit with which an application belongs, then you‚Äôll also want to have a standardized list of business unit values to choose from, to facilitate effective filtering.</p><p>The OpenTelemetry community provides guidelines that should be followed when naming attributes as well, which can be found <a href=https://opentelemetry.io/docs/specs/otel/common/attribute-naming/ rel=external target=_blank>here</a>.</p><p>The <a href=https://opentelemetry.io/docs/specs/otel/common/attribute-naming/#recommendations-for-application-developers rel=external target=_blank>Recommendations for Application Developers</a> section is most relevant to our discussion.</p><p>They recommend:</p><ul><li>Prefixing the attribute name with your company‚Äôs domain name, e.g. <code>com.acme.shopname</code> (if the attribute may be used outside your company as well as inside).</li><li>Prefixing the attribute name with the application name, if the attribute is unique to a particular application and is only used within your organization.</li><li>Not using existing OpenTelemetry semantic convention names as a prefix for your attribute name.</li><li>Consider submitting a proposal to add your attribute name to the OpenTelemetry specification, if there‚Äôs a general need for it across different organizations and industries.</li><li>Avoid having attribute names start with <code>otel.*</code>, as this is reserved for OpenTelemetry specification usage.</li></ul><h2 id=metric-cardinality-considerations>Metric Cardinality Considerations</h2><p>One final thing to keep in mind when deciding on naming standards for attribute names and values is related to metric cardinality.</p><p>Metric cardinality is defined as **the number of unique metric time series (MTS) produced by a combination of metric <strong>names and their associated dimensions</strong>.</p><p>A metric has high cardinality when it has a high number of dimension keys and a high number of possible unique values for those dimension keys.</p><p>For example, suppose your application sends in data for a metric named <code>custom.metric</code>. In the absence of any attributes, <code>custom.metric</code> would generate a single metric time series (MTS).</p><p>On the other hand, if <code>custom.metric</code> includes an attribute named <code>customer.id</code>, and there are thousands of customer ID values, this would generate thousands of metric time series, which may impact costs and query performance.</p><p>Splunk Observability Cloud provides a <a href=https://docs.splunk.com/Observability/infrastructure/metrics-pipeline/metrics-usage-report.html rel=external target=_blank>report</a> that allows for the management of metrics usage. And <a href=https://docs.splunk.com/Observability/infrastructure/metrics-pipeline/use-metrics-pipeline.html rel=external target=_blank>rules</a> can be created to drop undesirable dimensions. However, the first line of defence is understanding how attribute name and value combinations can drive increased metric cardinality.</p><h2 id=summary>Summary</h2><p>In this document, we highlighted the importance of defining naming conventions for OpenTelemetry tags, preferably before starting a large rollout of OpenTelemetry instrumentation.</p><p>We discussed how OpenTelemetry‚Äôs resource semantic conventions define the naming conventions for several attributes, many of which are automatically collected via the OpenTelemetry SDKs, as well as processors that run within the OpenTelemetry collector.</p><p>Finally, we shared some best practices for creating your attribute names, for situations where the resource semantic conventions are not sufficient for your organization‚Äôs needs.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Apr 2, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=local-hosting>Local Hosting</h1><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info-circle"></i>
Info</summary><div class=box-content><p>Please disable any VPNs or proxies before setting up an instance e.g:</p><ul><li>ZScaler</li><li>Cisco AnyConnect</li></ul><p>These tools <strong>will</strong> prevent the instance from being created properly.</p></div></details><ul class="children children-li children-sort-"><li><a href=/observability-workshop/v5.88/en/resources/local-hosting/multipass/index.html>Local Hosting with Multipass</a><p>Learn how to create a local hosting environment with Multipass - Windows/Linux/Mac(Intel)</p><ul></ul></li><li><a href=/observability-workshop/v5.88/en/resources/local-hosting/orbstack/index.html>Local Hosting with OrbStack</a><p>Learn how to create a local hosting environment with OrbStack - Mac (Apple Silicon)</p><ul></ul></li><li><a href=/observability-workshop/v5.88/en/resources/local-hosting/diab/index.html>Running Demo-in-a-Box</a><p>Learn how to use Demo-in-a-Box to manage demos and otel collectors in an easy-to-use web interface.</p><ul></ul></li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Aug 13, 2024</span></span></footer></article><section><h1 class=a11y-only>Subsections of Local Hosting</h1><article class=default><header class=headline></header><h1 id=local-hosting-with-multipass>Local Hosting with Multipass</h1><p>Install <a href=https://multipass.run/ rel=external target=_blank>Multipass</a> and Terraform for your operating system. On a Mac (Intel), you can also install via <a href=https://brew.sh/ rel=external target=_blank>Homebrew</a> e.g.</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>brew install multipass
</span></span><span class=line><span class=cl>brew install terraform</span></span></code></pre></div><p>Clone workshop repository:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/splunk/observability-workshop</span></span></code></pre></div><p>Change into multipass directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> observability-workshop/local-hosting/multipass</span></span></code></pre></div><p>Log Observer Connect:</p><p>If you plan to use your own Splunk Observability Cloud Suite Org and or Splunk instance, you may need to create a new <strong>Log Observer Connect</strong> connection:
Follow the instructions found in the <a href=https://docs.splunk.com/observability/en/logs/lo-connect-landing.html rel=external target=_blank>documentation</a> for <a href=https://docs.splunk.com/observability/en/logs/scp.html#logs-scp rel=external target=_blank>Splunk Cloud</a> or <a href=https://docs.splunk.com/observability/en/logs/set-up-logconnect.html rel=external target=_blank>Splunk Enterprize</a>.</p><p>Additional requirements for running your own <strong>Log Observer Connect</strong> connection are:</p><ul><li>Create an index called <strong>splunk4rookies-workshop</strong></li><li>Make sure the Service account user used in the <strong>Log observer Connect</strong> connection has access to the <strong>splunk4rookies-workshop</strong> index (you can remove all other indexes, as all workshop log data should go to this index).</li></ul><p>Initialise Terraform:</p><div class=tab-panel data-tab-group=997350c97f5cbfb9fc17251c3cfc38af><div class=tab-nav><div class=tab-nav-title>&#8203;</div><button data-tab-item=command class="tab-nav-button tab-panel-style cstyle initial active" tabindex=-1 onclick='switchTab("997350c97f5cbfb9fc17251c3cfc38af","command")'>
<span class=tab-nav-text>Command</span>
</button>
<button data-tab-item=example-output class="tab-nav-button tab-panel-style cstyle initial" onclick='switchTab("997350c97f5cbfb9fc17251c3cfc38af","example-output")'>
<span class=tab-nav-text>Example Output</span></button></div><div class=tab-content-container><div data-tab-item=command class="tab-content tab-panel-style cstyle initial active"><div class=tab-content-text><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform init -upgrade</span></span></code></pre></div></div></div><div data-tab-item=example-output class="tab-content tab-panel-style cstyle initial"><div class=tab-content-text><p>```text
Initializing the backend...
Initializing provider plugins...
- Finding latest version of hashicorp/random...
- Finding latest version of hashicorp/local...
- Finding larstobi/multipass versions matching "~> 1.4.1"...
- Installing hashicorp/random v3.5.1...
- Installed hashicorp/random v3.5.1 (signed by HashiCorp)
- Installing hashicorp/local v2.4.0...
- Installed hashicorp/local v2.4.0 (signed by HashiCorp)
- Installing larstobi/multipass v1.4.2...
- Installed larstobi/multipass v1.4.2 (self-signed, key ID 797707331BF3549C)
```</div></div></div></div><p>Create Terraform variables file. Variables are kept in file <code>terrform.tfvars</code> and a template is provided, <code>terraform.tfvars.template</code>, to copy and edit:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>cp terraform.tfvars.template terraform.tfvars</span></span></code></pre></div><p>The following Terraform variables are required:</p><ul><li><code>splunk_access_token</code>: Observability Cloud Access Token</li><li><code>splunk_api_token</code>: Observability Cloud API Token</li><li><code>splunk_rum_token</code>: Observability Cloud RUM Token</li><li><code>splunk_realm</code>: Observability Cloud Realm e.g. <code>eu0</code></li><li><code>splunk_hec_url</code>: Splunk HEC URL. Do not use a <code>raw</code> endpoint, use the <code>event</code> endpoint so logs process correctly.</li><li><code>splunk_hec_token</code>: Splunk HEC Token</li><li><code>splunk_index</code>: Splunk Index to send logs to. Defaults to <code>splunk4rookies-workshop</code>.</li></ul><p>Instance type variables:</p><ul><li><code>splunk_presetup</code>: Provide a preconfigured instance (OTel Collector and Online Boutique deployed with RUM enabled). The default is <code>false</code>.</li><li><code>splunk_diab</code>: Install and run Demo-in-a-Box. The default is <code>false</code>.</li><li><code>tagging_workshop</code>: Install and configure the Tagging Workshop. The default is <code>false</code>.</li><li><code>otel_demo</code> : Install and configure the OpenTelemetry Astronomy Shop Demo. This requires that <code>splunk_presetup</code> is set to <code>false</code>. The default is <code>false</code>.</li></ul><p>Optional advanced variables:</p><ul><li><code>wsversion</code>: Set this to <code>main</code> if working on the development of the workshop, otherwise this can be omitted.</li><li><code>architecture</code>: Set this to <code>arm64</code> if you are running on Apple Silicon. Defaults to <code>amd64</code>.</li></ul><p>Run <code>terraform plan</code> to check that all configuration is OK. Once happy run <code>terraform apply</code> to create the instance.</p><div class=tab-panel data-tab-group=640b7dccee83f5ea37169e831215b0ec><div class=tab-nav><div class=tab-nav-title>&#8203;</div><button data-tab-item=command class="tab-nav-button tab-panel-style cstyle initial active" tabindex=-1 onclick='switchTab("640b7dccee83f5ea37169e831215b0ec","command")'>
<span class=tab-nav-text>Command</span>
</button>
<button data-tab-item=example-output class="tab-nav-button tab-panel-style cstyle initial" onclick='switchTab("640b7dccee83f5ea37169e831215b0ec","example-output")'>
<span class=tab-nav-text>Example Output</span></button></div><div class=tab-content-container><div data-tab-item=command class="tab-content tab-panel-style cstyle initial active"><div class=tab-content-text><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform apply</span></span></code></pre></div></div></div><div data-tab-item=example-output class="tab-content tab-panel-style cstyle initial"><div class=tab-content-text><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>random_string.hostname: Creating...
</span></span><span class=line><span class=cl>random_string.hostname: Creation complete after 0s [id=cynu]
</span></span><span class=line><span class=cl>local_file.user_data: Creating...
</span></span><span class=line><span class=cl>local_file.user_data: Creation complete after 0s [id=46a5c50e396a1a7820c3999c131a09214db903dd]
</span></span><span class=line><span class=cl>multipass_instance.ubuntu: Creating...
</span></span><span class=line><span class=cl>multipass_instance.ubuntu: Still creating... [10s elapsed]
</span></span><span class=line><span class=cl>multipass_instance.ubuntu: Still creating... [20s elapsed]
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>multipass_instance.ubuntu: Still creating... [1m30s elapsed]
</span></span><span class=line><span class=cl>multipass_instance.ubuntu: Creation complete after 1m38s [name=cynu]
</span></span><span class=line><span class=cl>data.multipass_instance.ubuntu: Reading...
</span></span><span class=line><span class=cl>data.multipass_instance.ubuntu: Read complete after 1s [name=cynu]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Apply complete! Resources: 3 added, 0 changed, 0 destroyed.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Outputs:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>instance_details = [
</span></span><span class=line><span class=cl>  {
</span></span><span class=line><span class=cl>    &#34;image&#34; = &#34;Ubuntu 22.04.2 LTS&#34;
</span></span><span class=line><span class=cl>    &#34;image_hash&#34; = &#34;345fbbb6ec82 (Ubuntu 22.04 LTS)&#34;
</span></span><span class=line><span class=cl>    &#34;ipv4&#34; = &#34;192.168.205.185&#34;
</span></span><span class=line><span class=cl>    &#34;name&#34; = &#34;cynu&#34;
</span></span><span class=line><span class=cl>    &#34;state&#34; = &#34;Running&#34;
</span></span><span class=line><span class=cl>  },
</span></span><span class=line><span class=cl>]</span></span></code></pre></div></div></div></div></div><p>Once the instance has been successfully created (this can take several minutes), <code>exec</code> into it using the <code>name</code> from the output above. The password for Multipass instance is <code>Splunk123!</code>.</p><div class=tab-panel data-tab-group=e6d1097a86b2ca7618deb527089a86c6><div class=tab-nav><div class=tab-nav-title>&#8203;</div><button data-tab-item=command class="tab-nav-button tab-panel-style cstyle initial active" tabindex=-1 onclick='switchTab("e6d1097a86b2ca7618deb527089a86c6","command")'>
<span class=tab-nav-text>Command</span>
</button>
<button data-tab-item=example-output class="tab-nav-button tab-panel-style cstyle initial" onclick='switchTab("e6d1097a86b2ca7618deb527089a86c6","example-output")'>
<span class=tab-nav-text>Example Output</span></button></div><div class=tab-content-container><div data-tab-item=command class="tab-content tab-panel-style cstyle initial active"><div class=tab-content-text><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>multipass <span class=nb>exec</span> cynu -- su -l splunk</span></span></code></pre></div></div></div><div data-tab-item=example-output class="tab-content tab-panel-style cstyle initial"><div class=tab-content-text><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>$ multipass exec kdhl -- su -l splunk
</span></span><span class=line><span class=cl>Password:
</span></span><span class=line><span class=cl>Waiting for cloud-init status...
</span></span><span class=line><span class=cl>Your instance is ready!</span></span></code></pre></div></div></div></div></div><p>Validate the instance:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl version --output<span class=o>=</span>yaml</span></span></code></pre></div><p>To delete the instance, first make sure you have exited from instance and then run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>terraform destroy</span></span></code></pre></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Sep 25, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=local-hosting-with-orbstack>Local Hosting with OrbStack</h1><p>Install Orbstack:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>brew install orbstack</span></span></code></pre></div><p>Log Observer Connect:</p><p>If you plan to use your own Splunk Observability Cloud Suite Org and or Splunk instance, you may need to create a new <strong>Log Observer Connect</strong> connection:
Follow the instructions found in the <a href=https://docs.splunk.com/observability/en/logs/lo-connect-landing.html rel=external target=_blank>documentation</a> for <a href=https://docs.splunk.com/observability/en/logs/scp.html#logs-scp rel=external target=_blank>Splunk Cloud</a> or <a href=https://docs.splunk.com/observability/en/logs/set-up-logconnect.html rel=external target=_blank>Splunk Enterprize</a>.</p><p>Additional requirements for running your own <strong>Log Observer Connect</strong> connection are:
Create an index called <strong>splunk4rookies-workshop</strong>
Make sure the Service account user used in the <strong>Log observer Connect</strong> Connection has access to the <strong>splunk4rookies-workshop</strong> index. (You can remove all other indexes, as all workshop log data should go to this index)</p><p>Clone workshop repository:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/splunk/observability-workshop</span></span></code></pre></div><p>Change into Orbstack directory:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> observability-workshop/local-hosting/orbstack</span></span></code></pre></div><p>Copy the <code>start.sh.example</code> to <code>start.sh</code> and edit the file to set the following required variables
Make sure that you do not use a Raw Endpoint, but use an Event Endpoint instead as this will process the logs correctly</p><ul><li><code>ACCESS_TOKEN</code></li><li><code>REALM</code></li><li><code>API_TOKEN</code></li><li><code>RUM_TOKEN</code></li><li><code>HEC_TOKEN</code></li><li><code>HEC_URL</code></li></ul><p>Run the script and provide and instance name e.g.:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./start.sh my-instance</span></span></code></pre></div><p>Once the instance has been successfully created (this can take several minutes), you will automatically be logged into the instance. If you exit you can SSH back in using the following command (replace <code>&lt;my_instance></code> with the name of your instance):</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ssh splunk@&lt;my_instance&gt;@orb</span></span></code></pre></div><p>Once in the shell, you can validate that the instance is ready by running the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl version --output<span class=o>=</span>yaml</span></span></code></pre></div><p>To get the IP address of the instance, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ifconfig eth0</span></span></code></pre></div><p>To delete the instance, run the following command:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>orb delete my-instance</span></span></code></pre></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Aug 20, 2024</span></span></footer></article><article class=default><header class=headline></header><h1 id=running-demo-in-a-box>Running Demo-in-a-Box</h1><p><strong>Demo-in-a-box</strong> is a method for running demo apps easily using a web interface.</p><p>It provides:</p><ul><li>A quick way to deploy demo apps and states</li><li>A way to easily change configuration of your otel collector and see logs</li><li>Get pod status, pod logs, etc.</li></ul><p>To leverage this locally using multipass:</p><ul><li>Follow the <a href=../multipass>local hosting for multipass</a> instructions<ul><li>In the <code>terraform.tfvars</code> file, set <code>splunk_diab</code> to <code>true</code> and make sure <strong>all</strong> other options are set to <code>false</code></li><li>Then set the other required and important tokens/url</li><li>Then run the terraform steps</li></ul></li><li>Once the instance is up, navigate in your browser to: <code>http://&lt;IP>:8083</code><ul><li>In the <code>terraform.tfvars</code> file the <code>wsversion</code> defaults to the current version of the workshop e.g <code>4.64</code>:<ul><li>To use the latest developments change <code>wsversion</code> to use <code>main</code></li><li>There are only three versions of the workshop maintained, development (<code>main</code>) current (e.g. <code>4.64</code> and the previous (e.g. <code>4.63</code>)</li><li>After making the change, run <code>terraform apply</code> to make the changes</li></ul></li></ul></li><li>Now you can deploy any of the demos; this will also deploy the collector as part of the deployment</li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Aug 14, 2024</span></span></footer></article></section></section></div></main></div><script src=/observability-workshop/v5.88/js/clipboard.min.js?1742286784 defer></script><script src=/observability-workshop/v5.88/js/perfect-scrollbar.min.js?1742286784 defer></script><script src=/observability-workshop/v5.88/js/theme.js?1742286784 defer></script></body></html>