<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.119.0"><meta name=generator content="Relearn 5.23.2+tip"><meta name=description content="Splunk Observability Workshops"><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Fix PHP/Apache Issue :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="1. Kubernetes Resources Especially in Production Kubernetes Clusters, CPU and Memory are considered precious resources. Cluster Operators will normally require you to specify the amount of CPU and Memory your Pod or Service will require in the deployment, so they can have the Cluster automatically manage on which Node(s) your solution will be placed.
You do this by placing a Resource section in the deployment of your application/Pod
Example:
resources: limits: # Maximum amount of CPU & memory for peek use cpu: &#34;8&#34; # Maximum of 8 cores of CPU allowed at for peek use memory: &#34;9Mi&#34; # Maximum allowed 9Mb of memory requests: # Request are the expected amount of CPU & memory for normal use cpu: &#34;6&#34; # Requesting 4 cores of a CPU memory: &#34;4Mi&#34; # Requesting 4Mb of memoryMore information can be found here: Resource Management for Pods and Containers"><meta property="og:title" content="Fix PHP/Apache Issue :: Splunk Observability Cloud Workshops"><meta property="og:description" content="1. Kubernetes Resources Especially in Production Kubernetes Clusters, CPU and Memory are considered precious resources. Cluster Operators will normally require you to specify the amount of CPU and Memory your Pod or Service will require in the deployment, so they can have the Cluster automatically manage on which Node(s) your solution will be placed.
You do this by placing a Resource section in the deployment of your application/Pod
Example:
resources: limits: # Maximum amount of CPU & memory for peek use cpu: &#34;8&#34; # Maximum of 8 cores of CPU allowed at for peek use memory: &#34;9Mi&#34; # Maximum allowed 9Mb of memory requests: # Request are the expected amount of CPU & memory for normal use cpu: &#34;6&#34; # Requesting 4 cores of a CPU memory: &#34;4Mi&#34; # Requesting 4Mb of memoryMore information can be found here: Resource Management for Pods and Containers"><meta property="og:type" content="article"><meta property="og:url" content="https://splunk.github.io/observability-workshop/v5.38/en/other/4-hpa/4-fix-apache/index.html"><meta property="article:section" content="Monitoring Horizontal Pod Autoscaling in Kubernetes :: Splunk Observability Cloud Workshops"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><title>Fix PHP/Apache Issue :: Splunk Observability Cloud Workshops</title><link href=https://splunk.github.io/observability-workshop/v5.38/en/other/4-hpa/4-fix-apache/index.html rel=canonical type=text/html title="Fix PHP/Apache Issue :: Splunk Observability Cloud Workshops"><link href=../../../../en/other/4-hpa/4-fix-apache/index.xml rel=alternate type=application/rss+xml title="Fix PHP/Apache Issue :: Splunk Observability Cloud Workshops"><link href=../../../../images/favicon.ico?1706259254 rel=icon type=image/x-icon sizes=any><link href=../../../../css/fontawesome-all.min.css?1706259260 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../../../css/fontawesome-all.min.css?1706259260 rel=stylesheet></noscript><link href=../../../../css/nucleus.css?1706259260 rel=stylesheet><link href=../../../../css/auto-complete.css?1706259260 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../../../css/auto-complete.css?1706259260 rel=stylesheet></noscript><link href=../../../../css/perfect-scrollbar.min.css?1706259260 rel=stylesheet><link href=../../../../css/fonts.css?1706259260 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=../../../../css/fonts.css?1706259260 rel=stylesheet></noscript><link href=../../../../css/theme.css?1706259260 rel=stylesheet><link href=../../../../css/theme-splunk-light.css?1706259260 rel=stylesheet id=R-variant-style><link href=../../../../css/variant.css?1706259260 rel=stylesheet><link href=../../../../css/print.css?1706259260 rel=stylesheet media=print><link href=../../../../css/format-print.css?1706259260 rel=stylesheet><link href=../../../../css/ie.css?1706259260 rel=stylesheet><script src=../../../../js/url.js?1706259260></script>
<script src=../../../../js/variant.js?1706259260></script>
<script>window.index_js_url="../../../../en/index.search.js";var root_url="../../../../",baseUri=root_url.replace(/\/$/,"");window.relearn=window.relearn||{},window.relearn.baseUriFull="https://splunk.github.io/observability-workshop/v5.38/",window.variants&&variants.init(["splunk-light","splunk-dark"]),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script>
<script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script>
<script>SplunkRum.init({beaconUrl:"https://rum-ingest.eu0.signalfx.com/v1/rum",rumAuth:"EDIbCJR4LlxWdXMLjkYX1g",app:"observability-workshop",version:"1",environment:"observability-workshop-env"}),SplunkSessionRecorder.init({beaconUrl:"https://rum-ingest.eu0.signalfx.com/v1/rumreplay",rumAuth:"EDIbCJR4LlxWdXMLjkYX1g"})</script><style>@media screen and (min-width:1000px){#R-body .flex-block-wrapper{margin-left:auto;margin-right:auto;max-width:1400px;width:100%}}:root{--MENU-WIDTH-L:22.5rem}</style></head><body class="mobile-support print disableInlineCopyToClipboard" data-url=../../../../en/other/4-hpa/4-fix-apache/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)">
<i class="fa-fw fas fa-bars"></i></button></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../../../en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../../../en/other/index.html><span itemprop=name>Ninja Workshops</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=../../../../en/other/4-hpa/index.html><span itemprop=name>Monitoring Horizontal Pod Autoscaling in Kubernetes</span></a><meta itemprop=position content="3">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Fix PHP/Apache Issue</span><meta itemprop=position content="4"></li></ol><div class="topbar-area topbar-area-end" data-area=end></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable default" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=fix-phpapache-issue>Fix PHP/Apache Issue</h1><h2 id=1-kubernetes-resources>1. Kubernetes Resources</h2><p>Especially in Production Kubernetes Clusters, CPU and Memory are considered precious resources. Cluster Operators will normally require you to specify the amount of CPU and Memory your Pod or Service will require in the deployment, so they can have the Cluster automatically manage on which Node(s) your solution will be placed.</p><p>You do this by placing a Resource section in the deployment of your application/Pod</p><p><strong>Example:</strong></p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>limits</span><span class=p>:</span><span class=w>         </span><span class=c># Maximum amount of CPU &amp; memory for peek use</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;8&#34;</span><span class=w>      </span><span class=c># Maximum of 8 cores of CPU allowed at for peek use</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;9Mi&#34;</span><span class=w> </span><span class=c># Maximum allowed 9Mb of memory</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>requests</span><span class=p>:</span><span class=w>       </span><span class=c># Request are the expected amount of CPU &amp; memory for normal use</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;6&#34;</span><span class=w>      </span><span class=c># Requesting 4 cores of a CPU</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;4Mi&#34;</span><span class=w> </span><span class=c># Requesting 4Mb of memory</span></span></span></code></pre></div><p>More information can be found here: <a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/ target=_blank><strong>Resource Management for Pods and Containers</strong></a></p><p>If your application or Pod will go over the limits set in your deployment, Kubernetes will kill and restart your Pod to protect the other applications on the Cluster.</p><p>Another scenario that you will run into is when there is not enough Memory or CPU on a Node. In that case, the Cluster will try to reschedule your Pod(s) on a different Node with more space.</p><p>If that fails, or if there is not enough space when you deploy your application, the Cluster will put your workload/deployment in schedule mode until there is enough room on any of the available Nodes to deploy the Pods according to their limits.</p><h2 id=2-fix-phpapache-deployment>2. Fix PHP/Apache Deployment</h2><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Before we start, let&rsquo;s check the current status of the PHP/Apache deployment. Under <strong>Alerts & Detectors</strong> which detector has fired? Where else can you find this information?</p></div></div><p>To fix the PHP/Apache StatefulSet, edit <code>~/workshop/k3s/php-apache.yaml</code> using the following commands to reduce the CPU resources:</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim ~/workshop/k3s/php-apache.yaml</span></span></code></pre></div><p>Find the resources section and reduce the CPU limits to <strong>1</strong> and the CPU requests to <strong>0.5</strong>:</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>limits</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;9Mi&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0.5&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;4Mi&#34;</span></span></span></code></pre></div><p>Save the changes you have made. (Hint: Use <code>Esc</code> followed by <code>:wq!</code> to save your changes).</p><p>Now, we must delete the existing StatefulSet and re-create it. StatefulSets are immutable, so we must delete the existing one and re-create it with the new changes.</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl delete statefulset php-apache -n apache</span></span></code></pre></div><p>Now, deploy your changes:</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl apply -f ~/workshop/k3s/php-apache.yaml -n apache</span></span></code></pre></div><h2 id=3-validate-the-changes>3. Validate the changes</h2><p>You can validate the changes have been applied by running the following command:</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl describe statefulset php-apache -n apache</span></span></code></pre></div><p>Validate the Pod is now running in Splunk Observability Cloud.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>Is the <strong>Apache Web Servers</strong> dashboard showing any data now?</p><p><strong>Tip:</strong> Don&rsquo;t forget to use filters and time frames to narrow down your data.</p></div></div><p>Monitor the Apache web servers Navigator dashboard for a few minutes.</p><div class="box notices cstyle tip"><div class=box-label><i class="fa-fw fas fa-question"></i> Workshop Question</div><div class=box-content><p>What is happening with the # Hosts reporting chart?</p></div></div><h2 id=4-fix-the-memory-issue>4. Fix the memory issue</h2><p>If you navigate back to the Apache dashboard, you will notice that metrics are no longer coming in. We have another resource issue and this time we are Out of Memory. Let&rsquo;s edit the stateful set and increase the memory to what is shown in the image below:</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl edit statefulset php-apache -n apache</span></span></code></pre></div><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>limits</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>16Mi</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=l>500m</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>12Mi</span></span></span></code></pre></div><p>Save the changes you have made.</p><div class="box notices cstyle info"><div class=box-label><i class="fa-fw fas fa-exclamation"></i> Hint</div><div class=box-content><p><code>kubectl edit</code> will open the contents in the <code>vi</code> editor, use <code>Esc</code> followed by <code>:wq!</code> to save your changes.</p></div></div><p>Because StatefulSets are immutable, we must delete the existing Pod and let the StatefulSet re-create it with the new changes.</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl delete pod php-apache-0 -n apache</span></span></code></pre></div><p>Validate the changes have been applied by running the following command:</p><div class="wrap-code highlight"><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl describe statefulset php-apache -n apache</span></span></code></pre></div><footer class=footline></footer></article></div></main></div><script src=../../../../js/clipboard.min.js?1706259260 defer></script>
<script src=../../../../js/perfect-scrollbar.min.js?1706259260 defer></script>
<script src=../../../../js/theme.js?1706259260 defer></script></body></html>