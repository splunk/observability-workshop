var relearn_searchindex = [
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "APM サービスマップは、APM で計装された（インストルメンテーション）サービスと推測されるサービスの間の依存関係と接続を表示します。このマップは、時間範囲、環境、ワークフロー、サービス、タグフィルターでの選択に基づいて動的に生成されます。\nRUM ウォーターフォールで APM リンクをクリックすると、そのワークフロー名（frontend:/cart/checkout）に関連するサービスを表示するために、サービスマップビューに自動的にフィルターが追加されました。\nワークフローに関連するサービスはService Mapで確認できます。サイドペインのBusiness Workflowの下には、選択したワークフローのチャートが表示されています。Service Mapとビジネスワークフローチャートは同期しています。Service Mapでサービスを選択すると、Business Workflowペインのチャートが更新され、選択したサービスのメトリクスが表示されます。\n演習 サービスマップでpaymentserviceをクリックします。 Splunk APM はまた、リアルタイムで発生している問題を確認し、問題がサービス、特定のエンドポイント、または基盤となるインフラストラクチャに関連しているかどうかを迅速に判断するのに役立つ組み込みの Service Centric View(サービス中心ビュー) も提供しています。より詳しく見てみましょう。\n演習 右側のペインで、青色のpaymentserviceをクリックします。",
    "description": "APM サービスマップは、APM で計装された（インストルメンテーション）サービスと推測されるサービスの間の依存関係と接続を表示します。このマップは、時間範囲、環境、ワークフロー、サービス、タグフィルターでの選択に基づいて動的に生成されます。\nRUM ウォーターフォールで APM リンクをクリックすると、そのワークフロー名（frontend:/cart/checkout）に関連するサービスを表示するために、サービスマップビューに自動的にフィルターが追加されました。\nワークフローに関連するサービスはService Mapで確認できます。サイドペインのBusiness Workflowの下には、選択したワークフローのチャートが表示されています。Service Mapとビジネスワークフローチャートは同期しています。Service Mapでサービスを選択すると、Business Workflowペインのチャートが更新され、選択したサービスのメトリクスが表示されます。\n演習 サービスマップでpaymentserviceをクリックします。 Splunk APM はまた、リアルタイムで発生している問題を確認し、問題がサービス、特定のエンドポイント、または基盤となるインフラストラクチャに関連しているかどうかを迅速に判断するのに役立つ組み込みの Service Centric View(サービス中心ビュー) も提供しています。より詳しく見てみましょう。\n演習 右側のペインで、青色のpaymentserviceをクリックします。",
    "tags": [],
    "title": "1. APM探索",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/6-apm/1-apm-explore/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "EC2 インスタンスへ接続 各参加者のために、AWS/EC2 に Ubuntu Linux インスタンスを用意しました。\nインストラクターから提供された IP アドレスとパスワードを使用して、以下のいずれかの方法で EC2 インスタンスに接続してください：\nMac OS / Linux ssh splunk@IP アドレス Windows 10+ OpenSSH クライアントを使用 以前のバージョンの Windows Putty を使用",
    "description": "EC2 インスタンスへ接続 各参加者のために、AWS/EC2 に Ubuntu Linux インスタンスを用意しました。\nインストラクターから提供された IP アドレスとパスワードを使用して、以下のいずれかの方法で EC2 インスタンスに接続してください：\nMac OS / Linux ssh splunk@IP アドレス Windows 10+ OpenSSH クライアントを使用 以前のバージョンの Windows Putty を使用",
    "tags": [],
    "title": "EC2インスタンスへの接続",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/1-connect-to-instance/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 3. レシーバー",
    "content": "Host Metrics レシーバー Host Metrics レシーバー は、さまざまなソースからスクレイピングされたホストシステムに関するメトリクスを生成します。これは、コレクターがエージェントとしてデプロイされるときに使用さます。\netc/otel-contrib/config.yaml ファイルを更新して、hostmetrics レシーバーを設定してみましょう。以下の YAML を receivers セクションの下に挿入します。\nsudo vi /etc/otelcol-contrib/config.yaml Tips: vi or nano vi/vimの操作に慣れていない場合は、nano もお試しいただくと良いかもしれません。nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nsudo nano /etc/otelcol-contrib/config.yaml Alt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 ​ Host Metrics Receiver Configuration receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process:",
    "description": "Host Metrics レシーバー Host Metrics レシーバー は、さまざまなソースからスクレイピングされたホストシステムに関するメトリクスを生成します。これは、コレクターがエージェントとしてデプロイされるときに使用さます。\netc/otel-contrib/config.yaml ファイルを更新して、hostmetrics レシーバーを設定してみましょう。以下の YAML を receivers セクションの下に挿入します。\nsudo vi /etc/otelcol-contrib/config.yaml Tips: vi or nano vi/vimの操作に慣れていない場合は、nano もお試しいただくと良いかもしれません。nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nsudo nano /etc/otelcol-contrib/config.yaml Alt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 ​ Host Metrics Receiver Configuration receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process:",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/3-receivers/1-hostmetrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. はじめに OpenTelemetry Collector は、インフラストラクチャーとアプリケーションを計装するためのコアコンポーネントです。 その役割は収集と送信です：\nインフラストラクチャーのメトリクス（ディスク、CPU、メモリなど） Application Performance Monitoring（APM）のトレース情報 プロファイリングに関するデータ ホストおよびアプリケーションのログ Splunk Observability Cloud では、インフラストラクチャーとアプリケーションの両方で Collector のセットアップを案内するウィザードを提供しています。デフォルトでは、ウィザードはコレクターのインストールのみを行うコマンドのみを提供します。\n2. 環境変数を設定する すでに Splunk IM ワークショップを終了している場合は、既存の環境変数を利用することができます。そうでない場合は、ACCESS_TOKENとREALMの環境変数を設定して、OpenTelemetry Collector のインストールコマンドを実行していきます。\n例えば、Realm が us1 の場合、export REALM=us1 と入力し、eu0 の場合は export REALM=eu0 と入力します。\n​ ACCESS TOKENを環境変数に設定する export ACCESS_TOKEN=\"\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e\" ​ REALMを環境変数に設定する export REALM=\"\u003creplace_with_REALM\u003e\" 既存のOpenTelemetryコレクターをすべて削除する 同じ VM インスタンスに Splunk IM ワークショップのセットアップをしている場合、Otel Collector をインストールする前に Kubernetes で実行中の Collector を削除していることを確認してください。これは、以下のコマンドを実行することで行うことができます：\nhelm delete splunk-otel-collector 3. OpenTelemetry Collector をインストールする 次に、Collector をインストールします。インストールスクリプトに渡される追加のパラメータは --deployment-environment です。\ncurl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh \u0026\u0026 \\ sudo sh /tmp/splunk-otel-collector.sh --deployment-environment $(hostname)-petclinic --realm $REALM -- $ACCESS_TOKEN AWS/EC2インスタンスの場合 。 AWS/EC2 インスタンス上でこのワークショップを行う場合、インスタンスのホスト名を公開するためにコレクターにパッチを適用する必要があります：\nsudo sed -i 's/gcp, ecs, ec2, azure, system/system, gcp, ecs, ec2, azure/g' /etc/otel/collector/agent_config.yaml agent_config.yaml にパッチを適用したあと、Collector を再起動してください：\nsudo systemctl restart splunk-otel-collector インストールが完了したら、Splunk Observability の Hosts with agent installed ダッシュボードに移動して、Dashboards → Hosts with agent installed からホストのデータを確認してみましょう。\nダッシュボードのフィルタを使用して host.nameを選択し、仮想マシンのホスト名を入力または選択します。ホストのデータが表示されたら、APM コンポーネントを使用する準備が整いました。",
    "description": "1. はじめに OpenTelemetry Collector は、インフラストラクチャーとアプリケーションを計装するためのコアコンポーネントです。 その役割は収集と送信です：\nインフラストラクチャーのメトリクス（ディスク、CPU、メモリなど） Application Performance Monitoring（APM）のトレース情報 プロファイリングに関するデータ ホストおよびアプリケーションのログ Splunk Observability Cloud では、インフラストラクチャーとアプリケーションの両方で Collector のセットアップを案内するウィザードを提供しています。デフォルトでは、ウィザードはコレクターのインストールのみを行うコマンドのみを提供します。\n2. 環境変数を設定する すでに Splunk IM ワークショップを終了している場合は、既存の環境変数を利用することができます。そうでない場合は、ACCESS_TOKENとREALMの環境変数を設定して、OpenTelemetry Collector のインストールコマンドを実行していきます。\n例えば、Realm が us1 の場合、export REALM=us1 と入力し、eu0 の場合は export REALM=eu0 と入力します。\n​ ACCESS TOKENを環境変数に設定する export ACCESS_TOKEN=\"\u003creplace_with_O11y-Workshop-ACCESS_TOKEN\u003e\" ​ REALMを環境変数に設定する export REALM=\"\u003creplace_with_REALM\u003e\" 既存のOpenTelemetryコレクターをすべて削除する 同じ VM インスタンスに Splunk IM ワークショップのセットアップをしている場合、Otel Collector をインストールする前に Kubernetes で実行中の Collector を削除していることを確認してください。これは、以下のコマンドを実行することで行うことができます：",
    "tags": [],
    "title": "OpenTelemetry Collectorをインストールする",
    "uri": "/observability-workshop/v5.99/ja/other/pet-clinic/docs/imt/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "Splunk Observability Cloud のメインメニューから、RUMをクリックします。RUM ホームページに到着します。このビューについては、先ほどの短い紹介ですでに説明しました。\n演習 ドロップダウンが以下のように設定/選択されていることを確認して、ワークショップを選択してください： 時間枠は -15m に設定されていること。 選択されているEnvironmentは [ワークショップ名]-workshop であること。 選択されているAppは [ワークショップ名]-store であること。 SourceはAllに設定されていること。 次に、Page Views / JavaScript Errorsチャートの上にある [ワークショップ名]-store をクリックします。 これにより、UX Metrics、Front-end Health、Back-end Health、Custom Eventsごとにメトリクスを分類し、過去のメトリクス（デフォルトでは 1 時間）と比較する新しいダッシュボードビューが表示されます。 UX Metrics: ページビュー、ページロード、Web バイタルメトリクス。 Front-end Health: JavaScript エラーとロングタスクの期間と数の内訳。 Back-end Health: ネットワークエラー、リクエスト、最初のバイトまでの時間。 Custom Events: Custom Events の RED メトリクス（レート、エラー、期間）。 演習 各タブ（UX Metrics、Front-end Health、Back-end Health、Custom Events）をクリックしてデータを調べます。 ​ 質問 回答 「Custom Events」タブのチャートを調べると、どのチャートがレイテンシースパイクを明確に示していますか？\nそれは 「Custom Event Latency」 チャートです",
    "description": "Splunk Observability Cloud のメインメニューから、RUMをクリックします。RUM ホームページに到着します。このビューについては、先ほどの短い紹介ですでに説明しました。\n演習 ドロップダウンが以下のように設定/選択されていることを確認して、ワークショップを選択してください： 時間枠は -15m に設定されていること。 選択されているEnvironmentは [ワークショップ名]-workshop であること。 選択されているAppは [ワークショップ名]-store であること。 SourceはAllに設定されていること。 次に、Page Views / JavaScript Errorsチャートの上にある [ワークショップ名]-store をクリックします。 これにより、UX Metrics、Front-end Health、Back-end Health、Custom Eventsごとにメトリクスを分類し、過去のメトリクス（デフォルトでは 1 時間）と比較する新しいダッシュボードビューが表示されます。 UX Metrics: ページビュー、ページロード、Web バイタルメトリクス。 Front-end Health: JavaScript エラーとロングタスクの期間と数の内訳。 Back-end Health: ネットワークエラー、リクエスト、最初のバイトまでの時間。 Custom Events: Custom Events の RED メトリクス（レート、エラー、期間）。 演習 各タブ（UX Metrics、Front-end Health、Back-end Health、Custom Events）をクリックしてデータを調べます。 ​ 質問 回答 「Custom Events」タブのチャートを調べると、どのチャートがレイテンシースパイクを明確に示していますか？",
    "tags": [],
    "title": "1. RUMダッシュボード",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/5-rum/1-rum-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "Splunk Observability Cloud のメインメニューから、Syntheticsをクリックします。AllまたはBrowser testsをクリックして、アクティブなテストのリストを表示します。\nRUM セクションでの調査中に、Place orderトランザクションに問題があることがわかりました。Synthetics テストからもこれを確認できるか見てみましょう。テストの 4 ページ目のFirst byte timeというメトリクスを使用します。これはPlace orderステップです。\n演習 Searchボックスに [ワークショップ名] を入力し、あなたのワークショップのテストを選択します（インストラクターがどれを選択するか指示します）。 Performance KPIsの下で、時間選択を過去 1 時間に設定して Enter キーを押します。 Locationをクリックし、ドロップダウンからPageを選択します。次のフィルターには、テストの一部であるページが表示されます。 Durationをクリックし、Durationの選択を解除してFirst byte timeを選択します。 凡例を見て、First byte time - Page 4の色に注目してください。 First byte time - Page 4の最も高いデータポイントを選択します。これで、この特定のテスト実行のRun resultsに移動します。",
    "description": "Splunk Observability Cloud のメインメニューから、Syntheticsをクリックします。AllまたはBrowser testsをクリックして、アクティブなテストのリストを表示します。\nRUM セクションでの調査中に、Place orderトランザクションに問題があることがわかりました。Synthetics テストからもこれを確認できるか見てみましょう。テストの 4 ページ目のFirst byte timeというメトリクスを使用します。これはPlace orderステップです。\n演習 Searchボックスに [ワークショップ名] を入力し、あなたのワークショップのテストを選択します（インストラクターがどれを選択するか指示します）。 Performance KPIsの下で、時間選択を過去 1 時間に設定して Enter キーを押します。 Locationをクリックし、ドロップダウンからPageを選択します。次のフィルターには、テストの一部であるページが表示されます。 Durationをクリックし、Durationの選択を解除してFirst byte timeを選択します。 凡例を見て、First byte time - Page 4の色に注目してください。 First byte time - Page 4の最も高いデータポイントを選択します。これで、この特定のテスト実行のRun resultsに移動します。",
    "tags": [],
    "title": "1. Syntheticsダッシュボード",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/8-synthetics/1-synthetics-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "はじめに\nこのワークショップの目的は、Splunk Observability Cloud を使用して問題のトラブルシューティングを行い、根本原因を特定する実践的な経験を提供することです。私たちは、Kubernetes 上で動作する完全に計装されたマイクロサービスベースのアプリケーションを用意しており、これがメトリクス、トレース、ログを Splunk Observability Cloud にリアルタイム分析のために送信します。\n対象者\nこのワークショップは、Splunk Observability Cloud の実践的な知識を得たいと考えている方を対象としています。Observability Cloud を含む Splunk Platform に関する事前知識がほとんど、または全くない方向けに設計されています。\n必要なもの\nノートパソコンと外部ウェブサイトにアクセスできるブラウザが必要です。ワークショップは対面または Zoom を通じて参加できます。Zoom クライアントをインストールしていない場合でも、ブラウザを使用して参加できます。\nワークショップ概要\nこの 3 時間のセッションでは、ストリーミング分析と NoSample で完全に忠実な分散トレースを提供する唯一のプラットフォームである Splunk Observability の基礎を、インタラクティブなハンズオン形式で説明します。以下が期待できる内容です：\nOpenTelemetry\n最新の Observability に OpenTelemetry が不可欠である理由と、システムの可視性をどのように向上させるかを学びます。\nSplunk Observability ユーザーインターフェイスツアー\nSplunk Observability Cloud のインターフェイスのガイド付きツアーで、APM、RUM、Log Observer、Synthetics、Infrastructure という 5 つの主要コンポーネントの操作方法を紹介します。\n実際のユーザーデータを生成\nオンラインブティックというウェブサイトでシミュレートされた小売体験に飛び込みます。ブラウザ、モバイル、またはタブレットを使用して、サイトを探索し、メトリクス（問題はありますか？）、トレース（問題はどこにありますか？）、ログ（何が問題を引き起こしていますか？）を含む実際のユーザーデータを生成します。\nSplunk Real User Monitoring（RUM）\n参加者のブラウザセッションから収集された実際のユーザーデータを分析します。あなたの課題は、パフォーマンスの悪いセッションを特定し、トラブルシューティングプロセスを開始することです。\nSplunk Application Performance Monitoring（APM）\nRUM トレース（フロントエンド）を APM トレース（バックエンド）にリンクすることで、End to End を可視化する能力を理解しましょう。様々なサービスからのテレメトリが Splunk Observability Cloud でどのように取得され、視覚化されるかを探り、異常とエラーを検出します。\nSplunk Log Observer（LO）\nRelated Content 機能を活用してコンポーネント間を簡単に移動する方法を学びます。このワークショップでは、APM トレースから関連するログに移動して、問題についてより深い洞察を得ます。\nSplunk Synthetics\nSynthetics がアプリケーションの 24 時間 365 日のモニタリングにどのように役立つかを発見します。オンラインブティックウェブサイトのパフォーマンスと可用性を監視するために、毎分実行される簡単な合成テストの設定方法を説明します。\nこのセッションを終えると、Splunk Observability Cloud の実践的な経験と、アプリケーションスタック全体の問題をトラブルシューティングして解決する方法についての確かな理解が得られるでしょう。",
    "description": "ワークショップ概要",
    "tags": [],
    "title": "ワークショップ概要",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/1-workshop-goals/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "OpenTelemetry Collector の Contrib ディストリビューションをダウンロードする OpenTelemetry Collector のインストールのために、まずはダウンロードするのが最初のステップです。このラボでは、 wget コマンドを使って OpenTelemetry の GitHub リポジトリから .deb パッケージをダウンロードしていきます。\nOpenTelemetry Collector Contrib releases page から、ご利用のプラットフォーム用の .deb パッケージを入手してください。\nwget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.80.0/otelcol-contrib_0.80.0_linux_amd64.deb OpenTelemetry Collector の Contrib ディストリビューションをインストールする dpkg を使って、 .deb パッケージをインストールします。下記の dpkg Output のようになれば、インストールは成功です！\n​ Install dpkg Output sudo dpkg -i otelcol-contrib_0.80.0_linux_amd64.deb Selecting previously unselected package otelcol-contrib. (Reading database ... 64218 files and directories currently installed.) Preparing to unpack otelcol-contrib_0.75.0_linux_amd64.deb ... Unpacking otelcol-contrib (0.75.0) ... Setting up otelcol-contrib (0.75.0) ... Created symlink /etc/systemd/system/multi-user.target.wants/otelcol-contrib.service → /lib/systemd/system/otelcol-contrib.service.",
    "description": "OpenTelemetry Collector の Contrib ディストリビューションをダウンロードする OpenTelemetry Collector のインストールのために、まずはダウンロードするのが最初のステップです。このラボでは、 wget コマンドを使って OpenTelemetry の GitHub リポジトリから .deb パッケージをダウンロードしていきます。\nOpenTelemetry Collector Contrib releases page から、ご利用のプラットフォーム用の .deb パッケージを入手してください。\nwget https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.80.0/otelcol-contrib_0.80.0_linux_amd64.deb OpenTelemetry Collector の Contrib ディストリビューションをインストールする dpkg を使って、 .deb パッケージをインストールします。下記の dpkg Output のようになれば、インストールは成功です！\n​ Install dpkg Output sudo dpkg -i otelcol-contrib_0.80.0_linux_amd64.deb Selecting previously unselected package otelcol-contrib. (Reading database ... 64218 files and directories currently installed.) Preparing to unpack otelcol-contrib_0.75.0_linux_amd64.deb ... Unpacking otelcol-contrib (0.75.0) ... Setting up otelcol-contrib (0.75.0) ... Created symlink /etc/systemd/system/multi-user.target.wants/otelcol-contrib.service → /lib/systemd/system/otelcol-contrib.service.",
    "tags": [],
    "title": "OpenTelemetry Collector Contrib をインストールする",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/1-installation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "前提条件 Observability ワークショップインスタンス Observability ワークショップは、多くの場合、Splunk が提供する事前設定済みの Ubuntu EC2 インスタンス上で実施されます。\nワークショップのインストラクターから、割り当てられたワークショップインスタンスの認証情報が提供されます。\nインスタンスには以下の環境変数が既に設定されているはずです：\nACCESS_TOKEN REALM これらはワークショップ用の Splunk Observability Cloud の Access Token と Realm です。 これらは OpenTelemetry Collector によって、データを正しい Splunk Observability Cloud 組織に転送するために使用されます。 また、Multipass を使用してローカルの Observability ワークショップインスタンスをデプロイすることもできます。\nAWS Command Line Interface (awscli) AWS Command Line Interface、またはawscliは、AWS リソースと対話するために使用される API です。このワークショップでは、特定のスクリプトがデプロイするリソースと対話するために使用されます。\nSplunk が提供するワークショップインスタンスには、既に awscli がインストールされているはずです。\nインスタンスに aws コマンドがインストールされているか、次のコマンドで確認します：\nwhich aws 予想される出力は /usr/local/bin/aws です インスタンスに aws コマンドがインストールされていない場合は、次のコマンドを実行します：\nsudo apt install awscli Terraform Terraform は、リソースを構成ファイルで定義することで、デプロイ、管理、破棄するための Infrastructure as Code（IaC）プラットフォームです。Terraform は HCL を使用してこれらのリソースを定義し、さまざまなプラットフォームやテクノロジのための複数のプロバイダーをサポートしています。\nこのワークショップでは、コマンドラインで Terraform を使用して、以下のリソースをデプロイします：\nAWS API Gateway Lambda 関数 Kinesis Stream CloudWatch ロググループ S3 バケット およびその他のサポートリソース Splunk が提供するワークショップインスタンスには、既に terraform がインストールされているはずです。\nインスタンスに terraform コマンドがインストールされているか確認します：\nwhich terraform 予想される出力は /usr/local/bin/terraform です インスタンスに terraform コマンドがインストールされていない場合は、以下の Terraform が推奨するインストールコマンドを実行してください：\nwget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hashicorp.list sudo apt update \u0026\u0026 sudo apt install terraform ワークショップディレクトリ (o11y-lambda-workshop) ワークショップディレクトリ o11y-lambda-workshop は、今日使用する例の Lambda ベースのアプリケーションの自動計装と手動計装の両方を完了するための、すべての設定ファイルとスクリプトを含むリポジトリです。\nホームディレクトリにワークショップディレクトリがあることを確認します：\ncd \u0026\u0026 ls 予想される出力には o11y-lambda-workshop が含まれるはずです o11y-lambda-workshop ディレクトリがホームディレクトリにない場合は、次のコマンドでクローンします：\ngit clone https://github.com/gkono-splunk/o11y-lambda-workshop.git AWS \u0026 Terraform 変数 AWS AWS の CLI では、サービスによってデプロイされたリソースにアクセスし管理するための認証情報が必要です。このワークショップでは、Terraform と Python スクリプトの両方がタスクを実行するためにこれらの変数を必要とします。\nこのワークショップのために awscli を access key ID、secret access key および region で構成します：\naws configure このコマンドは以下のようなプロンプトを表示するはずです：\nAWS Access Key ID [None]: XXXXXXXXXXXXXXXX AWS Secret Acces Key [None]: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Default region name [None]: us-east-1 Default outoput format [None]: インスタンスで awscli が設定されていない場合は、次のコマンドを実行し、インストラクターから提供される値を入力してください。\naws configure Terraform Terraform では、機密情報や動的データを.tf 設定ファイルにハードコーディングさせない、またはそれらの値をリソース定義全体で再利用できるようにするため、変数の受け渡しをサポートしています。\nこのワークショップでは、OpenTelemetry Lambda layer の適切な値で Lambda 関数をデプロイするため、Splunk Observability Cloud の取り込み値のため、そして環境とリソースを独自で即座に認識できるようにするための変数を Terraform で必要とします。\nTerraform 変数(variable)は以下の方法で定義されます：\n変数を main.tf ファイルまたは variables.tf に定義する 以下のいずれかの方法で変数の値を設定する： ホストレベルで環境変数を設定し、その定義と同じ変数名を使用して、接頭辞として TF_VAR をつける terraform.tfvars ファイルに変数の値を設定する terraform apply 実行時に引数として値を渡す このワークショップでは、variables.tf と terraform.tfvars ファイルの組み合わせを使用して変数を設定します。\nvi または nano のいずれかを使用して、auto または manual ディレクトリにある terraform.tfvars ファイルを開きます\nvi ~/o11y-lambda-workshop/auto/terraform.tfvars 変数に値を設定します。CHANGEME プレースホルダーをインストラクターから提供された値に置き換えてください。\no11y_access_token = \"CHANGEME\" o11y_realm = \"CHANGEME\" otel_lambda_layer = [\"CHANGEME\"] prefix = \"CHANGEME\" 引用符（\"）や括弧 ( [ ] ) はそのまま残し、プレースホルダーCHANGEMEのみを変更してください。 prefix は、他の参加者のリソースと区別するため、任意の文字列で設定する固有の識別子です。氏名やメールアドレスのエイリアスを使用することをお勧めします。 prefix には小文字のみを使用してください。S3 のような特定の AWS リソースでは、大文字を使用するとエラーが発生します。 ファイルを保存してエディタを終了します。\n最後に、編集した terraform.tfvars ファイルを他のディレクトリにコピーします。\ncp ~/o11y-lambda-workshop/auto/terraform.tfvars ~/o11y-lambda-workshop/manual これは、自動計装と手動計装の両方の部分で同じ値を使用するためです ファイル権限 他のすべてのファイルはそのままでよいですが、autoとmanualの両方にあるsend_message.pyスクリプトは、ワークショップの一部として実行する必要があります。そのため、期待通りに実行するには、適切な権限が必要です。以下の手順に従って設定してください。\nまず、o11y-lambda-workshopディレクトリにいることを確認します：\ncd ~/o11y-lambda-workshop 次に、以下のコマンドを実行してsend_message.pyスクリプトに実行権限を設定します：\nsudo chmod 755 auto/send_message.py manual/send_message.py これで前提条件が整いましたので、ワークショップを始めることができます！",
    "description": "前提条件 Observability ワークショップインスタンス Observability ワークショップは、多くの場合、Splunk が提供する事前設定済みの Ubuntu EC2 インスタンス上で実施されます。\nワークショップのインストラクターから、割り当てられたワークショップインスタンスの認証情報が提供されます。\nインスタンスには以下の環境変数が既に設定されているはずです：\nACCESS_TOKEN REALM これらはワークショップ用の Splunk Observability Cloud の Access Token と Realm です。 これらは OpenTelemetry Collector によって、データを正しい Splunk Observability Cloud 組織に転送するために使用されます。 また、Multipass を使用してローカルの Observability ワークショップインスタンスをデプロイすることもできます。\nAWS Command Line Interface (awscli) AWS Command Line Interface、またはawscliは、AWS リソースと対話するために使用される API です。このワークショップでは、特定のスクリプトがデプロイするリソースと対話するために使用されます。\nSplunk が提供するワークショップインスタンスには、既に awscli がインストールされているはずです。\nインスタンスに aws コマンドがインストールされているか、次のコマンドで確認します：",
    "tags": [],
    "title": "セットアップ",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/1-setup/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 9. サービスヘルスダッシュボード",
    "content": "Log Observer 演習ですでにいくつかの便利なログチャートをダッシュボードに保存したので、そのダッシュボードを拡張していきます。\n演習 2 つのログチャートがあるダッシュボードに戻るには、メインメニューからDashboardをクリックすると、チームダッシュボードビューに移動します。Dashboardの下にあるSearch Dashboardをクリックして、あなたのサービスヘルスダッシュボードグループを検索します。 名前をクリックすると、以前に保存したダッシュボードが表示されます。 ログ情報は便利ですが、チームにとって意味のあるものにするにはさらに情報が必要なので、もう少し情報を追加しましょう。 最初のステップは、ダッシュボードに説明チャートを追加することです。New text noteをクリックし、ノート内のテキストを次のテキストに置き換えてから、Save and Closeボタンをクリックし、チャートに手順と名前をつけます。 テキストノートで使用する情報 これは**支払いサービス**のためのカスタムヘルスダッシュボードです。 ログのエラーに注意してください。 詳細については[リンク](https://https://www.splunk.com/en_us/products/observability.html)をご覧ください。 チャートが適切な順序になっていません。チャートを役立つように並べ替えましょう。 手順チャートの上端にマウスを移動すると、マウスポインタが ☩ に変わります。これにより、ダッシュボード内でチャートをドラッグできるようになります。手順チャートを左上の位置にドラッグし、右端をドラッグしてページの 1/3 のサイズにリサイズします。 ログタイムラインビューチャートを手順チャートの横にドラッグして追加し、ページの残りの 2/3 を埋めるようにリサイズして、2 つのチャートの横にエラー率チャートを配置し、ページ全体を埋めるようにリサイズします。 次に、ログラインチャートをページの幅にリサイズし、少なくとも 2 倍の長さになるようにリサイズします。 以下のダッシュボードに似た形になっているはずです： これは素晴らしいですね。引き続き、より意味のあるチャートを追加していきましょう。",
    "description": "Log Observer 演習ですでにいくつかの便利なログチャートをダッシュボードに保存したので、そのダッシュボードを拡張していきます。\n演習 2 つのログチャートがあるダッシュボードに戻るには、メインメニューからDashboardをクリックすると、チームダッシュボードビューに移動します。Dashboardの下にあるSearch Dashboardをクリックして、あなたのサービスヘルスダッシュボードグループを検索します。 名前をクリックすると、以前に保存したダッシュボードが表示されます。 ログ情報は便利ですが、チームにとって意味のあるものにするにはさらに情報が必要なので、もう少し情報を追加しましょう。 最初のステップは、ダッシュボードに説明チャートを追加することです。New text noteをクリックし、ノート内のテキストを次のテキストに置き換えてから、Save and Closeボタンをクリックし、チャートに手順と名前をつけます。 テキストノートで使用する情報 これは**支払いサービス**のためのカスタムヘルスダッシュボードです。 ログのエラーに注意してください。 詳細については[リンク](https://https://www.splunk.com/en_us/products/observability.html)をご覧ください。 チャートが適切な順序になっていません。チャートを役立つように並べ替えましょう。 手順チャートの上端にマウスを移動すると、マウスポインタが ☩ に変わります。これにより、ダッシュボード内でチャートをドラッグできるようになります。手順チャートを左上の位置にドラッグし、右端をドラッグしてページの 1/3 のサイズにリサイズします。 ログタイムラインビューチャートを手順チャートの横にドラッグして追加し、ページの残りの 2/3 を埋めるようにリサイズして、2 つのチャートの横にエラー率チャートを配置し、ページ全体を埋めるようにリサイズします。 次に、ログラインチャートをページの幅にリサイズし、少なくとも 2 倍の長さになるようにリサイズします。 以下のダッシュボードに似た形になっているはずです： これは素晴らしいですね。引き続き、より意味のあるチャートを追加していきましょう。",
    "tags": [],
    "title": "ダッシュボードの強化",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/9-custom-dashboard/1-custom-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "1. Splunk Observability Cloud にサインインする Splunk が主催するワークショップの場合、Workshop Org に招待するメールを受け取っているはずです。このメールは下のスクリーンショットのようになっています。見つからない場合は、迷惑メールフォルダを確認するか、インストラクターにお知らせください。また、ログイン FAQで他の解決策を確認することもできます。\n進めるには、Join Now（参加する）ボタンをクリックするか、メールに記載されているリンクをクリックしてください。\n登録プロセスをすでに完了している場合は、残りの手順をスキップして直接 Splunk Observability Cloud にログインできます：\nhttps://app.eu0.signalfx.com (EMEA) https://app.us1.signalfx.com (APAC/AMER) Splunk Observability Cloud を初めて使用する場合は、登録フォームが表示されます。フルネームと希望するパスワードを入力してください。パスワードの要件は次のとおりです：\n8 文字から 32 文字の間である 少なくとも 1 つの大文字を含む 少なくとも 1 つの数字を含む 少なくとも 1 つの記号（例：!@#$%^\u0026*()_+）を含む 利用規約に同意するためのチェックボックスをクリックし、SIGN IN NOW（今すぐサインイン）ボタンをクリックします。",
    "description": "Splunk Observability Cloudの使い方を学びます。",
    "tags": [],
    "title": "はじめに",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/1-homepage/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "Log Observer (LO)は、複数の方法で使用できます。クイックツアーでは、LO のコード不要インターフェースを使用して、ログ内の特定のエントリを検索しました。しかし、このセクションでは、関連コンテンツリンクを使用して APM のトレースから LO に到達したと想定しています。\nこれの利点は、RUM と APM 間のリンクと同様に、以前のアクションのコンテキスト内でログを見ていることです。この場合、コンテキストはトレースの時間枠（1）とtrace_idに設定されたフィルター（2）です。\nこのビューには、エンドユーザーとオンラインブティックのやり取りによって開始されたバックエンドトランザクションに参加したすべてのアプリケーションまたはサービスからのすべてのログ行が含まれます。\n私たちのオンラインブティックのような小さなアプリケーションでさえ、見つかるログの膨大な量により、調査している実際のインシデントに関連する特定のログ行を見つけることが難しくなる場合があります。\n演習 ログ内のエラーメッセージだけに焦点を当てる必要があります：\nGroup By（グループ化）ドロップダウンボックスをクリックし、フィルターを使用してSeverity（重要度）を見つけます。 選択したらApplyボタンをクリックします（チャートの凡例がデバッグ、エラー、情報を表示するように変わることに注意してください）。 エラーログのみを選択するには、凡例の「error」（1）という単語をクリックし、Add to filterを選択します。次にRun Searchをクリックします。 複数のサービスにエラー行がある場合は、sf_service=paymentserviceなどのサービス名もフィルターに追加できますが、今回のケースでは必要ありません。 次に、ログエントリの詳細を見ていきます。",
    "description": "Log Observer (LO)は、複数の方法で使用できます。クイックツアーでは、LO のコード不要インターフェースを使用して、ログ内の特定のエントリを検索しました。しかし、このセクションでは、関連コンテンツリンクを使用して APM のトレースから LO に到達したと想定しています。\nこれの利点は、RUM と APM 間のリンクと同様に、以前のアクションのコンテキスト内でログを見ていることです。この場合、コンテキストはトレースの時間枠（1）とtrace_idに設定されたフィルター（2）です。\nこのビューには、エンドユーザーとオンラインブティックのやり取りによって開始されたバックエンドトランザクションに参加したすべてのアプリケーションまたはサービスからのすべてのログ行が含まれます。\n私たちのオンラインブティックのような小さなアプリケーションでさえ、見つかるログの膨大な量により、調査している実際のインシデントに関連する特定のログ行を見つけることが難しくなる場合があります。\n演習 ログ内のエラーメッセージだけに焦点を当てる必要があります：\nGroup By（グループ化）ドロップダウンボックスをクリックし、フィルターを使用してSeverity（重要度）を見つけます。 選択したらApplyボタンをクリックします（チャートの凡例がデバッグ、エラー、情報を表示するように変わることに注意してください）。 エラーログのみを選択するには、凡例の「error」（1）という単語をクリックし、Add to filterを選択します。次にRun Searchをクリックします。 複数のサービスにエラー行がある場合は、sf_service=paymentserviceなどのサービス名もフィルターに追加できますが、今回のケースでは必要ありません。 次に、ログエントリの詳細を見ていきます。",
    "tags": [],
    "title": "1. ログフィルタリング",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/7-log-observer/1-log-filtering/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 10. ワークショップ まとめ",
    "content": "このワークショップを通じて、Splunk Observability Cloud と OpenTelemetry シグナル（メトリクス、トレース、ログ）の組み合わせが、検出までの平均時間（MTTD）と解決までの平均時間（MTTR）をどのように短縮できるかを見てきました。\nメインユーザーインターフェイスとそのコンポーネント、ランディング、インフラストラクチャ、APM、RUM、Synthetics、ダッシュボードページ、そして設定ページについて理解を深めました。 時間に応じて、インフラストラクチャの演習を行い、Kubernetes ナビゲーターで使用されるメトリクスを確認し、Kubernetes クラスターで見つかった関連サービスを見ました： ユーザーが何を体験しているかを理解し、RUM と APM を使用して特に長いページ読み込みのトラブルシューティングを行いました。フロントエンドとバックエンド全体でトレースをたどり、ログエントリーまで追跡しました。 RUM のセッション再生と APM の依存関係マップを使用し、ブレークダウン機能を使って問題の原因を発見しました： RUM と APM の両方でTag Spotlightを使用して、影響範囲を理解し、パフォーマンス問題とエラーのトレンドやコンテキストを検出しました。APM のトレースウォーターフォールでスパンを詳しく調べ、サービスがどのように相互作用し、エラーを見つけました： 関連コンテンツ機能を使用して、トレースからトレースに関連するログへの直接のリンクをたどり、フィルターを使用して問題の正確な原因まで掘り下げました。 次に、Web とモバイルトラフィックをシミュレートできる Synthetics を調べ、利用可能な Synthetics テストを使用して、まず RUM/APM と Log Observer での発見を確認し、次にテストの実行時間が SLA を超えた場合にアラートを受け取るためのディテクターを作成しました。\n最後の演習では、開発者と SRE のために TV スクリーンで継続的に表示するヘルスダッシュボードを作成しました：",
    "description": "このワークショップを通じて、Splunk Observability Cloud と OpenTelemetry シグナル（メトリクス、トレース、ログ）の組み合わせが、検出までの平均時間（MTTD）と解決までの平均時間（MTTR）をどのように短縮できるかを見てきました。\nメインユーザーインターフェイスとそのコンポーネント、ランディング、インフラストラクチャ、APM、RUM、Synthetics、ダッシュボードページ、そして設定ページについて理解を深めました。 時間に応じて、インフラストラクチャの演習を行い、Kubernetes ナビゲーターで使用されるメトリクスを確認し、Kubernetes クラスターで見つかった関連サービスを見ました： ユーザーが何を体験しているかを理解し、RUM と APM を使用して特に長いページ読み込みのトラブルシューティングを行いました。フロントエンドとバックエンド全体でトレースをたどり、ログエントリーまで追跡しました。 RUM のセッション再生と APM の依存関係マップを使用し、ブレークダウン機能を使って問題の原因を発見しました： RUM と APM の両方でTag Spotlightを使用して、影響範囲を理解し、パフォーマンス問題とエラーのトレンドやコンテキストを検出しました。APM のトレースウォーターフォールでスパンを詳しく調べ、サービスがどのように相互作用し、エラーを見つけました： 関連コンテンツ機能を使用して、トレースからトレースに関連するログへの直接のリンクをたどり、フィルターを使用して問題の正確な原因まで掘り下げました。 次に、Web とモバイルトラフィックをシミュレートできる Synthetics を調べ、利用可能な Synthetics テストを使用して、まず RUM/APM と Log Observer での発見を確認し、次にテストの実行時間が SLA を超えた場合にアラートを受け取るためのディテクターを作成しました。",
    "tags": [],
    "title": "主要なポイント",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/10-wrap-up/key-takeaways/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 1. インストール",
    "content": "Collector が動作していることを確認する これで、Collector が動いているはずです。root権限で systemctl コマンドを使って、それを確かめてみましょう。\n​ Command Status Output sudo systemctl status otelcol-contrib ● otelcol-contrib.service - OpenTelemetry Collector Contrib Loaded: loaded (/lib/systemd/system/otelcol-contrib.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2023-05-16 08:23:23 UTC; 25s ago Main PID: 1415 (otelcol-contrib) Tasks: 5 (limit: 1141) Memory: 22.2M CPU: 125ms CGroup: /system.slice/otelcol-contrib.service └─1415 /usr/bin/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: NumberDataPoints #0 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Data point attributes: May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e exporter: Str(logging) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_instance_id: Str(df8a57f4-abdc-46b9-a847-acd62db1001f) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_name: Str(otelcol-contrib) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_version: Str(0.75.0) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: StartTimestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Timestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Value: 0.000000 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: {\"kind\": \"exporter\", \"data_type\": \"metrics\", \"name\": \"logging\"} Tips: status 表示を中止するには systemctl status コマンドの表示を中止するときは q キーを押してください。\nサービスを停止するときは、 stop コマンドを使います。\n​ Command sudo systemctl stop otelcol-contrib 更新した設定ファイルを読み込ませるときは、 restart コマンドでサービスの再起動をしましょう。\n​ Command sudo systemctl restart otelcol-contrib Ninja: Open Telemetry Collector Builder (ocb) を使って、独自のコレクターを作る このパートでは、お使いのシステムに以下のものがインストールされている必要があります：\nGo (latest version)\ncd /tmp wget https://golang.org/dl/go1.20.linux-amd64.tar.gz sudo tar -C /usr/local -xzf go1.20.linux-amd64.tar.gz .profile を編集して、次の環境変数をセットします:\nexport GOROOT=/usr/local/go export GOPATH=$HOME/go export PATH=$GOPATH/bin:$GOROOT/bin:$PATH そして、シェルのセッションを更新します:\nsource ~/.profile Go のバージョンを確認します:\ngo version ocb のインストール\nocb バイナリーを project releases からダウンロードして、次のコマンドを実行します:\nmv ocb_0.80.0_darwin_arm64 /usr/bin/ocb chmod 755 /usr/bin/ocb 別のアプローチとして、Go のツールチェーンを使ってバイナリをローカルにビルドする方法もあります:\ngo install go.opentelemetry.io/collector/cmd/builder@v0.80.0 mv $(go env GOPATH)/bin/builder /usr/bin/ocb (Optional) Docker\nなぜ独自のコレクターをビルドするの？ コレクターのデフォルトのディストリビューション（core および contrib）は、含まれれるコンポーネントが少なすぎたり、もしくは多すぎたりします。\n本番環境で contrib コレクターを実行することはできますが、インストールされているコンポーネントの量が多く、デプロイに必要ではないものも含まれるため、一般的には推奨されません。\n独自のコレクターをビルドする利点は？ 独自のコレクターバイナリー（通常は「ディストリビューション」と呼ばれる）を作成することで、必要なものだけをビルドすることができます。\nメリットは次のとおりです:\nバイナリーのサイズが小さい 一般的な Go の脆弱性スキャナーを利用できる 組織独自のコンポーネントを組み込むことができる カスタムコレクターをビルドするときの注意事項は？ さて、これは Ninja ゾーンの人たちにあえて言うことではないかもしれませんが:\nGo の開発経験を、必須ではないが、推奨される Splunk の サポートがない ディストリビューションのライフサイクルを管理しなければならない プロジェクトは安定性に向けて進んでいますが、行われた変更がワークフローを壊す可能性があることに注意してください。Splunk チームは、より高い安定性とサポートを提供し、デプロイメントニーズに対応するためのキュレーションされた経験を提供しています。\nNinja ゾーン 必要なツールをすべてインストールしたら、以下のディレクトリ構造に従い、 otelcol-builder.yaml という新しいファイルを作成します:\n. └── otelcol-builder.yaml ファイルを作成したら、インストールするコンポーネントのリストと追加のメタデータを追加する必要があります。\nこの例では、導入設定に必要なコンポーネントのみをインストールするためのビルダーマニフェストを作成します:\ndist: name: otelcol-ninja description: A custom build of the Open Telemetry Collector output_path: ./dist extensions: - gomod: go.opentelemetry.io/collector/extension/ballastextension v0.80.0 - gomod: go.opentelemetry.io/collector/extension/zpagesextension v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/httpforwarder v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckextension v0.80.0 exporters: - gomod: go.opentelemetry.io/collector/exporter/loggingexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlpexporter v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/splunkhecexporter v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/exporter/signalfxexporter v0.80.0 processors: - gomod: go.opentelemetry.io/collector/processor/batchprocessor v0.80.0 - gomod: go.opentelemetry.io/collector/processor/memorylimiterprocessor v0.80.0 receivers: - gomod: go.opentelemetry.io/collector/receiver/otlpreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/hostmetricsreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/zipkinreceiver v0.80.0 ocb のためのyamlファイルを作成して更新したら、 次のコマンドを実行します:\nocb --config=otelcol-builder.yaml すると、次のようなディレクトリ構造が作成されます:\n├── dist │ ├── components.go │ ├── components_test.go │ ├── go.mod │ ├── go.sum │ ├── main.go │ ├── main_others.go │ ├── main_windows.go │ └── otelcol-ninja └── otelcol-builder.yaml 最後に、 ./dist/otelcol-ninja を実行すれば、独自ビルドのCollectorが動作することがわかります。このコマンドを実行する前に、 otelcol-contrib サービスが停止していることを確認してください。\n./dist/otelcol-ninja --config=file:/etc/otelcol-contrib/config.yaml この設定ファイルで記述されているコンポーネントは、ビルドに含まれていないかもしれません。エラーの内容を含めて、何が起こるかを見てみましょう 。\nリファレンス https://opentelemetry.io/docs/collector/custom-collector/ デフォルト設定 OpenTelemetry Collector は YAML ファイルを使って設定をしていきます。これらのファイルには、必要に応じて変更できるデフォルト設定が含まれています。提供されているデフォルト設定を見てみましょう:\n​ Command config.yaml cat /etc/otelcol-contrib/config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 extensions: health_check: pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] おめでとうございます！OpenTelemetry Collector のダウンロードとインストールに成功しました。あなたは OTel Ninja になる準備ができました。しかしまずは、設定ファイルと OpenTelemetry Collector の異なるディストリビューションについて見ていきましょう。\nメモ Splunk は、自社で完全にサポートされた OpenTelemetry Collector のディストリビューションを提供しています。このディストリビューションは、Splunk GitHub Repository からインストールするか、Splunk Observability Cloud のウィザードを使用して、簡単なインストールスクリプトを作成し、コピー＆ペーストすることで利用できます。このディストリビューションには、OpenTelemetry Collector Contrib ディストリビューションにはない追加機能や強化が含まれています。\nSplunk の OpenTelemetry Collector ディストリビューションは本番環境でテスト済みであり、多くの顧客が本番環境で使用しています。 このディストリビューションを使用する顧客は、公式の Splunk サポートから、SLA の範囲内で直接支援を受けることができます。 メトリクスとトレース収集のコア構成体験に将来的な破壊的変更がないことを心配せずに、Splunk の OpenTelemetry Collector ディストリビューションを使用または移行することができます（OpenTelemetry ログ収集の設定はベータ版です）。Collector 自身のメトリクスに破壊的変更がある可能性はあります。 このセクションでは、ホストメトリクスを Splunk Observability Cloud に送信するために、設定ファイルの各セクションを詳しく見ていき、変更する方法について説明します。",
    "description": "Collector が動作していることを確認する これで、Collector が動いているはずです。root権限で systemctl コマンドを使って、それを確かめてみましょう。\n​ Command Status Output sudo systemctl status otelcol-contrib ● otelcol-contrib.service - OpenTelemetry Collector Contrib Loaded: loaded (/lib/systemd/system/otelcol-contrib.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2023-05-16 08:23:23 UTC; 25s ago Main PID: 1415 (otelcol-contrib) Tasks: 5 (limit: 1141) Memory: 22.2M CPU: 125ms CGroup: /system.slice/otelcol-contrib.service └─1415 /usr/bin/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: NumberDataPoints #0 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Data point attributes: May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e exporter: Str(logging) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_instance_id: Str(df8a57f4-abdc-46b9-a847-acd62db1001f) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_name: Str(otelcol-contrib) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: -\u003e service_version: Str(0.75.0) May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: StartTimestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Timestamp: 2023-05-16 08:23:39.006 +0000 UTC May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: Value: 0.000000 May 16 08:23:39 ip-10-0-9-125 otelcol-contrib[1415]: {\"kind\": \"exporter\", \"data_type\": \"metrics\", \"name\": \"logging\"} Tips: status 表示を中止するには systemctl status コマンドの表示を中止するときは q キーを押してください。",
    "tags": [],
    "title": "OpenTelemetry Collector Contribをインストールする",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/1-installation/1-confirmation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 2. エクステンション",
    "content": "Health Check エクステンション 他のコンポーネントと同様に、エクステンションは config.yaml ファイルで設定できます。ここでは実際に config.yaml ファイルを編集して、エクステンションを設定していきましょう。デフォルトの config.yaml では、すでに pprof エクステンションと zpages エクステンションが設定されていることを確認してみてください。このワークショップでは、設定ファイルをアップデートして health_check エクステンションを追加し、ポートを解放し、外部ネットワークからコレクターのヘルスチェックにアクセスできるようにしていきます。\n​ Command sudo vi /etc/otelcol-contrib/config.yaml ​ Extensions Configuration extensions: health_check: endpoint: 0.0.0.0:13133 コレクターを起動します:\n​ Command sudo systemctl restart otelcol-contrib このエクステンションは HTTP の URL を公開し、OpenTelemetry Collector の稼働状況をチェックするプローブを提供します。このエクステンションは Kubernetes 環境での Liveness/Readiness プローブとしても使われています。 curl コマンドの使い方は、curl man page を参照してください。\n次のコマンドを実行します:\n​ curl Command curl Output curl http://localhost:13133 {\"status\":\"Server available\",\"upSince\":\"2023-04-27T10:11:22.153295874+01:00\",\"uptime\":\"16m24.684476004s\"}",
    "description": "Health Check エクステンション 他のコンポーネントと同様に、エクステンションは config.yaml ファイルで設定できます。ここでは実際に config.yaml ファイルを編集して、エクステンションを設定していきましょう。デフォルトの config.yaml では、すでに pprof エクステンションと zpages エクステンションが設定されていることを確認してみてください。このワークショップでは、設定ファイルをアップデートして health_check エクステンションを追加し、ポートを解放し、外部ネットワークからコレクターのヘルスチェックにアクセスできるようにしていきます。\n​ Command sudo vi /etc/otelcol-contrib/config.yaml ​ Extensions Configuration extensions: health_check: endpoint: 0.0.0.0:13133 コレクターを起動します:\n​ Command sudo systemctl restart otelcol-contrib このエクステンションは HTTP の URL を公開し、OpenTelemetry Collector の稼働状況をチェックするプローブを提供します。このエクステンションは Kubernetes 環境での Liveness/Readiness プローブとしても使われています。 curl コマンドの使い方は、curl man page を参照してください。",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/2-extensions/1-health/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 4. プロセッサー",
    "content": "Batch プロセッサー デフォルトでは、batch プロセッサーだけが有効になっています。このプロセッサーは、データをエクスポートする前にバッチ処理して、エクスポーターへのネットワーク・コールの回数を減らすために使われます。このワークショップではデフォルトの設定を使用します：\nsend_batch_size (デフォルト = 8192): タイムアウトに関係なく、バッチを送信するスパン、メトリクスデータポイント、またはログレコードの数。パイプラインの次のコンポーネントに送信されるバッチサイズを制限する場合には、 send_batch_max_size を使います。 timeout (デフォルト = 200ms): サイズに関係なく、バッチが送信されるまでの時間。ゼロに設定すると、send_batch_size の設定を無視して send_batch_max_size だけが適用され、データは直ちに送信されます。 send_batch_max_size (デフォルト = 0): バッチサイズの上限。0 を設定すると、バッチサイズの上限がないことして扱われます。この設定は、大きなバッチが小さなユニットに分割されることを保証します。send_batch_size 以上でなければななりません。",
    "description": "Batch プロセッサー デフォルトでは、batch プロセッサーだけが有効になっています。このプロセッサーは、データをエクスポートする前にバッチ処理して、エクスポーターへのネットワーク・コールの回数を減らすために使われます。このワークショップではデフォルトの設定を使用します：\nsend_batch_size (デフォルト = 8192): タイムアウトに関係なく、バッチを送信するスパン、メトリクスデータポイント、またはログレコードの数。パイプラインの次のコンポーネントに送信されるバッチサイズを制限する場合には、 send_batch_max_size を使います。 timeout (デフォルト = 200ms): サイズに関係なく、バッチが送信されるまでの時間。ゼロに設定すると、send_batch_size の設定を無視して send_batch_max_size だけが適用され、データは直ちに送信されます。 send_batch_max_size (デフォルト = 0): バッチサイズの上限。0 を設定すると、バッチサイズの上限がないことして扱われます。この設定は、大きなバッチが小さなユニットに分割されることを保証します。send_batch_size 以上でなければななりません。",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/4-processors/1-batch-processor/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 5. エクスポーター",
    "content": "OTLP HTTP エクスポーター Splunk Observability Cloud へ HTTP 経由でメトリックスを送信するためには、otlphttp エクスポーターを設定する必要があります。\n/etc/otelcol-contrib/config.yaml ファイルを編集し、otlphttp エクスポーターを設定しましょう。以下の YAML を exporters セクションの下に挿入し、例えば2スペースでインデントしてください。\nまた、ディスクの容量不足を防ぐために、ロギングエクスポーターの詳細度を変更します。デフォルトの detailed は非常に詳細です。\nexporters: logging: verbosity: normal otlphttp/splunk: 次に、metrics_endpoint を定義して、ターゲットURLを設定していきます。\nメモ Splunk 主催のワークショップの参加者である場合、使用しているインスタンスにはすでに Realm 環境変数が設定されています。その環境変数を設定ファイルで参照します。それ以外の場合は、新しい環境変数を作成して Realm を設定する必要があります。例えば：\nexport REALM=\"us1\" 使用するURLは https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp です。（Splunkは、データの居住地に応じて世界中の主要地域に Realm を持っています）。\notlphttp エクスポーターは、traces_endpoint と logs_endpoint それぞれのターゲットURLを定義することにより、トレースとログを送信するようにも設定できますが、そのような設定はこのワークショップの範囲外とします。\nexporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp デフォルトでは、すべてのエンドポイントで gzip 圧縮が有効になっています。エクスポーターの設定で compression: none を設定することにより、圧縮を無効にすることができます。このワークショップでは圧縮を有効にしたままにし、データを送信する最も効率的な方法としてデフォルト設定を使っていきます。\nSplunk Observability Cloud にメトリクスを送信するためには、アクセストークンを使用する必要があります。これは、Splunk Observability Cloud UI で新しいトークンを作成することにより行うことができます。トークンの作成方法についての詳細は、Create a token を参照してください。トークンは INGEST タイプである必要があります。\nメモ Splunk　主催のワークショップの参加者である場合、使用しているインスタンスにはすでにアクセストークンが設定されています（環境変数として設定されています）ので、その環境変数を設定ファイルで参照します。それ以外の場合は、新しいトークンを作成し、それを環境変数として設定する必要があります。例えば：\nexport ACCESS_TOKEN=\u003creplace-with-your-token\u003e トークンは、設定ファイル内で headers: セクションの下に X-SF-TOKEN: ${env:ACCESS_TOKEN} を挿入することにで定義します：\nexporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-TOKEN: ${env:ACCESS_TOKEN} 設定を確認しましょう これで、エクスポーターもカバーできました。設定を確認していきましょう：\nCheck-in設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-TOKEN: ${env:ACCESS_TOKEN} service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] もちろん、OTLP プロトコルをサポートする他のソリューションを指すように metrics_endpoint を簡単に設定することができます。\n次に、config.yaml のサービスセクションで、今設定したレシーバー、プロセッサー、エクスポーターを有効にしていきます。",
    "description": "OTLP HTTP エクスポーター Splunk Observability Cloud へ HTTP 経由でメトリックスを送信するためには、otlphttp エクスポーターを設定する必要があります。\n/etc/otelcol-contrib/config.yaml ファイルを編集し、otlphttp エクスポーターを設定しましょう。以下の YAML を exporters セクションの下に挿入し、例えば2スペースでインデントしてください。\nまた、ディスクの容量不足を防ぐために、ロギングエクスポーターの詳細度を変更します。デフォルトの detailed は非常に詳細です。\nexporters: logging: verbosity: normal otlphttp/splunk: 次に、metrics_endpoint を定義して、ターゲットURLを設定していきます。\nメモ Splunk 主催のワークショップの参加者である場合、使用しているインスタンスにはすでに Realm 環境変数が設定されています。その環境変数を設定ファイルで参照します。それ以外の場合は、新しい環境変数を作成して Realm を設定する必要があります。例えば：\nexport REALM=\"us1\" 使用するURLは https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp です。（Splunkは、データの居住地に応じて世界中の主要地域に Realm を持っています）。\notlphttp エクスポーターは、traces_endpoint と logs_endpoint それぞれのターゲットURLを定義することにより、トレースとログを送信するようにも設定できますが、そのような設定はこのワークショップの範囲外とします。\nexporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp デフォルトでは、すべてのエンドポイントで gzip 圧縮が有効になっています。エクスポーターの設定で compression: none を設定することにより、圧縮を無効にすることができます。このワークショップでは圧縮を有効にしたままにし、データを送信する最も効率的な方法としてデフォルト設定を使っていきます。",
    "tags": [],
    "title": "OpenTelemetry Collector エクスポーター",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/5-exporters/otlphttp/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Hostmetrics レシーバー ワークショップのレシーバー部分で振り返ると、ホストシステムに関するメトリクスを生成するために、様々なソースからスクレイピングする Host Metrics レシーバーを定義しました。このレシーバーを有効にするためには、メトリクスパイプラインに hostmetrics レシーバーを含める必要があります。\nmetrics パイプラインで、メトリクスの receivers セクションに hostmetrics を追加します。\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus] processors: [batch] exporters: [logging]",
    "description": "Hostmetrics レシーバー ワークショップのレシーバー部分で振り返ると、ホストシステムに関するメトリクスを生成するために、様々なソースからスクレイピングする Host Metrics レシーバーを定義しました。このレシーバーを有効にするためには、メトリクスパイプラインに hostmetrics レシーバーを含める必要があります。\nmetrics パイプラインで、メトリクスの receivers セクションに hostmetrics を追加します。\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus] processors: [batch] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/6-service/1-hostmetrics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ",
    "content": "このワークショップでは、Splunk Observability Cloud がフロントエンドアプリケーションからバックエンドサービスまで、ユーザー体験に関する即時の可視性をどのように提供するかをデモンストレーションします。他の可観測性ソリューションと一線を画す、プラットフォームの最も強力な機能をいくつか体験していただきます：\nインフラ監視（Infrastructure Monitoring, IM） 完全で忠実な Real User Monitoring（RUM） Application Performance Monitoring（APM）による End to End の NoSample で完全忠実なトレースの可視性 コード入力を必要としないログクエリ 外形監視・合成監視（Synthetic Monitoring） タグ分析とエラースタックによる根本原因分析 Related Contents によるコンポーネント間のシームレスなナビゲーション Splunk Observability Cloud のコアとなる強みの一つは、テレメトリデータを統合し、エンドユーザーエクスペリエンスとアプリケーションスタック全体の包括的な全体像を作成する能力です。\nこのワークショップでは、AWS EC2 インスタンス上にデプロイされたマイクロサービスベースの e コマースアプリケーションに焦点を当てます。ユーザーは商品を閲覧し、カートに商品を追加し、注文を完了できます。このアプリケーションは、詳細なパフォーマンスデータを取得するために OpenTelemetry で計装されています。\nOpenTelemetry とは？\nOpenTelemetry は、メトリクス、トレース、ログなどのテレメトリデータの計装、生成、収集、エクスポートを支援するために設計されたオープンソースのツール、API、ソフトウェア開発キット（SDK）のコレクションです。このデータにより、ソフトウェアのパフォーマンスと動作の詳細な分析が可能になります。\nOpenTelemetry コミュニティは急速に成長しており、Splunk、Google、Microsoft、Amazon などの大手企業からのサポートを受けています。現在、Cloud Native Computing Foundation において、Kubernetes に次いで 2 番目に多くのコントリビューターを抱えています。",
    "description": "このワークショップでは、Splunk Observability Cloudがフロントエンドアプリケーションからバックエンドサービスまで、ユーザー体験の視点からどのように即座に可視性を提供するかをお見せします - Splunk Observability Cloudの最も魅力的な機能と差別化要因を体験していただきます。",
    "tags": [],
    "title": "Observability Cloud",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6.2 Optional Exercise",
    "content": "This is the first section of our optimal Kubernetes Navigator exercise. Below is some high-level information regarding Kubernetes, just in case you’re not familiar with it.\nKubernetes Terminology K8s, short for Kubernetes, is an open-source container orchestration platform. It manages the deployment, scaling, and maintenance of containerized applications, and we use it in this workshop to host our e-commerce application\nSome terminology:\nA Kubernetes cluster is a group of machines, called nodes, that work together to run containerized applications. Nodes are individual servers or VMs in the cluster. Typically, you would have several nodes in a cluster but you may have just one node, just like in this workshop. Pods are the smallest deployable units in Kubernetes, representing one or more containers that share the same network and storage, enabling efficient application scaling and management Applications are a collection of one or more Pods interacting together to provide a service. Namespaces help you keep your applications organized and separate within the cluster, by providing a logical separation for multiple teams or projects within a cluster. Workloads are like a task list and define how many instances of your application should run, how they should be created, and how they should respond to failures Please select the K8s nodes tile from the Tile pane if you have not yet done so. (Select Kubernetes as your Technology). This will bring you to the Kubernetes Navigator Page.\nThe screenshot above shows the main part of the Kubernetes navigator. It will show all the clusters \u0026 their nodes that send metrics to Splunk Observability Cloud, and the first row of charts that show cluster-based Metrics. In the workshop, you will mostly see single-node Kubernetes clusters.\nBefore we dive deeper, let’s make sure we are looking at our cluster.\nExercise First, use the option to pick your cluster. This can be done by selecting k8s.cluster.name from the filter drop-down box. You then can start typing the name of your cluster, (as provided by your instructor). The name should also appear in the drop-down values. Select yours and make sure just the one for your workshop is highlighted with a . Click the Apply Filter button to focus on our Cluster We now should have a single cluster visible. Let’s move on to the next page of this exercise and look at your cluster in detail.",
    "description": "This is the first section of our optimal Kubernetes Navigator exercise. Below is some high-level information regarding Kubernetes, just in case you’re not familiar with it.\nKubernetes Terminology K8s, short for Kubernetes, is an open-source container orchestration platform. It manages the deployment, scaling, and maintenance of containerized applications, and we use it in this workshop to host our e-commerce application\nSome terminology:\nA Kubernetes cluster is a group of machines, called nodes, that work together to run containerized applications. Nodes are individual servers or VMs in the cluster. Typically, you would have several nodes in a cluster but you may have just one node, just like in this workshop. Pods are the smallest deployable units in Kubernetes, representing one or more containers that share the same network and storage, enabling efficient application scaling and management Applications are a collection of one or more Pods interacting together to provide a service. Namespaces help you keep your applications organized and separate within the cluster, by providing a logical separation for multiple teams or projects within a cluster. Workloads are like a task list and define how many instances of your application should run, how they should be created, and how they should respond to failures Please select the K8s nodes tile from the Tile pane if you have not yet done so. (Select Kubernetes as your Technology). This will bring you to the Kubernetes Navigator Page.",
    "tags": [],
    "title": "Infrastructure Exercise - Part 1",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/30-im-exercise/1-im-exercise/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ",
    "content": "このワークショップでは、Splunk Observabilityプラットフォームの以下のコンポーネントを構成するための、基本的なステップを体験できます：\nSplunk Infrastructure Monitoring (IM) Splunk APM Endpoint Performance Database Query Performance AlwaysOn Profiling Splunk Real User Monitoring (RUM) Splunk LogObserver ワークショップの中では、Javaのサンプルアプリケーション（Spring Pet Clinic）をクローン（ダウンロード）し、アプリケーションのコンパイル、パッケージ、実行していきます。\nアプリケーションを起動すると、OpenTelemetry Javaエージェントを通じて、Splunk APMでメトリクスとトレースが即座に表示されるようになります。\nその後、Splunk OpenTelemetry Javascript Libraries (RUM)を使用して、Pet Clinicのエンドユーザーインターフェース（アプリケーションによってレンダリングされるHTMLページ）を計装し、エンドユーザーが実行する個々のクリックとページロードのすべてについて、RUMトレースを生成していきます。\n前提条件 このワークショップは、ホスト/インスタンスが提供されるSplunk実行ワークショップ または 自前のホスト/Multipassインスタンス で行う、自己主導型のワークショップです。\nご自身のシステムには、以下のものがインストールされ、有効になっている必要があります：\nJDK 17 ポート 8083 が開いていること（インバウンド/アウトバウンド）",
    "description": "JavaアプリケーションをつかったSplunk Oservabilityのワークショップです",
    "tags": [],
    "title": "Pet Clinic Java ワークショップ",
    "uri": "/observability-workshop/v5.99/ja/other/pet-clinic/index.html"
  },
  {
    "breadcrumb": "",
    "content": "Splunk Observabilityワークショップへようこそ Splunk Observability Cloud の監視、分析、対応ツールを使用して、アプリケーションとインフラストラクチャをリアルタイムで把握することができます。\nこのワークショップでは、メトリクス、トレース、ログを取り込み、監視し、可視化し、分析するためのクラス最高のオブザーバビリティ（可観測性）プラットフォームについて説明します。\nOpenTelemetry このワークショップでOpenTelemetryをアプリケーションやインフラの分析に役立つテレメトリデータ（メトリクス、トレース、ログ）の計装、生成、収集、エクスポートに使用します。\nGitHub このドキュメントには、issue や pull request で 貢献 することができます。より良いワークショップにするために、是非ご協力ください。\nTwitter SplunkのTwitterチャンネルでは、アップデート情報や興味深い読み物を紹介しています。\nSplunk4Rookies ワークショップ以下は初心者向けワークショップです。\nSplunk4Ninjas WorkshopsThe following workshops require Ninja skills, wax on, wax off.\nその他のワークショップ Pet Clinic Java ワークショップJavaアプリケーションをつかったSplunk Oservabilityのワークショップです\nOpenTelemetry CollectorOpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。\nリソース よくある質問とその回答オブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\nディメンション、プロパティ、タグディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。\nOpenTelemetryでのタグ付け大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "description": "Splunk を使用したオブザーバビリティソリューションの構築方法をご紹介します。",
    "tags": [],
    "title": "Splunk Observability Workshops",
    "uri": "/observability-workshop/v5.99/ja/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "Observability Cloudこのワークショップでは、Splunk Observability Cloudがフロントエンドアプリケーションからバックエンドサービスまで、ユーザー体験の視点からどのように即座に可視性を提供するかをお見せします - Splunk Observability Cloudの最も魅力的な機能と差別化要因を体験していただきます。",
    "description": "以下は初心者向けワークショップです。",
    "tags": [],
    "title": "Splunk4Rookies ワークショップ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e リソース",
    "content": "オブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\nQ: アラートとインシデント対応、インシデント管理の違いは？ A: アラート、インシデント対応、インシデント管理は関連する機能です。これらは一緒にインシデント対応および解決プロセスを構成します。\nモニタリングやオブザーバビリティのツールはインシデント対応プラットフォームにアラートを送信します。これらのプラットフォームはアラートのコレクションを収集し、それらをインシデントとして相関させます。\nこれらのインシデントは記録のためにインシデント管理（ITSM）プラットフォームに記録されます。アラートは何かが起こったことを示すトリガーであり、インシデントへのコンテキストを提供します。\nインシデントには、アラートの内容、インシデントが作成されてから関連するすべての活動、およびフォローされるオンコールポリシーが含まれます。ITSMは、インシデントがアクティブであるときおよび解決された後のインシデントを記録するシステムです。\nインシデント対応および管理をより良く実践するために、これらのコンポーネントが必要になります。\nOn-Call Q: オブザーバビリティはモニタリングとは違うものですか？ A: モニタリングとオブザーバビリティの主な違いは、「既知の未知」と「未知の未知」の違いです。\nモニタリングでは、オペレーターは通常、システムのアーキテクチャと要素に関する事前の知識を持っています。彼らは要素間の関係とそれに関連するメタデータを確実に予測することができます。モニタリングは、頻繁に変更されない状態のインフラストラクチャに適しています。\nオブザーバビリティは、オペレーターがシステム内のすべての要素とそれらの関係を予測し、追跡する能力が限定されているシステム向けです。\nオブザーバビリティは、従来のメトリクスのモニタリングを含む一連のプラクティスと技術です。\nこれらのプラクティスと技術を組み合わせることで、オペレーターはシステムのすべての要素に関する事前の知識がなくても、頻繁に変更がある複雑な環境を理解することができます。オブザーバビリティ技術は、環境の変動やメタデータの変化（カーディナリティ）を従来のモニタリングよりもよく考慮できるため、より静的なモニタリングと比較して優れています。\nObservability Q: トレースとスパンとは何ですか？ A: トレースとスパンは、メトリクスとログと共に、現代のオブザーバビリティツールにフィードされるコアタイプのデータを構成します。それらは特定の要素と機能を持っていますが、一緒にうまく機能します。\nマイクロサービスベースのアーキテクチャは分散しているため、システム内のトランザクションは完了する前に複数のサービスにアクセスします。これにより、問題の場所を正確に特定することが困難になります。トレースは、分散システム内のすべてのサービスを通るリクエストの完全なパスを追跡するための方法です。スパンは、各サービスでの時間のかかる操作です。トレースはスパンの結合したものであり、一緒になると個々のサービスプロセスについてより詳細な情報を提供します。メトリクスはシステムの健康状態の良いスナップショットを提供し、ログは問題を調査する際に深さを提供しますが、トレースとスパンはオペレーターに問題の源泉をより多くのコンテキストでナビゲートするのに役立ちます。これにより、インシデントの調査にかかる時間が節約され、現代のアーキテクチャの複雑さがサポートされます。\nAPM Q: サイドカーパターンとは何ですか？ A: サイドカーパターンは、関連するサービスをインフラストラクチャによって直接接続するためのデザインパターンです。関連するサービスは、接続されているアプリケーションロジックに機能を追加したりサポートしたりすることができます。これは、管理計画に関連するエージェントをアプリケーションサービスと共に展開する方法として広く使用されます。\nオブザーバビリティでは、サイドカーサービスはアプリケーションロジックであり、そのサービスからデータを収集するエージェントです。このセットアップには、アプリケーションサービスを含むコンテナと、エージェントを実行するコンテナの2つが必要です。コンテナはポッドを共有し、ディスク、ネットワーク、名前空間などのリソースを共有します。また、一緒にデプロイされ、同じライフサイクルを共有します。\nObservability",
    "description": "オブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。",
    "tags": [],
    "title": "よくある質問とその回答",
    "uri": "/observability-workshop/v5.99/ja/resources/faq/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 1. はじめに",
    "content": "Splunk Observability Cloud に登録してログインすると、ホームページ（ランディングページ）に移動します。ここでは、開始に役立ついくつかの便利な機能が見つかります。\nデータ探索パネル: どの統合が有効になっているかを表示し、管理者の場合は追加の統合を追加できます。 ドキュメントパネル: Splunk Observability Cloud の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 最近のアクティビティパネル: 最近作成/訪問したダッシュボードやディテクターにすぐにアクセスできます。 メインメニューパネル: Splunk Observability Cloud のコンポーネントを操作します。 組織切り替え: 複数の組織のメンバーである場合は、組織間を簡単に切り替えることができます。 メインメニューの展開/縮小: スペースが限られている場合にメインメニューを展開 » / 折りたたむ « ことができます。 最初の演習から始めましょう：\n演習 メインメニューを展開し、設定をクリックします。 組織切り替えで、複数の組織にアクセスできるかどうかを確認します。 ヒント 以前に Splunk Observability を使用したことがある場合は、以前に使用した組織に配置されている可能性があります。正しいワークショップ組織にいることを確認してください。複数の組織へのアクセス権がある場合は、インストラクターに確認してください。\n演習 オンボーディングガイダンスをクリックします（ここでオンボーディングパネルの表示/非表示を切り替えることができます。製品に十分に精通していて、より多くの情報を表示するためにスペースを使用できる場合に便利です）。 ホームページのオンボーディングコンテンツを非表示にします。 メニューの下部で、お好みのテーマ：Light、Dark、または**System(Auto)**モードを選択します。 これがLog outオプションがある場所であることにも気づきましたか？どうかログアウトしないでください 😊！ \u003c をクリックしてメインメニューに戻ります。 次に、Splunk Real User Monitoring (RUM) を確認しましょう。",
    "description": "Splunk Observability Cloud に登録してログインすると、ホームページ（ランディングページ）に移動します。ここでは、開始に役立ついくつかの便利な機能が見つかります。\nデータ探索パネル: どの統合が有効になっているかを表示し、管理者の場合は追加の統合を追加できます。 ドキュメントパネル: Splunk Observability Cloud の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 最近のアクティビティパネル: 最近作成/訪問したダッシュボードやディテクターにすぐにアクセスできます。 メインメニューパネル: Splunk Observability Cloud のコンポーネントを操作します。 組織切り替え: 複数の組織のメンバーである場合は、組織間を簡単に切り替えることができます。 メインメニューの展開/縮小: スペースが限られている場合にメインメニューを展開 » / 折りたたむ « ことができます。 最初の演習から始めましょう：\n演習 メインメニューを展開し、設定をクリックします。 組織切り替えで、複数の組織にアクセスできるかどうかを確認します。 ヒント 以前に Splunk Observability を使用したことがある場合は、以前に使用した組織に配置されている可能性があります。正しいワークショップ組織にいることを確認してください。複数の組織へのアクセス権がある場合は、インストラクターに確認してください。\n演習 オンボーディングガイダンスをクリックします（ここでオンボーディングパネルの表示/非表示を切り替えることができます。製品に十分に精通していて、より多くの情報を表示するためにスペースを使用できる場合に便利です）。 ホームページのオンボーディングコンテンツを非表示にします。 メニューの下部で、お好みのテーマ：Light、Dark、または**System(Auto)**モードを選択します。 これがLog outオプションがある場所であることにも気づきましたか？どうかログアウトしないでください 😊！ \u003c をクリックしてメインメニューに戻ります。 次に、Splunk Real User Monitoring (RUM) を確認しましょう。",
    "tags": [],
    "title": "ホームページ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/1-homepage/1-home-page/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "サービスビュー サービスオーナーとして、Splunk APM のサービスビューを使用して、単一のパネルでサービスの健全性の完全なビューを取得できます。サービスビューには、可用性、依存関係、リクエスト、エラー、および期間（RED）メトリクス、ランタイムメトリクス、インフラストラクチャメトリクス、Tag Spotlight、エンドポイント、および選択したサービスのログのためのサービスレベルインジケーター（SLI）が含まれています。また、サービスビューからサービスのコードプロファイリングとメモリプロファイリングにすぐにアクセスすることもできます。\n演習 時間ボックスを確認すると、ダッシュボードは以前に選択した APM トレースが完了するまでにかかった時間に関連するデータのみを表示していることがわかります（チャートは静的であることに注意してください）。 時間ボックスで時間枠を -1h に変更します。 これらのチャートはパフォーマンスの問題を素早く特定するのに非常に役立ちます。このダッシュボードを使用して、サービスの健全性を監視できます。 ページを下にスクロールしてInfrustructure Metricsを展開します。ここでホストと Pod のメトリクスが表示されます。 Runtime Metricsは、Node.js で書かれたサービスにはプロファイリングデータが利用できないため、使用できません。 では、探索ビューに戻りましょう。ブラウザの戻るボタンを押してください。 演習 ​ 質問 回答 サービスマップでpaymentserviceの上にカーソルを置いてください。ポップアップサービスチャートからどのような結論を導き出せますか？\nエラーの割合が非常に高い。\nこのエラー率にパターンがあるかどうかを理解する必要があります。そのための便利なツール、Tag Spotlightがあります。",
    "description": "サービスビュー サービスオーナーとして、Splunk APM のサービスビューを使用して、単一のパネルでサービスの健全性の完全なビューを取得できます。サービスビューには、可用性、依存関係、リクエスト、エラー、および期間（RED）メトリクス、ランタイムメトリクス、インフラストラクチャメトリクス、Tag Spotlight、エンドポイント、および選択したサービスのログのためのサービスレベルインジケーター（SLI）が含まれています。また、サービスビューからサービスのコードプロファイリングとメモリプロファイリングにすぐにアクセスすることもできます。\n演習 時間ボックスを確認すると、ダッシュボードは以前に選択した APM トレースが完了するまでにかかった時間に関連するデータのみを表示していることがわかります（チャートは静的であることに注意してください）。 時間ボックスで時間枠を -1h に変更します。 これらのチャートはパフォーマンスの問題を素早く特定するのに非常に役立ちます。このダッシュボードを使用して、サービスの健全性を監視できます。 ページを下にスクロールしてInfrustructure Metricsを展開します。ここでホストと Pod のメトリクスが表示されます。 Runtime Metricsは、Node.js で書かれたサービスにはプロファイリングデータが利用できないため、使用できません。 では、探索ビューに戻りましょう。ブラウザの戻るボタンを押してください。 演習 ​ 質問 回答 サービスマップでpaymentserviceの上にカーソルを置いてください。ポップアップサービスチャートからどのような結論を導き出せますか？",
    "tags": [],
    "title": "2. APMサービスビュー",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/6-apm/2-apm-service-view/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. Spring PetClinic アプリケーションを動かす APMをセットアップするためにまず必要なのは…そう、アプリケーションです！この演習では、Spring PetClinicアプリケーションを使用します。これはSpringフレームワーク（Spring Boot）で作られた、非常に人気のあるサンプルJavaアプリケーションです。\nまずはPetClinicリポジトリをクローンし、そして、アプリケーションをコンパイル、ビルド、パッケージ、テストしていきます。\ngit clone https://github.com/spring-projects/spring-petclinic spring-petclinic ディレクトリに移動します:\ncd spring-petclinic PetClinic が使用する MySQL データベースを起動します:\ndocker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/biarms/mysql:5.7 そして、Splunk版のOpenTelemetry Java APMエージェントをダウンロードしておきましょう。\ncurl -L https://github.com/signalfx/splunk-otel-java/releases/latest/download/splunk-otel-javaagent.jar \\ -o splunk-otel-javaagent.jar 次に、mavenコマンドを実行してPetClinicをコンパイル/ビルド/パッケージ化します:\n./mvnw package -Dmaven.test.skip=true 情報 実際にアプリをコンパイルする前に、mavenが多くの依存ライブラリをダウンロードするため、初回実行時には数分かかるでしょう。2回目以降の実行はもっと短くなります。\nそして、以下のコマンドでアプリケーションを実行することができます:\njava -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.314 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql アプリケーションが動作しているかどうかは、http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスして確認することができます。 次に、トラフィックを生成し、クリックしまくり、エラーを生成し、ペットを追加するなどしてください。\n-Dotel.service.name=$(hostname).service では、アプリケーションの名前を定義しています。サービスマップ上のアプリケーションの名前等に反映されます。 -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.314 では、Environmentと、versionを定義しています。 deployment.environment=$(hostname) は、Splunk APM UIの上部「Environment」に反映されます。 version=0.314 はここでは、アプリケーションのバージョンを示しています。トレースをドリルダウンしたり、サービスマップの Breakdown の機能で分析したり、Tag Spotlightを開くと version 毎のパフォーマンス分析が使えます。 -Dsplunk.profiler.enabled=true および splunk.profiler.memory.enabled=true では、CPUとメモリのプロファイリングを有効にしています。Splunk APM UIから、AlwaysOn Profilingを開いてみてください。 -Dsplunk.metrics.enabled=true では、メモリやスレッドなどJVMメトリクスの送信を有効にしています。Dashboardsから、APM java servicesを開いてみてください。 その後、Splunk APM UIにアクセスして、それぞれのテレメトリーデータを確認してみましょう！\nTroubleshooting MetricSetsを追加する サービスマップやTab Spotlightで、 version などのカスタム属性で分析できるようにするためには、Troubleshooting MetricSetsの設定をあらかじめ追加する必要があります。 左メニューの Settings → APM MetricSets で、設定を管理することができます。 もしお使いのアカウントで分析できなければ、設定を追加してみましょう。\n次のセクションではカスタム計装を追加して、OpenTelemetryでは何ができるのか、さらに見ていきます。",
    "description": "1. Spring PetClinic アプリケーションを動かす APMをセットアップするためにまず必要なのは…そう、アプリケーションです！この演習では、Spring PetClinicアプリケーションを使用します。これはSpringフレームワーク（Spring Boot）で作られた、非常に人気のあるサンプルJavaアプリケーションです。\nまずはPetClinicリポジトリをクローンし、そして、アプリケーションをコンパイル、ビルド、パッケージ、テストしていきます。\ngit clone https://github.com/spring-projects/spring-petclinic spring-petclinic ディレクトリに移動します:\ncd spring-petclinic PetClinic が使用する MySQL データベースを起動します:\ndocker run -d -e MYSQL_USER=petclinic -e MYSQL_PASSWORD=petclinic -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=petclinic -p 3306:3306 docker.io/biarms/mysql:5.7 そして、Splunk版のOpenTelemetry Java APMエージェントをダウンロードしておきましょう。\ncurl -L https://github.com/signalfx/splunk-otel-java/releases/latest/download/splunk-otel-javaagent.jar \\ -o splunk-otel-javaagent.jar 次に、mavenコマンドを実行してPetClinicをコンパイル/ビルド/パッケージ化します:\n./mvnw package -Dmaven.test.skip=true 情報 実際にアプリをコンパイルする前に、mavenが多くの依存ライブラリをダウンロードするため、初回実行時には数分かかるでしょう。2回目以降の実行はもっと短くなります。\nそして、以下のコマンドでアプリケーションを実行することができます:\njava -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.314 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql アプリケーションが動作しているかどうかは、http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスして確認することができます。 次に、トラフィックを生成し、クリックしまくり、エラーを生成し、ペットを追加するなどしてください。",
    "tags": [],
    "title": "OpenTelemetry Javaエージェントをインストールする",
    "uri": "/observability-workshop/v5.99/ja/other/pet-clinic/docs/apm/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "OpenTelemetry クラウドコンピューティング、マイクロサービスアーキテクチャ、そして複雑化するビジネス要件の増加に伴い、可観測性の必要性はかつてないほど高まっています。可観測性とは、システムの出力を調査することで、そのシステムの内部状態を理解する能力です。ソフトウェアの文脈では、これはメトリクス、トレース、ログを含むテレメトリデータを調査することでシステムの内部状態を理解できることを意味します。\nシステムを観測可能にするには、計装が必要です。つまり、コードはトレース、メトリクス、ログを発行する必要があります。この計装データは、Splunk Observability Cloudなどの可観測性バックエンドに送信される必要があります。\nメトリクス トレース ログ 問題がありますか？ 問題はどこですか？ 問題は何ですか？ OpenTelemetry は 2 つの重要なことを行います：\n独自のデータフォーマットやツールに縛られるのではなく、生成したデータを所有できるようにします。 単一のAPI セットと規約を学ぶことができます これら 2 つの要素が組み合わさることで、今日の現代的なコンピューティング環境で必要な柔軟性をチームや組織に提供します。\n可観測性を始めるにあたっては、重要な質問を含め多くの変数を考慮する必要があります： 「どのようにしてデータを可観測性ツールに取り込むのか？」 OpenTelemetry の業界全体での採用は、この質問に答えることをこれまで以上に容易にしています。\nなぜ重要なのか？ OpenTelemetry は完全にオープンソースで無料で使用できます。過去のモニタリングや可観測性ツールは、独自のエージェントに大きく依存していたため、追加のツールを変更したり設定したりするために必要な労力は、インフラレベルからアプリケーションレベルまで、システム全体に大規模な変更を必要としていました。\nOpenTelemetry はベンダー中立であり、可観測性分野の多くの業界リーダーにサポートされているため、採用者は計装にわずかな変更を加えるだけで、サポートされている可観測性ツール間をいつでも切り替えることができます。これは、Linux のように様々なディストリビューションが設定やアドオンをバンドルしていても、基本的にはすべてがコミュニティ主導の OpenTelemetry プロジェクトに基づいているため、どの OpenTelemetry ディストリビューションを使用しても変わりません。\nSplunk は完全に OpenTelemetry にコミットしており、お客様があらゆる種類、あらゆる構造、あらゆるソースから、あらゆる規模で、すべてリアルタイムですべてのデータを収集して使用できるようにしています。OpenTelemetry は基本的にモニタリングの環境を変え、IT チームや DevOps チームがすべての質問とすべてのアクションにデータをもたらすことを可能にしています。これらのワークショップでこれを体験することになります。",
    "description": "OpenTelemetryについて学び、なぜそれが重要なのかを理解しましょう。",
    "tags": [],
    "title": "OpenTelemetryとは何か、なぜ重要なのか？",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/2-opentelemetry/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "OpenTelemetry コレクターのアンインストール EC2 インスタンスには、すでに Splunk Distribution の OpenTelemetry コレクターの古いバージョンが インストールされている可能性があります。先に進む前に、次のコマンドを使用してアンインストールしましょう：\n​ Script Example Output curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; sudo sh /tmp/splunk-otel-collector.sh --uninstall Reading package lists... Done Building dependency tree... Done Reading state information... Done The following packages will be REMOVED: splunk-otel-collector* 0 upgraded, 0 newly installed, 1 to remove and 167 not upgraded. After this operation, 766 MB disk space will be freed. (Reading database ... 157441 files and directories currently installed.) Removing splunk-otel-collector (0.92.0) ... (Reading database ... 147373 files and directories currently installed.) Purging configuration files for splunk-otel-collector (0.92.0) ... Scanning processes... Scanning candidates... Scanning linux images... Running kernel seems to be up-to-date. Restarting services... systemctl restart fail2ban.service falcon-sensor.service Service restarts being deferred: systemctl restart networkd-dispatcher.service systemctl restart unattended-upgrades.service No containers need to be restarted. No user sessions are running outdated binaries. No VM guests are running outdated hypervisor (qemu) binaries on this host. Successfully removed the splunk-otel-collector package OpenTelemetry collector のデプロイ Linux EC2 インスタンスに、Splunk Distribution の OpenTelemetry コレクターの最新バージョンをデプロイしましょう。\nこれはcurlを使用してコレクターバイナリをダウンロードし、特定の引数を指定して実行することで可能です。 これらの引数は、データを送信する realm、使用するアクセストークン、 およびデータを送信するデプロイメント環境をコレクターに指示します。\nSplunk Observability Cloud におけるデプロイメント環境とは、システムまたはアプリケーションの個別のデプロイメントであり、同じアプリケーションの他のデプロイメントの設定と重複しない設定を行うことができます。\n​ Script Example Output curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; \\ sudo sh /tmp/splunk-otel-collector.sh \\ --realm $REALM \\ --mode agent \\ --without-instrumentation \\ --deployment-environment otel-$INSTANCE \\ -- $ACCESS_TOKEN Splunk OpenTelemetry Collector Version: latest Memory Size in MIB: 512 Realm: us1 Ingest Endpoint: https://ingest.us1.signalfx.com API Endpoint: https://api.us1.signalfx.com HEC Endpoint: https://ingest.us1.signalfx.com/v1/log etc. 詳細については、インストーラースクリプトを使用した Linux 用コレクターのインストール を参照してください。\nコレクターが実行中であることを確認 インスタンスでコレクターが正常に実行されていることを確認しましょう。\nステータスコマンドを終了するには、Ctrl + C を押します。\n​ Script Example Output sudo systemctl status splunk-otel-collector ● splunk-otel-collector.service - Splunk OpenTelemetry Collector Loaded: loaded (/lib/systemd/system/splunk-otel-collector.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/splunk-otel-collector.service.d └─service-owner.conf Active: active (running) since Fri 2024-12-20 00:13:14 UTC; 45s ago Main PID: 14465 (otelcol) Tasks: 9 (limit: 19170) Memory: 117.4M CPU: 681ms CGroup: /system.slice/splunk-otel-collector.service └─14465 /usr/bin/otelcol コレクターログの確認方法 journalctlを使用してコレクターログを表示できます：\nログの監視を終了するには、Ctrl + C を押します。\n​ Script Example Output sudo journalctl -u splunk-otel-collector -f -n 100 Dec 20 00:13:14 derek-1 systemd[1]: Started Splunk OpenTelemetry Collector. Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:483: Set config to /etc/otel/collector/agent_config.yaml Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:539: Set memory limit to 460 MiB Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:524: Set soft memory limit set to 460 MiB Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:373: Set garbage collection target percentage (GOGC) to 400 Dec 20 00:13:14 derek-1 otelcol[14465]: 2024/12/20 00:13:14 settings.go:414: set \"SPLUNK_LISTEN_INTERFACE\" to \"127.0.0.1\" etc. コレクターの設定 このコレクターが使用している設定はどこで見つけられるでしょうか？\nその設定は/etc/otel/collectorディレクトリにあります。コレクターをagentモードで インストールしたため、コレクター設定はagent_config.yamlファイルにあります。",
    "description": "OpenTelemetry コレクターのアンインストール EC2 インスタンスには、すでに Splunk Distribution の OpenTelemetry コレクターの古いバージョンが インストールされている可能性があります。先に進む前に、次のコマンドを使用してアンインストールしましょう：\n​ Script Example Output curl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; sudo sh /tmp/splunk-otel-collector.sh --uninstall Reading package lists... Done Building dependency tree... Done Reading state information... Done The following packages will be REMOVED: splunk-otel-collector* 0 upgraded, 0 newly installed, 1 to remove and 167 not upgraded. After this operation, 766 MB disk space will be freed. (Reading database ... 157441 files and directories currently installed.) Removing splunk-otel-collector (0.92.0) ... (Reading database ... 147373 files and directories currently installed.) Purging configuration files for splunk-otel-collector (0.92.0) ... Scanning processes... Scanning candidates... Scanning linux images... Running kernel seems to be up-to-date. Restarting services... systemctl restart fail2ban.service falcon-sensor.service Service restarts being deferred: systemctl restart networkd-dispatcher.service systemctl restart unattended-upgrades.service No containers need to be restarted. No user sessions are running outdated binaries. No VM guests are running outdated hypervisor (qemu) binaries on this host. Successfully removed the splunk-otel-collector package OpenTelemetry collector のデプロイ Linux EC2 インスタンスに、Splunk Distribution の OpenTelemetry コレクターの最新バージョンをデプロイしましょう。",
    "tags": [],
    "title": "OpenTelemetryコレクターのデプロイ",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/2-deploy-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 3. レシーバー",
    "content": "Prometheus レシーバー Prometheus のレシーバーも、もちろんあります。Prometheus は OpenTelemetry Collector で使われているオープンソースのツールキットです。このレシーバーは、OpenTelemetry Collector 自身からメトリクスをスクレイピングするためにも使われます。これらのメトリクスは、コレクタの健全性をモニタリングするために使用できる。\nここでは、prometheus レシーバーを変更して、コレクター自身からメトリクスを収集できるようにしてみます。レシーバーの名前を prometheus から prometheus/internal に変更して、レシーバーが何をしているのかをより明確しましょう。設定ファイルを以下のように更新します：\n​ Prometheus Receiver Configuration prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] 上記の設定では、OpenTelemetry Collector 自身が公開している Prometheus エンドポイントをスクレイピングしています。どのような情報が得られるか、curl コマンドで試すことができます:\ncurl http://localhost:8888/metrics Tips: コンポーネントに名前をつける レシーバー、プロセッサー、エクスポーター、パイプラインなどのコンポーネントは、 otlp や otlp/2 のように、 type[/name] 形式に従った識別子によって定義されます。識別子が一意である限り、与えられたタイプのコンポーネントを複数回定義することができるようになります。\nここでは prometheus/internal という識別子でこのコンポーネントを特定できるようにしたので、別の prometheus レシーバーを追加して、監視対象インスタンスの Prometheus エンドポイントをスクレイピングさせることもできます。\nダッシュボード例 - Prometheus メトリクス このスクリーンショットは、 prometheus/internal レシーバーが OpenTelemetry Collector から収集したメトリクスの、spmeのダッシュボードの例です。ここではスパン・メトリクス・ログの、それぞれの受信および送信の様子を見ることができます。\nメモ このダッシュボードはSplunk Observability Cloud にある組み込みダッシュボードで、Splunk OpenTelemetry Collector のインストールの状況を簡単にモニタリングできます。",
    "description": "Prometheus レシーバー Prometheus のレシーバーも、もちろんあります。Prometheus は OpenTelemetry Collector で使われているオープンソースのツールキットです。このレシーバーは、OpenTelemetry Collector 自身からメトリクスをスクレイピングするためにも使われます。これらのメトリクスは、コレクタの健全性をモニタリングするために使用できる。\nここでは、prometheus レシーバーを変更して、コレクター自身からメトリクスを収集できるようにしてみます。レシーバーの名前を prometheus から prometheus/internal に変更して、レシーバーが何をしているのかをより明確しましょう。設定ファイルを以下のように更新します：\n​ Prometheus Receiver Configuration prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] 上記の設定では、OpenTelemetry Collector 自身が公開している Prometheus エンドポイントをスクレイピングしています。どのような情報が得られるか、curl コマンドで試すことができます:\ncurl http://localhost:8888/metrics Tips: コンポーネントに名前をつける レシーバー、プロセッサー、エクスポーター、パイプラインなどのコンポーネントは、 otlp や otlp/2 のように、 type[/name] 形式に従った識別子によって定義されます。識別子が一意である限り、与えられたタイプのコンポーネントを複数回定義することができるようになります。",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/3-receivers/2-prometheus/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk RUM は業界で唯一のエンドツーエンドのNoSample（サンプリングなし）RUM ソリューションで、すべての Web およびモバイルセッションの完全なユーザーエクスペリエンスに関する可視性を提供し、発生時にすべてのフロントエンドトレースとバックエンドのメトリクス、トレース、ログを独自に組み合わせます。IT オペレーションとエンジニアリングチームは、エラーの範囲を迅速に特定し、優先順位を付け、分離し、パフォーマンスが実際のユーザーにどのように影響するかを測定し、すべてのユーザー操作のビデオ再構築とともにパフォーマンスメトリクスを相関させることでエンドユーザーエクスペリエンスを最適化できます。\n完全なユーザーセッション分析： ストリーミング分析により、シングルページおよびマルチページアプリからの完全なユーザーセッションをキャプチャし、すべてのリソース、画像、ルート変更、API コールの顧客への影響を測定します。\n問題をより迅速に関連付ける： 無限のカーディナリティと完全なトランザクション分析により、複雑な分散システム全体で問題をより迅速に特定し関連付けることができます。\nレイテンシーとエラーの分離： 各コード変更とデプロイメントに対するレイテンシー、エラー、パフォーマンスの低下を簡単に特定します。コンテンツ、画像、サードパーティの依存関係がお客様にどのように影響するかを測定します。\nページパフォーマンスのベンチマークと改善： コアウェブバイタルを活用して、ページ読み込み体験、インタラクティビティ、視覚的安定性を測定し改善します。影響力のある JavaScript エラーを見つけて修正し、最初に改善すべきページを簡単に理解します。\n意味のあるメトリクスの探索： 特定のワークフロー、カスタムタグ、未インデックス化タグの自動提案に関するメトリクスを使用して、顧客への影響を即座に視覚化し、問題の根本原因をすばやく見つけます。\nエンドユーザーエクスペリエンスの最適化： すべてのユーザー操作のビデオ再構築とともにパフォーマンスメトリクスを相関させて、エンドユーザーエクスペリエンスを最適化します。",
    "description": "Splunk RUMについて学び、すべてのWebおよびモバイルセッションの完全なユーザーエクスペリエンスを監視する方法を理解します。",
    "tags": [],
    "title": "Real User Monitoring概要",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/2-rum-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "現在、単一の Synthetic Browser テストの結果を見ています。このテストはビジネストランザクションに分割されています。これは、ビジネス上重要なユーザーフローを表す、論理的に関連する 1 つ以上の操作のグループと考えてください。\n情報 以下のスクリーンショットにはエラーを示す赤いバナーは含まれていませんが、あなたの実行結果には表示されている場合があります。これは、場合によってはテスト実行が失敗することがあり、ワークショップに影響しないため予期されることです。\nフィルムストリップ： サイトのパフォーマンスのスクリーンショットのセットを提供し、ページがリアルタイムでどのように応答するかを確認できます。 ビデオ： 特定のテスト実行の場所とデバイスからあなたのサイトを読み込もうとするユーザーが体験する内容を正確に確認できます。 ブラウザテストメトリクス： ウェブサイトのパフォーマンスの全体像を提供するビューです。 Synthetic トランザクション： サイトとの対話を構成する Synthetic トランザクションのリスト ウォーターフォールチャート ウォーターフォールチャートは、テストランナーとテスト対象サイトの間の対話を視覚的に表現したものです。 デフォルトでは、Splunk Synthetics はテストのスクリーンショットとビデオキャプチャを提供します。これは問題のデバッグに役立ちます。例えば、大きな画像の読み込みが遅い、ページのレンダリングが遅いなどを確認できます。\n演習 マウスを使用してフィルムストリップを左右にスクロールし、テスト実行中にサイトがどのようにレンダリングされていたかを確認します。 ビデオペインで、再生ボタン ▶ を押してテスト再生を見ます。省略記号 ⋮ をクリックすると、再生速度の変更、ピクチャーインピクチャーでの表示、さらにビデオのダウンロードもできます。 Synthetic トランザクションペインのビジネストランザクションヘッダーの下で、最初のボタンHomeをクリックします。 下のウォーターフォールにはページを構成するすべてのオブジェクトが表示されます。最初の行は HTML 自体です。次の行は、ページを構成するオブジェクト（HTML、CSS、JavaScript、画像、フォントなど）です。 ウォーターフォールでGET splunk-otel-web.jsの行を見つけます。 \u003e ボタンをクリックしてメタデータセクションを開き、リクエスト/レスポンスヘッダー情報を確認します。 Synthetic トランザクションペインで、2 番目のビジネストランザクションShopをクリックします。フィルムストリップが調整され、新しいトランザクションの先頭に移動することに注意してください。 他のすべてのトランザクションについても同じことを繰り返し、最後にPlace Orderトランザクションを選択します。",
    "description": "現在、単一の Synthetic Browser テストの結果を見ています。このテストはビジネストランザクションに分割されています。これは、ビジネス上重要なユーザーフローを表す、論理的に関連する 1 つ以上の操作のグループと考えてください。\n情報 以下のスクリーンショットにはエラーを示す赤いバナーは含まれていませんが、あなたの実行結果には表示されている場合があります。これは、場合によってはテスト実行が失敗することがあり、ワークショップに影響しないため予期されることです。\nフィルムストリップ： サイトのパフォーマンスのスクリーンショットのセットを提供し、ページがリアルタイムでどのように応答するかを確認できます。 ビデオ： 特定のテスト実行の場所とデバイスからあなたのサイトを読み込もうとするユーザーが体験する内容を正確に確認できます。 ブラウザテストメトリクス： ウェブサイトのパフォーマンスの全体像を提供するビューです。 Synthetic トランザクション： サイトとの対話を構成する Synthetic トランザクションのリスト ウォーターフォールチャート ウォーターフォールチャートは、テストランナーとテスト対象サイトの間の対話を視覚的に表現したものです。 デフォルトでは、Splunk Synthetics はテストのスクリーンショットとビデオキャプチャを提供します。これは問題のデバッグに役立ちます。例えば、大きな画像の読み込みが遅い、ページのレンダリングが遅いなどを確認できます。\n演習 マウスを使用してフィルムストリップを左右にスクロールし、テスト実行中にサイトがどのようにレンダリングされていたかを確認します。 ビデオペインで、再生ボタン ▶ を押してテスト再生を見ます。省略記号 ⋮ をクリックすると、再生速度の変更、ピクチャーインピクチャーでの表示、さらにビデオのダウンロードもできます。 Synthetic トランザクションペインのビジネストランザクションヘッダーの下で、最初のボタンHomeをクリックします。 下のウォーターフォールにはページを構成するすべてのオブジェクトが表示されます。最初の行は HTML 自体です。次の行は、ページを構成するオブジェクト（HTML、CSS、JavaScript、画像、フォントなど）です。 ウォーターフォールでGET splunk-otel-web.jsの行を見つけます。 \u003e ボタンをクリックしてメタデータセクションを開き、リクエスト/レスポンスヘッダー情報を確認します。 Synthetic トランザクションペインで、2 番目のビジネストランザクションShopをクリックします。フィルムストリップが調整され、新しいトランザクションの先頭に移動することに注意してください。 他のすべてのトランザクションについても同じことを繰り返し、最後にPlace Orderトランザクションを選択します。",
    "tags": [],
    "title": "2. Syntheticsテスト詳細",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/8-synthetics/2-synthetics-detail/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "演習 Custom Eventsタブを選択して、そのタブにいることを確認します。\nCustom Event Latencyチャートを見てください。ここに表示されているメトリクスはアプリケーションのレイテンシーを示しています。横の比較メトリクスは、1 時間前（上部のフィルターバーで選択されています）と比較したレイテンシーを示しています。\nチャートタイトルの下にあるすべて表示リンクをクリックします。\nこのダッシュボードビューでは、RUM データに関連付けられたすべてのタグが表示されます。タグはデータを識別するために使用されるキーと値のペアです。この場合、タグは OpenTelemetry 計装によって自動的に生成されます。タグはデータをフィルタリングし、チャートやテーブルを作成するために使用されます。Tag Spotlight ビューでは、ユーザーセッションを詳しく調べることができます。\n演習 時間枠を過去 1 時間に変更します。 Add filtersをクリックし、OS Versionを選択し、!=をクリックしてSyntheticsとRUMLoadGenを選択し、フィルターを適用ボタンをクリックします。 Custom Events Nameチャートを見つけ、リスト内のPlaceOrderを見つけてクリックし、Add to filterを選択します。 上部のグラフに大きなスパイクがあることに注目してください。 User Sessionタブをクリックします。 Durationの見出しを 2 回クリックして、セッションを期間で並べ替えます（最も長いものが上部に表示されます）。 テーブルの上にあるをクリックし、追加の列のリストからSf Geo Cityを選択し、保存をクリックします。 これで、最も長い期間の降順でソートされたユーザーセッションテーブルができました。このテーブルには、サイトでショッピングしたすべてのユーザーの都市も含まれています。OS バージョン、ブラウザバージョンなど、さらにフィルターを適用してデータを絞り込むこともできます。",
    "description": "演習 Custom Eventsタブを選択して、そのタブにいることを確認します。\nCustom Event Latencyチャートを見てください。ここに表示されているメトリクスはアプリケーションのレイテンシーを示しています。横の比較メトリクスは、1 時間前（上部のフィルターバーで選択されています）と比較したレイテンシーを示しています。\nチャートタイトルの下にあるすべて表示リンクをクリックします。\nこのダッシュボードビューでは、RUM データに関連付けられたすべてのタグが表示されます。タグはデータを識別するために使用されるキーと値のペアです。この場合、タグは OpenTelemetry 計装によって自動的に生成されます。タグはデータをフィルタリングし、チャートやテーブルを作成するために使用されます。Tag Spotlight ビューでは、ユーザーセッションを詳しく調べることができます。\n演習 時間枠を過去 1 時間に変更します。 Add filtersをクリックし、OS Versionを選択し、!=をクリックしてSyntheticsとRUMLoadGenを選択し、フィルターを適用ボタンをクリックします。 Custom Events Nameチャートを見つけ、リスト内のPlaceOrderを見つけてクリックし、Add to filterを選択します。 上部のグラフに大きなスパイクがあることに注目してください。 User Sessionタブをクリックします。 Durationの見出しを 2 回クリックして、セッションを期間で並べ替えます（最も長いものが上部に表示されます）。 テーブルの上にあるをクリックし、追加の列のリストからSf Geo Cityを選択し、保存をクリックします。 これで、最も長い期間の降順でソートされたユーザーセッションテーブルができました。このテーブルには、サイトでショッピングしたすべてのユーザーの都市も含まれています。OS バージョン、ブラウザバージョンなど、さらにフィルターを適用してデータを絞り込むこともできます。",
    "tags": [],
    "title": "2. Tag Spotlight",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/5-rum/2-tag-spotlight/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "さて、OpenTelemetry Collector はインストールできました。次は OpenTelemetry Collector のエクステンション（拡張機能）を見てみましょう。エクステンションはオプションで、主にテレメトリーデータの処理を伴わないタスクで使用できます。例としては、ヘルスモニタリング、サービスディスカバリ、データ転送などがあります。\n%%{ init:{ \"theme\": \"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style E fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "さて、OpenTelemetry Collector はインストールできました。次は OpenTelemetry Collector のエクステンション（拡張機能）を見てみましょう。エクステンションはオプションで、主にテレメトリーデータの処理を伴わないタスクで使用できます。例としては、ヘルスモニタリング、サービスディスカバリ、データ転送などがあります。\n%%{ init:{ \"theme\": \"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style E fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/2-extensions/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 9. サービスヘルスダッシュボード",
    "content": "このセクションでは、コピー＆ペースト機能を使用してダッシュボードを拡張します。APM サービスダッシュボードのセクションでいくつかのチャートをコピーしたことを思い出してください。これからそれらのチャートをダッシュボードに追加します。\n演習 ページ上部の 2+ を選択し、チャートの貼り付けを選択します。これにより、カスタムダッシュボードにチャートが作成されます。 現在、チャートはすべてのEnvironmentとServiceのデータを表示しているので、環境とpaymentserviceのフィルターを追加しましょう。 リクエスト率単一値チャートの右上にある 3 つのドット … をクリックします。これにより、チャートが編集モードで開きます。 新しい画面で、画面中央のsf_environment:* xボタン（1）のxをクリックして閉じます。 +をクリックして新しいフィルターを追加し、sf_environmentを選択してからドロップダウンから[ワークショップ名]を選択し、適用を押します。ボタンが**sf_environment:[ワークショップ名]**に変わります。 sf_service.ボタン（2）についても同様に、閉じてsf_serviceの新しいフィルターを作成します。ただし、今回はpaymentserviceに変更します。 保存して閉じるボタン（3）をクリックします。 リクエスト率テキストチャートについても前の 4 つのステップを繰り返します。 2 つのチャートを更新した後、保存をクリックします。 新しく貼り付けられたチャートはダッシュボードの下部に表示されるので、ダッシュボードを再度整理する必要があります。 先ほど学んだドラッグ＆ドロップとリサイズのスキルを使用して、以下の画像のようにダッシュボードを表示させてください。 次に、実行中の Synthetics テストに基づいてカスタムチャートを作成します。",
    "description": "このセクションでは、コピー＆ペースト機能を使用してダッシュボードを拡張します。APM サービスダッシュボードのセクションでいくつかのチャートをコピーしたことを思い出してください。これからそれらのチャートをダッシュボードに追加します。\n演習 ページ上部の 2+ を選択し、チャートの貼り付けを選択します。これにより、カスタムダッシュボードにチャートが作成されます。 現在、チャートはすべてのEnvironmentとServiceのデータを表示しているので、環境とpaymentserviceのフィルターを追加しましょう。 リクエスト率単一値チャートの右上にある 3 つのドット … をクリックします。これにより、チャートが編集モードで開きます。 新しい画面で、画面中央のsf_environment:* xボタン（1）のxをクリックして閉じます。 +をクリックして新しいフィルターを追加し、sf_environmentを選択してからドロップダウンから[ワークショップ名]を選択し、適用を押します。ボタンが**sf_environment:[ワークショップ名]**に変わります。 sf_service.ボタン（2）についても同様に、閉じてsf_serviceの新しいフィルターを作成します。ただし、今回はpaymentserviceに変更します。 保存して閉じるボタン（3）をクリックします。 リクエスト率テキストチャートについても前の 4 つのステップを繰り返します。 2 つのチャートを更新した後、保存をクリックします。 新しく貼り付けられたチャートはダッシュボードの下部に表示されるので、ダッシュボードを再度整理する必要があります。 先ほど学んだドラッグ＆ドロップとリサイズのスキルを使用して、以下の画像のようにダッシュボードを表示させてください。 次に、実行中の Synthetics テストに基づいてカスタムチャートを作成します。",
    "tags": [],
    "title": "コピーしたチャートの追加",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/9-custom-dashboard/2-add-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "特定のログ行を見る前に、これまでに行ったことと、可観測性の 3 本柱に基づいてなぜここにいるのかを簡単に振り返ってみましょう：\nメトリクス トレース ログ 問題がありますか？ 問題はどこですか？ 問題は何ですか？ メトリクスを使用して、アプリケーションに問題があることを特定しました。これはサービスダッシュボードのエラー率が、あるべき値よりも高かったことから明らかでした。 トレースとスパンタグを使用して、問題がどこにあるかを見つけました。paymentserviceにはv350.9とv350.10の 2 つのバージョンがあり、v350.10のエラー率は 100% でした。 paymentserviceのv350.10からのこのエラーが、複数の再試行とオンラインブティックのチェックアウトからの応答の長い遅延を引き起こしたことを確認しました。 トレースから、関連コンテンツの力を使用して、失敗したpaymentserviceバージョンのログエントリに到達しました。これで、問題が何であるかを特定できます。 演習 ログテーブルのエラーエントリをクリックします（リストに別のサービスからのまれなエラーもある場合は、hostname: \"paymentservice-xxxx\"と表示されていることを確認してください）。 ​ 質問 回答 メッセージに基づいて、問題を解決するために開発チームに何を伝えますか？\n開発チームは、有効な API トークンでコンテナを再構築してデプロイするか、v350.9にロールバックする必要があります。\nログメッセージペインのXをクリックして閉じます。 おめでとうございます Splunk Observability Cloud を正常に使用して、オンラインブティックでショッピング中に不良なユーザーエクスペリエンスを体験した理由を理解しました。RUM、APM、ログを使用して、サービス環境で何が起こったかを理解し、その後、可観測性の 3 本柱であるメトリクス、トレース、ログに基づいて根本原因を見つけました。\nまた、アプリケーションの動作パターンを検出するためにTag Spotlightでインテリジェントなタグ付けと分析を使用する方法と、問題のコンテキストを維持しながら異なるコンポーネント間を迅速に移動するために関連コンテンツのフルスタック相関パワーを使用する方法も学びました。\nワークショップの次のパートでは、問題発見モードから緩和、防止、プロセス改善モードに移行します。\n次は、カスタムダッシュボードでのログチャートの作成です。",
    "description": "特定のログ行を見る前に、これまでに行ったことと、可観測性の 3 本柱に基づいてなぜここにいるのかを簡単に振り返ってみましょう：\nメトリクス トレース ログ 問題がありますか？ 問題はどこですか？ 問題は何ですか？ メトリクスを使用して、アプリケーションに問題があることを特定しました。これはサービスダッシュボードのエラー率が、あるべき値よりも高かったことから明らかでした。 トレースとスパンタグを使用して、問題がどこにあるかを見つけました。paymentserviceにはv350.9とv350.10の 2 つのバージョンがあり、v350.10のエラー率は 100% でした。 paymentserviceのv350.10からのこのエラーが、複数の再試行とオンラインブティックのチェックアウトからの応答の長い遅延を引き起こしたことを確認しました。 トレースから、関連コンテンツの力を使用して、失敗したpaymentserviceバージョンのログエントリに到達しました。これで、問題が何であるかを特定できます。 演習 ログテーブルのエラーエントリをクリックします（リストに別のサービスからのまれなエラーもある場合は、hostname: \"paymentservice-xxxx\"と表示されていることを確認してください）。 ​ 質問 回答 メッセージに基づいて、問題を解決するために開発チームに何を伝えますか？\n開発チームは、有効な API トークンでコンテナを再構築してデプロイするか、v350.9にロールバックする必要があります。\nログメッセージペインのXをクリックして閉じます。 おめでとうございます Splunk Observability Cloud を正常に使用して、オンラインブティックでショッピング中に不良なユーザーエクスペリエンスを体験した理由を理解しました。RUM、APM、ログを使用して、サービス環境で何が起こったかを理解し、その後、可観測性の 3 本柱であるメトリクス、トレース、ログに基づいて根本原因を見つけました。",
    "tags": [],
    "title": "2. ログエントリの表示",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/7-log-observer/2-log-entry/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "ワークショップの最初の部分では、OpenTelemetry による自動計装がどのようにして OpenTelemetry Collector に関数がどの言語で書かれているかを自動検出させ、それらの関数のトレースの取得を開始させるかを示します。\n自動計装ワークショップディレクトリとコンテンツ まず、o11y-lambda-workshop/autoディレクトリとそのファイルの一部を見てみましょう。ここにはワークショップの自動計装部分のすべてのコンテンツがあります。\nauto ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/auto ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/auto このディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars 出力には以下のファイルとディレクトリが含まれるはずです：\nget_logs.py main.tf send_message.py handler outputs.tf terraform.tf main.tf ファイル main.tf ファイルをより詳しく見てみましょう：\ncat main.tf ワークショップの質問 このテンプレートによってどの AWS リソースが作成されているか特定できますか？ OpenTelemetry 計装がどこでセットアップされているか特定できますか？ ヒント: Lambda 関数の定義を調べてください 以前に設定した環境変数によってどの計装情報が提供されているか判断できますか？ 各 Lambda 関数の環境変数が設定されているセクションが見つかるはずです。\nenvironment { variables = { SPLUNK_ACCESS_TOKEN = var.o11y_access_token SPLUNK_REALM = var.o11y_realm OTEL_SERVICE_NAME = \"producer-lambda\" OTEL_RESOURCE_ATTRIBUTES = \"deployment.environment=${var.prefix}-lambda-shop\" AWS_LAMBDA_EXEC_WRAPPER = \"/opt/nodejs-otel-handler\" KINESIS_STREAM = aws_kinesis_stream.lambda_streamer.name } } これらの環境変数を使用することで、いくつかの方法で自動計装を構成しています：\n環境変数を設定して、データのエクスポート先となる Splunk Observability Cloud 組織を OpenTelemetry collector に伝えています。\nSPLUNK_ACCESS_TOKEN = var.o11y_access_token SPLUNK_ACCESS_TOKEN = var.o11y_realm また、OpenTelemetry が関数/サービスを識別し、それが属する環境/アプリケーションを認識するのに役立つ変数も設定しています。\nOTEL_SERVICE_NAME = \"producer-lambda\" # consumer関数の場合はconsumer-lambda OTEL_RESOURCE_ATTRIBUTES = \"deployment.environment=${var.prefix}-lambda-shop\" コード言語に基づいて、関数のハンドラーに自動的にトレースデータを取得するために適用する必要があるラッパーを OpenTelemetry に知らせる環境変数を設定しています。\nAWS_LAMBDA_EXEC_WRAPPER - \"/opt/nodejs-otel-handler\" producer-lambda関数の場合、レコードを配置する Kinesis ストリームを関数に知らせるための環境変数を設定しています。\nKINESIS_STREAM = aws_kinesis_stream.lambda_streamer.name これらの値は、「前提条件」セクションで設定した環境変数、および、この Terraform 構成ファイルの一部としてデプロイされるリソースから取得されます。\nまた、各関数に Splunk OpenTelemetry Lambda layer を設定する引数も確認できるはずです\nlayers = var.otel_lambda_layer OpenTelemetry Lambda layer は、Lambda 関数の呼び出し時に計測データを収集、処理、およびエクスポートするために必要なライブラリと依存関係を含むパッケージです。\nすべての OpenTelemetry サポート言語のライブラリと依存関係を持つ一般的な OTel Lambda layer がありますが、関数をさらに軽量化するための言語固有の Lambda layer も存在します。\n各 AWS リージョンの関連する Splunk OpenTelemetry Lambda layer ARN（Amazon Resource Name）と最新バージョンはこちらで確認できます producer.mjs ファイル 次に、producer-lambda関数のコードを見てみましょう：\n以下のコマンドを実行してproducer.mjsファイルの内容を表示します：\ncat ~/o11y-lambda-workshop/auto/handler/producer.mjs この NodeJS モジュールにはプロデューサー関数のコードが含まれています。 基本的に、この関数はメッセージを受け取り、そのメッセージを対象の Kinesis ストリームにレコードとして配置します Lambda 関数のデプロイとトレースデータの生成 autoディレクトリの内容に慣れたところで、ワークショップ用のリソースをデプロイし、Lambda 関数からトレースデータを生成していきます。\nautoディレクトリで Terraform を初期化する main.tfファイルで定義されたリソースをデプロイするには、まず Terraform がそのファイルと同じフォルダで初期化されていることを確認する必要があります。\nauto ディレクトリにいることを確認します:\npwd 予想される出力は ~/o11y-lambda-workshop/auto です auto ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/auto 次のコマンドを実行して、このディレクトリで Terraform を初期化します\nterraform init このコマンドは同じフォルダにいくつかの要素を作成します： .terraform.lock.hcl ファイル：リソースを提供するために使用するプロバイダーを記録します .terraform ディレクトリ：プロバイダーの構成を保存します 上記のファイルに加えて、apply サブコマンドを使用して terraform を実行すると、デプロイされたリソースの状態を追跡するために terraform.tfstate ファイルが作成されます。 これらにより、Terraform は auto ディレクトリの main.tf ファイル内で定義されたとおりに、リソースの作成、状態、破棄を管理できます Lambda 関数とその他の AWS リソースをデプロイする このディレクトリで Terraform を初期化したら、リソースのデプロイに進むことができます。\nまず、terraform plan コマンドを実行して、Terraform が問題なくリソースを作成できることを確認します。\nterraform plan これにより、リソースをデプロイするプランといくつかのデータが出力され、意図したとおりに動作することを確認できます。 プランに表示される値の一部は、作成後に判明するか、セキュリティ上の理由でマスクされていることに注意してください。 次に、terraform apply コマンドを実行して、main.tf ファイルから Lambda 関数とその他のサポートリソースをデプロイします：\nterraform apply Enter a value: プロンプトが表示されたら yes と応答します\nこれにより、以下のような出力が得られます：\nOutputs: base_url = \"https://______.amazonaws.com/serverless_stage/producer\" consumer_function_name = \"_____-consumer\" consumer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-consumer\" consumer_log_group_name = \"/aws/lambda/______-consumer\" environment = \"______-lambda-shop\" lambda_bucket_name = \"lambda-shop-______-______\" producer_function_name = \"______-producer\" producer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-producer\" producer_log_group_name = \"/aws/lambda/______-producer\" Terraform 出力は outputs.tf ファイルで定義されています。 これらの出力は、ワークショップの他の部分でもプログラム的に使用されます。 producer-lambda URL (base_url) にトラフィックを送信する デプロイした Lambda 関数からトレースを取得し始めるには、トラフィックを生成する必要があります。producer-lambda関数のエンドポイントにメッセージを送信し、それを Kinesis ストリームにレコードとして配置し、その後consumer-lambda関数によってストリームから取得されるようにします。\nauto ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/auto です auto ディレクトリにいない場合は、次のコマンドを実行します\ncd ~/o11y-lambda-workshop/auto send_message.py スクリプトは、コマンドラインで入力を受け取り、JSON ディクショナリに追加し、while ループの一部として producer-lambda 関数のエンドポイントに繰り返し送信する Python スクリプトです。\nRun the send_message.py script as a background process\n--name と --superpower 引数が必要です nohup ./send_message.py --name CHANGEME --superpower CHANGEME \u0026 メッセージが成功した場合は、以下のような出力が表示されるはずです\n[1] 79829 user@host manual % appending output to nohup.out ここで重要な情報は 2 つあります: 1 行目のプロセス ID（この例では 79829）、および appending output to nohup.out メッセージ nohup コマンドはスクリプトがバックグラウンドに送られた時に切断されないようにします。また、コマンドからの curl 出力を、現在いるフォルダと同じフォルダにある nohup.out ファイルにキャプチャします。 \u0026 はシェルプロセスにこのプロセスをバックグラウンドで実行するよう指示し、シェルが他のコマンドを実行できるようにします。 次に、response.logs ファイルの内容を確認して、producer-lambda エンドポイントへのリクエストが成功したことを確認します：\ncat response.logs メッセージが成功していれば、画面に印刷された行の中に次の出力が表示されるはずです： {\"message\": \"Message placed in the Event Stream: {prefix}-lambda_stream\"} 失敗した場合は、次のように表示されます： {\"message\": \"Internal server error\"} 重要 この場合は、ワークショップ進行役の一人に支援を求めてください。\nLambda 関数のログを表示する 次に、Lambda 関数のログを確認しましょう。\nproducer-lambda ログを表示するには、producer.logs ファイルを確認します：\ncat producer.logs consumer-lambda ログを表示するには、consumer.logs ファイルを確認します：\ncat consumer.logs ログを注意深く調べてください。\nワークショップの質問 OpenTelemetry が読み込まれているのが見えますか？splunk-extension-wrapperのある行に注目してください splunk-extension-wrapperが読み込まれているのを見るためにhead -n 50 producer.logsまたはhead -n 50 consumer.logsの実行を検討してください。",
    "description": "ワークショップの最初の部分では、OpenTelemetry による自動計装がどのようにして OpenTelemetry Collector に関数がどの言語で書かれているかを自動検出させ、それらの関数のトレースの取得を開始させるかを示します。\n自動計装ワークショップディレクトリとコンテンツ まず、o11y-lambda-workshop/autoディレクトリとそのファイルの一部を見てみましょう。ここにはワークショップの自動計装部分のすべてのコンテンツがあります。\nauto ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/auto ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/auto このディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars 出力には以下のファイルとディレクトリが含まれるはずです：\nget_logs.py main.tf send_message.py handler outputs.tf terraform.tf main.tf ファイル main.tf ファイルをより詳しく見てみましょう：\ncat main.tf ワークショップの質問 このテンプレートによってどの AWS リソースが作成されているか特定できますか？ OpenTelemetry 計装がどこでセットアップされているか特定できますか？ ヒント: Lambda 関数の定義を調べてください 以前に設定した環境変数によってどの計装情報が提供されているか判断できますか？ 各 Lambda 関数の環境変数が設定されているセクションが見つかるはずです。\nenvironment { variables = { SPLUNK_ACCESS_TOKEN = var.o11y_access_token SPLUNK_REALM = var.o11y_realm OTEL_SERVICE_NAME = \"producer-lambda\" OTEL_RESOURCE_ATTRIBUTES = \"deployment.environment=${var.prefix}-lambda-shop\" AWS_LAMBDA_EXEC_WRAPPER = \"/opt/nodejs-otel-handler\" KINESIS_STREAM = aws_kinesis_stream.lambda_streamer.name } } これらの環境変数を使用することで、いくつかの方法で自動計装を構成しています：",
    "tags": [],
    "title": "自動計装",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/2-auto-instrumentation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 2. RUM概要",
    "content": "メインメニューのRUMをクリックすると、RUM のメインホームページ（ランディングページ）に移動します。このページの主な概念は、選択したすべての RUM アプリケーションの全体的な状態を、フルダッシュボードまたはコンパクトビューのいずれかで一目で提供することです。\n使用する状態ダッシュボードのタイプに関係なく、RUM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk RUM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。（画面のスペースが必要な場合、このペインを非表示にすることができます。） フィルターペイン: 時間枠、環境、アプリケーション、ソースタイプでフィルタリングします。 アプリケーションサマリーペイン: RUM データを送信するすべてのアプリケーションの概要。 RUM環境とアプリケーション、およびソースタイプ Splunk Observability は、RUM トレースの一部として送信されるEnvironmentタグ（ウェブサイトやモバイルアプリとの各操作で作成される）を使用して、「本番環境」や「開発環境」などの異なる環境からのデータを分離します。 さらに アプリケーション(App) タグによる分離も可能です。これにより、同じ環境で実行されている別々のブラウザ/モバイルアプリケーションを区別することができます。 Splunk RUM はブラウザとモバイルアプリケーションの両方で利用可能です。Source タイプを使用してそれらを区別することも可能ですが、このワークショップではブラウザベースの RUM のみを使用します。 演習 時間ウィンドウが -15m に設定されていることを確認します ドロップダウンボックスからワークショップの環境を選択します。命名規則は [ワークショップ名]-workshop です（これを選択すると、ワークショップ RUM アプリケーションが表示されます） App名を選択します。命名規則は [ワークショップ名]-store で、Sourceはすべてのままにしておきます JavaScript Errorsタイルで、TypeErrorエントリ：Cannot read properties of undefined (reading ‘Prcie’) をクリックして詳細を確認します。ウェブサイトのどの部分でエラーが発生したかを素早く示してくれることに注意してください。これにより、迅速に修正することができます。 ペインを閉じます。 3 番目のタイルはWeb Vitalsを報告します。これはユーザーエクスペリエンスの 3 つの重要な側面である読み込み、対話性、視覚的安定性に焦点を当てたメトリクスです。 ​ 質問 回答 Web Vitals メトリクスに基づいて、現在のウェブサイトのパフォーマンスをどのように評価しますか？\nWeb Vitals メトリクスによれば、サイトの初期読み込みは良好であり、Goodと評価されています\n最後のタイル、Most recent alerts タイルは、アプリケーションに対してアラートが発生しているかどうかを表示します。 アプリケーション名の前にある下向き矢印 ⌵ をクリックして、ビューをコンパクトスタイルに切り替えます。このビューでもすべての主要情報が利用可能であることに注目してください。コンパクトビューの任意の場所をクリックすると、フルビューに戻ります。 次に、Splunk Application Performance Monitoring（APM） を確認しましょう。",
    "description": "メインメニューのRUMをクリックすると、RUM のメインホームページ（ランディングページ）に移動します。このページの主な概念は、選択したすべての RUM アプリケーションの全体的な状態を、フルダッシュボードまたはコンパクトビューのいずれかで一目で提供することです。\n使用する状態ダッシュボードのタイプに関係なく、RUM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk RUM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。（画面のスペースが必要な場合、このペインを非表示にすることができます。） フィルターペイン: 時間枠、環境、アプリケーション、ソースタイプでフィルタリングします。 アプリケーションサマリーペイン: RUM データを送信するすべてのアプリケーションの概要。 RUM環境とアプリケーション、およびソースタイプ Splunk Observability は、RUM トレースの一部として送信されるEnvironmentタグ（ウェブサイトやモバイルアプリとの各操作で作成される）を使用して、「本番環境」や「開発環境」などの異なる環境からのデータを分離します。 さらに アプリケーション(App) タグによる分離も可能です。これにより、同じ環境で実行されている別々のブラウザ/モバイルアプリケーションを区別することができます。 Splunk RUM はブラウザとモバイルアプリケーションの両方で利用可能です。Source タイプを使用してそれらを区別することも可能ですが、このワークショップではブラウザベースの RUM のみを使用します。 演習 時間ウィンドウが -15m に設定されていることを確認します ドロップダウンボックスからワークショップの環境を選択します。命名規則は [ワークショップ名]-workshop です（これを選択すると、ワークショップ RUM アプリケーションが表示されます） App名を選択します。命名規則は [ワークショップ名]-store で、Sourceはすべてのままにしておきます JavaScript Errorsタイルで、TypeErrorエントリ：Cannot read properties of undefined (reading ‘Prcie’) をクリックして詳細を確認します。ウェブサイトのどの部分でエラーが発生したかを素早く示してくれることに注意してください。これにより、迅速に修正することができます。 ペインを閉じます。 3 番目のタイルはWeb Vitalsを報告します。これはユーザーエクスペリエンスの 3 つの重要な側面である読み込み、対話性、視覚的安定性に焦点を当てたメトリクスです。 ​ 質問 回答 Web Vitals メトリクスに基づいて、現在のウェブサイトのパフォーマンスをどのように評価しますか？",
    "tags": [],
    "title": "Real User Monitoring ホームページ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/2-rum-home/1-rum-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 2. エクステンション",
    "content": "Performance Profiler エクステンション Performance Profiler エクステンションは、Go の net/http/pprof エンドポイントを有効化します。これは通常、開発者がパフォーマンスプロファイルを収集し、サービスの問題を調査するために使用します。このワークショップでは詳しく紹介はしません。",
    "description": "Performance Profiler エクステンション Performance Profiler エクステンションは、Go の net/http/pprof エンドポイントを有効化します。これは通常、開発者がパフォーマンスプロファイルを収集し、サービスの問題を調査するために使用します。このワークショップでは詳しく紹介はしません。",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/2-extensions/2-performance/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 3. APM概要",
    "content": "メインメニューのAPMをクリックすると、APM ホームページが表示されます。APM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk APM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 APM 概要ペイン: トップサービスとトップビジネスワークフローのリアルタイムメトリクス。 機能ペイン: サービス、タグ、トレース、データベースクエリパフォーマンス、コードプロファイリングの詳細分析へのリンク。 APM 概要ペインは、アプリケーションの健全性の高レベルの概要を提供します。これにはアプリケーション内のサービス、レイテンシー、エラーの概要が含まれます。また、エラー率別のトップサービスとエラー率別のトップビジネスワークフローのリストも含まれています（ビジネスワークフローは、特定のアクティビティやトランザクションに関連するトレースコレクションの開始から終了までの旅程であり、エンドツーエンドの KPI の監視やルート原因とボトルネックの特定を可能にします）。\n環境について 複数のアプリケーションを簡単に区別するために、Splunk は Environment を使用します。ワークショップ環境の命名規則は [ワークショップ名]-workshop です。インストラクターが選択する正しい環境を提供します。\n演習 作業している時間ウィンドウが過去 15 分（-15m）に設定されていることを確認します。 ドロップダウンボックスからワークショップ名を選択して、環境をワークショップ用に変更し、それのみが選択されていることを確認します。 ​ 質問 回答 エラー率別のトップサービスチャートから何を結論づけることができますか？\npaymentserviceはエラー率が高い\n概要ページを下にスクロールすると、一部のサービスの横にInferred Serviceと表示されていることに気づくでしょう。\nSplunk APM は、リモートサービスを呼び出すスパンが必要な情報を持っている場合、リモートサービスまたは推測されたサービスの存在を推測できます。推測されるサービスの例としては、データベース、HTTP エンドポイント、メッセージキューなどがあります。推測されたサービスは計装されていませんが、サービスマップとサービスリストに表示されます。\n次に、Splunk ログオブザーバー（LO） を確認しましょう。",
    "description": "メインメニューのAPMをクリックすると、APM ホームページが表示されます。APM ホームページは 3 つの明確なセクションで構成されています：\nオンボーディングペイン: Splunk APM の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 APM 概要ペイン: トップサービスとトップビジネスワークフローのリアルタイムメトリクス。 機能ペイン: サービス、タグ、トレース、データベースクエリパフォーマンス、コードプロファイリングの詳細分析へのリンク。 APM 概要ペインは、アプリケーションの健全性の高レベルの概要を提供します。これにはアプリケーション内のサービス、レイテンシー、エラーの概要が含まれます。また、エラー率別のトップサービスとエラー率別のトップビジネスワークフローのリストも含まれています（ビジネスワークフローは、特定のアクティビティやトランザクションに関連するトレースコレクションの開始から終了までの旅程であり、エンドツーエンドの KPI の監視やルート原因とボトルネックの特定を可能にします）。\n環境について 複数のアプリケーションを簡単に区別するために、Splunk は Environment を使用します。ワークショップ環境の命名規則は [ワークショップ名]-workshop です。インストラクターが選択する正しい環境を提供します。\n演習 作業している時間ウィンドウが過去 15 分（-15m）に設定されていることを確認します。 ドロップダウンボックスからワークショップ名を選択して、環境をワークショップ用に変更し、それのみが選択されていることを確認します。 ​ 質問 回答 エラー率別のトップサービスチャートから何を結論づけることができますか？\npaymentserviceはエラー率が高い",
    "tags": [],
    "title": "Application Performance Monitoring ホームページ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/3-apm-home/1-apm-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 4. Log Observer概要",
    "content": "メインメニューのLog Observerをクリックすると、Log Observer ホームページが表示されます。Log Observer ホームページは 4 つの明確なセクションで構成されています：\nオンボーディングペイン: SplunkLog Observer の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 フィルターバー: 時間、インデックス、フィールドでフィルタリングし、クエリを保存することもできます。 ログテーブルペイン: 現在のフィルター条件に一致するログエントリのリスト。 フィールドペイン: 現在選択されているインデックスで利用可能なフィールドのリスト。 Splunk Index 一般的に、Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk 内のデータは、検索や分析が容易になるように整理され構造化されています。特定のタイプのデータを保存するために異なるインデックスを作成できます。たとえば、Web サーバーログ用のインデックス、アプリケーションログ用の別のインデックスなどがあります。\nヒント 以前に Splunk Enterprise または Splunk Cloud を使用したことがある場合は、おそらくログから調査を開始することに慣れているでしょう。以下の演習で見るように、Splunk Observability Cloud でも同様のことができます。ただし、このワークショップでは、調査にOpenTelemetryのすべてのシグナルを使用します。\n簡単な検索演習を行いましょう：\n演習 時間枠を -15m に設定します。\nフィルターバーでAdd Filterをクリックし、ダイアログでFieldをクリックします。\ncardTypeと入力して選択します。\nトップ値の下でvisaをクリックし、次に = をクリックしてフィルターに追加します。\nログテーブルのログエントリの 1 つをクリックして、エントリにcardType: \"visa\"が含まれていることを確認します。\n出荷されたすべての注文を見つけましょう。フィルターバーのClear Allをクリックして、前のフィルターを削除します。\nフィルターバーで再びAdd Filterをクリックし、キーワードを選択します。次に**キーワードを入力…**ボックスにorder:と入力し、Enter キーを押します。\nこれで「order:」という単語を含むログ行のみが表示されるはずです。まだたくさんのログ行があるので、さらにフィルタリングしましょう。\n別のフィルターを追加します。今回はFieldボックスを選択し、Find a field … 検索ボックスにseverityと入力して選択します。 注文ログ行には重要度が割り当てられていないため、ダイアログボックスの下部にあるExclude all logs with this fieldをクリックしてください。これにより、他のログが削除されます。\n上部にオンボーディングコンテンツがまだ表示されている場合は、Exclude all logs with this fieldボタンを見るためにページを下にスクロールする必要があるかもしれません。\nこれで、過去 15 分間に販売された注文のリストが表示されるはずです。\n次に、Splunk Syntheticsを確認しましょう。",
    "description": "メインメニューのLog Observerをクリックすると、Log Observer ホームページが表示されます。Log Observer ホームページは 4 つの明確なセクションで構成されています：\nオンボーディングペイン: SplunkLog Observer の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 フィルターバー: 時間、インデックス、フィールドでフィルタリングし、クエリを保存することもできます。 ログテーブルペイン: 現在のフィルター条件に一致するログエントリのリスト。 フィールドペイン: 現在選択されているインデックスで利用可能なフィールドのリスト。 Splunk Index 一般的に、Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk では、「Index」はデータが保存される指定された場所を指します。これはデータのフォルダやコンテナのようなものです。Splunk 内のデータは、検索や分析が容易になるように整理され構造化されています。特定のタイプのデータを保存するために異なるインデックスを作成できます。たとえば、Web サーバーログ用のインデックス、アプリケーションログ用の別のインデックスなどがあります。\nヒント 以前に Splunk Enterprise または Splunk Cloud を使用したことがある場合は、おそらくログから調査を開始することに慣れているでしょう。以下の演習で見るように、Splunk Observability Cloud でも同様のことができます。ただし、このワークショップでは、調査にOpenTelemetryのすべてのシグナルを使用します。\n簡単な検索演習を行いましょう：\n演習 時間枠を -15m に設定します。",
    "tags": [],
    "title": "Log Observerホームページ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/4-log-observer-home/1-log-observer-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 4. プロセッサー",
    "content": "Resource Detection プロセッサー resourcedetection プロセッサーは、ホストからリソース情報を検出して、テレメトリーデータ内のリソース値をこの情報で追加または上書きすることができます。\nデフォルトでは、可能であればホスト名を FQDN に設定し、そうでなければ OS が提供するホスト名になります。このロジックは hostname_sources オプションを使って変更できます。FQDN を取得せず、OSが提供するホスト名を使用するには、hostname_sourcesをosに設定します。\n​ System Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] If the workshop instance is running on an AWS/EC2 instance we can gather the following tags from the EC2 metadata API (this is not available on other platforms). ワークショップのインスタンスが AWS/EC2 インスタンスで実行されている場合、EC2 のメタデータ API から以下のタグを収集します（これは他のプラットフォームでは利用できないものもあります）。\ncloud.provider (\"aws\") cloud.platform (\"aws_ec2\") cloud.account.id cloud.region cloud.availability_zone host.id host.image.id host.name host.type これらのタグをメトリクスに追加するために、別のプロセッサーとして定義してみましょう。\n​ EC2 Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2]",
    "description": "Resource Detection プロセッサー resourcedetection プロセッサーは、ホストからリソース情報を検出して、テレメトリーデータ内のリソース値をこの情報で追加または上書きすることができます。\nデフォルトでは、可能であればホスト名を FQDN に設定し、そうでなければ OS が提供するホスト名になります。このロジックは hostname_sources オプションを使って変更できます。FQDN を取得せず、OSが提供するホスト名を使用するには、hostname_sourcesをosに設定します。\n​ System Resource Detection Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] If the workshop instance is running on an AWS/EC2 instance we can gather the following tags from the EC2 metadata API (this is not available on other platforms). ワークショップのインスタンスが AWS/EC2 インスタンスで実行されている場合、EC2 のメタデータ API から以下のタグを収集します（これは他のプラットフォームでは利用できないものもあります）。",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/4-processors/2-resource-detection/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 5. Synthetics概要",
    "content": "メインメニューのSyntheticsをクリックします。これにより、Synthetics ホームページに移動します。このページには、役立つ情報を提供するか、Synthetic テストを選択または作成できる 3 つの明確なセクションがあります。\nオンボーディングペイン: SplunkSynthetics の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 テストペイン: 設定されているすべてのテスト（ブラウザ、API、稼働時間）のリスト。 テスト作成ペイン: 新しい Synthetic テストを作成するためのドロップダウン。 情報 ワークショップの一環として、実行しているアプリケーションに対するデフォルトのブラウザテストを作成しています。テストペイン（2）でそれを見つけることができます。名前はWorkshop Browser Test forで、その後にワークショップの名前が続きます（インストラクターがそれを提供しているはずです）。\nツアーを続けるために、ワークショップの自動ブラウザテストの結果を見てみましょう。\n演習 テストペインで、ワークショップの名前を含む行をクリックします。結果は次のようになります： 注意：Synthetic テストページでは、最初のペインに過去 1 日、8 日、30 日間のサイトのパフォーマンスが表示されます。上のスクリーンショットに示すように、テストが過去に十分遡って開始された場合のみ、対応するチャートに有効なデータが含まれます。ワークショップでは、これはワークショップが作成された時期によって異なります。 パフォーマンス KPI ドロップダウンで、デフォルトの 4 時間から過去 1 時間に時間を変更します。 ​ 質問 回答 テストはどのくらいの頻度で、どこから実行されていますか？\nテストは1 分間隔でラウンドロビン方式によりフランクフルト、ロンドン、パリから実行されています\n次に、Splunk インフラストラクチャモニタリング（IM） を使用して、アプリケーションが実行されているインフラストラクチャを調べてみましょう。",
    "description": "メインメニューのSyntheticsをクリックします。これにより、Synthetics ホームページに移動します。このページには、役立つ情報を提供するか、Synthetic テストを選択または作成できる 3 つの明確なセクションがあります。\nオンボーディングペイン: SplunkSynthetics の使用を開始するためのトレーニングビデオとドキュメントへのリンク。 テストペイン: 設定されているすべてのテスト（ブラウザ、API、稼働時間）のリスト。 テスト作成ペイン: 新しい Synthetic テストを作成するためのドロップダウン。 情報 ワークショップの一環として、実行しているアプリケーションに対するデフォルトのブラウザテストを作成しています。テストペイン（2）でそれを見つけることができます。名前はWorkshop Browser Test forで、その後にワークショップの名前が続きます（インストラクターがそれを提供しているはずです）。\nツアーを続けるために、ワークショップの自動ブラウザテストの結果を見てみましょう。\n演習 テストペインで、ワークショップの名前を含む行をクリックします。結果は次のようになります： 注意：Synthetic テストページでは、最初のペインに過去 1 日、8 日、30 日間のサイトのパフォーマンスが表示されます。上のスクリーンショットに示すように、テストが過去に十分遡って開始された場合のみ、対応するチャートに有効なデータが含まれます。ワークショップでは、これはワークショップが作成された時期によって異なります。 パフォーマンス KPI ドロップダウンで、デフォルトの 4 時間から過去 1 時間に時間を変更します。 ​ 質問 回答 テストはどのくらいの頻度で、どこから実行されていますか？",
    "tags": [],
    "title": "Syntheticsホームページ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/5-synthetics-home/1-synthetics-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 6. インフラストラクチャ概要",
    "content": "メインメニューのInfrastructureをクリックすると、Infrastructure ホームページが表示されます。このページは 4 つの異なるセクションで構成されています。\nオンボーディングペイン: SplunkInfrastructure モニタリングの使用を開始するためのトレーニングビデオとドキュメントへのリンク。 時間とフィルターペイン: 時間ウィンドウ（トップレベルでは設定できません） インテグレーションペイン: Splunk Observability Cloud にメトリクスを送信しているすべてのテクノロジーのリスト。 タイルペイン: インテグレーション別に分類された、監視されているサービスの総数。 Infrastructure ペインを使用して、関心のある Infrastructure/テクノロジーを選択できます。早速試してみましょう。\n演習 インテグレーションペイン（3）のコンテナセクションで、調査したいテクノロジーとしてKubernetesを選択します。\nすると、K8s ノードとK8s ワークロードの 2 つのタイルが表示されます。\n各タイルの下部には履歴グラフが表示され、上部にはアラートが発生した通知が表示されます。すべてのタイルで、各タイルのこの追加情報により、Infrastructure の健全性の良い概要が得られます。\nK8s ノードタイルをクリックします。\nKubernetes クラスターの表示が一つ以上表示されます。\nフィルターを追加ボタンをクリックします。k8s.cluster.nameと入力し、検索結果をクリックします。\nリストから**[ワークショップ名]-k3s-cluster**を選択し、フィルターを適用ボタンをクリックします。\nKubernetes ナビゲーターは色を使用して健全性を示します。ご覧のように、失敗状態（1）にある 2 つの不健全なポッドまたはサービスがあります。残りは健全で実行中です。これは共有 Kubernetes 環境では珍しくないため、ワークショップ用にこの状況を再現しました。\n側面のタイル、特にノード依存関係（2）の下の MySQL と Redis のタイルに注目してください。これらは私たちの E コマースアプリケーションで使用されている 2 つのデータベースです。\nノード依存関係 UI では、OpenTelemetry コレクターによって監視するよう設定されている場合、選択したノードで実行されているサービスが表示されます。\n演習 Redisタイルをクリックすると、Redis インスタンスナビゲーターに移動します。REDIS インスタンスの下で**redis-[ワークショップ名]**をクリックします。 これによりRedis インスタンスに移動します。このナビゲーターでは、E コマースサイトのアクティブな Redis インスタンスからのメトリクスデータのチャートが表示されます。 ​ 質問 回答 このビューでインスタンス依存関係タイルの名前を言えますか？\nはい、Kubernetes のものがあります。\nタイルをクリックすると、Kubernetes ナビゲーターに戻りますが、今回は Redis サービスを実行している Pod を表示する Pod レベルになります。 クラスターレベルに戻るには、画面上部のクラスターリンク（1）をクリックするだけです。 これでSplunk Observability Cloudのツアーは終了です。\n仮想の 💶 を持って、私たちの E コマースサイト「Online Boutique」を見て、ショッピングをしましょう。",
    "description": "メインメニューのInfrastructureをクリックすると、Infrastructure ホームページが表示されます。このページは 4 つの異なるセクションで構成されています。\nオンボーディングペイン: SplunkInfrastructure モニタリングの使用を開始するためのトレーニングビデオとドキュメントへのリンク。 時間とフィルターペイン: 時間ウィンドウ（トップレベルでは設定できません） インテグレーションペイン: Splunk Observability Cloud にメトリクスを送信しているすべてのテクノロジーのリスト。 タイルペイン: インテグレーション別に分類された、監視されているサービスの総数。 Infrastructure ペインを使用して、関心のある Infrastructure/テクノロジーを選択できます。早速試してみましょう。\n演習 インテグレーションペイン（3）のコンテナセクションで、調査したいテクノロジーとしてKubernetesを選択します。\nすると、K8s ノードとK8s ワークロードの 2 つのタイルが表示されます。\n各タイルの下部には履歴グラフが表示され、上部にはアラートが発生した通知が表示されます。すべてのタイルで、各タイルのこの追加情報により、Infrastructure の健全性の良い概要が得られます。\nK8s ノードタイルをクリックします。\nKubernetes クラスターの表示が一つ以上表示されます。\nフィルターを追加ボタンをクリックします。k8s.cluster.nameと入力し、検索結果をクリックします。\nリストから**[ワークショップ名]-k3s-cluster**を選択し、フィルターを適用ボタンをクリックします。\nKubernetes ナビゲーターは色を使用して健全性を示します。ご覧のように、失敗状態（1）にある 2 つの不健全なポッドまたはサービスがあります。残りは健全で実行中です。これは共有 Kubernetes 環境では珍しくないため、ワークショップ用にこの状況を再現しました。\n側面のタイル、特にノード依存関係（2）の下の MySQL と Redis のタイルに注目してください。これらは私たちの E コマースアプリケーションで使用されている 2 つのデータベースです。",
    "tags": [],
    "title": "Infrastructureナビゲーター",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/6-infrastructure-home/1-infrastructure-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Prometheus Internal レシーバー ワークショップの前半で、prometheus レシーバーの名前を変更し、コレクター内部のメトリクスを収集していることを反映して、prometheus/internal という名前にしました。\n現在、メトリクスパイプラインの下で prometheus/internal レシーバーを有効にする必要があります。metrics パイプラインの下の receivers セクションを更新して、prometheus/internal を含めます：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch] exporters: [logging]",
    "description": "Prometheus Internal レシーバー ワークショップの前半で、prometheus レシーバーの名前を変更し、コレクター内部のメトリクスを収集していることを反映して、prometheus/internal という名前にしました。\n現在、メトリクスパイプラインの下で prometheus/internal レシーバーを有効にする必要があります。metrics パイプラインの下の receivers セクションを更新して、prometheus/internal を含めます：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/6-service/2-prometheus/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6.2 Optional Exercise",
    "content": "This is Part 2, of the Infrastructure Monitoring exercise, you should now have a single cluster visible.\nIn the Kubernetes Navigator, the cluster is represented by the square with the black line around it. It will contain one or more blue squares representing the node(s) or compute engines. Each of them containing one or more colored boxes that represent Pods. (this is where your services run in). And as you can guess, green means healthy and red means that there is a problem. Given there are two red boxes or tiles, let’s see what is going on and if this will affect our Online Boutique site.\nExercise First, set the time window we are working with to the last 15 minutes. You do this by changing the the Time picker in the filter pane from -4h to Last 15 minutes. Hover with your mouse over the Cluster, Node and pods, both green and red ones. The resulting information pane that appears will tell you the state of the object. Note, That the red Pods show that they are in Pod Phase: Failed. This means they have crashed and are not working. Examine the Cluster Metric charts that provide information on your cluster. (The charts below the cluster image). They provide general information about the health of your cluster like Memory consumption and the number of pods per node. Nothing flags for the red pods, as crashed pods do not affect the performance of Kubernetes. Let’s check if the Spunk Kubernetes Analyzer can tell us something more useful, so click on K8s Analyzer. Spunk Kubernetes Analyzer The Splunk Kubernetes Analyzer is a smart process that runs in the background in Splunk Observability Cloud and is designed to detect relations between anomalies.\nThe K8s Analyzer should have detected that the two red pods are similar, indicated by the 2 after each line, and running in the same Namespace. In the K8s analyzer view can you find what namespace? (hint, look for k8s.namespace.name). Next, we want to check this on the node level as well, so drill down to the node, first by hovering your mouse over the cluster until you see a blue line appear around the node with a in the left top, inside the black Cluster Line. Click on the triangle . Your view should now show little boxes in each pod, these represent the containers that run the actual code. The K8s Analyzer should confirm that this issue is also occurring on the node level. Click on K8s node. This will show the node metrics, and if you examine the charts, you can see that there are only two pods in the development namespace. It is easier to see if you filter on the k8s.namespace.name=development in the Filter Pane. The # Total Pods chart shows only two pods and in the Node Workload chart there is only the test-job and it has failed. Spunk Kubernetes Analyzer The above scenario is common in a shared Kubernetes environment, where teams deploy applications in different stages. Kubernetes is designed to keep these environments completely separate.\nNone of the Pods that make up our Online Boutique site run in the development namespace and all the other pods are green, we can safely assume these pods do not affect us, so let’s move on to look at a few more things.",
    "description": "This is Part 2, of the Infrastructure Monitoring exercise, you should now have a single cluster visible.\nIn the Kubernetes Navigator, the cluster is represented by the square with the black line around it. It will contain one or more blue squares representing the node(s) or compute engines. Each of them containing one or more colored boxes that represent Pods. (this is where your services run in). And as you can guess, green means healthy and red means that there is a problem. Given there are two red boxes or tiles, let’s see what is going on and if this will affect our Online Boutique site.",
    "tags": [],
    "title": "Infrastructure Exercise - Part 2",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/30-im-exercise/2-im-exercise/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "Lambdaトレーシングこのワークショップでは、AWS Lambdaで実行される小規模なサーバーレスアプリケーションの分散トレースを構築し、AWS Kinesisを介してメッセージをproduceおよびconsumeする方法を学びます\nOpenTelemetry、Docker、K8sを実践で学ぶこのワークショップでは、これらの概念を説明するためにシンプルな.NETアプリケーションを使用します。さあ、始めましょう！ワークショップの終わりまでに、OpenTelemetryを使用した.NETアプリケーションの計装の実践経験を積み、そのアプリケーションのDocker化およびKubernetesへのデプロイを行います。また、Helmを使用したOpenTelemetryコレクターのデプロイ、コレクター設定のカスタマイズ、コレクター設定の問題のトラブルシューティングの経験も得られます。",
    "description": "The following workshops require Ninja skills, wax on, wax off.",
    "tags": [],
    "title": "Splunk4Ninjas Workshops",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e リソース",
    "content": "メトリクスにコンテキストを与える ディメンションとプロパティの違いや、どちらを使うべきかというのは、よく話題にされます。それぞれの説明から始めるのではなく、私たちがどのように使い、どのように似ているのかを理解してから、それぞれの違いや、なぜどちらかを使うのかの例を見ていくことにしましょう。\nディメンションとプロパティの類似点 最も単純な答えは、ディメンションとプロパティはともに、メトリクスにコンテキスト（状況）を追加するメタデータの key:value ペアであるということです。メトリクス自体は、cpu.utilization のような標準的なインフラストラクチャメトリクスであろうと、API呼び出しの回数のようなカスタムメトリクスであろうと、実際に測定しているものなら全てに当てはまります。\ncpu.utilization メトリクスの値が50%であっても、それがどこから来たのかなどのコンテキストを知らなければ、それは単なる数字であり、私たちにとって有用ではありません。少なくとも、どのホストから来たのかを知る必要があります。\n現在では、個々のホストのパフォーマンスや利用率よりも、クラスターやデータセンター全体のパフォーマンスや利用率をより気にすることが多く、ホストのクラスター全体の平均 cpu.utilization、あるホストの cpu.utilization が同じサービスを実行する他のホストと比べて外れ値である場合、あるいは環境間での平均 cpu.utilization を比較することに興味を持っています。\nこのように cpu.utilization メトリクスをスライス、集約、またはグループ化するためには、受け取る cpu.utilization メトリクスのメタデータに、ホストが属するクラスター、ホスト上で実行されているサービス、およびそれが属する環境などの情報が必要です。このメタデータは、ディメンションまたはプロパティの key:value ペアの形で存在することができます。\n例えば、ダッシュボードでフィルターを適用したり、分析関数を実行する際にグループ化機能を使用したりするとき、プロパティまたはディメンションを使用することができます。\nでは、ディメンションとプロパティはどう違うの？ ディメンションはメトリクスと共に取り込み時に送信されるのに対し、プロパティは取り込み後にメトリクスやディメンションに適用されます。これは、`cpu.utilization`` の値がどのホストから来ているかのような、データポイント（メトリクスの単一の報告値）をユニークにするために必要なメタデータはディメンションでなければならないことを意味します。メトリクス名 + ディメンションは MTS（メトリクスの時間系列）をユニークに定義します。\n例：特定のホスト（server1）によって送信される cpu.utilization メトリクスで、ディメンション host:server1 があれば、それはユニークな時間系列と見なされます。もし 10 台のサーバーがそのメトリクスを送信していれば、メトリクス名 cpu.utilization を共有し、ディメンションのキー値ペア（host:server1, host:server2…host:server10）でユニークに識別される 10 の時間系列があります。\nしかし、サーバー名がデータセンター内でのみユニークである場合、データセンターの場所を示す 2 番目のディメンション dc を追加する必要があります。これにより、可能な MTS の数は倍になります。受信された cpu.utilization メトリクスは、2 組のディメンションのキー値ペアによってユニークに識別されます。\ncpu.utilization に dc:east と host:server1 を加えたものは、cpu.utilization に dc:west と host:server1 を加えたものとは異なる時間系列を作り出します。\nディメンションは不変だが、プロパティは可変である 上記で述べたように、メトリクス名 + ディメンションの組み合わせで、ユニークな MTS を作ります。したがって、ディメンションの値が変わると、メトリクス名 + ディメンション値の新しいユニークな組み合わせが生まれ、新しい MTS が作成されます。\n一方、プロパティはメトリクス（またはディメンション）が取り込まれた後に適用されます。メトリクスにプロパティを適用すると、そのメトリクスが属するすべての MTS に伝播して適用されます。または、ディメンションにプロパティを適用する場合、例えば host:server1 とすると、そのホストからのすべてのメトリクスにそのプロパティが添付されます。プロパティの値を変更すると、そのプロパティが添付されているすべての MTS のプロパティ値が更新されます。これが重要な理由は何でしょうか？ プロパティの歴史的な値にこだわる場合、それをディメンションにする必要があることを意味しています。\n例：私たちはアプリケーションに関するカスタムメトリクスを収集しています。1つのメトリクスは latency で、アプリケーションへのリクエストのレイテンシーをカウントします。顧客ごとにレイテンシーを分類して比較できるように customer ディメンションを持っています。私たちは、顧客が使用しているバージョン別にアプリケーションの latency を分類して比較したいと考え、プロパティ version を customer ディメンションに添付しました。最初はすべての顧客がアプリケーションバージョン1を使用しているので、version:1 です。\n現在、いくつかの顧客がアプリケーションのバージョン2を使用しているため、それらの顧客に対してプロパティを version:2 に更新します。これらの顧客の version プロパティの値を更新すると、その顧客に関連するすべての MTS に伝播します。これにより、これらの顧客が以前に version:1 を使用していたという歴史が失われるため、歴史的な期間にわたって version:1 と version:2 の latency を比較する場合、正確なデータを得ることはできません。この場合、メトリクスの時間系列をユニークにするためにアプリケーションの version が必要ではないかもしれませんが、歴史的な値にこだわるために version をディメンションにする必要があります。\n結局、いつ、ディメンションじゃなくてプロパティを使うの？ メトリクスに添付したいメタデータがあるが、取り込み時にはそれを知らない場合が第一の理由です。第二の理由は、ベストプラクティスとして、ディメンションである必要がなければ、それをプロパティにすることです。なぜでしょうか？\n一つの理由は、現在、分析ジョブやチャートレンダリングあたりの MTS の上限が 5K であり、ディメンションが多いほど多くの MTS を生成することです。プロパティは完全に自由形式であり、MTS の数を増やすことなく、メトリクスやディメンションに必要な情報を追加することができます。\nディメンションは各データポイントと共に送信されるため、ディメンションが多いほど、より多くのデータを送信することになります。これは、クラウドプロバイダーがデータ転送に料金を請求する場合、コストが高くなる可能性があります。\nプロパティを使う良い例としては、ホスト情報の追加などがあります。 machine_type, processor, os などの情報を確認することが重要ですが、これらをディメンションとして設定し、各ホストからのすべてのメトリクスと共に送信するのではなく、プロパティとして設定し、ホストディメンションに添付することができます。\n例えば host:server1 では、プロパティ machine_type:ucs, processor:xeon-5560, os:rhel71 を設定します。host:server1 というディメンションを持つメトリクスが入ってくるたびに、上記のすべてのプロパティが自動的に適用されます。\nプロパティの使用例としては、各サービスのエスカレーション連絡先や、各顧客の SLA レベルを知りたい場合があります。これらの項目は、メトリクスをユニークに識別するために必要ではなく、歴史的な値にも関心がないため、プロパティにすることができます。プロパティはサービスディメンションや顧客ディメンションに追加され、これらのディメンションを持つすべてのメトリクスや MTS に適用されます。\nタグについてはどうですか？ タグは、メトリクスにコンテキストを与えたり整理するのに使われる、メタデータの 3 番目のタイプです。ディメンションやプロパティとは異なり、タグは key:value ペアではありません。タグはラベルやキーワードとして考えることができます。プロパティと同様に、タグは取り込み後に UI の Catalog や API を通じてプログラム的にデータに適用されます。タグはメトリクス、ディメンション、ディテクターなどの他のオブジェクトに適用することができます。\nタグを使う場面はどこですか？ タグが必要とされるのは、タグとオブジェクトの間に多対一の関係がある場合や、タグとそれに適用されるオブジェクト間に一対多の関係がある場合です。本質的に関連していないメトリクスをまとめるのに役立ちます。\n例として、複数のアプリケーションを実行しているホストがある場合です。各アプリケーションに対してタグ（ラベル）を作成し、それぞれのホストに複数のタグを適用して、その上で実行されているアプリケーションをラベル付けします。\n例：Server1 は 3 つのアプリケーションを実行しています。タグ app1, app2, app3 を作成し、ディメンション host:server1 にこれら 3 つのタグをすべて適用します。\n上記の例を拡張すると、アプリケーションからのメトリクスも収集しているとします。作成したタグを、アプリケーション自体から来るメトリクスに適用することができます。タグに基づいてフィルタリングすることで、アプリケーションに基づいてフィルタリングしながら、アプリケーションと関連するホストメトリクスの全体像を得ることができます。\n例：App1 は service:application1 というディメンションでメトリクスを送信します。service:application1 のディメンションにタグ app1 を適用します。その後、チャートやダッシュボードでタグ app1 でフィルタリングすることができます。\nタグの他の使用例には、単一の可能な値を持つ二進状態があります。例として、カナリアテストを行い、カナリアデプロイを行った際に新しいコードを受け取ったホストをマークして、新しいコードを受け取らなかったホストとのパフォーマンスを比較しやすくすることがあります。単一の値 canary しかないため、key:value ペアは必要ありません。\nただし、タグでフィルタリングはできますが、groupBy 関数では使用できないことに注意してください。groupBy 関数は key:value ペアのキー部分を指定して実行され、そのキーの値に基づいて結果がグループ化されます。\nさらなる情報 カスタムメトリクスのディメンションを送信する方法に関する情報については、お使いのライブラリに関するクライアントライブラリのドキュメントをご覧ください。\nAPI を通じてメトリクスやディメンションにプロパティやタグを適用する方法については、 /metric/:name、/dimension/:key/:value に関する API ドキュメントを参照してください。\nUI のメタデータカタログでプロパティやタグを追加または編集する方法については、Search the Metric Finder and Metadata catalogで、​Add or edit metadata セクションをご覧ください。",
    "description": "ディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。",
    "tags": [],
    "title": "ディメンション、プロパティ、タグ",
    "uri": "/observability-workshop/v5.99/ja/resources/dimensions_properties_tags/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 9. サービスヘルスダッシュボード",
    "content": "ワークショップのこのパートでは、ダッシュボードに追加するチャートを作成し、また以前に構築したディテクターにリンクします。これにより、テストの動作を確認し、1 つ以上のテスト実行が SLA を違反した場合にアラートを受け取ることができます。\n演習 ダッシュボードの上部にある + をクリックし、チャートを選択します。 まず、Untitled Chart入力フィールドを使用して、チャートに全体テスト所要時間という名前を付けます。 この演習では棒グラフまたは柱状グラフが必要なので、チャートオプションボックスの 3 番目のアイコンをクリックします。 Plot editorのSignalボックスにsynthetics.run.duration.time.ms（これはテストの実行時間です）と入力し、Enter キーを押します。 現在、異なる色の棒が表示されています。テストが実行される各リージョンごとに異なる色になっています。これは必要ないので、分析を追加することでその動作を変更できます。 Add Analyticsボタンをクリックします。 ドロップダウンからMeanオプションを選択し、mean:aggregationを選択してダイアログボックスの外をクリックします。メトリクスが集計されるため、チャートが単色に変わることに注目してください。 x 軸は現在、時間を表していません。これを変更するには、プロットラインの最後にある設定アイコンをクリックします。次のダイアログが開きます： ドロップダウンボックスのDisplay Units（2）をnoneから Time (autoscaling)/Milliseconds(ms) に変更します。ドロップダウンがMillisecondに変わり、チャートの x 軸がテスト所要時間を表すようになります。 設定アイコンをクリックするか、Closeボタンをクリックして、ダイアログを閉じます。 Link Detectirボタンをクリックし、以前に作成したディテクターの名前の入力を開始して、ディテクターを追加します。 ディテクター名をクリックして選択します。 チャートの周りに色付きの枠が表示され、アラートのステータスが示されます。また、以下のようにダッシュボードの上部にベルアイコンが表示されることに注目してください： Save and Closeボタンをクリックします。 ダッシュボードで、チャートを移動して以下のスクリーンショットのように表示させます： 最後のタスクとして、ページ上部（Event Overlayの横）にある 3 つのドット … をクリックし、View fullscreenをクリックします。これは壁掛けテレビモニターで使用するビューです（元に戻るには Esc キーを押します）。 ヒント 時間があれば、RUM メトリクスを使用してダッシュボードにもう 1 つのカスタムチャートを追加してみてください。既製のRUM アプリケーションダッシュボードグループからチャートをコピーすることができます。または、RUM メトリクスrum.client_error.countを使用して、アプリケーションのクライアントエラー数を表示するチャートを作成することもできます。\n最後に、ワークショップのまとめを行います。",
    "description": "ワークショップのこのパートでは、ダッシュボードに追加するチャートを作成し、また以前に構築したディテクターにリンクします。これにより、テストの動作を確認し、1 つ以上のテスト実行が SLA を違反した場合にアラートを受け取ることができます。\n演習 ダッシュボードの上部にある + をクリックし、チャートを選択します。 まず、Untitled Chart入力フィールドを使用して、チャートに全体テスト所要時間という名前を付けます。 この演習では棒グラフまたは柱状グラフが必要なので、チャートオプションボックスの 3 番目のアイコンをクリックします。 Plot editorのSignalボックスにsynthetics.run.duration.time.ms（これはテストの実行時間です）と入力し、Enter キーを押します。 現在、異なる色の棒が表示されています。テストが実行される各リージョンごとに異なる色になっています。これは必要ないので、分析を追加することでその動作を変更できます。 Add Analyticsボタンをクリックします。 ドロップダウンからMeanオプションを選択し、mean:aggregationを選択してダイアログボックスの外をクリックします。メトリクスが集計されるため、チャートが単色に変わることに注目してください。 x 軸は現在、時間を表していません。これを変更するには、プロットラインの最後にある設定アイコンをクリックします。次のダイアログが開きます： ドロップダウンボックスのDisplay Units（2）をnoneから Time (autoscaling)/Milliseconds(ms) に変更します。ドロップダウンがMillisecondに変わり、チャートの x 軸がテスト所要時間を表すようになります。 設定アイコンをクリックするか、Closeボタンをクリックして、ダイアログを閉じます。 Link Detectirボタンをクリックし、以前に作成したディテクターの名前の入力を開始して、ディテクターを追加します。 ディテクター名をクリックして選択します。 チャートの周りに色付きの枠が表示され、アラートのステータスが示されます。また、以下のようにダッシュボードの上部にベルアイコンが表示されることに注目してください： Save and Closeボタンをクリックします。 ダッシュボードで、チャートを移動して以下のスクリーンショットのように表示させます： 最後のタスクとして、ページ上部（Event Overlayの横）にある 3 つのドット … をクリックし、View fullscreenをクリックします。これは壁掛けテレビモニターで使用するビューです（元に戻るには Esc キーを押します）。 ヒント 時間があれば、RUM メトリクスを使用してダッシュボードにもう 1 つのカスタムチャートを追加してみてください。既製のRUM アプリケーションダッシュボードグループからチャートをコピーすることができます。または、RUM メトリクスrum.client_error.countを使用して、アプリケーションのクライアントエラー数を表示するチャートを作成することもできます。",
    "tags": [],
    "title": "カスタムチャートの追加",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/9-custom-dashboard/3-custom-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 2. エクステンション",
    "content": "zPages エクステンション zPages は、外部エクスポータに代わるプロセス内部の機能です。有効化すると、バックグラウンドでトレースとメトリクス情報を収集し、集計し、どのようなデータを扱ったかの Web ページを公開します。zpages は、コレクターが期待どおりに動作していることを確認するための非常に便利な診断機能です。\n​ ServiceZ PipelineZ ExtensionZ ServiceZ は、コレクターサービスの概要と、pipelinez、extensionz、featurez zPages へのクイックアクセスを提供します。このページでは、ビルドとランタイムの情報も提供します。\nURL: http://localhost:55679/debug/servicez (localhost は、適切なホスト名に切り替えてください)\nPipelineZ は、コレクターで実行中のパイプラインに関する情報を提供します。タイプ、データが変更されているか、各パイプラインで使用されているレシーバー、プロセッサー、エクスポーターの情報を見ることができます。\nURL: http://localhost:55679/debug/pipelinez (localhost は、適切なホスト名に切り替えてください)\nExtensionZ は、コレクターで有効化されたエクステンションを確認できます。\nExample URL: http://localhost:55679/debug/extensionz (localhost は、適切なホスト名に切り替えてください)\nNinja: storage エクステンションでデータの耐久性を向上させる これをこなうには、ディストリビューションに file_storage エクステンションモジュールがインストールされていることを確認する必要があります。確認するには、otelcol-contrib components コマンドを実行します:\n​ Command Truncated Output Full Output otelcol-contrib components # ... truncated for clarity extensions: - file_storage buildinfo: command: otelcol-contrib description: OpenTelemetry Collector Contrib version: 0.80.0 receivers: - prometheus_simple - apache - influxdb - purefa - purefb - receiver_creator - mongodbatlas - vcenter - snmp - expvar - jmx - kafka - skywalking - udplog - carbon - kafkametrics - memcached - prometheus - windowseventlog - zookeeper - otlp - awsecscontainermetrics - iis - mysql - nsxt - aerospike - elasticsearch - httpcheck - k8sobjects - mongodb - hostmetrics - signalfx - statsd - awsxray - cloudfoundry - collectd - couchdb - kubeletstats - jaeger - journald - riak - splunk_hec - active_directory_ds - awscloudwatch - sqlquery - windowsperfcounters - flinkmetrics - googlecloudpubsub - podman_stats - wavefront - k8s_events - postgresql - rabbitmq - sapm - sqlserver - redis - solace - tcplog - awscontainerinsightreceiver - awsfirehose - bigip - filelog - googlecloudspanner - cloudflare - docker_stats - k8s_cluster - pulsar - zipkin - nginx - opencensus - azureeventhub - datadog - fluentforward - otlpjsonfile - syslog processors: - resource - batch - cumulativetodelta - groupbyattrs - groupbytrace - k8sattributes - experimental_metricsgeneration - metricstransform - routing - attributes - datadog - deltatorate - spanmetrics - span - memory_limiter - redaction - resourcedetection - servicegraph - transform - filter - probabilistic_sampler - tail_sampling exporters: - otlp - carbon - datadog - f5cloud - kafka - mezmo - skywalking - awsxray - dynatrace - loki - prometheus - logging - azuredataexplorer - azuremonitor - instana - jaeger - loadbalancing - sentry - splunk_hec - tanzuobservability - zipkin - alibabacloud_logservice - clickhouse - file - googlecloud - prometheusremotewrite - awscloudwatchlogs - googlecloudpubsub - jaeger_thrift - logzio - sapm - sumologic - otlphttp - googlemanagedprometheus - opencensus - awskinesis - coralogix - influxdb - logicmonitor - signalfx - tencentcloud_logservice - awsemf - elasticsearch - pulsar extensions: - zpages - bearertokenauth - oidc - host_observer - sigv4auth - file_storage - memory_ballast - health_check - oauth2client - awsproxy - http_forwarder - jaegerremotesampling - k8s_observer - pprof - asapclient - basicauth - headers_setter このエクステンションは、エクスポーターが設定されたエンドポイントにデータを送信できない事象が発生したときに、データをディスクにキューイングする機能をエクスポーターに提供します。\nこのエクステンションを設定するには、以下の情報を含むように設定を更新する必要があります。まず、 /tmp/otel-data ディレクトリを作成し、読み取り/書き込み権限を与えてください：\nextensions: ... file_storage: directory: /tmp/otel-data timeout: 10s compaction: directory: /tmp/otel-data on_start: true on_rebound: true rebound_needed_threshold_mib: 5 rebound_trigger_threshold_mib: 3 # ... truncated for clarity service: extensions: [health_check, pprof, zpages, file_storage] なぜキューデータをディスクに書くの？ コレクターはネットワークの不調（および、コレクターの再起動）を乗り切って、アップストリームプロバイダーに確実にデータを送信できるようになります。\nキューデータをディスクに書く時の注意事項は？ ディスクの性能により、データスループットの性能に影響を与える可能性があります\n参照 https://community.splunk.com/t5/Community-Blog/Data-Persistence-in-the-OpenTelemetry-Collector/ba-p/624583 https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/storage/filestorage 設定を確認しましょう さて、エクステンションについて説明したので、設定の変更箇所を確認していきましょう。\nCheck-in設定ファイルを確認してください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] さて、エクステンションについて復習したところで、ワークショップのデータパイプラインの部分に飛び込んでみましょう。パイプラインとは、コレクター内でデータがたどる経路を定義するもので、レシーバーから始まり、追加の処理や変更をし、最終的にエクスポーターを経由してコレクターを出ます。\nOpenTelemetry Collector のデータパイプラインは、レシーバー、プロセッサー、エクスポーターで構成されています。まずは、レシーバーから見ていきましょう。",
    "description": "zPages エクステンション zPages は、外部エクスポータに代わるプロセス内部の機能です。有効化すると、バックグラウンドでトレースとメトリクス情報を収集し、集計し、どのようなデータを扱ったかの Web ページを公開します。zpages は、コレクターが期待どおりに動作していることを確認するための非常に便利な診断機能です。\n​ ServiceZ PipelineZ ExtensionZ ServiceZ は、コレクターサービスの概要と、pipelinez、extensionz、featurez zPages へのクイックアクセスを提供します。このページでは、ビルドとランタイムの情報も提供します。\nURL: http://localhost:55679/debug/servicez (localhost は、適切なホスト名に切り替えてください)\nPipelineZ は、コレクターで実行中のパイプラインに関する情報を提供します。タイプ、データが変更されているか、各パイプラインで使用されているレシーバー、プロセッサー、エクスポーターの情報を見ることができます。\nURL: http://localhost:55679/debug/pipelinez (localhost は、適切なホスト名に切り替えてください)\nExtensionZ は、コレクターで有効化されたエクステンションを確認できます。\nExample URL: http://localhost:55679/debug/extensionz (localhost は、適切なホスト名に切り替えてください)",
    "tags": [],
    "title": "OpenTelemetry Collector エクステンション",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/2-extensions/3-zpages/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "前提条件 アプリケーションをデプロイする前に、インスタンスに.NET 8 SDK をインストールする必要があります。\n​ Script Example Output sudo apt-get update \u0026\u0026 \\ sudo apt-get install -y dotnet-sdk-8.0 Hit:1 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy InRelease Hit:2 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease Hit:3 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-backports InRelease Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease Ign:5 https://splunk.jfrog.io/splunk/otel-collector-deb release InRelease Hit:6 https://splunk.jfrog.io/splunk/otel-collector-deb release Release Reading package lists... Done Reading package lists... Done Building dependency tree... Done Reading state information... Done The following additional packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 The following NEW packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-sdk-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 0 upgraded, 13 newly installed, 0 to remove and 0 not upgraded. Need to get 138 MB of archives. After this operation, 495 MB of additional disk space will be used. etc. 詳細については、Ubuntu に.NET SDK または.NET Runtime をインストールする を参照してください。\n.NET アプリケーションの確認 ターミナルで、アプリケーションディレクトリに移動します：\ncd ~/workshop/docker-k8s-otel/helloworld このワークショップでは、シンプルな「Hello World」.NET アプリケーションを使用します。主要なロジックは HelloWorldController.cs ファイルにあります：\npublic class HelloWorldController : ControllerBase { private ILogger\u003cHelloWorldController\u003e logger; public HelloWorldController(ILogger\u003cHelloWorldController\u003e logger) { this.logger = logger; } [HttpGet(\"/hello/{name?}\")] public string Hello(string name) { if (string.IsNullOrEmpty(name)) { logger.LogInformation(\"/hello endpoint invoked anonymously\"); return \"Hello, World!\"; } else { logger.LogInformation(\"/hello endpoint invoked by {name}\", name); return String.Format(\"Hello, {0}!\", name); } } } .NET アプリケーションのビルドと実行 以下のコマンドを使用してアプリケーションをビルドできます：\n​ Script Example Output dotnet build MSBuild version 17.8.5+b5265ef37 for .NET Determining projects to restore... All projects are up-to-date for restore. helloworld -\u003e /home/splunk/workshop/docker-k8s-otel/helloworld/bin/Debug/net8.0/helloworld.dll Build succeeded. 0 Warning(s) 0 Error(s) Time Elapsed 00:00:02.04 ビルドが成功したら、次のように実行できます：\n​ Script Example Output dotnet run Building... info: Microsoft.Hosting.Lifetime[14] Now listening on: http://localhost:8080 info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down. info: Microsoft.Hosting.Lifetime[0] Hosting environment: Development info: Microsoft.Hosting.Lifetime[0] Content root path: /home/splunk/workshop/docker-k8s-otel/helloworld 実行したら、Ubuntu インスタンスへの SSH 接続を 2 つ目のターミナルで開き、curl を使用してアプリケーションにアクセスします：\n​ Script Example Output curl http://localhost:8080/hello Hello, World! 名前を渡すこともできます：\n​ Script Example Output curl http://localhost:8080/hello/Tom Hello, Tom! 次のステップに進む前に、Ctrl + C を押して Helloworld アプリを終了してください。\n次のステップ アプリケーションを OpenTelemetry で計装するために使用できる 3 つの方法は何でしょうか？\nオプションの詳細については、Splunk Observability Cloud 用の.NET アプリケーションの計装 を参照してください。",
    "description": "前提条件 アプリケーションをデプロイする前に、インスタンスに.NET 8 SDK をインストールする必要があります。\n​ Script Example Output sudo apt-get update \u0026\u0026 \\ sudo apt-get install -y dotnet-sdk-8.0 Hit:1 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy InRelease Hit:2 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-updates InRelease Hit:3 http://us-west-1.ec2.archive.ubuntu.com/ubuntu jammy-backports InRelease Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease Ign:5 https://splunk.jfrog.io/splunk/otel-collector-deb release InRelease Hit:6 https://splunk.jfrog.io/splunk/otel-collector-deb release Release Reading package lists... Done Reading package lists... Done Building dependency tree... Done Reading state information... Done The following additional packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 The following NEW packages will be installed: aspnetcore-runtime-8.0 aspnetcore-targeting-pack-8.0 dotnet-apphost-pack-8.0 dotnet-host-8.0 dotnet-hostfxr-8.0 dotnet-runtime-8.0 dotnet-sdk-8.0 dotnet-targeting-pack-8.0 dotnet-templates-8.0 liblttng-ust-common1 liblttng-ust-ctl5 liblttng-ust1 netstandard-targeting-pack-2.1-8.0 0 upgraded, 13 newly installed, 0 to remove and 0 not upgraded. Need to get 138 MB of archives. After this operation, 495 MB of additional disk space will be used. etc. 詳細については、Ubuntu に.NET SDK または.NET Runtime をインストールする を参照してください。",
    "tags": [],
    "title": ".NETアプリケーションのデプロイ",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/3-deploy-dotnet-app/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "演習 paymentserviceのタグを表示するには、paymentserviceをクリックし、右側の機能ペインのTag Spotlightをクリックします（画面の解像度によっては下にスクロールする必要があるかもしれません）。 Tag Spotlightに入ったら、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。 Tag Spotlightのビューは、チャートとカードの両方で設定可能です。デフォルトではリクエストとエラーに設定されています。\nまた、カードに表示されるタグメトリクスを設定することも可能です。以下の任意の組み合わせを選択できます：\nRequests Errors Root Cause errors P50 Latency P90 Latency P99 Latency 改めて、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。\n演習 ​ 質問 回答 どのカードが問題を特定するタグを明らかにしていますか？\n「Version」カードです。v350.10に対するリクエスト数がエラー数と一致しています（つまり 100%）\npaymentserviceの問題を引き起こしているバージョンを特定したので、エラーについてさらに詳しい情報が見つかるか確認してみましょう。ページ上部の ← Tag Spotlight をクリックして、サービスマップに戻ります。",
    "description": "演習 paymentserviceのタグを表示するには、paymentserviceをクリックし、右側の機能ペインのTag Spotlightをクリックします（画面の解像度によっては下にスクロールする必要があるかもしれません）。 Tag Spotlightに入ったら、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。 Tag Spotlightのビューは、チャートとカードの両方で設定可能です。デフォルトではリクエストとエラーに設定されています。\nまた、カードに表示されるタグメトリクスを設定することも可能です。以下の任意の組み合わせを選択できます：\nRequests Errors Root Cause errors P50 Latency P90 Latency P99 Latency 改めて、フィルターアイコンからShow tags with no valuesチェックボックスがオフになっていることを確認してください。\n演習 ​ 質問 回答 どのカードが問題を特定するタグを明らかにしていますか？",
    "tags": [],
    "title": "3. APM Tag Spotlight",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/6-apm/3-apm-tag-spotlight/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk APM は、モノリスとマイクロサービス全体で問題をより迅速に解決するために、すべてのサービスとその依存関係のNoSample（サンプリングなし）エンドツーエンドの可視性を提供します。チームは新しいデプロイメントからの問題をすぐに検出し、問題の原因の範囲を特定して分離することで自信を持ってトラブルシューティングを行い、バックエンドサービスがエンドユーザーとビジネスワークフローにどのように影響するかを理解することでサービスのパフォーマンスを最適化できます。\nリアルタイム監視とアラート： Splunk は標準でサービスダッシュボードを提供し、急激な変化があった場合に RED メトリクス（レート、エラー、期間）を自動的に検出してアラートを発します。 動的テレメトリマップ： 現代の本番環境でのサービスパフォーマンスをリアルタイムで簡単に視覚化できます。インフラストラクチャ、アプリケーション、エンドユーザー、およびすべての依存関係からのサービスパフォーマンスのエンドツーエンドの可視性により、新しい問題の範囲をすばやく特定し、より効果的にトラブルシューティングを行うことができます。\nインテリジェントなタグ付けと分析： ビジネス、インフラストラクチャ、アプリケーションからのすべてのタグを 1 か所で表示し、レイテンシーやエラーの新しい傾向を特定のタグ値と簡単に比較できます。\nAI によるトラブルシューティングが最も影響の大きい問題を特定： 個々のダッシュボードを手動で掘り下げる代わりに、より効率的に問題を分離します。サービスと顧客に最も影響を与える異常とエラーの原因を自動的に特定します。\n完全な分散トレースがすべてのトランザクションを分析： クラウドネイティブ環境の問題をより効果的に特定します。Splunk 分散トレースは、バックエンドとフロントエンドからのすべてのトランザクションをインフラストラクチャ、ビジネスワークフロー、アプリケーションのコンテキストで視覚化し相関付けます。\nフルスタック相関： Splunk Observability 内では、APM がトレース、メトリクス、ログ、プロファイリングをリンクし、スタック全体のすべてのコンポーネントとその依存関係のパフォーマンスを簡単に理解できるようにします。\nデータベースクエリパフォーマンスの監視： SQL および NoSQL データベースからの遅いクエリと高実行クエリがサービス、エンドポイント、ビジネスワークフローにどのように影響するかを簡単に特定できます — 計装は不要です。",
    "description": "Splunk APM は、モノリスとマイクロサービス全体で問題をより迅速に解決するために、すべてのサービスとその依存関係のNoSample（サンプリングなし）エンドツーエンドの可視性を提供します。チームは新しいデプロイメントからの問題をすぐに検出し、問題の原因の範囲を特定して分離することで自信を持ってトラブルシューティングを行い、バックエンドサービスがエンドユーザーとビジネスワークフローにどのように影響するかを理解することでサービスのパフォーマンスを最適化できます。\nリアルタイム監視とアラート： Splunk は標準でサービスダッシュボードを提供し、急激な変化があった場合に RED メトリクス（レート、エラー、期間）を自動的に検出してアラートを発します。 動的テレメトリマップ： 現代の本番環境でのサービスパフォーマンスをリアルタイムで簡単に視覚化できます。インフラストラクチャ、アプリケーション、エンドユーザー、およびすべての依存関係からのサービスパフォーマンスのエンドツーエンドの可視性により、新しい問題の範囲をすばやく特定し、より効果的にトラブルシューティングを行うことができます。\nインテリジェントなタグ付けと分析： ビジネス、インフラストラクチャ、アプリケーションからのすべてのタグを 1 か所で表示し、レイテンシーやエラーの新しい傾向を特定のタグ値と簡単に比較できます。\nAI によるトラブルシューティングが最も影響の大きい問題を特定： 個々のダッシュボードを手動で掘り下げる代わりに、より効率的に問題を分離します。サービスと顧客に最も影響を与える異常とエラーの原因を自動的に特定します。\n完全な分散トレースがすべてのトランザクションを分析： クラウドネイティブ環境の問題をより効果的に特定します。Splunk 分散トレースは、バックエンドとフロントエンドからのすべてのトランザクションをインフラストラクチャ、ビジネスワークフロー、アプリケーションのコンテキストで視覚化し相関付けます。\nフルスタック相関： Splunk Observability 内では、APM がトレース、メトリクス、ログ、プロファイリングをリンクし、スタック全体のすべてのコンポーネントとその依存関係のパフォーマンスを簡単に理解できるようにします。\nデータベースクエリパフォーマンスの監視： SQL および NoSQL データベースからの遅いクエリと高実行クエリがサービス、エンドポイント、ビジネスワークフローにどのように影響するかを簡単に特定できます — 計装は不要です。",
    "tags": [],
    "title": "Application Performance Monitoring概要",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/3-apm-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "Lambda 関数は相当量のトレースデータを生成しているはずで、それを確認する必要があります。Lambda 関数のリソース定義で構成された環境変数と OpenTelemetry Lambda layer の組み合わせにより、Splunk APM で関数とトレースを表示する準備が整いました。\nSplunk APM 概要で環境名を確認する まず、Splunk APM が受信しているトレースデータからEnvironmentを認識していることを確認しましょう。これはmain.tfの Lambda 関数定義で設定したOTEL_RESOURCE_ATTRIBUTES変数の一部として設定したdeployment.nameです。これは先ほど実行したterraform applyコマンドの出力の 1 つでもありました。\nSplunk Observability Cloud で：\n左側のメインメニューからAPMボタンをクリックします。これにより Splunk APM 概要に移動します。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 環境はPREFIX-lambda-shop形式になっているはずです。PREFIXは前提条件セクションで設定した環境変数から取得されます メモ トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください\n環境のサービスマップを表示する Environment ドロップダウンから環境名を選択したら、Lambda 関数のサービスマップを確認できます。\nAPM 概要ページの右側にあるService Mapボタンをクリックします。これによりサービスマップビューに移動します。 producer-lambda関数とそのレコードを配置するために Kinesis ストリームに対して行っている呼び出しが表示されるはずです。\nワークショップの質問 あなたのconsumer-lambda関数はどうなっていますか？\nLambda 関数からのトレースを調査する Tracesボタンをクリックしてトレースアナライザーを表示します。 このページでは、producer-lambda関数の OpenTelemetry Lambda layer から取り込まれたトレースを確認できます。\nリストからハイパーリンクされたTrace IDをクリックして、調査するトレースを選択します。 producer-lambda関数が Kinesis ストリームにレコードを配置しているのが確認できます。しかし、consumer-lambda関数のアクションが見当たりません！\nこれはトレースコンテキストが伝播されていないためです。このワークショップの時点では、Kinesis サービスはトレースコンテキスト伝播をすぐには対応していません。分散トレースは Kinesis サービスで止まっており、そのコンテキストがストリームを通じて自動的に伝播されないため、それ以上先を見ることができません。\n少なくとも、今はまだ…\n次のセクションでこの問題にどう対処するか見ていきましょう。しかしその前に、後片付けをしましょう！\nクリーンアップ この自動計装演習の一部としてデプロイしたリソースはクリーンアップする必要があります。同様に、producer-lambdaエンドポイントに対してトラフィックを生成していたスクリプトも、まだ実行中であれば停止する必要があります。以下の手順に従ってクリーンアップを行ってください。\nsend_messageの停止 send_message.pyスクリプトがまだ実行中の場合は、次のコマンドで停止します：\nfg これによりバックグラウンドプロセスがフォアグラウンドに移動します。 次に[CONTROL-C]を押してプロセスを終了できます。 全ての AWS リソースを破棄する Terraform は個々のリソースの状態をデプロイメントとして管理するのに優れています。定義に変更があっても、デプロイされたリソースを更新することもできます。しかし、一からやり直すために、リソースを破棄し、このワークショップの手動計装部分の一部として再デプロイします。\n以下の手順に従ってリソースを破棄してください：\nautoディレクトリにいることを確認します：\npwd 期待される出力は ~/o11y-lambda-workshop/auto です autoディレクトリにいない場合は、以下のコマンドを実行します：\ncd ~/o11y-lambda-workshop/auto 先ほどデプロイした Lambda 関数とその他の AWS リソースを破棄します：\nterraform destroy Enter a value:プロンプトが表示されたらyesと応答します これによりリソースが破棄され、クリーンな環境が残ります このプロセスにより、私たちの活動の結果として作成されたファイルとディレクトリは残ります。それらについては心配する必要はありません。",
    "description": "Lambda 関数は相当量のトレースデータを生成しているはずで、それを確認する必要があります。Lambda 関数のリソース定義で構成された環境変数と OpenTelemetry Lambda layer の組み合わせにより、Splunk APM で関数とトレースを表示する準備が整いました。\nSplunk APM 概要で環境名を確認する まず、Splunk APM が受信しているトレースデータからEnvironmentを認識していることを確認しましょう。これはmain.tfの Lambda 関数定義で設定したOTEL_RESOURCE_ATTRIBUTES変数の一部として設定したdeployment.nameです。これは先ほど実行したterraform applyコマンドの出力の 1 つでもありました。\nSplunk Observability Cloud で：\n左側のメインメニューからAPMボタンをクリックします。これにより Splunk APM 概要に移動します。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 環境はPREFIX-lambda-shop形式になっているはずです。PREFIXは前提条件セクションで設定した環境変数から取得されます メモ トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください\n環境のサービスマップを表示する Environment ドロップダウンから環境名を選択したら、Lambda 関数のサービスマップを確認できます。\nAPM 概要ページの右側にあるService Mapボタンをクリックします。これによりサービスマップビューに移動します。",
    "tags": [],
    "title": "Splunk APM、Lambda関数およびトレース",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/3-lambdas-in-splunk/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "今、以下のような表示が見えているはずです。\n演習 ウォーターフォールでPOST checkoutで始まるエントリを見つけます。 その前にある \u003e ボタンをクリックして、メタデータセクションを展開します。収集されたメタデータを観察し、Server-Timingヘッダーに注目してください。このヘッダーにより、テスト実行をバックエンドトレースに関連付けることができます。 ウォーターフォールのPOST checkout行にある青い APMリンクをクリックします。 演習 paymentserviceに対して 1 つ以上のエラーが表示されていることを確認します（1）。 同じエラーであることを確認するには、ログの関連コンテンツをクリックします（2）。 前回の演習を繰り返して、エラーのみにフィルタリングします。 エラーログを表示して、無効なトークンによる支払い失敗を確認します。",
    "description": "今、以下のような表示が見えているはずです。\n演習 ウォーターフォールでPOST checkoutで始まるエントリを見つけます。 その前にある \u003e ボタンをクリックして、メタデータセクションを展開します。収集されたメタデータを観察し、Server-Timingヘッダーに注目してください。このヘッダーにより、テスト実行をバックエンドトレースに関連付けることができます。 ウォーターフォールのPOST checkout行にある青い APMリンクをクリックします。 演習 paymentserviceに対して 1 つ以上のエラーが表示されていることを確認します（1）。 同じエラーであることを確認するには、ログの関連コンテンツをクリックします（2）。 前回の演習を繰り返して、エラーのみにフィルタリングします。 エラーログを表示して、無効なトークンによる支払い失敗を確認します。",
    "tags": [],
    "title": "3. SyntheticsからAPMへ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/8-synthetics/3-synthetics-to-apm/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "Splunk Observability Cloud の様々なコンポーネントについて簡単な説明から始めます。これは UI に慣れてもらうことを目的としています。\nSplunk Observability Cloud へのサインイン Real User Monitoring (RUM) Application Performance Monitoring (APM) Log Observer Synthetics Infrastructure Monitoring（IM） ヒント このワークショップを進める最も簡単な方法は以下を使用することです:\nこのページの右上にある左右の矢印（\u003c | \u003e） キーボードの左（◀️）と右（▶️）のカーソルキー",
    "description": "Splunk Observability Cloud UIのクイックツアー",
    "tags": [],
    "title": "UI - クイックツアー 🚌",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "セッション セッションは、ユーザーがアプリケーションと対話する際に実行するアクションに対応するトレースの集まりです。デフォルトでは、セッションはセッションでキャプチャされた最後のイベントから 15 分経過するまで続きます。最大セッション時間は 4 時間です。\n演習 User Sessionテーブルで、最も長いDuration（20 秒以上）の上位のSession IDをクリックすると、RUM セッションビューに移動します。 演習 RUM セッションリプレイ Replayボタンをクリックします。RUM セッションリプレイでは、ユーザーセッションを再生して確認することができます。これはユーザーが体験した内容を正確に確認するための優れた方法です。 ボタンをクリックしてリプレイを開始します。 RUM セッションリプレイでは情報を編集することができます。デフォルトではテキストが編集されます。画像も編集することができます（このワークショップ例では実施済み）。これは、機密情報が含まれるセッションを再生する場合に役立ちます。また、再生速度を変更したり、再生を一時停止したりすることもできます。\nヒント セッションを再生する際、マウスの動きがキャプチャされていることに注目してください。これは、ユーザーがどこに注意を向けているかを確認するのに役立ちます。",
    "description": "セッション セッションは、ユーザーがアプリケーションと対話する際に実行するアクションに対応するトレースの集まりです。デフォルトでは、セッションはセッションでキャプチャされた最後のイベントから 15 分経過するまで続きます。最大セッション時間は 4 時間です。\n演習 User Sessionテーブルで、最も長いDuration（20 秒以上）の上位のSession IDをクリックすると、RUM セッションビューに移動します。 演習 RUM セッションリプレイ Replayボタンをクリックします。RUM セッションリプレイでは、ユーザーセッションを再生して確認することができます。これはユーザーが体験した内容を正確に確認するための優れた方法です。 ボタンをクリックしてリプレイを開始します。 RUM セッションリプレイでは情報を編集することができます。デフォルトではテキストが編集されます。画像も編集することができます（このワークショップ例では実施済み）。これは、機密情報が含まれるセッションを再生する場合に役立ちます。また、再生速度を変更したり、再生を一時停止したりすることもできます。\nヒント セッションを再生する際、マウスの動きがキャプチャされていることに注目してください。これは、ユーザーがどこに注意を向けているかを確認するのに役立ちます。",
    "tags": [],
    "title": "3. セッションリプレイ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/5-rum/3-session-replay/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 3. レシーバー",
    "content": "その他のレシーバー デフォルトの設定には、他のレシーバーがあることに気づくはずです。 otlp、opencensus、jaeger、zipkin が定義されています。これらは他のソースからテレメトリーデータを受信するために使われます。このワークショップでは、これらのレシーバーについては取り上げませんので、そのままにしておきましょう。\nNinja: レシーバーを動的に生成する dockerコンテナ、kubernetesポッド、sshセッションのような短時間のタスクを観測するために、receiver creator レシーバーと observer エクステンションを使って、対象のサービスが起動するタイミングで新しいレシーバーを作成することができます。\n何が必要なの？ receiver creator とそれに関連する observer エクステンションの使用を開始するには、collector build manifest に追加する必要があります。\n詳細は installation を参照してください。\n注意事項はある？ 短命なタスクの中には、username や password のような追加設定を必要とするものがあります。それらの値は環境変数 を参照したり、 ${file:./path/to/database/password} のようなスキーム展開構文を使うこともできます。\n組織における機密情報の取り扱い規定に従って、どのような方法を取るかを検討してください。\nNinja ゾーン この Ninja ゾーンに必要なものは2つだけです:\nbuilder manifestに、 receiver creator レシーバーと observer エクステンションを追加する 検出されたエンドポイントを検出するように、設定を作成する 次のようにすると、設定をテンプレート化できます:\nreceiver_creator: watch_observers: [host_observer] receivers: redis: rule: type == \"port\" \u0026\u0026 port == 6379 config: password: ${env:HOST_REDIS_PASSWORD} 他の例は receiver creator’s examples にあります。\n設定を確認しましょう これで、レシーバーをカバーできました。ここで、設定のの変更内容をチェックしてみましょう。\nCheck-in設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus/internal] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages] これで、レシーバーを通して OpenTelemetry Collector にデータがどのように取り込まれるかを確認しました。次に、コレクターが受信したデータをどのように処理するかを見てみましょう。\n警告 ここではコレクターを再起動しないでください！ /etc/otelcol-contrib/config.yaml の変更はまだ完了していません。",
    "description": "その他のレシーバー デフォルトの設定には、他のレシーバーがあることに気づくはずです。 otlp、opencensus、jaeger、zipkin が定義されています。これらは他のソースからテレメトリーデータを受信するために使われます。このワークショップでは、これらのレシーバーについては取り上げませんので、そのままにしておきましょう。\nNinja: レシーバーを動的に生成する dockerコンテナ、kubernetesポッド、sshセッションのような短時間のタスクを観測するために、receiver creator レシーバーと observer エクステンションを使って、対象のサービスが起動するタイミングで新しいレシーバーを作成することができます。\n何が必要なの？ receiver creator とそれに関連する observer エクステンションの使用を開始するには、collector build manifest に追加する必要があります。\n詳細は installation を参照してください。\n注意事項はある？ 短命なタスクの中には、username や password のような追加設定を必要とするものがあります。それらの値は環境変数 を参照したり、 ${file:./path/to/database/password} のようなスキーム展開構文を使うこともできます。\n組織における機密情報の取り扱い規定に従って、どのような方法を取るかを検討してください。\nNinja ゾーン この Ninja ゾーンに必要なものは2つだけです:\nbuilder manifestに、 receiver creator レシーバーと observer エクステンションを追加する 検出されたエンドポイントを検出するように、設定を作成する 次のようにすると、設定をテンプレート化できます:\nreceiver_creator: watch_observers: [host_observer] receivers: redis: rule: type == \"port\" \u0026\u0026 port == 6379 config: password: ${env:HOST_REDIS_PASSWORD} 他の例は receiver creator’s examples にあります。",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/3-receivers/3-other-receivers/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. 依存ライブラリを追加する 前のセクション足したような、プロセス全体に渡る属性は便利なのですが、ときにはさらに、リクエストの内容に応じた状況を知りたくなるかもしれません。 心配ありません、OpenTelemetryのAPIを通じてそれらを計装し、データを送り、Splunk Observabilityで分析できるようになります。\n最初に、JavaアプリケーションがOpenTelemetryのAPIを使えるように、ライブラリの依存を追加していきます。 もちろん、vimなどのお好みのエディタをお使い頂いても大丈夫です！\nアプリケーションが起動中であれば、一旦停止しましょう。ターミナルで Ctrl-c を押すと、停止することができます。\nnano pom.xml そして、\u003cdependencies\u003e セクションの中（33行目）に↓を追加してください。 ファイル修正後、 ctrl-O のあとに Enter で、ファイルを保存します。次に ctrl-X で、nanoを終了します。\n\u003cdependency\u003e \u003cgroupId\u003eio.opentelemetry\u003c/groupId\u003e \u003cartifactId\u003eopentelemetry-api\u003c/artifactId\u003e \u003c/dependency\u003e 念のため、コンパイルできるか確かめてみましょう:\n./mvnw package -Dmaven.test.skip=true Tips: nanoの使い方と壊れたファイルの直し方 nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nAlt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 もしファイルをどうしようもなく壊してしまって元に戻したい場合は、gitを使って次のようにするとよいでしょう。\ngit checkout pom.xml これで、JavaのアプリケーションでOpenTelemetryのAPIが使う準備ができました。\n2. Javaのコードにマニュアル計装を追加する では、アプリケーションコードをちょっと変更して、リクエストのコンテキストのデータをスパン属性に追加してみましょう。\nここでは Pet Clinic アプリケーションの中で Find Owners が使われたときに、どのような検索文字列が指定されたのかを調査できるようにしていきます。 検索条件によってパフォーマンスが劣化してしまうケース、よくありませんか？そんなときは OwnerController に計装を追加していきましょう！\nnano src/main/java/org/springframework/samples/petclinic/owner/OwnerController.java このコードを 変更するのは2箇所 です。\nまず、import jakarta.validation.Valid; の下、37行目付近に↓を足します:\nimport io.opentelemetry.api.trace.Span; 次に、 // find owners by last name のコメントがある箇所（おそらく95行目付近にあります）の下に、次のコードを足していきましょう:\nSpan span = Span.current(); span.setAttribute(\"lastName\", owner.getLastName()); このコードで、Last Nameとして指定された検索条件が、スパン属性 lastName としてSplunk Observabilityに伝えるようになりました。\nアプリケーションをコンパイルし直ししますが、Javaコードを多少汚してしまったかもしれません。 spring-javaformat:apply を指定しながらコンパイルしてみましょう。\n./mvnw spring-javaformat:apply package -Dmaven.test.skip=true アプリケーションを起動します。せっかくなので、バージョンを一つあげて version=0.315 としましょう。\njava -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.315 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスして、オーナー検索をいくつか試してましょう。そしてSplunk APM UIからExploreを開き、アプリケーションのトレースを見ていきます。\nさらなる情報: マニュアル計装について マニュアル計装で何ができるか、他の言語でのやり方などは、OpenTelemetryの公式ウェブサイトにある Instrumentation ページをご覧ください。\n検証が完了したら、ターミナルで Ctrl-c を押すと、アプリケーションを停止することができます。\n次のセクションでは、RUMを使ってブラウザ上のパフォーマンスデータを収集してみましょう。",
    "description": "1. 依存ライブラリを追加する 前のセクション足したような、プロセス全体に渡る属性は便利なのですが、ときにはさらに、リクエストの内容に応じた状況を知りたくなるかもしれません。 心配ありません、OpenTelemetryのAPIを通じてそれらを計装し、データを送り、Splunk Observabilityで分析できるようになります。\n最初に、JavaアプリケーションがOpenTelemetryのAPIを使えるように、ライブラリの依存を追加していきます。 もちろん、vimなどのお好みのエディタをお使い頂いても大丈夫です！\nアプリケーションが起動中であれば、一旦停止しましょう。ターミナルで Ctrl-c を押すと、停止することができます。\nnano pom.xml そして、\u003cdependencies\u003e セクションの中（33行目）に↓を追加してください。 ファイル修正後、 ctrl-O のあとに Enter で、ファイルを保存します。次に ctrl-X で、nanoを終了します。\n\u003cdependency\u003e \u003cgroupId\u003eio.opentelemetry\u003c/groupId\u003e \u003cartifactId\u003eopentelemetry-api\u003c/artifactId\u003e \u003c/dependency\u003e 念のため、コンパイルできるか確かめてみましょう:\n./mvnw package -Dmaven.test.skip=true Tips: nanoの使い方と壊れたファイルの直し方 nanoはLinux環境でよく使われる、シンプルなエディタの一つです。\nAlt-U で、アンドゥができます。Macの場合は Esc キーを押したあとに U を押してください！ ctrl-_ のあとに数字を入力すると、指定した行数にジャンプします。 ctrl-O のあとに Enter で、ファイルを保存します。 ctrl-X で、nanoを終了します。 もしファイルをどうしようもなく壊してしまって元に戻したい場合は、gitを使って次のようにするとよいでしょう。\ngit checkout pom.xml これで、JavaのアプリケーションでOpenTelemetryのAPIが使う準備ができました。\n2. Javaのコードにマニュアル計装を追加する では、アプリケーションコードをちょっと変更して、リクエストのコンテキストのデータをスパン属性に追加してみましょう。\nここでは Pet Clinic アプリケーションの中で Find Owners が使われたときに、どのような検索文字列が指定されたのかを調査できるようにしていきます。 検索条件によってパフォーマンスが劣化してしまうケース、よくありませんか？そんなときは OwnerController に計装を追加していきましょう！",
    "tags": [],
    "title": "マニュアル計装",
    "uri": "/observability-workshop/v5.99/ja/other/pet-clinic/docs/manual_instrumentation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "レシーバーワークショップへようこそ！OpenTelemetry Collectorのデータパイプラインのスタート地点です。さあ、始めましょう。\nレシーバーはデータをCollectorに取り込む方法で、プッシュベースとプルベースのものがあります。レシーバーは1つ以上のデータソースをサポートします。一般的に、レシーバーは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサやエクスポータにデータを渡します。\nプッシュまたはプルベースのレシーバは、データをCollectorに取り込む方法です。レシーバは 1 つまたは複数のデータソースをサポートします。通常、レシーバは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサーや エクスポーターにデータを渡します。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style M fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "レシーバーワークショップへようこそ！OpenTelemetry Collectorのデータパイプラインのスタート地点です。さあ、始めましょう。\nレシーバーはデータをCollectorに取り込む方法で、プッシュベースとプルベースのものがあります。レシーバーは1つ以上のデータソースをサポートします。一般的に、レシーバーは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサやエクスポータにデータを渡します。\nプッシュまたはプルベースのレシーバは、データをCollectorに取り込む方法です。レシーバは 1 つまたは複数のデータソースをサポートします。通常、レシーバは指定されたフォーマットでデータを受け入れ、内部フォーマットに変換し、該当するパイプラインで定義されたプロセッサーや エクスポーターにデータを渡します。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style M fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector レシーバー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/3-receivers/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "Log Observer で特定のビューを持った後、そのビューをダッシュボードで使用できると、将来的に問題の検出や解決にかかる時間を短縮するのに非常に役立ちます。ワークショップの一環として、これらのチャートを使用する例示的なカスタムダッシュボードを作成します。\nログタイムラインチャートの作成を見ていきましょう。ログタイムラインチャートは、時間経過に伴うログメッセージを視覚化するために使用されます。ログメッセージの頻度を確認し、パターンを特定するための優れた方法です。また、環境全体でのログメッセージの分布を確認するための素晴らしい方法でもあります。これらのチャートはカスタムダッシュボードに保存できます。\n演習 まず、関心のある列のみに情報量を減らします：\nログテーブルの上にあるテーブル設定アイコンをクリックしてTable Settingを開き、_rawのチェックを外し、次のフィールドが選択されていることを確認します：k8s.pod.name、message、version。 時間選択から固定時間を削除し、過去 15 分に設定します。 すべてのトレースでこれを機能させるには、フィルターからtrace_idを削除し、フィールドsf_service=paymentserviceとsf_environment=[WORKSHOPNAME]を追加します。 Saveをクリックし、Save to Dashboardを選択します。 表示されるチャート作成ダイアログボックスで、Chart nameとしてログタイムラインを使用します。 Select Dashboardをクリックし、ダッシュボード選択ダイアログボックスでNew Dashboardをクリックします。 New Dashboardダイアログボックスに、新しいダッシュボードの名前を入力します（説明を入力する必要はありません）。次の形式を使用します：イニシャル - サービスヘルスダッシュボード、そしてSaveをクリックします。 リスト内で新しいダッシュボードが強調表示されていることを確認し（1）、OK（2）をクリックします。 Chart TypeとしてLog timelineが選択されていることを確認します。 Saveボタンをクリックします（この時点ではSave and go to dashboardをクリックしないでください）。 次に、ログビューチャートを作成します。",
    "description": "Log Observer で特定のビューを持った後、そのビューをダッシュボードで使用できると、将来的に問題の検出や解決にかかる時間を短縮するのに非常に役立ちます。ワークショップの一環として、これらのチャートを使用する例示的なカスタムダッシュボードを作成します。\nログタイムラインチャートの作成を見ていきましょう。ログタイムラインチャートは、時間経過に伴うログメッセージを視覚化するために使用されます。ログメッセージの頻度を確認し、パターンを特定するための優れた方法です。また、環境全体でのログメッセージの分布を確認するための素晴らしい方法でもあります。これらのチャートはカスタムダッシュボードに保存できます。\n演習 まず、関心のある列のみに情報量を減らします：\nログテーブルの上にあるテーブル設定アイコンをクリックしてTable Settingを開き、_rawのチェックを外し、次のフィールドが選択されていることを確認します：k8s.pod.name、message、version。 時間選択から固定時間を削除し、過去 15 分に設定します。 すべてのトレースでこれを機能させるには、フィルターからtrace_idを削除し、フィールドsf_service=paymentserviceとsf_environment=[WORKSHOPNAME]を追加します。 Saveをクリックし、Save to Dashboardを選択します。 表示されるチャート作成ダイアログボックスで、Chart nameとしてログタイムラインを使用します。 Select Dashboardをクリックし、ダッシュボード選択ダイアログボックスでNew Dashboardをクリックします。 New Dashboardダイアログボックスに、新しいダッシュボードの名前を入力します（説明を入力する必要はありません）。次の形式を使用します：イニシャル - サービスヘルスダッシュボード、そしてSaveをクリックします。 リスト内で新しいダッシュボードが強調表示されていることを確認し（1）、OK（2）をクリックします。 Chart TypeとしてLog timelineが選択されていることを確認します。 Saveボタンをクリックします（この時点ではSave and go to dashboardをクリックしないでください）。 次に、ログビューチャートを作成します。",
    "tags": [],
    "title": "3. ログタイムラインチャート",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/7-log-observer/3-log-timeline-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 4. プロセッサー",
    "content": "Attributes プロセッサー attribute プロセッサーを使うと、スパン、ログ、またはメトリクスの属性を変更できます。また、このプロセッサーは、入力データをフィルタリングし、マッチさせ、指定されたアクションに含めるべきか、除外すべきかを決定する機能もサポートしています。\nアクションを設定するには、指定された順序で実行されるアクションのリストを記述します。サポートされるアクションは以下の通りです：\ninsert: その属性がない場合に、新しい属性値を挿入します。 update: その属性がある場合に、その属性値を更新します。 upsert: insert または update を実行します。属性がない場合には新しい属性値を挿入し、属性がある場合にはその値を更新します。 delete: 入力データから属性値を削除します。 hash: 属性値をハッシュ化 (SHA1) します。 extract: 入力キーの値を正規表現ルールを使って抽出し、対象キーの値を更新します。対象キーがすでに存在する場合は、その値は上書きされます。 次の例のように、attribute プロセッサーを使って、キーは participant.name、あたいはあなたの名前（例: marge_simpson）という新しい属性を追加してみましょう。\n警告 INSERT_YOUR_NAME_HERE の箇所は、自分の名前に置き換えてください。また、自分の名前に スペースを使わない ようにしてください。\nこのワークショップの後半では、この属性を使用して Splunk Observability Cloud でメトリクスをフィルタリングします。\n​ Attributes Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" Ninja: コネクターを使って内部への洞察を加速する 最近追加されたものの一つとして、connector というコンセプトがあります。これを使うと、あるパイプラインの出力を別のパイプラインの入力に結合できるようになります。\n利用シーンとして、送信するデータポイントの量、エラーステータスを含むログの数をメトリクスをとして出力するサービスがあります。他には、あるデプロイ環境から送信されるデータ量のメトリクスを生成するサービスがあります。このような場合に、count コネクターですぐに対応できます。\nプロセッサーではなくコネクターなのはなぜ？ プロセッサーは、処理したデータを次に渡すものであり、追加の情報を出力することはできません。コネクターはレシーバーで受け取ったデータを出力せずに、私たちが求める洞察を作り出す機会を提供します。\nたとえば、count コネクターを使うと、環境変数 deployment を持たないログ、メトリクス、トレースの数をカウントすることができます。\nまた、非常にシンプルな例として、deployment 別にデータ使用量を分解して出力することもできます。\nコネクターの注意事項 コネクターは、あるパイプラインからエクスポートされ、別のパイプラインでレシーバーで定義されたデータのみを受け入れます。コレクターをどう構築してどう利用するか、設定を検討する必要があります。\n参照 https://opentelemetry.io/docs/collector/configuration/#connectors https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/connector/countconnector 設定を確認しましょう これで、プロセッサーがカバーできました。ここで、設定のの変更内容をチェックしてみましょう。\nCheck-in設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: logging: verbosity: detailed service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [otlp, opencensus, prometheus] processors: [batch] exporters: [logging] extensions: [health_check, pprof, zpages]",
    "description": "Attributes プロセッサー attribute プロセッサーを使うと、スパン、ログ、またはメトリクスの属性を変更できます。また、このプロセッサーは、入力データをフィルタリングし、マッチさせ、指定されたアクションに含めるべきか、除外すべきかを決定する機能もサポートしています。\nアクションを設定するには、指定された順序で実行されるアクションのリストを記述します。サポートされるアクションは以下の通りです：\ninsert: その属性がない場合に、新しい属性値を挿入します。 update: その属性がある場合に、その属性値を更新します。 upsert: insert または update を実行します。属性がない場合には新しい属性値を挿入し、属性がある場合にはその値を更新します。 delete: 入力データから属性値を削除します。 hash: 属性値をハッシュ化 (SHA1) します。 extract: 入力キーの値を正規表現ルールを使って抽出し、対象キーの値を更新します。対象キーがすでに存在する場合は、その値は上書きされます。 次の例のように、attribute プロセッサーを使って、キーは participant.name、あたいはあなたの名前（例: marge_simpson）という新しい属性を追加してみましょう。\n警告 INSERT_YOUR_NAME_HERE の箇所は、自分の名前に置き換えてください。また、自分の名前に スペースを使わない ようにしてください。\nこのワークショップの後半では、この属性を使用して Splunk Observability Cloud でメトリクスをフィルタリングします。\n​ Attributes Processor Configuration processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" Ninja: コネクターを使って内部への洞察を加速する 最近追加されたものの一つとして、connector というコンセプトがあります。これを使うと、あるパイプラインの出力を別のパイプラインの入力に結合できるようになります。",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/4-processors/3-attributes/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Resource Detection プロセッサー また、コレクターがインスタンスのホスト名やAWS/EC2のメタデータを取得できるように、resourcedetection/system および resourcedetection/ec2 プロセッサーを追加しました。これらのプロセッサーをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、resourcedetection/system および resourcedetection/ec2 を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2] exporters: [logging]",
    "description": "Resource Detection プロセッサー また、コレクターがインスタンスのホスト名やAWS/EC2のメタデータを取得できるように、resourcedetection/system および resourcedetection/ec2 プロセッサーを追加しました。これらのプロセッサーをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、resourcedetection/system および resourcedetection/ec2 を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/6-service/3-resourcedetection/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e リソース",
    "content": "はじめに 大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、その規則が遵守されるようにガバナンスプロセスを設定することが非常に重要です。\nこれにより、OpenTelemetry を通じて収集される MELT データ（メトリクス、イベント、ログ、トレース）を、アラート、ダッシュボード作成、トラブルシューティングの目的で効率的に活用することが可能になります。また、Splunk Observability Cloud のユーザーが探しているデータを迅速に見つけることができます。\n命名規則はまた、データを効果的に集約するためにも重要です。例えば、環境ごとのユニークなホストの数を数えたい場合、ホスト名と環境名を捉えるための標準化された規則を使用する必要があります。\n属性 vs タグ 先に進む前に、用語についての注意をしておきましょう。OpenTelemetry の「タグ」は「属性（attribute）」と呼ばれます。属性は、手動または自動の計装を通じて、メトリクス、ログ、トレースに添付することができます。\n属性はまた、Resource Detection processorなどのさまざまなプロセッサを使用して、OpenTelemetry コレクターレベルでメトリクス、ログ、トレースに添付することもできます。\nSplunk Observability Cloud に属性付きのトレースが取り込まれると、それらは「タグ」として利用可能になります。オプションとして、トレースの一部として収集された属性は、Troubleshooting Metric Setsの作成に使用され、Tag Spotlightなどのさまざまな機能と共に使用することができます。\nまた、属性はMonitoring Metric Setsの作成に使用され、アラートのトリガーとして使用することもできます。\nリソースに関するセマンティック規約 OpenTelemetry リソースセマンティック規約は、組織が標準化すべき属性を決定する際の出発点として使用できます。以下のセクションでは、よく使用される属性のいくつか見ていきましょう。\nサービス属性 監視されるサービスを記述するために多くの属性が使用されます。\nservice.name はサービスの論理名を定義する必須の属性です。OpenTelemetry SDK によって自動的に追加されますが、カスタマイズすることができます。これはシンプルに保つことが最善です（例えば、inventoryservice は inventoryservice-prod-hostxyz よりも良いでしょう。他の属性を使用してサービスの他の側面を捉えることができます）。\n以下のサービス属性が推奨されます：\nservice.namespace はサービスを所有するチームを識別するために使用されます service.instance.id はサービスのユニークなインスタンスを識別するために使用されます service.version はサービスのバージョンを識別するために使用されます テレメトリSDK これらの属性はSDKによって自動的に設定され、使用されている計測ライブラリに関する情報を記録します：\ntelemetry.sdk.name は通常 opentelemetry に設定されます。 telemetry.sdk.language は SDK の言語で、例えば java です。 telemetry.sdk.version は使用されている SDK のバージョンを識別します。 コンテナ コンテナで実行されるサービスには、container.id、container.name、container.image.name など、コンテナのランタイムを記述するための多くの属性が使用されます。完全なリストはこちらで確認できます。\nホスト これらの属性は、サービスが実行されているホストを記述し、host.id、host.name、host.arch などの属性を含みます。完全なリストはこちらで確認できます。\nデプロイ環境 deployment.environment 属性は、サービスがデプロイされている環境（ staging や production など）を識別するために使用されます。\nSplunk Observability Cloud は、この属性を使用して関連コンテンツを有効する（詳細はこちら）ため、この属性を含めることが重要です。\nクラウド AWS などのパブリッククラウド環境で実行されるサービスに関する情報を捉えるための属性もあります。これには、cloud.provider、cloud.account.id、cloud.region が含まれます。\n属性の完全なリストはこちらで確認できます。\n一部のクラウドプロバイダー、例えば GCP は、独自のセマンティック規則を定義しています。\nKubernetes Kubernetesで実行されるアプリケーションにも、いくつかの標準化された属性があります。これらの多くは、Splunk の OpenTelemetry コレクター配布によって自動的に追加されます（詳細はこちら）。\n属性は、例えば k8s.cluster.name、k8s.node.name、k8s.pod.name、k8s.namespace.name、kubernetes.workload.name などがあります。\nカスタム属性のベストプラクティス 多くの組織では、OpenTelemetryのリソースセマンティック規約で定義されているもの以上の属性が欲しくなります。\nこの場合、セマンティック規約にすでに含まれている属性名との命名競合を避けることが重要です。つまり、特定の属性名を命名規則に決定する前に、セマンティック規約をチェックすると良いでしょう。\n属性名の命名規則に加えて、属性値も考慮する必要があります。例えば、アプリケーションが属する特定のビジネスユニットをキャプチャしたい場合、簡単にかつ効果的にフィルタリングするために、標準化されたビジネスユニット値のリストも持ちたいでしょう。\nOpenTelemetryコミュニティでは、属性の命名に従うべきガイドラインも提供しています。こちらで見つけることができます。\nRecommendations for Application Developersは、私たちの議論に最も関連しています。\nそこでは、以下を推奨しています：\ncom.acme.shopname のように、会社のドメイン名で属性名を接頭辞として付けること（属性が社内だけでなく外部で使用される可能性がある場合） 属性が特定のアプリケーションに固有であり、組織内でのみ使用される場合は、アプリケーション名で属性名に接頭辞を付けること 既存の OpenTelemetry セマンティック規約の名前を属性名の接頭辞として使用しないこと 異なる組織や業界全体で一般的なニーズがある場合は、あなたの属性名を OpenTelemetry 仕様に追加する提案を検討すること otel.* で始まる属性名は避けること。これは OpenTelemetry 仕様の使用に予約されています カーディナリティに関する考慮事項 属性名と値の命名基準を決定する際に考慮すべき最後の点は、メトリクスのカーディナリティに関連しています。\nのカーディナリティは、メトリクス名とそれに関連する次元の組み合わせによって生成されるユニークなメトリクス時系列（MTS: Metric Time Series）の数として定義されます。\nメトリクスは、ディメンションの数とそれらのディメンションが持つユニークな値の数が多い場合に、高いカーディナリティを持つことになります。\n例えば、あなたのアプリケーションが custom.metric という名前のメトリクスのデータを送信するとします。属性がない場合、custom.metric は単一のメトリクス時系列（MTS）を生成します。\n一方で、custom.metricが customer.id という属性を含み、数千の顧客ID値がある場合、これは数千のメトリクス時系列を生成し、コストやクエリ性能に影響を与える可能性があります。\nSplunk Observability Cloud は、メトリクスの使用量を管理するためのレポートを提供しています。そして、望ましくないディメンションを削除するルールを作成することができます。しかし、最初の防衛線は、属性名と値の組み合わせがどのようにメトリクスのカーディナリティを増加させるかを理解することです。\nまとめ このドキュメントでは、大規模な OpenTelemetry インストゥルメンテーションの展開を開始する前に、OpenTelemetry タグの命名規則を定義することの重要性を強調しました。\nOpenTelemetry のリソースセマンティック規約がいくつかの属性の命名規則を定義し、多くの属性が OpenTelemetry SDKや OpenTelemetry コレクター内で動作するプロセッサーを通じて自動的に収集される方法について説明しました。\n最後に、リソースセマンティック規約が組織のニーズに十分でない場合に、属性名を作成するためのベストプラクティスを共有しました。",
    "description": "大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "tags": [],
    "title": "OpenTelemetryとSplunkにおける、タグ付けのための命名規則",
    "uri": "/observability-workshop/v5.99/ja/resources/otel_tagging/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6.2 Optional Exercise",
    "content": "Let’s look at some other parts of the UI like the Information Pane on the right of the navigator or the Related Content Pane at the bottom.\nFirst, let’s look at the Information Pane, this pane provides alert and detected services information and the metadata related to the object you’re looking at.\nMeta Data is sent along with the metrics and is very useful for identifying trends when looking into issues. An example could be a pod failing when deployed on a specific Operating System.\nExercise Can you identify the Operating System and Architecture of the node from the metadata? As we have seen in the previous exercise, these fields are very useful for filtering the view in charts and Navigators down to a specific subset of metrics we are interested in.\nAnother feature in the UI is Related content.\nRelated Content The Splunk Observability User Interface will attempt to show you additional information that is related to what you’re actively looking at. A good example of this is the Kubernetes Navigator showing you related Content tiles in the information Pane for the services found running on this node.\nIn the Information Pane, you should see two tiles for services detected, the two databases used by our e-commerce application. Let’s use this Related Content.\nExercise First, make sure you no longer have a filter for the development namespace active. (Simply click on the x to remove it from the Filter Pane) as there are no databases in the Development Namespace. Hoover on the Redis tile, and click on the Goto all my Redis instances button The Navigator view should change to the overall Redis instances view. Select the the instance running on your cluster. (Click on the blue link, named redis-[the name of your workshop], in the Redis Instances pane). We should now see just the information for your Redis Instance \u0026 there should also be an Information Pane. Again we see Meta Data, but we also see that UI is showing in the Related Content tiles that this Redis Server runs in a Container running on Kubernetes. Let’s verify that by clicking on the Kubernetes Tile. We should be back in the Kubernetes Navigator, at the container level. Confirm that the names of our cluster and node are all visible at the top of the page and we are back looking at our K8s Cluster, where we started. This completes the tour of Splunk Observability Cloud. Let’s go and look at our e-commerce site and do some shopping.",
    "description": "Let’s look at some other parts of the UI like the Information Pane on the right of the navigator or the Related Content Pane at the bottom.\nFirst, let’s look at the Information Pane, this pane provides alert and detected services information and the metadata related to the object you’re looking at.\nMeta Data is sent along with the metrics and is very useful for identifying trends when looking into issues. An example could be a pod failing when deployed on a specific Operating System.",
    "tags": [],
    "title": "Infrastructure Exercise - Part 3",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/30-im-exercise/3-im-exercise/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "演習 サービスマップでpaymentserviceを選択します。 右側のペインでBreakdownをクリックします。 リストからtenant.levelを選択します。 サービスマップに戻り、goldをクリックします。 Breakdownをクリックしてversionを選択します。これはサービスバージョンを表示するタグです。 これをsilverとbronzeについても繰り返します。 ​ 質問 回答 表示されている内容からどのような結論が導き出せますか？\nすべてのtenant.levelがv350.10の影響を受けています\nこれでpaymentserviceがgold、silver、bronzeの 3 つのサービスに分解されているのが確認できます。各テナントは 2 つのサービスに分解されており、それぞれのバージョン（v350.10とv350.9）に対応しています。\nスパンタグ スパンタグを使用してサービスを分解することは非常に強力な機能です。これにより、異なる顧客、異なるバージョン、異なる地域などに対して、サービスがどのようにパフォーマンスを発揮しているかを確認できます。この演習では、paymentserviceのv350.10がすべての顧客に問題を引き起こしていることを特定しました。\n次に、何が起きているかを確認するためにトレースを詳しく調べる必要があります。",
    "description": "演習 サービスマップでpaymentserviceを選択します。 右側のペインでBreakdownをクリックします。 リストからtenant.levelを選択します。 サービスマップに戻り、goldをクリックします。 Breakdownをクリックしてversionを選択します。これはサービスバージョンを表示するタグです。 これをsilverとbronzeについても繰り返します。 ​ 質問 回答 表示されている内容からどのような結論が導き出せますか？\nすべてのtenant.levelがv350.10の影響を受けています\nこれでpaymentserviceがgold、silver、bronzeの 3 つのサービスに分解されているのが確認できます。各テナントは 2 つのサービスに分解されており、それぞれのバージョン（v350.10とv350.9）に対応しています。\nスパンタグ スパンタグを使用してサービスを分解することは非常に強力な機能です。これにより、異なる顧客、異なるバージョン、異なる地域などに対して、サービスがどのようにパフォーマンスを発揮しているかを確認できます。この演習では、paymentserviceのv350.10がすべての顧客に問題を引き起こしていることを特定しました。\n次に、何が起きているかを確認するためにトレースを詳しく調べる必要があります。",
    "tags": [],
    "title": "4. APMサービスブレイクダウン",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/6-apm/4-apm-service-breakdown/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Log Observer Connect を使用すると、Splunk プラットフォームからの同じログデータをシームレスに直感的でコード不要のインターフェースに取り込み、問題を迅速に見つけて修正するのに役立ちます。ログベースの分析を簡単に実行し、Splunk Infrastructure Monitoring のリアルタイムメトリクスと Splunk APM トレースを 1 か所でシームレスに関連付けることができます。\nエンドツーエンドの可視性： Splunk プラットフォームの強力なロギング機能と Splunk Observability Cloud のトレースおよびリアルタイムメトリクスを組み合わせることで、ハイブリッド環境のより深い洞察とより多くのコンテキストを得ることができます。\n迅速かつ簡単なログベースの調査を実行： すでに Splunk Cloud Platform または Enterprise に取り込まれているログを、シンプルで直感的なインターフェース（SPL を知る必要はありません！）でカスタマイズ可能な標準搭載のダッシュボードとともに再利用することによって実現します。\nより高いスケールの経済性と運用効率を実現： チーム間でログ管理を一元化し、データとチームのサイロを壊し、全体的により良いサポートを得ることによって実現します。",
    "description": "Log Observer Connect を使用すると、Splunk プラットフォームからの同じログデータをシームレスに直感的でコード不要のインターフェースに取り込み、問題を迅速に見つけて修正するのに役立ちます。ログベースの分析を簡単に実行し、Splunk Infrastructure Monitoring のリアルタイムメトリクスと Splunk APM トレースを 1 か所でシームレスに関連付けることができます。\nエンドツーエンドの可視性： Splunk プラットフォームの強力なロギング機能と Splunk Observability Cloud のトレースおよびリアルタイムメトリクスを組み合わせることで、ハイブリッド環境のより深い洞察とより多くのコンテキストを得ることができます。\n迅速かつ簡単なログベースの調査を実行： すでに Splunk Cloud Platform または Enterprise に取り込まれているログを、シンプルで直感的なインターフェース（SPL を知る必要はありません！）でカスタマイズ可能な標準搭載のダッシュボードとともに再利用することによって実現します。\nより高いスケールの経済性と運用効率を実現： チーム間でログ管理を一元化し、データとチームのサイロを壊し、全体的により良いサポートを得ることによって実現します。",
    "tags": [],
    "title": "Log Observer概要",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/4-log-observer-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "Splunk Distribution of OpenTelemetry のダウンロード このワークショップでは、NuGet パッケージを使用せず、Splunk Distribution of OpenTelemetry を 手動でインストールします。\n最新のsplunk-otel-dotnet-install.shファイルをダウンロードすることから始めます。 これを使用して.NET アプリケーションを計装します：\ncd ~/workshop/docker-k8s-otel/helloworld curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O インストールプロセスの詳細については、Splunk Distribution of OpenTelemetry .NET の手動インストール を参照してください。\nディストリビューションのインストール ターミナルで、以下のようにディストリビューションをインストールします\n​ Script Example Output sh ./splunk-otel-dotnet-install.sh Downloading v1.8.0 for linux-glibc (/tmp/tmp.m3tSdtbmge/splunk-opentelemetry-dotnet-linux-glibc-x64.zip)... 注意：上記のコマンドを実行する際には、ARCHITECTURE 環境変数を含める必要がある場合があります：\nARCHITECTURE=x64 sh ./splunk-otel-dotnet-install.sh 計装の有効化 次に、OpenTelemetry 計装を有効化できます：\n. $HOME/.splunk-otel-dotnet/instrument.sh デプロイメント環境の設定 デプロイメント環境を設定して、データが Splunk Observability Cloud 内の独自の 環境に流れるようにしましょう：\nexport OTEL_RESOURCE_ATTRIBUTES=deployment.environment=otel-$INSTANCE 計装を使用したアプリケーションの実行 以下のようにアプリケーションを実行できます：\ndotnet run チャレンジ Linux インスタンスから C#アプリケーションによってエクスポートされているトレースをどのように確認できるでしょうか？\n答えを見るにはここをクリック これを行う方法は 2 つあります：\ndotnet runコマンドの開始時にOTEL_TRACES_EXPORTER=otlp,consoleを追加することで、トレースが OTLP 経由でコレクターに書き込まれるとともに、コンソールにも書き込まれるようになります。 OTEL_TRACES_EXPORTER=otlp,console dotnet run あるいは、コレクター設定にデバッグエクスポーターを追加し、それをトレースパイプラインに追加することで、トレースがコレクターログに書き込まれるようになります。 exporters: debug: verbosity: detailed service: pipelines: traces: receivers: [jaeger, otlp, zipkin] processors: - memory_limiter - batch - resourcedetection exporters: [otlphttp, signalfx, debug] アプリケーションへのアクセス アプリケーションが実行中になったら、2 つ目の SSH ターミナルを使用して curl でアクセスします：\ncurl http://localhost:8080/hello 以前と同様に、Hello, World!が返されるはずです。\nトレースログを有効にした場合は、以下のようなトレースがコンソールまたはコレクターログに書き込まれているのを確認できるはずです：\ninfo: Program[0] /hello endpoint invoked anonymously Activity.TraceId: c7bbf57314e4856447508cd8addd49b0 Activity.SpanId: 1c92ac653c3ece27 Activity.TraceFlags: Recorded Activity.ActivitySourceName: Microsoft.AspNetCore Activity.DisplayName: GET /hello/{name?} Activity.Kind: Server Activity.StartTime: 2024-12-20T00:45:25.6551267Z Activity.Duration: 00:00:00.0006464 Activity.Tags: server.address: localhost server.port: 8080 http.request.method: GET url.scheme: http url.path: /hello network.protocol.version: 1.1 user_agent.original: curl/7.81.0 http.route: /hello/{name?} http.response.status_code: 200 Resource associated with Activity: splunk.distro.version: 1.8.0 telemetry.distro.name: splunk-otel-dotnet telemetry.distro.version: 1.8.0 service.name: helloworld os.type: linux os.description: Ubuntu 22.04.5 LTS os.build_id: 6.8.0-1021-aws os.name: Ubuntu os.version: 22.04 host.name: derek-1 host.id: 20cf15fcc7054b468647b73b8f87c556 process.owner: splunk process.pid: 16997 process.runtime.description: .NET 8.0.11 process.runtime.name: .NET process.runtime.version: 8.0.11 container.id: 2 telemetry.sdk.name: opentelemetry telemetry.sdk.language: dotnet telemetry.sdk.version: 1.9.0 deployment.environment: otel-derek-1 Splunk Observability Cloud でのアプリケーションの確認 セットアップが完了したので、トレースがSplunk Observability Cloudに送信されていることを確認しましょう。アプリケーションが初回デプロイされた場合、データが表示されるまでに数分かかる場合があることに注意してください。\nAPM にナビゲートし、Environment ドロップダウンを使用してあなたの環境（つまりotel-instancename）を選択します。\nすべてが正しくデプロイされている場合、サービスのリストにhelloworldが表示されるはずです：\n右側のService Mapをクリックしてサービスマップを表示します。\n次に、右側のTracesをクリックして、このアプリケーションでキャプチャされたトレースを確認します。\n個別のトレースは以下のように表示されるはずです：\n次のステップに進む前に、Ctrl + C を押して Helloworld アプリを終了してください。",
    "description": "Splunk Distribution of OpenTelemetry のダウンロード このワークショップでは、NuGet パッケージを使用せず、Splunk Distribution of OpenTelemetry を 手動でインストールします。\n最新のsplunk-otel-dotnet-install.shファイルをダウンロードすることから始めます。 これを使用して.NET アプリケーションを計装します：\ncd ~/workshop/docker-k8s-otel/helloworld curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O インストールプロセスの詳細については、Splunk Distribution of OpenTelemetry .NET の手動インストール を参照してください。\nディストリビューションのインストール ターミナルで、以下のようにディストリビューションをインストールします\n​ Script Example Output sh ./splunk-otel-dotnet-install.sh Downloading v1.8.0 for linux-glibc (/tmp/tmp.m3tSdtbmge/splunk-opentelemetry-dotnet-linux-glibc-x64.zip)... 注意：上記のコマンドを実行する際には、ARCHITECTURE 環境変数を含める必要がある場合があります：\nARCHITECTURE=x64 sh ./splunk-otel-dotnet-install.sh 計装の有効化 次に、OpenTelemetry 計装を有効化できます：\n. $HOME/.splunk-otel-dotnet/instrument.sh デプロイメント環境の設定 デプロイメント環境を設定して、データが Splunk Observability Cloud 内の独自の 環境に流れるようにしましょう：",
    "tags": [],
    "title": "OpenTelemetryで.NETアプリケーションを計装する",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/4-instrument-app-with-otel/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "1. RUMを有効にする Real User Monitoring (RUM)計装のために、Open Telemetry Javascript https://github.com/signalfx/splunk-otel-js-web スニペットをページ内に追加します。再度ウィザードを使用します Data Management → Add Integrationボタン → Monitor user experience（画面上部タブ） → Browser Instrumentationを開きます。\nドロップダウンから設定済みの RUM ACCESS TOKEN を選択し、Next をクリックします。以下の構文で App name とEnvironment を入力します：\n次に、ワークショップのRUMトークンを選択し、 App nameとEnvironmentを定義します。ウィザードでは、ページ上部の \u003chead\u003e セクションに配置する必要のある HTML コードの断片が表示されます。この例では、次のように記述していますが、ウィザードでは先程入力した値が反映されてるはずです。\nApplication Name: \u003chostname\u003e-petclinic-service Environment: \u003chostname\u003e-petclinic-env ウィザードで編集済みコードスニペットをコピーするか、以下のスニペットをコピーして適宜編集してください。ただし：\n[hostname]-petclinic-service - [hostname] をお使いのホスト名に書き換えてください [hostname]-petclinic-env - [hostname] をお使いのホスト名に書き換えてください \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ beaconUrl: \"https://rum-ingest.\u003cREALM\u003e.signalfx.com/v1/rum\", rumAuth: \"\u003cRUM_ACCESS_TOKEN\u003e\", app: \"\u003chostname\u003e.service\", environment: \"\u003chostname\u003e\" }); \u003c/script\u003e Spring PetClinicアプリケーションでは、1つのHTMLページを「レイアウト」ページとして使用し、アプリケーションのすべてのページで再利用しています。これは、Splunk RUM計装ライブラリを挿入するのに最適な場所であり、すべてのページで自動的に読み込まれます。\nでは、レイアウトページを編集してみましょう：\nnano src/main/resources/templates/fragments/layout.html そして、上で生成したスニップをページの \u003chead\u003e セクションに挿入してみましょう。さて、アプリケーションを再構築して、再び実行する必要があります。\n2. PetClinicを再ビルドする mavenコマンドを実行して、PetClinicをコンパイル/ビルド/パッケージ化します：\n./mvnw package -Dmaven.test.skip=true そして、アプリケーションを動かしてみましょう。バージョンを version=0.316 とするのをお忘れなく。\njava -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.316 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql versionを自動で設定する ここまできて version を毎回変えるためにコマンドラインを修正するのは大変だと思うことでしょう。実際、修正が漏れた人もいるかもしれません。 本番環境では、環境変数でアプリケーションバージョンを与えたり、コンテナイメージの作成時にビルドIDを与えたりすることになるはずです。\n次に、より多くのトラフィックを生成するために、アプリケーションに再度アクセスしてみましょう。 http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスすると、今度はRUMトレースが報告されるはずです。\nRUMにアクセスして、トレースとメトリクスのいくつかを見てみましょう。左のメニューから RUM を選ぶと、Spring Pet Clinicでのユーザー（あなたです！）が体験したパフォーマンスが表示されます。",
    "description": "1. RUMを有効にする Real User Monitoring (RUM)計装のために、Open Telemetry Javascript https://github.com/signalfx/splunk-otel-js-web スニペットをページ内に追加します。再度ウィザードを使用します Data Management → Add Integrationボタン → Monitor user experience（画面上部タブ） → Browser Instrumentationを開きます。\nドロップダウンから設定済みの RUM ACCESS TOKEN を選択し、Next をクリックします。以下の構文で App name とEnvironment を入力します：\n次に、ワークショップのRUMトークンを選択し、 App nameとEnvironmentを定義します。ウィザードでは、ページ上部の \u003chead\u003e セクションに配置する必要のある HTML コードの断片が表示されます。この例では、次のように記述していますが、ウィザードでは先程入力した値が反映されてるはずです。\nApplication Name: \u003chostname\u003e-petclinic-service Environment: \u003chostname\u003e-petclinic-env ウィザードで編集済みコードスニペットをコピーするか、以下のスニペットをコピーして適宜編集してください。ただし：\n[hostname]-petclinic-service - [hostname] をお使いのホスト名に書き換えてください [hostname]-petclinic-env - [hostname] をお使いのホスト名に書き換えてください \u003cscript src=\"https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript\u003e SplunkRum.init({ beaconUrl: \"https://rum-ingest.\u003cREALM\u003e.signalfx.com/v1/rum\", rumAuth: \"\u003cRUM_ACCESS_TOKEN\u003e\", app: \"\u003chostname\u003e.service\", environment: \"\u003chostname\u003e\" }); \u003c/script\u003e Spring PetClinicアプリケーションでは、1つのHTMLページを「レイアウト」ページとして使用し、アプリケーションのすべてのページで再利用しています。これは、Splunk RUM計装ライブラリを挿入するのに最適な場所であり、すべてのページで自動的に読み込まれます。\nでは、レイアウトページを編集してみましょう：\nnano src/main/resources/templates/fragments/layout.html そして、上で生成したスニップをページの \u003chead\u003e セクションに挿入してみましょう。さて、アプリケーションを再構築して、再び実行する必要があります。",
    "tags": [],
    "title": "Real User Monitoring",
    "uri": "/observability-workshop/v5.99/ja/other/pet-clinic/docs/rum/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 8. Splunk Synthetics",
    "content": "これらのテストを 24 時間 365 日実行できるため、テストが失敗したり、合意した SLA よりも長く実行され始めた場合に、ソーシャルメディアやアップタイムウェブサイトから通知される前に、早期に警告を受けるための理想的なツールです。\nそのような事態を防ぐために、テストが 1.1 分以上かかっているかどうかを検知しましょう。\n演習 左側のメニューから Synthetics ホームページに戻ります\nワークショップのテストを再度選択し、ページ上部のCreate Detectorボタンをクリックします。\nNew Synthetics Detectorというテキスト（1）を編集し、イニシャル - [ワークショップ名]に置き換えます。\nRun DurationとStatic threasholdが選択されていることを確認します。\nTrigger threasholt（2）を65,000〜68,000に設定し、Enter キーを押してチャートを更新します。上図のように、しきい値ラインを切る複数のスパイクがあることを確認してください（実際のレイテンシーに合わせてしきい値を少し調整する必要があるかもしれません）。\n残りはデフォルトのままにします。\nスパイクの下に赤と白の三角形の列が表示されるようになったことに注意してください（3）。赤い三角形は、テストが指定されたしきい値を超えたことを Detector が検出したことを知らせ、白い三角形は結果がしきい値を下回ったことを示します。各赤い三角形がアラートをトリガーします。\nアラートの重大度（4）は、ドロップダウンを別のレベルに変更することで変更できます。また、アラート方法も変更できます。受信者を追加しないでください。アラートストームの対象になる可能性があります！\nActibateをクリックして、 Detector をデプロイします。\n新しく作成した Detector を見るには、Edit Testボタンをクリックします。\nページの下部にアクティブな Detector のリストがあります。\nあなたの Detector が見つからず、新しい Synthetics Detectorという名前のものが表示されている場合は、あなたの名前で正しく保存されていない可能性があります。新しい Synthetics Detectorのリンクをクリックして、名前の変更をやり直してください。\n閉じるボタンをクリックして編集モードを終了します。",
    "description": "これらのテストを 24 時間 365 日実行できるため、テストが失敗したり、合意した SLA よりも長く実行され始めた場合に、ソーシャルメディアやアップタイムウェブサイトから通知される前に、早期に警告を受けるための理想的なツールです。\nそのような事態を防ぐために、テストが 1.1 分以上かかっているかどうかを検知しましょう。\n演習 左側のメニューから Synthetics ホームページに戻ります\nワークショップのテストを再度選択し、ページ上部のCreate Detectorボタンをクリックします。\nNew Synthetics Detectorというテキスト（1）を編集し、イニシャル - [ワークショップ名]に置き換えます。\nRun DurationとStatic threasholdが選択されていることを確認します。\nTrigger threasholt（2）を65,000〜68,000に設定し、Enter キーを押してチャートを更新します。上図のように、しきい値ラインを切る複数のスパイクがあることを確認してください（実際のレイテンシーに合わせてしきい値を少し調整する必要があるかもしれません）。\n残りはデフォルトのままにします。\nスパイクの下に赤と白の三角形の列が表示されるようになったことに注意してください（3）。赤い三角形は、テストが指定されたしきい値を超えたことを Detector が検出したことを知らせ、白い三角形は結果がしきい値を下回ったことを示します。各赤い三角形がアラートをトリガーします。\nアラートの重大度（4）は、ドロップダウンを別のレベルに変更することで変更できます。また、アラート方法も変更できます。受信者を追加しないでください。アラートストームの対象になる可能性があります！\nActibateをクリックして、 Detector をデプロイします。\n新しく作成した Detector を見るには、Edit Testボタンをクリックします。",
    "tags": [],
    "title": "4. Synthetics Detector",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/8-synthetics/4-synthetics-detector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 5. Splunk RUM",
    "content": "演習 右上隅のXをクリックして、RUM セッションリプレイを閉じます。 スパンの長さに注目してください。これは注文を完了するのにかかった時間で、良くありません！ ページを下にスクロールすると、タグメタデータ（Tag Spotlight で使用されるもの）が表示されます。タグの後に、ウォーターフォールが表示され、読み込まれたページオブジェクト（HTML、CSS、画像、JavaScript など）が表示されます。 ページを下にスクロールし続けて、青いAPMリンク（URL の末尾に/cart/checkoutがあるもの）まで移動し、その上にカーソルを置きます。 これにより APM パフォーマンスサマリーが表示されます。このエンドツーエンド（RUM から APM）のビューは、問題のトラブルシューティングを行う際に非常に便利です。\n演習 上のスクリーンショットのように、paymentserviceとcheckoutserviceがエラー状態にあることがわかります。 ワークフロー名の下にあるfront-end:/cart/checkoutをクリックすると、APM サービスマップが表示されます。",
    "description": "演習 右上隅のXをクリックして、RUM セッションリプレイを閉じます。 スパンの長さに注目してください。これは注文を完了するのにかかった時間で、良くありません！ ページを下にスクロールすると、タグメタデータ（Tag Spotlight で使用されるもの）が表示されます。タグの後に、ウォーターフォールが表示され、読み込まれたページオブジェクト（HTML、CSS、画像、JavaScript など）が表示されます。 ページを下にスクロールし続けて、青いAPMリンク（URL の末尾に/cart/checkoutがあるもの）まで移動し、その上にカーソルを置きます。 これにより APM パフォーマンスサマリーが表示されます。このエンドツーエンド（RUM から APM）のビューは、問題のトラブルシューティングを行う際に非常に便利です。\n演習 上のスクリーンショットのように、paymentserviceとcheckoutserviceがエラー状態にあることがわかります。 ワークフロー名の下にあるfront-end:/cart/checkoutをクリックすると、APM サービスマップが表示されます。",
    "tags": [],
    "title": "4. ユーザーセッション",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/5-rum/4-user-sessions/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ あなたは次の目新しいアイテムを有名なオンラインブティックショップで購入したいと思っているおしゃれな都会人です。オンラインブティックはあなたのヒップスターな要求すべてを満たすための場所だと聞いています。\nこの演習の目的は、オンラインブティックウェブアプリケーションと対話することです。これは Splunk Observability Cloud の機能を実演するために使用されるサンプルアプリケーションです。このアプリケーションは簡単な E コマースサイトで、商品の閲覧、カートへの追加、そして精算が可能です。\nこのアプリケーションはすでにデプロイされており、インストラクターがオンラインブティックウェブサイトへのリンクを提供します。例：\nhttp://\u003cs4r-workshop-i-xxx.splunk\u003e.show:81/。アプリケーションは80および443ポートでも実行されているので、そちらを使用するか、ポート81が到達不能な場合はそれらを使用することもできます。 演習 - ショッピングに行きましょう オンラインブティックへのリンクが得られたら、いくつかの商品を閲覧し、カートに追加し、最後に精算を行ってください。 この演習を数回繰り返し、可能であれば異なるブラウザ、モバイルデバイス、またはタブレットを使用してください。これによりより多くのデータが生成され、探索できるようになります。 ヒント ページの読み込みを待っている間は、ページ上でマウスカーソルを動かしてください。これにより、このワークショップの後半で探索するためのより多くのデータが生成されます。\n演習 (続き) 精算プロセスについて何か気づいたことはありますか？完了までに時間がかかったように思えましたが、最終的には完了しましたか？こうした場合は、注文確認 IDをコピーしてローカルに保存してください。後で必要になります。 ショッピングに使用したブラウザセッションを閉じてください。 これは、ユーザーエクスペリエンスが悪い場合の感覚で、これは潜在的な顧客満足度の問題であるため、すぐにトラブルシューティングを行う必要があります。\nSplunk RUMでデータがどのように見えるか確認してみましょう。",
    "description": "オンラインブティックウェブアプリケーションと対話し、Splunk Observability Cloud用のデータを生成します。",
    "tags": [],
    "title": "ショッピングに行きましょう 💶",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/4-online-boutique/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "プロセッサーは、レシーバーとエクスポーターとの間で、データに対して実行される処理です。プロセッサーはオプションですが、いくつかは推奨されています。OpenTelemetry Collector Contrib には多数のプロセッサーが含まれています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Processors fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "プロセッサーは、レシーバーとエクスポーターとの間で、データに対して実行される処理です。プロセッサーはオプションですが、いくつかは推奨されています。OpenTelemetry Collector Contrib には多数のプロセッサーが含まれています。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Processors fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector プロセッサー",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/4-processors/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 7. Splunk Log Observer",
    "content": "ログで使用できる次のチャートタイプはログビューチャートタイプです。このチャートでは、事前定義されたフィルターに基づいてログメッセージを確認できます。\n前回のログタイムラインチャートと同様に、このチャートのバージョンをカスタマーヘルスサービスダッシュボードに追加します：\n演習 前回の演習後、まだLog Observerにいることを確認してください。 フィルターは前回の演習と同じで、時間選択が過去 15 分に設定され、severity=error、sf_service=paymentservice、sf_environment=[WORKSHOPNAME]でフィルタリングされている必要があります。 必要なフィールドのみを含むヘッダーがあることを確認してください。 再度Saveをクリックし、Save to Dashvoardをクリックします。 これによりチャート作成ダイアログが再度表示されます。 Chart nameとしてログビューを使用します。 今回はSelect Dashboardをクリックし、前回の演習で作成したダッシュボードを検索します。検索ボックス（1）にあなたのイニシャルを入力することから始めることができます。 あなたのダッシュボード名をクリックして強調表示し（2）、OK（3）をクリックします。 これによりチャート作成ダイアログに戻ります。 Chart typeとしてLog viewが選択されていることを確認します。 ダッシュボードを表示するには、Save and go to dashboardをクリックします。 結果は以下のダッシュボードと同様になるはずです： この演習の最後のステップとして、あなたのダッシュボードをワークショップチームページに追加しましょう。これにより、ワークショップの後半で簡単に見つけることができます。 ページ上部で、あなたのダッシュボード名の左にある … をクリックします。 ドロップダウンからLinks to Teamを選択します。 次のLinks to Teamダイアログボックスで、インストラクターが提供したワークショップチームを見つけてDoneをクリックします。 次のセッションでは、Splunk Synthetics を見て、Web ベースのアプリケーションのテストを自動化する方法を確認します。",
    "description": "ログで使用できる次のチャートタイプはログビューチャートタイプです。このチャートでは、事前定義されたフィルターに基づいてログメッセージを確認できます。\n前回のログタイムラインチャートと同様に、このチャートのバージョンをカスタマーヘルスサービスダッシュボードに追加します：\n演習 前回の演習後、まだLog Observerにいることを確認してください。 フィルターは前回の演習と同じで、時間選択が過去 15 分に設定され、severity=error、sf_service=paymentservice、sf_environment=[WORKSHOPNAME]でフィルタリングされている必要があります。 必要なフィールドのみを含むヘッダーがあることを確認してください。 再度Saveをクリックし、Save to Dashvoardをクリックします。 これによりチャート作成ダイアログが再度表示されます。 Chart nameとしてログビューを使用します。 今回はSelect Dashboardをクリックし、前回の演習で作成したダッシュボードを検索します。検索ボックス（1）にあなたのイニシャルを入力することから始めることができます。 あなたのダッシュボード名をクリックして強調表示し（2）、OK（3）をクリックします。 これによりチャート作成ダイアログに戻ります。 Chart typeとしてLog viewが選択されていることを確認します。 ダッシュボードを表示するには、Save and go to dashboardをクリックします。 結果は以下のダッシュボードと同様になるはずです： この演習の最後のステップとして、あなたのダッシュボードをワークショップチームページに追加しましょう。これにより、ワークショップの後半で簡単に見つけることができます。 ページ上部で、あなたのダッシュボード名の左にある … をクリックします。 ドロップダウンからLinks to Teamを選択します。 次のLinks to Teamダイアログボックスで、インストラクターが提供したワークショップチームを見つけてDoneをクリックします。 次のセッションでは、Splunk Synthetics を見て、Web ベースのアプリケーションのテストを自動化する方法を確認します。",
    "tags": [],
    "title": "4. ログビューチャート",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/7-log-observer/4-log-view-chart/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "ワークショップの第 2 部では、OpenTelemetry による手動計装が計測データ収集を強化する方法を実演することに焦点を当てます。より具体的には、今回のケースでは、producer-lambda関数からconsumer-lambda関数にトレースコンテキストデータを伝播させることができるようになります。これにより、現在は自動コンテキスト伝播をサポートしていない Kinesis ストリームを介しても、2 つの関数間の関係を見ることができるようになります。\n手動計装ワークショップディレクトリとコンテンツ 再度、作業ディレクトリとそのファイルの一部を確認することから始めます。今回は o11y-lambda-workshop/manual ディレクトリです。ここにはワークショップの手動計装部分のすべてのコンテンツがあります。\nmanual ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/manual ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/manual ls コマンドでこのディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars ワークショップの質問 このディレクトリと最初に始めた auto ディレクトリに何か違いがありますか？\nauto と manual のファイルを比較する 見た目が同じように見えるこれらのファイルが実際に同じかどうか確認しましょう。\nauto と manual ディレクトリの main.tf ファイルを比較します：\ndiff ~/o11y-lambda-workshop/auto/main.tf ~/o11y-lambda-workshop/manual/main.tf 違いはありません！(違いがあるはずはありません。もし違いがあれば、ワークショップ進行役に支援を求めてください) 次に、producer.mjs ファイルを比較してみましょう：\ndiff ~/o11y-lambda-workshop/auto/handler/producer.mjs ~/o11y-lambda-workshop/manual/handler/producer.mjs ここにはかなりの違いがあります！ ファイル全体を表示してその内容を調べたい場合は以下を実行します：\ncat ~/o11y-lambda-workshop/handler/producer.mjs 必要な手動計装タスクを処理するために、いくつかの OpenTelemetry オブジェクトを関数に直接インポートしていることに注目してください。 import { context, propagation, trace } from \"@opentelemetry/api\"; プロデューサー関数でコンテキストを伝播するために、@opentelemetry/api から次のオブジェクトをインポートしています： context propagation trace 最後に、consumer.mjs ファイルを比較します：\ndiff ~/o11y-lambda-workshop/auto/handler/consumer.mjs ~/o11y-lambda-workshop/manual/handler/consumer.mjs ここにもいくつかの注目すべき違いがあります。より詳しく見てみましょう：\ncat handler/consumer.mjs このファイルでは、次の @opentelemetry/api オブジェクトをインポートしています： propagation trace ROOT_CONTEXT これらを使用して、プロデューサー関数から伝播されたトレースコンテキストを抽出します その後、抽出したトレースコンテキストに name と superpower に基づいた新しいスパン属性を追加します プロデューサー関数からのトレースコンテキスト伝播 以下のコードはプロデューサー関数内で次のステップを実行します：\nこのトレース用のトレーサーを取得する コンテキストキャリアオブジェクトを初期化する アクティブスパンのコンテキストをキャリアオブジェクトに注入する Kinesis ストリームに配置しようとしているレコードを修正し、アクティブスパンのコンテキストをコンシューマーに運ぶキャリアを含める ... import { context, propagation, trace, } from \"@opentelemetry/api\"; ... const tracer = trace.getTracer('lambda-app'); ... return tracer.startActiveSpan('put-record', async(span) =\u003e { let carrier = {}; propagation.inject(context.active(), carrier); const eventBody = Buffer.from(event.body, 'base64').toString(); const data = \"{\\\"tracecontext\\\": \" + JSON.stringify(carrier) + \", \\\"record\\\": \" + eventBody + \"}\"; console.log( `Record with Trace Context added: ${data}` ); try { await kinesis.send( new PutRecordCommand({ StreamName: streamName, PartitionKey: \"1234\", Data: data, }), message = `Message placed in the Event Stream: ${streamName}` ) ... span.end(); コンシューマー関数でのトレースコンテキスト抽出 以下のコードはコンシューマー関数内で次のステップを実行します：\nproducer-lambdaから取得したコンテキストをキャリアオブジェクトに抽出する 現在のコンテキストからトレーサーを抽出する 抽出したコンテキスト内でトレーサーを使用して新しいスパンを開始する ボーナス：メッセージからの値を含むカスタム属性など、追加の属性をスパンに追加する！ 完了したら、スパンを終了する import { propagation, trace, ROOT_CONTEXT } from \"@opentelemetry/api\"; ... const carrier = JSON.parse( message ).tracecontext; const parentContext = propagation.extract(ROOT_CONTEXT, carrier); const tracer = trace.getTracer(process.env.OTEL_SERVICE_NAME); const span = tracer.startSpan(\"Kinesis.getRecord\", undefined, parentContext); span.setAttribute(\"span.kind\", \"server\"); const body = JSON.parse( message ).record; if (body.name) { span.setAttribute(\"custom.tag.name\", body.name); } if (body.superpower) { span.setAttribute(\"custom.tag.superpower\", body.superpower); } ... span.end(); これでどのような違いが生まれるか見てみましょう！",
    "description": "ワークショップの第 2 部では、OpenTelemetry による手動計装が計測データ収集を強化する方法を実演することに焦点を当てます。より具体的には、今回のケースでは、producer-lambda関数からconsumer-lambda関数にトレースコンテキストデータを伝播させることができるようになります。これにより、現在は自動コンテキスト伝播をサポートしていない Kinesis ストリームを介しても、2 つの関数間の関係を見ることができるようになります。\n手動計装ワークショップディレクトリとコンテンツ 再度、作業ディレクトリとそのファイルの一部を確認することから始めます。今回は o11y-lambda-workshop/manual ディレクトリです。ここにはワークショップの手動計装部分のすべてのコンテンツがあります。\nmanual ディレクトリ 以下のコマンドを実行して o11y-lambda-workshop/manual ディレクトリに移動します：\ncd ~/o11y-lambda-workshop/manual ls コマンドでこのディレクトリの内容を確認します：\nls 出力には以下のファイルとディレクトリが含まれるはずです：\nhandler outputs.tf terraform.tf variables.tf main.tf send_message.py terraform.tfvars ワークショップの質問 このディレクトリと最初に始めた auto ディレクトリに何か違いがありますか？\nauto と manual のファイルを比較する 見た目が同じように見えるこれらのファイルが実際に同じかどうか確認しましょう。\nauto と manual ディレクトリの main.tf ファイルを比較します：\ndiff ~/o11y-lambda-workshop/auto/main.tf ~/o11y-lambda-workshop/manual/main.tf 違いはありません！(違いがあるはずはありません。もし違いがあれば、ワークショップ進行役に支援を求めてください) 次に、producer.mjs ファイルを比較してみましょう：\ndiff ~/o11y-lambda-workshop/auto/handler/producer.mjs ~/o11y-lambda-workshop/manual/handler/producer.mjs ここにはかなりの違いがあります！ ファイル全体を表示してその内容を調べたい場合は以下を実行します：\ncat ~/o11y-lambda-workshop/handler/producer.mjs 必要な手動計装タスクを処理するために、いくつかの OpenTelemetry オブジェクトを関数に直接インポートしていることに注目してください。 import { context, propagation, trace } from \"@opentelemetry/api\"; プロデューサー関数でコンテキストを伝播するために、@opentelemetry/api から次のオブジェクトをインポートしています： context propagation trace 最後に、consumer.mjs ファイルを比較します：",
    "tags": [],
    "title": "手動計装",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/4-manual-instrumentation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "Attributes プロセッサー また、このワークショップのプロセッサーセクションでは、attributes/conf プロセッサーを追加し、コレクターがすべてのメトリクスに participant.name という新しい属性を挿入するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、attributes/conf を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging]",
    "description": "Attributes プロセッサー また、このワークショップのプロセッサーセクションでは、attributes/conf プロセッサーを追加し、コレクターがすべてのメトリクスに participant.name という新しい属性を挿入するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の processors セクションを更新して、attributes/conf を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging]",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/6-service/4-attributes/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "Splunk APM はすべてのサービスのNoSample（サンプリングなし）エンドツーエンドの可視性を提供するため、Splunk APM はすべてのトレースをキャプチャします。このワークショップでは、Order Confirmation IDがタグとして利用可能です。これは、ワークショップの前半で遭遇した不良なユーザー体験の正確なトレースを検索するためにこれを使用できることを意味します。\nトレースアナライザー Splunk Observability Cloud は、アプリケーション監視データを探索するためのいくつかのツールを提供しています。Trace Analyzerは、未知または新しい問題を調査するための高カーディナリティ、高粒度の検索と探索が必要なシナリオに適しています。\n演習 paymentserviceの外側のボックスを選択した状態で、右側のペインでTraceをクリックします。 Trace Analyzerを使用していることを確認するため、ク Switch to Classic Viewボタンが表示されていることを確認します。表示されていない場合は、Switch to Trace Analyzerをクリックします。 時間範囲を過去 15 分に設定します。 Sample Ratioが1:10ではなく1:1に設定されていることを確認します。 Trace \u0026 Error countビューは、積み上げ棒グラフで合計トレース数とエラーのあるトレース数を表示します。マウスを使用して、利用可能な時間枠内の特定の期間を選択できます。\n演習 Trace \u0026 Error countと表示されているドロップダウンメニューをクリックし、Trace Durationに変更します Trace Durationビューは、期間ごとのトレースのヒートマップを表示します。ヒートマップは 3 次元のデータを表しています：\nx 軸の時間 y 軸のトレース期間 ヒートマップの色合いで表される 1 秒あたりのトレース（またはリクエスト）数 マウスを使ってヒートマップ上の領域を選択し、特定の時間帯とトレース期間の範囲にフォーカスすることができます。\n演習 Trace DurationからTrace \u0026 Error countに戻します。 時間選択で過去 1 時間を選択します。 ほとんどのトレースにエラー（赤）があり、エラーのないトレース（青）は限られていることに注意してください。 Sample Ratioが1:10ではなく1:1に設定されていることを確認します。 Add filtersをクリックし、orderIdと入力してリストからorderIdを選択します。 ワークショップの前半でショッピングを行った際のOrder Confirmation IDを貼り付けて Enter キーを押します。もし ID を記録していない場合は、インストラクターに確認してください。 これで、非常に長いチェックアウト待ちという不良なユーザーエクスペリエンスに遭遇した正確なトレースまでフィルタリングできました。\nこのトレースを表示することの二次的な利点は、トレースが最大 13 か月間アクセス可能であることです。これにより、開発者は後の段階でこの問題に戻り、このトレースを引き続き表示することができます。\n演習 リスト内のトレースをクリックします。 次に、トレースウォーターフォールを確認していきます。",
    "description": "Splunk APM はすべてのサービスのNoSample（サンプリングなし）エンドツーエンドの可視性を提供するため、Splunk APM はすべてのトレースをキャプチャします。このワークショップでは、Order Confirmation IDがタグとして利用可能です。これは、ワークショップの前半で遭遇した不良なユーザー体験の正確なトレースを検索するためにこれを使用できることを意味します。\nトレースアナライザー Splunk Observability Cloud は、アプリケーション監視データを探索するためのいくつかのツールを提供しています。Trace Analyzerは、未知または新しい問題を調査するための高カーディナリティ、高粒度の検索と探索が必要なシナリオに適しています。\n演習 paymentserviceの外側のボックスを選択した状態で、右側のペインでTraceをクリックします。 Trace Analyzerを使用していることを確認するため、ク Switch to Classic Viewボタンが表示されていることを確認します。表示されていない場合は、Switch to Trace Analyzerをクリックします。 時間範囲を過去 15 分に設定します。 Sample Ratioが1:10ではなく1:1に設定されていることを確認します。 Trace \u0026 Error countビューは、積み上げ棒グラフで合計トレース数とエラーのあるトレース数を表示します。マウスを使用して、利用可能な時間枠内の特定の期間を選択できます。\n演習 Trace \u0026 Error countと表示されているドロップダウンメニューをクリックし、Trace Durationに変更します",
    "tags": [],
    "title": "5. APMトレースアナライザー",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/6-apm/5-apm-trace-analyzer/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "トレースデータを収集したい関数やサービスに手動計装を適用する方法がわかったので、Lambda 関数を再度デプロイして、producer-lambdaエンドポイントに対するトラフィックを生成していきましょう。\nmanual ディレクトリで Terraform を初期化する 新しいディレクトリにいるので、ここでもう一度 Terraform を初期化する必要があります。\nmanual ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manual ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual 次のコマンドを実行して、このディレクトリで Terraform を初期化します：\nterraform init Lambda 関数とその他の AWS リソースをデプロイする それでは、これらのリソースを再度デプロイしましょう！\n問題がないことを確認するために、terraform plan コマンドを実行します。\nterraform plan 続いて、terraform apply コマンドを使用して main.tf ファイルから Lambda 関数とその他のサポートリソースをデプロイします：\nterraform apply Enter a value: プロンプトが表示されたら yes と応答します\nこれにより、以下のような出力が得られます：\nOutputs: base_url = \"https://______.amazonaws.com/serverless_stage/producer\" consumer_function_name = \"_____-consumer\" consumer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-consumer\" consumer_log_group_name = \"/aws/lambda/______-consumer\" environment = \"______-lambda-shop\" lambda_bucket_name = \"lambda-shop-______-______\" producer_function_name = \"______-producer\" producer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-producer\" producer_log_group_name = \"/aws/lambda/______-producer\" 見ての通り、base_url の最初の部分とログループ ARN 以外は、このワークショップの自動計装部分をこの同じ時点まで実行したときと出力は概ね同じはずです。\nproducer-lambda エンドポイント (base_url) にトラフィックを送信する もう一度、name と superpower をメッセージとしてエンドポイントに送信します。これはトレースコンテキストとともに、Kinesis ストリーム内のレコードに追加されます。\nmanual ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manual ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual send_message.py スクリプトをバックグラウンドプロセスとして実行します：\nnohup ./send_message.py --name CHANGEME --superpower CHANGEME \u0026 次に、response.logs ファイルの内容を確認して、producer-lambdaエンドポイントへの呼び出しが成功しているか確認します：\ncat response.logs メッセージが成功していれば、画面に表示される行の中に次の出力が表示されるはずです：\n{\"message\": \"Message placed in the Event Stream: hostname-eventStream\"} 失敗した場合は、次のように表示されます：\n{\"message\": \"Internal server error\"} 重要 これが発生した場合は、ワークショップ進行役の一人に支援を求めてください。\nLambda 関数のログの確認 ログがどのようになっているか見てみましょう。\nproducer.logs ファイルを確認します：\ncat producer.logs そして consumer.logs ファイルを確認します：\ncat consumer.logs ログを注意深く調べてください。\nワークショップの質問 違いに気づきましたか？\nconsumer-lambda ログからのトレース ID のコピー 今回は、consumer-lambda のロググループが、我々が伝播したtracecontextとともに、メッセージをrecordとしてログに記録しているのが確認できます。\nトレース ID をコピーするには：\nKinesis Messageログの 1 つを見てみましょう。その中にはdataディクショナリがあります ネストされたtracecontextディクショナリを見るために、dataをより詳しく見てください tracecontextディクショナリ内には、traceparentというキーと値のペアがあります traceparentキーと値のペアには、私たちが探しているトレース ID が含まれています -で区切られた 4 つの値のグループがあります。トレース ID は 2 番目の文字グループです トレース ID をコピーして保存してください。 このワークショップの後のステップで必要になります",
    "description": "トレースデータを収集したい関数やサービスに手動計装を適用する方法がわかったので、Lambda 関数を再度デプロイして、producer-lambdaエンドポイントに対するトラフィックを生成していきましょう。\nmanual ディレクトリで Terraform を初期化する 新しいディレクトリにいるので、ここでもう一度 Terraform を初期化する必要があります。\nmanual ディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manual ディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual 次のコマンドを実行して、このディレクトリで Terraform を初期化します：\nterraform init Lambda 関数とその他の AWS リソースをデプロイする それでは、これらのリソースを再度デプロイしましょう！\n問題がないことを確認するために、terraform plan コマンドを実行します。\nterraform plan 続いて、terraform apply コマンドを使用して main.tf ファイルから Lambda 関数とその他のサポートリソースをデプロイします：\nterraform apply Enter a value: プロンプトが表示されたら yes と応答します\nこれにより、以下のような出力が得られます：\nOutputs: base_url = \"https://______.amazonaws.com/serverless_stage/producer\" consumer_function_name = \"_____-consumer\" consumer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-consumer\" consumer_log_group_name = \"/aws/lambda/______-consumer\" environment = \"______-lambda-shop\" lambda_bucket_name = \"lambda-shop-______-______\" producer_function_name = \"______-producer\" producer_log_group_arn = \"arn:aws:logs:us-east-1:############:log-group:/aws/lambda/______-producer\" producer_log_group_name = \"/aws/lambda/______-producer\" 見ての通り、base_url の最初の部分とログループ ARN 以外は、このワークショップの自動計装部分をこの同じ時点まで実行したときと出力は概ね同じはずです。",
    "tags": [],
    "title": "Lambda関数のデプロイとトレースデータの生成",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/5-redeploy-lambdas/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e Pet Clinic Java ワークショップ",
    "content": "このセクションでは、Spring PetClinicアプリケーションをファイルシステムのファイルにログを書き込むように設定し、 Splunk OpenTelemetry Collectorがそのログファイルを読み取り（tail）、Splunk Observability Platformに情報を報告するように設定していきます。\n1. FluentDの設定 Splunk OpenTelemetry Collectorを、Spring PetClinicのログファイルをtailし Splunk Observability Cloudエンドポイントにデータを報告するように設定する必要があります。\nSplunk OpenTelemetry Collectorは、FluentDを使用してログの取得/報告を行い、 Spring PetClinicのログを報告するための適切な設定を行うには、 デフォルトディレクトリ（/etc/otel/collector/fluentd/conf.d/）にFluentDの設定ファイルを追加するだけです。\n以下は、サンプルのFluentD設定ファイル petclinic.conf を新たに作成し、\nsudo nano /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイル /tmp/spring-petclinic.logを読み取るよう設定を記述します。\n\u003csource\u003e @type tail @label @SPLUNK tag petclinic.app path /tmp/spring-petclinic.log pos_file /tmp/spring-petclinic.pos_file read_from_head false \u003cparse\u003e @type none \u003c/parse\u003e \u003c/source\u003e このとき、ファイル petclinic.conf のアクセス権と所有権を変更する必要があります。\nsudo chown td-agent:td-agent /etc/otel/collector/fluentd/conf.d/petclinic.conf sudo chmod 755 /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイルが作成されたら、FluentDプロセスを再起動しましょう。\nsudo systemctl restart td-agent 3. Logbackの設定 Spring Pet Clinicアプリケーションは、いくつかのJavaログライブラリを使用することができます。 このシナリオでは、logbackを使ってみましょう。\nリソースフォルダに logback.xml という名前のファイルを作成して…\nnano src/main/resources/logback.xml 以下の設定を保存しましょう:\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE xml\u003e \u003cconfiguration scan=\"true\" scanPeriod=\"30 seconds\"\u003e \u003ccontextListener class=\"ch.qos.logback.classic.jul.LevelChangePropagator\"\u003e \u003cresetJUL\u003etrue\u003c/resetJUL\u003e \u003c/contextListener\u003e \u003clogger name=\"org.springframework.samples.petclinic\" level=\"debug\"/\u003e \u003cappender name=\"file\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003cfile\u003e/tmp/spring-petclinic.log\u003c/file\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003cfileNamePattern\u003espringLogFile.%d{yyyy-MM-dd}.log\u003c/fileNamePattern\u003e \u003cmaxHistory\u003e5\u003c/maxHistory\u003e \u003ctotalSizeCap\u003e1GB\u003c/totalSizeCap\u003e \u003c/rollingPolicy\u003e \u003cencoder\u003e \u003cpattern\u003e %d{yyyy-MM-dd HH:mm:ss} - %logger{36} - %msg trace_id=%X{trace_id} span_id=%X{span_id} trace_flags=%X{trace_flags} service.name=%property{otel.resource.service.name}, deployment.environment=%property{otel.resource.deployment.environment} %n \u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003croot level=\"debug\"\u003e \u003cappender-ref ref=\"file\" /\u003e \u003c/root\u003e \u003c/configuration\u003e その後、アプリケーションを再構築して再度実行していきます。\n./mvnw package -Dmaven.test.skip=true java -javaagent:./splunk-otel-javaagent.jar \\ -Dserver.port=8083 \\ -Dotel.service.name=$(hostname).service \\ -Dotel.resource.attributes=deployment.environment=$(hostname),version=0.317 \\ -Dsplunk.profiler.enabled=true \\ -Dsplunk.profiler.memory.enabled=true \\ -Dsplunk.metrics.enabled=true \\ -jar target/spring-petclinic-*.jar --spring.profiles.active=mysql これまで通り、アプリケーション http://\u003cVM_IP_ADDRESS\u003e:8083 にアクセスしてトラフィックを生成すると、ログメッセージが報告されるようになります。\n左側のLog Observerアイコンをクリックして、ホストとSpring PetClinicアプリケーションからのログメッセージのみを選択するためのフィルタを追加できます。\nAdd Filter → Field → host.name → \u003cあなたのホスト名\u003e Add Filter → Field → service.name → \u003cあなたのホスト名\u003e.service 4. まとめ これでワークショップは終了です。 これまでに、Splunk Observability Cloudにメトリクス、トレース、ログ、データベースクエリのパフォーマンス、コードプロファイリングが報告されるようになりました。 おめでとうございます！",
    "description": "このセクションでは、Spring PetClinicアプリケーションをファイルシステムのファイルにログを書き込むように設定し、 Splunk OpenTelemetry Collectorがそのログファイルを読み取り（tail）、Splunk Observability Platformに情報を報告するように設定していきます。\n1. FluentDの設定 Splunk OpenTelemetry Collectorを、Spring PetClinicのログファイルをtailし Splunk Observability Cloudエンドポイントにデータを報告するように設定する必要があります。\nSplunk OpenTelemetry Collectorは、FluentDを使用してログの取得/報告を行い、 Spring PetClinicのログを報告するための適切な設定を行うには、 デフォルトディレクトリ（/etc/otel/collector/fluentd/conf.d/）にFluentDの設定ファイルを追加するだけです。\n以下は、サンプルのFluentD設定ファイル petclinic.conf を新たに作成し、\nsudo nano /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイル /tmp/spring-petclinic.logを読み取るよう設定を記述します。\n\u003csource\u003e @type tail @label @SPLUNK tag petclinic.app path /tmp/spring-petclinic.log pos_file /tmp/spring-petclinic.pos_file read_from_head false \u003cparse\u003e @type none \u003c/parse\u003e \u003c/source\u003e このとき、ファイル petclinic.conf のアクセス権と所有権を変更する必要があります。\nsudo chown td-agent:td-agent /etc/otel/collector/fluentd/conf.d/petclinic.conf sudo chmod 755 /etc/otel/collector/fluentd/conf.d/petclinic.conf ファイルが作成されたら、FluentDプロセスを再起動しましょう。\nsudo systemctl restart td-agent 3. Logbackの設定 Spring Pet Clinicアプリケーションは、いくつかのJavaログライブラリを使用することができます。 このシナリオでは、logbackを使ってみましょう。",
    "tags": [],
    "title": "Log Observer",
    "uri": "/observability-workshop/v5.99/ja/other/pet-clinic/docs/logobserver/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ あなたはフロントエンドエンジニアまたはSREで、パフォーマンス問題の最初のトリアージを行うよう任されています。オンラインブティックアプリケーションに関する潜在的な顧客満足度の問題を調査するよう依頼されました。\nすべての参加者のブラウザセッションから受信したテレメトリによって提供された実際のユーザーデータを調査します。目標は、パフォーマンスの悪かったブラウザ、モバイル、またはタブレットセッションを見つけて、トラブルシューティングプロセスを開始することです。",
    "description": "このセクションでは、エンドユーザーの視点からアプリケーションのパフォーマンスを監視するためにSplunk RUMを使用する方法を理解するのに役立ちます。",
    "tags": [],
    "title": "Splunk RUM",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/5-rum/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk Synthetic Monitoring は、URL、API、重要な Web サービス全体に可視性を提供し、問題をより迅速に解決します。IT オペレーションとエンジニアリングチームは、問題の検出、アラート、優先順位付けを簡単に行い、複数ステップのユーザージャーニーをシミュレートし、新しいコードデプロイメントからのビジネスへの影響を測定し、ステップバイステップのガイド付き推奨事項を使用して Web パフォーマンスを最適化し、より良いデジタルエクスペリエンスを確保できます。\n可用性の確保： ユーザーエクスペリエンスを構成する複数ステップのワークフローをシミュレートするカスタマイズ可能なブラウザテストで、重要なサービス、URL、API の健全性と可用性を事前に監視し、アラートを出します。\nメトリクスの改善： コアウェブバイタルとモダンパフォーマンスメトリクスにより、ユーザーはすべてのパフォーマンス欠陥を 1 か所で表示し、ページ読み込み、インタラクティビティ、視覚的安定性を測定して改善し、JavaScript エラーを見つけて修正してページパフォーマンスを向上させることができます。\nフロントエンドからバックエンドまで： Splunk APM、Infrastructure Monitoring、On-Call、ITSI との統合により、チームはエンドポイントの稼働時間をバックエンドサービス、基盤となるインフラストラクチャ、およびインシデント対応の調整との関連で表示し、単一の UI 内で環境全体をトラブルシューティングできます。\n検出とアラート： エンドユーザー体験を監視してシミュレートし、顧客に影響を与える前に API、サービスエンドポイント、重要なビジネストランザクションの問題を検出、通信、解決します。\nビジネスパフォーマンス： 主要なビジネストランザクションの複数ステップのユーザーフローを簡単に定義し、数分で重要なユーザージャーニーの記録とテストを開始します。稼働時間とパフォーマンスの SLA と SLO を追跡・報告します。\nフィルムストリップとビデオ再生： 画面録画、フィルムストリップ、スクリーンショットを、最新のパフォーマンススコア、競合ベンチマーキング、メトリクスとともに表示して、人工的なエンドユーザー体験を視覚化します。ビジュアルコンテンツを配信する速度を最適化し、ページの安定性とインタラクティビティを向上させて、より良いデジタルエクスペリエンスをデプロイします。",
    "description": "Splunk Synthetic Monitoring は、URL、API、重要な Web サービス全体に可視性を提供し、問題をより迅速に解決します。IT オペレーションとエンジニアリングチームは、問題の検出、アラート、優先順位付けを簡単に行い、複数ステップのユーザージャーニーをシミュレートし、新しいコードデプロイメントからのビジネスへの影響を測定し、ステップバイステップのガイド付き推奨事項を使用して Web パフォーマンスを最適化し、より良いデジタルエクスペリエンスを確保できます。\n可用性の確保： ユーザーエクスペリエンスを構成する複数ステップのワークフローをシミュレートするカスタマイズ可能なブラウザテストで、重要なサービス、URL、API の健全性と可用性を事前に監視し、アラートを出します。\nメトリクスの改善： コアウェブバイタルとモダンパフォーマンスメトリクスにより、ユーザーはすべてのパフォーマンス欠陥を 1 か所で表示し、ページ読み込み、インタラクティビティ、視覚的安定性を測定して改善し、JavaScript エラーを見つけて修正してページパフォーマンスを向上させることができます。\nフロントエンドからバックエンドまで： Splunk APM、Infrastructure Monitoring、On-Call、ITSI との統合により、チームはエンドポイントの稼働時間をバックエンドサービス、基盤となるインフラストラクチャ、およびインシデント対応の調整との関連で表示し、単一の UI 内で環境全体をトラブルシューティングできます。\n検出とアラート： エンドユーザー体験を監視してシミュレートし、顧客に影響を与える前に API、サービスエンドポイント、重要なビジネストランザクションの問題を検出、通信、解決します。\nビジネスパフォーマンス： 主要なビジネストランザクションの複数ステップのユーザーフローを簡単に定義し、数分で重要なユーザージャーニーの記録とテストを開始します。稼働時間とパフォーマンスの SLA と SLO を追跡・報告します。\nフィルムストリップとビデオ再生： 画面録画、フィルムストリップ、スクリーンショットを、最新のパフォーマンススコア、競合ベンチマーキング、メトリクスとともに表示して、人工的なエンドユーザー体験を視覚化します。ビジュアルコンテンツを配信する速度を最適化し、ページの安定性とインタラクティビティを向上させて、より良いデジタルエクスペリエンスをデプロイします。",
    "tags": [],
    "title": "Synthetics概要",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/5-synthetics-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "このワークショップの後半では、.NET アプリケーションを Kubernetes クラスターにデプロイします。\nしかし、どのようにそれを行うのでしょうか？\n最初のステップは、アプリケーション用の Docker イメージを作成することです。これは アプリケーションの「Docker 化」として知られており、プロセスはDockerfileの作成から始まります。\nしかし、まず重要な用語を定義しましょう。\n重要な用語 Docker とは何ですか？ 「Docker は、コンテナと呼ばれる緩い分離環境でアプリケーションをパッケージ化して実行する機能を提供します。分離とセキュリティにより、指定されたホスト上で同時に多くのコンテナを実行できます。コンテナは軽量で、アプリケーションの実行に必要なすべてを含んでいるため、ホストにインストールされているものに依存する必要がありません。」\nソース: https://docs.docker.com/get-started/docker-overview/\nコンテナとは何ですか？ 「コンテナは、アプリのコンポーネントごとの分離されたプロセスです。各コンポーネントは…独自の分離された環境で実行され、マシン上の他のすべてのものから完全に分離されています。」\nソース: https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-a-container/\nコンテナイメージとは何ですか？ 「コンテナイメージは、コンテナを実行するためのすべてのファイル、バイナリ、ライブラリ、および設定を含む標準化されたパッケージです。」\nDockerfile 「Dockerfile は、コンテナイメージを作成するために使用されるテキストベースのドキュメントです。実行するコマンド、コピーするファイル、起動コマンドなどに関するイメージビルダーへの指示を提供します。」\nDockerfile の作成 /home/splunk/workshop/docker-k8s-otel/helloworldディレクトリにDockerfileという名前のファイルを作成しましょう。\ncd /home/splunk/workshop/docker-k8s-otel/helloworld ファイルの作成には vi または nano を使用できます。vi を使用した例を示します：\nvi Dockerfile 新しく開いたファイルに以下の内容をコピー＆ペーストします：\n以下のテキストを貼り付ける前に、vi で「i」を押して挿入モードに入ってください。\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base USER app WORKDIR /app EXPOSE 8080 FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build FROM build AS publish ARG BUILD_CONFIGURATION=Release RUN dotnet publish \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false FROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\"dotnet\", \"helloworld.dll\"] vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\nこれはすべて何を意味するのでしょうか？詳しく見てみましょう。\nDockerfile の詳細解説 この例では、マルチステージ Dockerfile を使用しており、Docker イメージ作成プロセスを以下のステージに分けています：\nBase（ベース） Build（ビルド） Publish（パブリッシュ） Final（最終） マルチステージアプローチはより複雑ですが、デプロイメント用により 軽量なランタイムイメージを作成することができます。以下では、 これらの各ステージの目的を説明します。\nベースステージ ベースステージでは、アプリを実行するユーザー、作業ディレクトリを定義し、 アプリにアクセスするために使用されるポートを公開します。 これは Microsoft のmcr.microsoft.com/dotnet/aspnet:8.0イメージをベースにしています：\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base USER app WORKDIR /app EXPOSE 8080 なお、mcr.microsoft.com/dotnet/aspnet:8.0イメージには.NET runtime のみが含まれており、 SDK は含まれていないため、比較的軽量です。これは Debian 12 Linux distribution がベースになっています。ASP.NET Core Runtime Docker イメージの詳細については GitHubで確認できます。\nBuild ステージ Dockerfile の次のステージは build ステージです。このステージでは、 mcr.microsoft.com/dotnet/sdk:8.0イメージが使用されます。これも Debian 12 がベースになっていますが、 runtime だけでなく完全な.NET SDKが含まれています。\nこのステージでは.csprojファイルを build イメージにコピーし、その後dotnet restoreを使用して アプリケーションが使用する依存関係をダウンロードします。\n次に、アプリケーションコードを build イメージにコピーし、 dotnet buildを使用してプロジェクトとその依存関係を .dllバイナリのセットにビルドします：\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build Publish ステージ 3 番目のステージは publish で、これは Microsoft イメージではなく build ステージイメージをベースにしています。このステージでは、dotnet publishを使用して アプリケーションとその依存関係を deployment 用にパッケージ化します：\nFROM build AS publish ARG BUILD_CONFIGURATION=Release RUN dotnet publish \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false Final ステージ 4 番目のステージは最終ステージで、これは base ステージイメージをベースにしています（build と publish ステージよりも軽量）。publish ステージイメージからの出力をコピーし、 アプリケーションの entry point を定義します：\nFROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\"dotnet\", \"helloworld.dll\"] Docker イメージのビルド Dockerfileができたので、これを使用してアプリケーションを含む Docker イメージを ビルドできます：\n​ Script Example Output docker build -t helloworld:1.0 . DEPRECATED: The legacy builder is deprecated and will be removed in a future release. Install the buildx component to build images with BuildKit: https://docs.docker.com/go/buildx/ Sending build context to Docker daemon 281.1kB Step 1/19 : FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base 8.0: Pulling from dotnet/aspnet af302e5c37e9: Pull complete 91ab5e0aabf0: Pull complete 1c1e4530721e: Pull complete 1f39ca6dcc3a: Pull complete ea20083aa801: Pull complete 64c242a4f561: Pull complete Digest: sha256:587c1dd115e4d6707ff656d30ace5da9f49cec48e627a40bbe5d5b249adc3549 Status: Downloaded newer image for mcr.microsoft.com/dotnet/aspnet:8.0 ---\u003e 0ee5d7ddbc3b Step 2/19 : USER app etc, これは、現在のディレクトリのDockerfileを使用してhelloworld:1.0のタグでイメージをビルドするよう Docker に指示します。\n以下のコマンドで正常に作成されたことを確認できます：\n​ Script Example Output docker images REPOSITORY TAG IMAGE ID CREATED SIZE helloworld 1.0 db19077b9445 20 seconds ago 217MB Docker イメージのテスト 続行する前に、以前に開始したアプリケーションがインスタンス上で実行されていないことを確認してください。\nDocker イメージを使用して以下のようにアプリケーションを実行できます：\ndocker run --name helloworld \\ --detach \\ --expose 8080 \\ --network=host \\ helloworld:1.0 注意：--network=hostパラメータを含めて、Docker コンテナが インスタンス上のリソースにアクセスできるようにしています。これは後でアプリケーションが localhost 上で実行されているコレクターにデータを送信する必要がある場合に重要です。\nDocker コンテナが実行されていることを確認しましょう：\n​ Script Example Output docker ps $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5f5b9cd56ac5 helloworld:1.0 \"dotnet helloworld.d…\" 2 mins ago Up 2 mins helloworld 以前と同様にアプリケーションにアクセスできます：\n​ Script Example Output curl http://localhost:8080/hello/Docker Hello, Docker! おめでとうございます。ここまで到達したということは、.NET アプリケーションの Docker 化に成功したということです。",
    "description": "このワークショップの後半では、.NET アプリケーションを Kubernetes クラスターにデプロイします。\nしかし、どのようにそれを行うのでしょうか？\n最初のステップは、アプリケーション用の Docker イメージを作成することです。これは アプリケーションの「Docker 化」として知られており、プロセスはDockerfileの作成から始まります。\nしかし、まず重要な用語を定義しましょう。\n重要な用語 Docker とは何ですか？ 「Docker は、コンテナと呼ばれる緩い分離環境でアプリケーションをパッケージ化して実行する機能を提供します。分離とセキュリティにより、指定されたホスト上で同時に多くのコンテナを実行できます。コンテナは軽量で、アプリケーションの実行に必要なすべてを含んでいるため、ホストにインストールされているものに依存する必要がありません。」\nソース: https://docs.docker.com/get-started/docker-overview/\nコンテナとは何ですか？ 「コンテナは、アプリのコンポーネントごとの分離されたプロセスです。各コンポーネントは…独自の分離された環境で実行され、マシン上の他のすべてのものから完全に分離されています。」\nソース: https://docs.docker.com/get-started/docker-concepts/the-basics/what-is-a-container/\nコンテナイメージとは何ですか？ 「コンテナイメージは、コンテナを実行するためのすべてのファイル、バイナリ、ライブラリ、および設定を含む標準化されたパッケージです。」\nDockerfile 「Dockerfile は、コンテナイメージを作成するために使用されるテキストベースのドキュメントです。実行するコマンド、コピーするファイル、起動コマンドなどに関するイメージビルダーへの指示を提供します。」\nDockerfile の作成 /home/splunk/workshop/docker-k8s-otel/helloworldディレクトリにDockerfileという名前のファイルを作成しましょう。\ncd /home/splunk/workshop/docker-k8s-otel/helloworld ファイルの作成には vi または nano を使用できます。vi を使用した例を示します：\nvi Dockerfile 新しく開いたファイルに以下の内容をコピー＆ペーストします：\n以下のテキストを貼り付ける前に、vi で「i」を押して挿入モードに入ってください。\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base USER app WORKDIR /app EXPOSE 8080 FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build FROM build AS publish ARG BUILD_CONFIGURATION=Release RUN dotnet publish \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false FROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [\"dotnet\", \"helloworld.dll\"] vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。",
    "tags": [],
    "title": "アプリケーションのDocker化",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/5-dockerize-app/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "エクスポーターは、プッシュまたはプルベースであり、一つ以上のバックエンド/デスティネーションにデータを送信する方法です。エクスポーターは、一つまたは複数のデータソースをサポートすることがあります。\nこのワークショップでは、otlphttp エクスポーターを使用します。OpenTelemetry Protocol (OTLP) は、テレメトリーデータを伝送するためのベンダーニュートラルで標準化されたプロトコルです。OTLP エクスポーターは、OTLP プロトコルを実装するサーバーにデータを送信します。OTLP エクスポーターは、gRPC および HTTP/JSON プロトコルの両方をサポートします。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Exporters fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "エクスポーターは、プッシュまたはプルベースであり、一つ以上のバックエンド/デスティネーションにデータを送信する方法です。エクスポーターは、一つまたは複数のデータソースをサポートすることがあります。\nこのワークショップでは、otlphttp エクスポーターを使用します。OpenTelemetry Protocol (OTLP) は、テレメトリーデータを伝送するためのベンダーニュートラルで標準化されたプロトコルです。OTLP エクスポーターは、OTLP プロトコルを実装するサーバーにデータを送信します。OTLP エクスポーターは、gRPC および HTTP/JSON プロトコルの両方をサポートします。\n%%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; style Exporters fill:#e20082,stroke:#333,stroke-width:4px,color:#fff subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "tags": [],
    "title": "OpenTelemetry Collector エクスポーター",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/5-exporters/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 6. サービス",
    "content": "OTLP HTTP エクスポーター ワークショップのエクスポーターセクションでは、otlphttp エクスポーターを設定して、メトリクスを Splunk Observability Cloud に送信するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の exporters セクションを更新して、otlphttp/splunk を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging, otlphttp/splunk] Ninja: コレクターの内部を観測する コレクターは、その動作に関する内部シグナルを捕捉しています。これには実行中のコンポーネントからの追加されるシグナルも含まれます。これは、データの流れに関する決定を行うコンポーネントが、その情報をメトリクスやトレースとして表面化する方法を必要とするためです。\nなぜコレクターを監視するの？ これは「監視者を監視するのは誰か？」という種類の問題ですが、このような情報を表面化できることは重要です。コレクターの歴史の興味深い部分は、GoメトリクスのSDKが安定と考えられる前に存在していたことで、コレクターは当面の間、この機能を提供するために Prometheus エンドポイントを公開しています。\n注意点 組織内で稼働している各コレクターの内部使用状況を監視することは、新しいメトリクス量（MTS）を大幅な増加させる可能性があります。Splunkディストリビューションはこれらのメトリクスをキュレーションしており、増加を予測するのに役立ちます。\nNinja ゾーン コレクターの内部オブザーバビリティを公開するためには、いくつかの設定を追加することがあります：\n​ telemetry schema example-config.yml service: telemetry: logs: level: \u003cinfo|warn|error\u003e development: \u003ctrue|false\u003e encoding: \u003cconsole|json\u003e disable_caller: \u003ctrue|false\u003e disable_stacktrace: \u003ctrue|false\u003e output_paths: [\u003cstdout|stderr\u003e, paths...] error_output_paths: [\u003cstdout|stderr\u003e, paths...] initial_fields: key: value metrics: level: \u003cnone|basic|normal|detailed\u003e # Address binds the promethues endpoint to scrape address: \u003chostname:port\u003e service: telemetry: logs: level: info encoding: json disable_stacktrace: true initial_fields: instance.name: ${env:INSTANCE} metrics: address: localhost:8888 参照 https://opentelemetry.io/docs/collector/configuration/#service 完成した設定 Check-in完成した設定をレビューしてください ​ config.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 extensions: health_check: endpoint: 0.0.0.0:13133 pprof: endpoint: 0.0.0.0:1777 zpages: endpoint: 0.0.0.0:55679 receivers: hostmetrics: collection_interval: 10s scrapers: # CPU utilization metrics cpu: # Disk I/O metrics disk: # File System utilization metrics filesystem: # Memory utilization metrics memory: # Network interface I/O metrics \u0026 TCP connection metrics network: # CPU load metrics load: # Paging/Swap space utilization and I/O metrics paging: # Process count metrics processes: # Per process CPU, Memory and Disk I/O metrics. Disabled by default. # process: otlp: protocols: grpc: http: opencensus: # Collect own metrics prometheus/internal: config: scrape_configs: - job_name: 'otel-collector' scrape_interval: 10s static_configs: - targets: ['0.0.0.0:8888'] jaeger: protocols: grpc: thrift_binary: thrift_compact: thrift_http: zipkin: processors: batch: resourcedetection/system: detectors: [system] system: hostname_sources: [os] resourcedetection/ec2: detectors: [ec2] attributes/conf: actions: - key: participant.name action: insert value: \"INSERT_YOUR_NAME_HERE\" exporters: logging: verbosity: normal otlphttp/splunk: metrics_endpoint: https://ingest.${env:REALM}.signalfx.com/v2/datapoint/otlp headers: X-SF-TOKEN: ${env:ACCESS_TOKEN} service: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging, otlphttp/splunk] extensions: [health_check, pprof, zpages] ヒント コレクターを再起動する前に、設定ファイルを検証することをお勧めします。これは、組み込みの validate コマンドを使用して行うことができます：\n​ Command Example error output otelcol-contrib validate --config=file:/etc/otelcol-contrib/config.yaml Error: failed to get config: cannot unmarshal the configuration: 1 error(s) decoding: * error decoding 'processors': error reading configuration for \"attributes/conf\": 1 error(s) decoding: * 'actions[0]' has invalid keys: actions 2023/06/29 09:41:28 collector server run finished with error: failed to get config: cannot unmarshal the configuration: 1 error(s) decoding: * error decoding 'processors': error reading configuration for \"attributes/conf\": 1 error(s) decoding: * 'actions[0]' has invalid keys: actions 動作する設定ができたので、コレクターを起動し、その後 zPages が報告している内容を確認しましょう。\n​ Command sudo systemctl restart otelcol-contrib",
    "description": "OTLP HTTP エクスポーター ワークショップのエクスポーターセクションでは、otlphttp エクスポーターを設定して、メトリクスを Splunk Observability Cloud に送信するようにしました。これをメトリクスパイプライン下で有効にする必要があります。\nmetrics パイプラインの下の exporters セクションを更新して、otlphttp/splunk を追加します：\nservice: pipelines: traces: receivers: [otlp, opencensus, jaeger, zipkin] processors: [batch] exporters: [logging] metrics: receivers: [hostmetrics, otlp, opencensus, prometheus/internal] processors: [batch, resourcedetection/system, resourcedetection/ec2, attributes/conf] exporters: [logging, otlphttp/splunk] Ninja: コレクターの内部を観測する コレクターは、その動作に関する内部シグナルを捕捉しています。これには実行中のコンポーネントからの追加されるシグナルも含まれます。これは、データの流れに関する決定を行うコンポーネントが、その情報をメトリクスやトレースとして表面化する方法を必要とするためです。\nなぜコレクターを監視するの？ これは「監視者を監視するのは誰か？」という種類の問題ですが、このような情報を表面化できることは重要です。コレクターの歴史の興味深い部分は、GoメトリクスのSDKが安定と考えられる前に存在していたことで、コレクターは当面の間、この機能を提供するために Prometheus エンドポイントを公開しています。",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/6-service/5-otlphttp/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 6. Splunk APM",
    "content": "トレースアナライザーからトレースウォーターフォールに到達しました。トレースは同じトレース ID を共有するスパンの集まりで、アプリケーションとその構成サービスによって処理される一意のトランザクションを表します。\nSplunk APM の各スパンは、単一の操作をキャプチャします。Splunk APM は、スパンがキャプチャする操作がエラーになった場合、そのスパンをエラースパンとみなします。\n演習 ウォーターフォール内の任意のpaymentservice:grpc.hipstershop.PaymentService/Chargeスパンの横にある!をクリックします。 ​ 質問 回答 スパン詳細で報告されているエラーメッセージとバージョンは何ですか？\nInvalid request（無効なリクエスト）とv350.10です。\n問題を引き起こしているpaymentserviceのバージョンを特定したので、エラーについてさらに詳しい情報が見つかるか確認してみましょう。ここで関連ログの出番です。\n関連コンテンツ(Related Contents)は、APM、インフラストラクチャモニタリング、および Log Observer が可観測性クラウド全体でフィルターを渡すことを可能にする特定のメタデータに依存しています。関連ログが機能するためには、ログに以下のメタデータが必要です：\nservice.name deployment.environment host.name trace_id span_id 演習 トレースウォーターフォールの一番下でLogs (1)をクリックします。これは、このトレースに関連ログがあることを示しています。 ポップアップのLogs for trace xxx（トレース xxx のログ）エントリをクリックすると、Log Observerで完全なトレースのログが開きます。 次に、ログのエラーについてさらに詳しく調べてみましょう。",
    "description": "トレースアナライザーからトレースウォーターフォールに到達しました。トレースは同じトレース ID を共有するスパンの集まりで、アプリケーションとその構成サービスによって処理される一意のトランザクションを表します。\nSplunk APM の各スパンは、単一の操作をキャプチャします。Splunk APM は、スパンがキャプチャする操作がエラーになった場合、そのスパンをエラースパンとみなします。\n演習 ウォーターフォール内の任意のpaymentservice:grpc.hipstershop.PaymentService/Chargeスパンの横にある!をクリックします。 ​ 質問 回答 スパン詳細で報告されているエラーメッセージとバージョンは何ですか？\nInvalid request（無効なリクエスト）とv350.10です。\n問題を引き起こしているpaymentserviceのバージョンを特定したので、エラーについてさらに詳しい情報が見つかるか確認してみましょう。ここで関連ログの出番です。\n関連コンテンツ(Related Contents)は、APM、インフラストラクチャモニタリング、および Log Observer が可観測性クラウド全体でフィルターを渡すことを可能にする特定のメタデータに依存しています。関連ログが機能するためには、ログに以下のメタデータが必要です：\nservice.name deployment.environment host.name trace_id span_id 演習 トレースウォーターフォールの一番下でLogs (1)をクリックします。これは、このトレースに関連ログがあることを示しています。 ポップアップのLogs for trace xxx（トレース xxx のログ）エントリをクリックすると、Log Observerで完全なトレースのログが開きます。",
    "tags": [],
    "title": "6. APMウォーターフォール",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/6-apm/6-apm-waterfall/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "アプリケーションを正常に Docker 化したので、次に OpenTelemetry による計装 を追加しましょう。\nこれは、Linux で実行しているアプリケーションを計装した際の手順と似ていますが、 注意すべきいくつかの重要な違いがあります。\nDockerfile の更新 /home/splunk/workshop/docker-k8s-otel/helloworldディレクトリのDockerfileを更新しましょう。\nDockerfile で.NET アプリケーションがビルドされた後、以下の操作を行いたいと思います：\nsplunk-otel-dotnet-install.shをダウンロードして実行するために必要な依存関係を追加する Splunk OTel .NET インストーラーをダウンロードする ディストリビューションをインストールする Dockerfile のビルドステージに以下を追加できます。vi で Dockerfile を開きましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile vi では「i」キーを押して編集モードに入ります ‘NEW CODE’とマークされている行を Dockerfile のビルドステージセクションに貼り付けてください：\n# CODE ALREADY IN YOUR DOCKERFILE: FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build # NEW CODE: add dependencies for splunk-otel-dotnet-install.sh RUN apt-get update \u0026\u0026 \\ apt-get install -y unzip # NEW CODE: download Splunk OTel .NET installer RUN curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O # NEW CODE: install the distribution RUN sh ./splunk-otel-dotnet-install.sh 次に、以下の変更で Dockerfile の最終ステージを更新します：\nビルドイメージから最終イメージに/root/.splunk-otel-dotnet/をコピーする entrypoint.sh ファイルもコピーする OTEL_SERVICE_NAMEとOTEL_RESOURCE_ATTRIBUTES環境変数を設定する ENTRYPOINTをentrypoint.shに設定する 最も簡単な方法は、最終ステージ全体を以下の内容で置き換えることです：\n重要 Dockerfile の$INSTANCEをあなたのインスタンス名に置き換えてください。 インスタンス名はecho $INSTANCEを実行することで確認できます。\n# CODE ALREADY IN YOUR DOCKERFILE FROM base AS final # NEW CODE: Copy instrumentation file tree WORKDIR \"//home/app/.splunk-otel-dotnet\" COPY --from=build /root/.splunk-otel-dotnet/ . # CODE ALREADY IN YOUR DOCKERFILE WORKDIR /app COPY --from=publish /app/publish . # NEW CODE: copy the entrypoint.sh script COPY entrypoint.sh . # NEW CODE: set OpenTelemetry environment variables ENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' # NEW CODE: replace the prior ENTRYPOINT command with the following two lines ENTRYPOINT [\"sh\", \"entrypoint.sh\"] CMD [\"dotnet\", \"helloworld.dll\"] vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\nこれらすべての変更の後、Dockerfile は以下のようになるはずです：\n重要 このコンテンツを自分の Dockerfile にコピー＆ペーストする場合は、 Dockerfile の$INSTANCEをあなたのインスタンス名に置き換えてください。 インスタンス名はecho $INSTANCEを実行することで確認できます。\nFROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base USER app WORKDIR /app EXPOSE 8080 FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build # NEW CODE: add dependencies for splunk-otel-dotnet-install.sh RUN apt-get update \u0026\u0026 \\ apt-get install -y unzip # NEW CODE: download Splunk OTel .NET installer RUN curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O # NEW CODE: install the distribution RUN sh ./splunk-otel-dotnet-install.sh FROM build AS publish ARG BUILD_CONFIGURATION=Release RUN dotnet publish \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false FROM base AS final # NEW CODE: Copy instrumentation file tree WORKDIR \"//home/app/.splunk-otel-dotnet\" COPY --from=build /root/.splunk-otel-dotnet/ . WORKDIR /app COPY --from=publish /app/publish . # NEW CODE: copy the entrypoint.sh script COPY entrypoint.sh . # NEW CODE: set OpenTelemetry environment variables ENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' # NEW CODE: replace the prior ENTRYPOINT command with the following two lines ENTRYPOINT [\"sh\", \"entrypoint.sh\"] CMD [\"dotnet\", \"helloworld.dll\"] entrypoint.sh ファイルの作成 また、/home/splunk/workshop/docker-k8s-otel/helloworldフォルダにentrypoint.shという名前のファイルを 以下の内容で作成する必要があります：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/entrypoint.sh 次に、新しく作成したファイルに以下のコードを貼り付けます：\n#!/bin/sh # Read in the file of environment settings . /$HOME/.splunk-otel-dotnet/instrument.sh # Then run the CMD exec \"$@\" vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\nentrypoint.shスクリプトは、計装に含まれる instrument.sh スクリプトが環境変数をコンテナ起動時に取得するために必要です。これにより、各プラットフォームに対して環境変数が正しく設定されることが保証されます。\n「なぜ Linux ホスト上で OpenTelemetry .NET instrumentation を有効化したときのように、 Dockerfile に以下のコマンドを含めるだけではだめなのか？」と疑問に思うかもしれません。\nRUN . $HOME/.splunk-otel-dotnet/instrument.sh この方法の問題点は、各 Dockerfile RUN ステップが新しいコンテナと新しいシェルで実行されることです。 あるシェルで環境変数を設定しようとしても、後で見ることはできません。 この問題は、ここで行ったようにエントリポイントスクリプトを使用することで解決されます。 この問題についての詳細は、こちらのStack Overflow の投稿を参照してください。\nDocker イメージのビルド OpenTelemetry .NET instrumentation を含む新しい Docker イメージをビルドしましょう：\ndocker build -t helloworld:1.1 . 注：以前のバージョンと区別するために、異なるバージョン（1.1）を使用しています。 古いバージョンをクリーンアップするには、以下のコマンドでコンテナ ID を取得します：\ndocker ps -a 次に、以下のコマンドでコンテナを削除します：\ndocker rm \u003cold container id\u003e --force 次にコンテナイメージ ID を取得します：\ndocker images | grep 1.0 最後に、以下のコマンドで古いイメージを削除できます：\ndocker image rm \u003cold image id\u003e アプリケーションの実行 新しい Docker イメージを実行しましょう：\ndocker run --name helloworld \\ --detach \\ --expose 8080 \\ --network=host \\ helloworld:1.1 以下を使用してアプリケーションにアクセスできます：\ncurl http://localhost:8080/hello トラフィックを生成するために上記のコマンドを数回実行しましょう。\n1 分ほど経過したら、Splunk Observability Cloud に新しいトレースが表示されることを確認します。\nあなたの特定の環境でトレースを探すことを忘れないでください。\nトラブルシューティング Splunk Observability Cloud にトレースが表示されない場合は、以下のようにトラブルシューティングを行うことができます。\nまず、コレクター設定ファイルを編集用に開きます：\nsudo vi /etc/otel/collector/agent_config.yaml 次に、トレースパイプラインにデバッグエクスポーターを追加します。これにより、トレースがコレクターログに書き込まれるようになります：\nservice: extensions: [health_check, http_forwarder, zpages, smartagent] pipelines: traces: receivers: [jaeger, otlp, zipkin] processors: - memory_limiter - batch - resourcedetection #- resource/add_environment # NEW CODE: デバッグエクスポーターをここに追加 exporters: [otlphttp, signalfx, debug] その後、コレクターを再起動して設定変更を適用します：\nsudo systemctl restart splunk-otel-collector journalctlを使用してコレクターログを表示できます：\nログの追跡を終了するには、Ctrl + C を押します。\nsudo journalctl -u splunk-otel-collector -f -n 100",
    "description": "アプリケーションを正常に Docker 化したので、次に OpenTelemetry による計装 を追加しましょう。\nこれは、Linux で実行しているアプリケーションを計装した際の手順と似ていますが、 注意すべきいくつかの重要な違いがあります。\nDockerfile の更新 /home/splunk/workshop/docker-k8s-otel/helloworldディレクトリのDockerfileを更新しましょう。\nDockerfile で.NET アプリケーションがビルドされた後、以下の操作を行いたいと思います：\nsplunk-otel-dotnet-install.shをダウンロードして実行するために必要な依存関係を追加する Splunk OTel .NET インストーラーをダウンロードする ディストリビューションをインストールする Dockerfile のビルドステージに以下を追加できます。vi で Dockerfile を開きましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile vi では「i」キーを押して編集モードに入ります ‘NEW CODE’とマークされている行を Dockerfile のビルドステージセクションに貼り付けてください：\n# CODE ALREADY IN YOUR DOCKERFILE: FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build ARG BUILD_CONFIGURATION=Release WORKDIR /src COPY [\"helloworld.csproj\", \"helloworld/\"] RUN dotnet restore \"./helloworld/./helloworld.csproj\" WORKDIR \"/src/helloworld\" COPY . . RUN dotnet build \"./helloworld.csproj\" -c $BUILD_CONFIGURATION -o /app/build # NEW CODE: add dependencies for splunk-otel-dotnet-install.sh RUN apt-get update \u0026\u0026 \\ apt-get install -y unzip # NEW CODE: download Splunk OTel .NET installer RUN curl -sSfL https://github.com/signalfx/splunk-otel-dotnet/releases/latest/download/splunk-otel-dotnet-install.sh -O # NEW CODE: install the distribution RUN sh ./splunk-otel-dotnet-install.sh 次に、以下の変更で Dockerfile の最終ステージを更新します：",
    "tags": [],
    "title": "Dockerfileに計装を追加する",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/6-add-instrumentation-to-dockerfile/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ あなたはバックエンド開発者で、SRE が発見した問題の調査を手伝うよう依頼されました。SRE はユーザーエクスペリエンスの低下を特定し、あなたにその問題を調査するよう依頼しました。\nRUM トレース（フロントエンド）から APM トレース（バックエンド）にジャンプすることで、完全なエンドツーエンドの可視性の力を発見します。すべてのサービスはテレメトリ（トレースとスパン）を送信しており、Splunk Observability Cloud はこれを視覚化、分析し、異常やエラーを検出するために使用できます。\nRUM と APM は同じコインの表と裏です。RUM はアプリケーションのクライアント側からの視点であり、APM はサーバー側からの視点です。このセクションでは、APM を使用して掘り下げ、問題がどこにあるかを特定します。",
    "description": "このセクションでは、APMを使用して掘り下げ、問題がどこにあるかを特定します。",
    "tags": [],
    "title": "Splunk APM",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/6-apm/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "ログの外部でコンテキスト伝播の結果を確認するために、もう一度Splunk APM UIを参照します。\nSplunk APM サービスマップで Lambda 関数を表示する もう一度 APM で環境のサービスマップを確認してみましょう。\nSplunk Observability Cloud で：\nメインメニューのAPMボタンをクリックします。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 概要ページの右側にあるService Mapボタンをクリックします。これによりサービスマップビューに移動します。\n\u003e 注意：トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください ワークショップの質問 違いに気づきましたか？\n今回は、伝播されたコンテキストによってリンクされたproducer-lambdaとconsumer-lambda関数が見えるはずです！ トレース ID で Lambda トレースを調査する 次に、環境に関連するトレースをもう一度確認します。\nコンシューマー関数のログからコピーしたトレース ID を、Traces 下のView Trace ID検索ボックスに貼り付け、Goをクリックします メモ トレース ID は、私たちが伝播したトレースコンテキストの一部でした。\n最も一般的な 2 つの伝播規格について読むことができます：\nW3C B3 ワークショップの質問 私たちはどちらを使用していますか？\n私たちの NodeJS 関数をサポートする Splunk Distribution of Opentelemetry JS は、デフォルトでW3C標準を使用しています ワークショップの質問 ボーナス質問：W3C ヘッダーと B3 ヘッダーを混在させるとどうなりますか？\nconsumer-lambdaスパンをクリックしてください。\nワークショップの質問 あなたのメッセージからの属性を見つけることができますか？\nクリーンアップ いよいよワークショップの最後に来ました。後片付けをしましょう！\nsend_messageの停止 send_message.pyスクリプトがまだ実行中の場合は、次のコマンドで停止します：\nfg これによりバックグラウンドプロセスがフォアグラウンドに移動します。 次に[CONTROL-C]を押してプロセスを終了できます。 すべての AWS リソースを破棄する Terraform は個々のリソースの状態をデプロイメントとして管理するのに優れています。定義に変更があっても、デプロイされたリソースを更新することもできます。しかし、一からやり直すために、リソースを破棄し、このワークショップの手動計装部分の一部として再デプロイします。\n以下の手順に従ってリソースを破棄してください：\nmanualディレクトリにいることを確認します：\npwd 予想される出力は ~/o11y-lambda-workshop/manual です manualディレクトリにいない場合は、次のコマンドを実行します：\ncd ~/o11y-lambda-workshop/manual 以前にデプロイした Lambda 関数とその他の AWS リソースを破棄します：\nterraform destroy Enter a value:プロンプトが表示されたらyesと応答します これにより、リソースが破棄され、クリーンな環境が残ります",
    "description": "ログの外部でコンテキスト伝播の結果を確認するために、もう一度Splunk APM UIを参照します。\nSplunk APM サービスマップで Lambda 関数を表示する もう一度 APM で環境のサービスマップを確認してみましょう。\nSplunk Observability Cloud で：\nメインメニューのAPMボタンをクリックします。\nEnvironment:ドロップダウンからあなたの APM 環境を選択します。\nAPM 概要ページの右側にあるService Mapボタンをクリックします。これによりサービスマップビューに移動します。\n\u003e 注意：トレースが Splunk APM に表示されるまで数分かかる場合があります。環境のリストにあなたの環境名が表示されるまで、ブラウザの更新ボタンを押してみてください ワークショップの質問 違いに気づきましたか？\n今回は、伝播されたコンテキストによってリンクされたproducer-lambdaとconsumer-lambda関数が見えるはずです！ トレース ID で Lambda トレースを調査する 次に、環境に関連するトレースをもう一度確認します。\nコンシューマー関数のログからコピーしたトレース ID を、Traces 下のView Trace ID検索ボックスに貼り付け、Goをクリックします",
    "tags": [],
    "title": "Splunk APM、Lambda関数とトレース、再び！",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/6-updated-lambdas/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "Service セクションでは、レシーバー、プロセッサー、エクスポーター、およびエクステンションにある設定に基づいて、コレクターで有効にするコンポーネントを設定していきます。\n情報 コンポーネントが設定されていても、Service セクション内で定義されていない場合、そのコンポーネントは有効化されません。\nサービスのセクションは、以下の3つのサブセクションで構成されています：\nextensions（拡張機能） pipelines（パイプライン） telemetry（テレメトリー） デフォルトの設定では、拡張機能セクションが health_check、pprof、zpages を有効にするように設定されており、これらは以前のエクステンションのモジュールで設定しました。\nservice: extensions: [health_check, pprof, zpages] それでは、メトリックパイプラインを設定していきましょう！",
    "description": "Service セクションでは、レシーバー、プロセッサー、エクスポーター、およびエクステンションにある設定に基づいて、コレクターで有効にするコンポーネントを設定していきます。\n情報 コンポーネントが設定されていても、Service セクション内で定義されていない場合、そのコンポーネントは有効化されません。\nサービスのセクションは、以下の3つのサブセクションで構成されています：\nextensions（拡張機能） pipelines（パイプライン） telemetry（テレメトリー） デフォルトの設定では、拡張機能セクションが health_check、pprof、zpages を有効にするように設定されており、これらは以前のエクステンションのモジュールで設定しました。\nservice: extensions: [health_check, pprof, zpages] それでは、メトリックパイプラインを設定していきましょう！",
    "tags": [],
    "title": "OpenTelemetry Collector サービス",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/6-service/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー",
    "content": "Splunk Infrastructure Monitoring（IM）は、ハイブリッドクラウド環境向けの市場をリードする監視および可観測性サービスです。特許取得済みのストリーミングアーキテクチャに基づいて構築されており、従来のソリューションよりもはるかに短時間で、より高い精度でインフラストラクチャ、サービス、アプリケーション全体のパフォーマンスを視覚化および分析するためのリアルタイムソリューションをエンジニアリングチームに提供します。\nOpenTelemetry 標準化： データの完全な制御を提供し、ベンダーロックインから解放し、独自のエージェントの実装から解放します。\nSplunk の OTel コレクター： シームレスなインストールと動的な構成により、スタック全体を数秒で自動検出し、クラウド、サービス、システム全体の可視性を提供します。\n300 以上の使いやすい標準コンテンツ： 事前構築されたナビゲーターとダッシュボードにより、環境全体の即時の視覚化を提供し、すべてのデータとリアルタイムで対話できます。\nKubernetes ナビゲーター： ノード、ポッド、コンテナの包括的な標準的な階層ビューを即座に提供します。わかりやすいインタラクティブなクラスターマップで、最も初心者の Kubernetes ユーザーでもすぐに使いこなせます。\nAutoDetect アラートとディテクター： 最も重要なメトリクスを標準で自動的に識別し、テレメトリデータが取り込まれた瞬間から正確にアラートを出すディテクターのアラート条件を作成し、重要な通知のために数秒でリアルタイムのアラート機能を使用します。\nダッシュボード内のログビュー： 共通のフィルターと時間制御を使用して、ログメッセージとリアルタイムメトリクスを 1 ページに組み合わせ、より迅速なコンテキスト内トラブルシューティングを実現します。\nメトリクスパイプライン管理： 再計装なしに取り込み時点でメトリクスの量を制御し、必要なデータのみを保存して分析するための集約およびデータ削除ルールのセットを使用します。メトリクスの量を削減し、可観測性のコストを最適化します。",
    "description": "Splunk Infrastructure Monitoring（IM）は、ハイブリッドクラウド環境向けの市場をリードする監視および可観測性サービスです。特許取得済みのストリーミングアーキテクチャに基づいて構築されており、従来のソリューションよりもはるかに短時間で、より高い精度でインフラストラクチャ、サービス、アプリケーション全体のパフォーマンスを視覚化および分析するためのリアルタイムソリューションをエンジニアリングチームに提供します。\nOpenTelemetry 標準化： データの完全な制御を提供し、ベンダーロックインから解放し、独自のエージェントの実装から解放します。\nSplunk の OTel コレクター： シームレスなインストールと動的な構成により、スタック全体を数秒で自動検出し、クラウド、サービス、システム全体の可視性を提供します。\n300 以上の使いやすい標準コンテンツ： 事前構築されたナビゲーターとダッシュボードにより、環境全体の即時の視覚化を提供し、すべてのデータとリアルタイムで対話できます。\nKubernetes ナビゲーター： ノード、ポッド、コンテナの包括的な標準的な階層ビューを即座に提供します。わかりやすいインタラクティブなクラスターマップで、最も初心者の Kubernetes ユーザーでもすぐに使いこなせます。\nAutoDetect アラートとディテクター： 最も重要なメトリクスを標準で自動的に識別し、テレメトリデータが取り込まれた瞬間から正確にアラートを出すディテクターのアラート条件を作成し、重要な通知のために数秒でリアルタイムのアラート機能を使用します。\nダッシュボード内のログビュー： 共通のフィルターと時間制御を使用して、ログメッセージとリアルタイムメトリクスを 1 ページに組み合わせ、より迅速なコンテキスト内トラブルシューティングを実現します。\nメトリクスパイプライン管理： 再計装なしに取り込み時点でメトリクスの量を制御し、必要なデータのみを保存して分析するための集約およびデータ削除ルールのセットを使用します。メトリクスの量を削減し、可観測性のコストを最適化します。",
    "tags": [],
    "title": "インフラストラクチャ概要",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/6-infrastructure-home/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops",
    "content": "このワークショップでは、AWS Lambda で実行される小規模なサーバーレスアプリケーションの分散トレースを構築し、AWS Kinesis を介してメッセージを produce および consume する方法を学びます。\nまず、OpenTelemetry の自動計装がどのようにトレースをキャプチャし、選択した宛先にエクスポートするかを確認します。\n次に、手動計装によってコンテキスト伝播を有効にする方法を見ていきます。\nこのワークショップのために、Splunk は AWS/EC2 上の Ubuntu Linux インスタンスを事前に構成しています。このインスタンスにアクセスするには、ワークショップインストラクターが提供する URL にアクセスしてください。",
    "description": "このワークショップでは、AWS Lambdaで実行される小規模なサーバーレスアプリケーションの分散トレースを構築し、AWS Kinesisを介してメッセージをproduceおよびconsumeする方法を学びます",
    "tags": [],
    "title": "AWS Lambda関数の分散トレーシング",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "ワークショップパート 1 の振り返り ワークショップのこの時点で、以下を正常に完了しました：\nLinux ホストに Splunk distribution of OpenTelemetry コレクターをデプロイ Splunk Observability Cloud にトレースとメトリクスを送信するよう設定 .NET アプリケーションをデプロイし、OpenTelemetry で計装 .NET アプリケーションを Docker 化し、o11y cloud にトレースが流れることを確認 上記のステップを完了していない場合は、ワークショップの残りの部分に進む前に以下のコマンドを実行してください：\ncp /home/splunk/workshop/docker-k8s-otel/docker/Dockerfile /home/splunk/workshop/docker-k8s-otel/helloworld/ cp /home/splunk/workshop/docker-k8s-otel/docker/entrypoint.sh /home/splunk/workshop/docker-k8s-otel/helloworld/ 重要 これらのファイルがコピーされたら、/home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile を エディターで開き、Dockerfile の $INSTANCE をあなたのインスタンス名に置き換えてください。 インスタンス名は echo $INSTANCE を実行することで確認できます。\nワークショップパート 2 の紹介 ワークショップの次の部分では、Kubernetes でアプリケーションを実行したいと思います。 そのため、Kubernetes クラスターに Splunk distribution of OpenTelemetry コレクターを デプロイする必要があります。\nまず、いくつかの重要な用語を定義しましょう。\n重要な用語 Kubernetes とは何ですか？ 「Kubernetes は、宣言的な設定と自動化の両方を促進する、コンテナ化されたワークロードとサービスを管理するためのポータブルで拡張可能なオープンソースプラットフォームです。」\nSource: https://kubernetes.io/docs/concepts/overview/\nDockerfile に小さな修正を加えた後、アプリケーション用に以前ビルドした Docker イメージを Kubernetes クラスターにデプロイします。\nHelm とは何ですか？ Helm は Kubernetes 用のパッケージマネージャーです。\n「最も複雑な Kubernetes アプリケーションだとしても、定義、インストール、アップグレード役立ちます」\nHelm を使用したコレクターのインストール プロダクト内ウィザードではなくコマンドラインを使用して、コレクターをインストールするための独自の helmコマンドを作成しましょう。\nまず、helm リポジトリを追加する必要があります：ます。」\nSource: https://helm.sh/\nHelm を使用して K8s クラスターに OpenTelemetry コレクターをデプロイします。\nHelm の利点 複雑性の管理 数十のマニフェストファイルではなく、単一の values.yaml ファイルを扱う 簡単な更新 インプレースアップグレード ロールバックサポート helm rollback を使用してリリースの古いバージョンにロールバック ホストコレクターのアンインストール 先に進む前に、Linux ホストに先ほどインストールしたコレクターを削除しましょう： \\\ncurl -sSL https://dl.signalfx.com/splunk-otel-collector.sh \u003e /tmp/splunk-otel-collector.sh; sudo sh /tmp/splunk-otel-collector.sh --uninstall Helm を利用して Collector をインストールする ウィザードの代わりに、コマンドラインを利用して collector をインストールします。\nまず初めに、Helm リポジトリに登録する必要があります\nhelm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart リポジトリが最新であることを確認します：\nhelm repo update helm チャートのデプロイメントを設定するために、/home/splunkディレクトリにvalues.yamlという名前の新しいファイルを作成しましょう：\n# swith to the /home/splunk dir cd /home/splunk # create a values.yaml file in vi vi values.yaml Press ‘i’ to enter into insert mode in vi before pasting the text below.　“i\"を押下すると vi はインサートモードになります。ペースト前に押下してください\nそして、下記のコードをコピーしてください\nlogsEngine: otel agent: config: receivers: hostmetrics: collection_interval: 10s root_path: /hostfs scrapers: cpu: null disk: null filesystem: exclude_mount_points: match_type: regexp mount_points: - /var/* - /snap/* - /boot/* - /boot - /opt/orbstack/* - /mnt/machines/* - /Users/* load: null memory: null network: null paging: null processes: null vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n次のコマンドを使用してコレクターをインストールできます：\n​ Script Example Output helm install splunk-otel-collector --version 0.111.0 \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector NAME: splunk-otel-collector LAST DEPLOYED: Fri Dec 20 01:01:43 2024 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Observability realm us1. コレクターが実行中であることを確認 以下のコマンドでコレクターが実行されているかどうかを確認できます：\n​ Script Example Output kubectl get pods NAME READY STATUS RESTARTS AGE splunk-otel-collector-agent-8xvk8 1/1 Running 0 49s splunk-otel-collector-k8s-cluster-receiver-d54857c89-tx7qr 1/1 Running 0 49s O11y Cloud で K8s クラスターを確認 Splunk Observability Cloud で、Infrastructure -\u003e Kubernetes -\u003e Kubernetes Clustersにナビゲートし、 クラスター名（$INSTANCE-cluster）を検索します：",
    "description": "ワークショップパート 1 の振り返り ワークショップのこの時点で、以下を正常に完了しました：\nLinux ホストに Splunk distribution of OpenTelemetry コレクターをデプロイ Splunk Observability Cloud にトレースとメトリクスを送信するよう設定 .NET アプリケーションをデプロイし、OpenTelemetry で計装 .NET アプリケーションを Docker 化し、o11y cloud にトレースが流れることを確認 上記のステップを完了していない場合は、ワークショップの残りの部分に進む前に以下のコマンドを実行してください：\ncp /home/splunk/workshop/docker-k8s-otel/docker/Dockerfile /home/splunk/workshop/docker-k8s-otel/helloworld/ cp /home/splunk/workshop/docker-k8s-otel/docker/entrypoint.sh /home/splunk/workshop/docker-k8s-otel/helloworld/ 重要 これらのファイルがコピーされたら、/home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile を エディターで開き、Dockerfile の $INSTANCE をあなたのインスタンス名に置き換えてください。 インスタンス名は echo $INSTANCE を実行することで確認できます。\nワークショップパート 2 の紹介 ワークショップの次の部分では、Kubernetes でアプリケーションを実行したいと思います。 そのため、Kubernetes クラスターに Splunk distribution of OpenTelemetry コレクターを デプロイする必要があります。\nまず、いくつかの重要な用語を定義しましょう。\n重要な用語 Kubernetes とは何ですか？ 「Kubernetes は、宣言的な設定と自動化の両方を促進する、コンテナ化されたワークロードとサービスを管理するためのポータブルで拡張可能なオープンソースプラットフォームです。」\nSource: https://kubernetes.io/docs/concepts/overview/\nDockerfile に小さな修正を加えた後、アプリケーション用に以前ビルドした Docker イメージを Kubernetes クラスターにデプロイします。",
    "tags": [],
    "title": "K8sでOpenTelemetryコレクターをインストール",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/7-install-collector-k8s/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ バックエンド開発者の役割を継続して、アプリケーションのログを調査して問題の根本原因を特定する必要があります。\nAPM トレースに関連するコンテンツ（ログ）を使用して、Splunk Log Observer でさらに掘り下げ、問題が正確に何であるかを理解します。\n関連コンテンツは、あるコンポーネントから別のコンポーネントにジャンプできる強力な機能で、メトリクス、トレース、ログで利用可能です。",
    "description": "このセクションでは、Log Observerを使用して掘り下げ、問題が何かを特定します。",
    "tags": [],
    "title": "Splunk Log Observer",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/7-log-observer/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "Splunk Observability Cloud OpenTelemetry Collector を設定して Splunk Observability Cloud にメトリクスを送信するようにしたので、Splunk Observability Cloud でデータを見てみましょう。Splunk Observability Cloud　への招待を受け取っていない場合は、講師がログイン資格情報を提供します。\nその前に、もう少し興味深くするために、インスタンスでストレステストを実行しましょう。これにより、ダッシュボードが活性化されます。\nsudo apt install stress while true; do stress -c 2 -t 40; stress -d 5 -t 40; stress -m 20 -t 40; done Splunk Observability Cloudにログインしたら、左側のナビゲーションを使用して Dashboards に移動します：\n検索ボックスで OTel Contrib を検索します：\n情報 ダッシュボードが存在しない場合は、講師が迅速に追加します。このワークショップの Splunk 主催版に参加していない場合、インポートするダッシュボードグループはこのページの下部にあります。\nOTel Contrib Dashboard ダッシュボードをクリックして開きます：\nダッシュボードの上部にある Filter 欄に「participant」の途中まで入力し、候補に出る participant.name を選択します：\nparticipant.name で、config.yaml 内で設定したあなたの名前を入力するか、リストから選択することができます：\nこれで、OpenTelemetry Collector を設定したホストの、ホストメトリクスを確認することができます。\nダッシュボードJSONのダウンロード方法 index.files/dashboard_OTel-Contrib-Dashboard.json (40 KB)",
    "description": "Splunk Observability Cloud OpenTelemetry Collector を設定して Splunk Observability Cloud にメトリクスを送信するようにしたので、Splunk Observability Cloud でデータを見てみましょう。Splunk Observability Cloud　への招待を受け取っていない場合は、講師がログイン資格情報を提供します。\nその前に、もう少し興味深くするために、インスタンスでストレステストを実行しましょう。これにより、ダッシュボードが活性化されます。\nsudo apt install stress while true; do stress -c 2 -t 40; stress -d 5 -t 40; stress -m 20 -t 40; done Splunk Observability Cloudにログインしたら、左側のナビゲーションを使用して Dashboards に移動します：\n検索ボックスで OTel Contrib を検索します：\n情報 ダッシュボードが存在しない場合は、講師が迅速に追加します。このワークショップの Splunk 主催版に参加していない場合、インポートするダッシュボードグループはこのページの下部にあります。",
    "tags": [],
    "title": "データの可視化",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/7-visualisation/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e Lambdaトレーシング",
    "content": "Lambda Tracing ワークショップを終えたことをおめでとうございます！自動計装を手動のステップで補完して、producer-lambda関数のコンテキストを Kinesis ストリーム内のレコードを介してconsumer-lambda関数に送信する方法を見てきました。これにより、期待される分散トレースを構築し、Splunk APM で両方の関数間の関係をコンテキスト化することができました。\nこれで、2 つの異なる関数を手動でリンクしてトレースを構築することができます。これは、自動計装や第三者のシステムがコンテキスト伝播を標準でサポートしていない場合や、より関連性の高いトレース分析のためにカスタム属性をトレースに追加したい場合に役立ちます。",
    "description": "Lambda Tracing ワークショップを終えたことをおめでとうございます！自動計装を手動のステップで補完して、producer-lambda関数のコンテキストを Kinesis ストリーム内のレコードを介してconsumer-lambda関数に送信する方法を見てきました。これにより、期待される分散トレースを構築し、Splunk APM で両方の関数間の関係をコンテキスト化することができました。\nこれで、2 つの異なる関数を手動でリンクしてトレースを構築することができます。これは、自動計装や第三者のシステムがコンテキスト伝播を標準でサポートしていない場合や、より関連性の高いトレース分析のためにカスタム属性をトレースに追加したい場合に役立ちます。",
    "tags": [],
    "title": "結論",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/6-lambda-kinesis/7-summary/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector",
    "content": "カスタムコンポーネントの開発 Open Telemetry Collectorのためのコンポーネントを構築するには、以下の3つの主要な部分が必要です：\nConfiguration - ユーザーが設定できる値は何か Factory - 提供された値を使ってコンポーネントを作成する Business Logic - コンポーネントが実行する必要があること これについて、プロジェクトの重要なDevOpsメトリクスを追跡するためにJenkinsと連携するコンポーネントを構築する例を考えていきます。\n測定しようとしているメトリクスは次のとおりです：\n変更に対するリードタイム - 「コミットが本番環境に入るまでにかかる時間」 変更失敗率 - 「本番環境での障害を引き起こすデプロイの割合」 デプロイ頻度 - 「[チーム]が本番環境に成功してリリースする頻度」 平均復旧時間 - 「[チーム]が本番環境の障害から復旧するのにかかる時間」 これらの指標は Google の DevOps Research and Assessment (DORA) チームによって特定されたもので、ソフトウェア開発チームのパフォーマンスを示すのに役立ちます。Jenkins CI を選択した理由は、私たちが同じオープンソースソフトウェアエコシステムに留まり、将来的にベンダー管理のCIツールが採用する例となることができるためです。\n計装 🆚 コンポーネント 組織内でオブザーバビリティを向上させる際には、トレードオフが発生するため、考慮する点があります。\n長所 短所 （自動）計装1 システムを観測するために外部APIが不要 計装を変更するにはプロジェクトの変更が必要 システム所有者/開発者は可観測性の変更が可能 ランタイムへの追加の依存が必要 システムの文脈を理解し、Exemplar とキャプチャされたデータを関連付けることが可能 システムのパフォーマンスに影響を与える可能性がある コンポーネント データ名や意味の変更をシステムのリリースサイクルから独立した展開が可能 APIの破壊的な変更の可能性があり、システムとコレクター間でリリースの調整が必要 その後の利用に合わせて収集されるデータの更新/拡張が容易 キャプチャされたデータの意味がシステムリリースと一致せず、予期せず壊れる可能性がある 計装（instrument, インストゥルメント）とは、アプリケーションなどのシステムコンポーネントに対して、トレースやメトリクス、ログなどのテレメトリーデータを出力させる実装。計装ライブラリを最低限セットアップするだけで一通りのトレースやメトリクスなどを出力できるような対応を「自動計装」と呼びます。 ↩︎",
    "description": "カスタムコンポーネントの開発 Open Telemetry Collectorのためのコンポーネントを構築するには、以下の3つの主要な部分が必要です：\nConfiguration - ユーザーが設定できる値は何か Factory - 提供された値を使ってコンポーネントを作成する Business Logic - コンポーネントが実行する必要があること これについて、プロジェクトの重要なDevOpsメトリクスを追跡するためにJenkinsと連携するコンポーネントを構築する例を考えていきます。\n測定しようとしているメトリクスは次のとおりです：\n変更に対するリードタイム - 「コミットが本番環境に入るまでにかかる時間」 変更失敗率 - 「本番環境での障害を引き起こすデプロイの割合」 デプロイ頻度 - 「[チーム]が本番環境に成功してリリースする頻度」 平均復旧時間 - 「[チーム]が本番環境の障害から復旧するのにかかる時間」 これらの指標は Google の DevOps Research and Assessment (DORA) チームによって特定されたもので、ソフトウェア開発チームのパフォーマンスを示すのに役立ちます。Jenkins CI を選択した理由は、私たちが同じオープンソースソフトウェアエコシステムに留まり、将来的にベンダー管理のCIツールが採用する例となることができるためです。\n計装 🆚 コンポーネント 組織内でオブザーバビリティを向上させる際には、トレードオフが発生するため、考慮する点があります。\n長所 短所 （自動）計装1 システムを観測するために外部APIが不要 計装を変更するにはプロジェクトの変更が必要 システム所有者/開発者は可観測性の変更が可能 ランタイムへの追加の依存が必要 システムの文脈を理解し、Exemplar とキャプチャされたデータを関連付けることが可能 システムのパフォーマンスに影響を与える可能性がある コンポーネント データ名や意味の変更をシステムのリリースサイクルから独立した展開が可能 APIの破壊的な変更の可能性があり、システムとコレクター間でリリースの調整が必要 その後の利用に合わせて収集されるデータの更新/拡張が容易 キャプチャされたデータの意味がシステムリリースと一致せず、予期せず壊れる可能性がある 計装（instrument, インストゥルメント）とは、アプリケーションなどのシステムコンポーネントに対して、トレースやメトリクス、ログなどのテレメトリーデータを出力させる実装。計装ライブラリを最低限セットアップするだけで一通りのトレースやメトリクスなどを出力できるような対応を「自動計装」と呼びます。 ↩︎",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/8-develop/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ SREの帽子を再び被って、オンラインブティックの監視を設定するよう依頼されました。アプリケーションが 24 時間 365 日、利用可能で良好なパフォーマンスを発揮していることを確認する必要があります。\nアプリケーションを 24 時間 365 日監視し、問題が発生したときにアラートを受け取ることができたらいいと思いませんか？ここで Synthetics の出番です。オンラインブティックを通じて典型的なユーザージャーニーのパフォーマンスと可用性を毎分チェックする簡単なテストを紹介します。",
    "description": "このセクションでは、Splunk Syntheticsを使用してアプリケーションのパフォーマンスと可用性を監視する方法を学びます。",
    "tags": [],
    "title": "Splunk Synthetics",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/8-synthetics/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "Dockerfile の更新 Kubernetes では、環境変数は通常、Docker イメージに組み込むのではなく.yamlマニフェストファイルで管理されます。そこで、Dockerfile から以下の 2 つの環境変数を削除しましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile 次に、以下の 2 つの環境変数を削除します：\nENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n新しい Docker イメージのビルド 環境変数を除外した新しい Docker イメージをビルドしましょう：\ncd /home/splunk/workshop/docker-k8s-otel/helloworld docker build -t helloworld:1.2 . Note: we’ve used a different version (1.2) to distinguish the image from our earlier version. To clean up the older versions, run the following command to get the container id:\ndocker ps -a Then run the following command to delete the container:\ndocker rm \u003cold container id\u003e --force Now we can get the container image id:\ndocker images | grep 1.1 Finally, we can run the following command to delete the old image:\ndocker image rm \u003cold image id\u003e Docker イメージを Kubernetes にインポート 通常であれば、Docker イメージを Docker Hub などのリポジトリにプッシュします。 しかし、今回のセッションでは、k3s に直接インポートする回避策を使用します。\ncd /home/splunk # Export the image from docker docker save --output helloworld.tar helloworld:1.2 # Import the image into k3s sudo k3s ctr images import helloworld.tar .NET アプリケーションのデプロイ ヒント：vi で編集モードに入るには「i」キーを押します。変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n.NET アプリケーションを K8s にデプロイするために、/home/splunkにdeployment.yamlという名前のファイルを作成しましょう：\nvi /home/splunk/deployment.yaml そして以下を貼り付けます：\napiVersion: apps/v1 kind: Deployment metadata: name: helloworld spec: selector: matchLabels: app: helloworld replicas: 1 template: metadata: labels: app: helloworld spec: containers: - name: helloworld image: docker.io/library/helloworld:1.2 imagePullPolicy: Never ports: - containerPort: 8080 env: - name: PORT value: \"8080\" Kubernetes における Deployment とは？ deployment.yaml ファイルは、deployment リソースを定義するために使用される kubernetes 設定ファイルです。このファイルは Kubernetes でアプリケーションを管理するための基盤となります！deployment 設定は deployment の 望ましい状態 を定義し、Kubernetes が 実際の状態 がそれと一致するよう保証します。これにより、アプリケーション pod の自己修復が可能になり、アプリケーションの簡単な更新やロールバックも可能になります。\n次に、同じディレクトリにservice.yamlという名前の 2 つ目のファイルを作成します：\nvi /home/splunk/service.yaml そして以下を貼り付けます：\napiVersion: v1 kind: Service metadata: name: helloworld labels: app: helloworld spec: type: ClusterIP selector: app: helloworld ports: - port: 8080 protocol: TCP Kubernetes における Service とは？ Kubernetes の Service は抽象化レイヤーであり、仲介者のような役割を果たします。Pod にアクセスするための固定 IP アドレスや DNS 名を提供し、時間の経過とともに Pod が追加、削除、または交換されても同じままです。\nこれらのマニフェストファイルを使用してアプリケーションをデプロイできます：\n​ Script Example Output # create the deployment kubectl apply -f deployment.yaml # create the service kubectl apply -f service.yaml deployment.apps/helloworld created service/helloworld created アプリケーションのテスト アプリケーションにアクセスするには、まず IP アドレスを取得する必要があります：\n​ Script Example Output kubectl describe svc helloworld | grep IP: IP: 10.43.102.103 その後、前のコマンドから返された Cluster IP を使用してアプリケーションにアクセスできます。 例：\ncurl http://10.43.102.103:8080/hello/Kubernetes OpenTelemetry の設定 .NET OpenTelemetry 計装はすでに Docker イメージに組み込まれています。しかし、データの送信先を指定するためにいくつかの環境変数を設定する必要があります。\n先ほど作成したdeployment.yamlファイルに以下を追加します：\n重要 以下の YAML の$INSTANCEをあなたのインスタンス名に置き換えてください。 インスタンス名はecho $INSTANCEを実行することで確認できます。\nenv: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=otel-$INSTANCE\" 完全なdeployment.yamlファイルは以下のようになります（$INSTANCEではなくあなたのインスタンス名を使用してください）：\napiVersion: apps/v1 kind: Deployment metadata: name: helloworld spec: selector: matchLabels: app: helloworld replicas: 1 template: metadata: labels: app: helloworld spec: containers: - name: helloworld image: docker.io/library/helloworld:1.2 imagePullPolicy: Never ports: - containerPort: 8080 env: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=otel-$INSTANCE\" 以下のコマンドで変更を適用します：\n​ Script Example Output kubectl apply -f deployment.yaml deployment.apps/helloworld configured その後、curlを使用してトラフィックを生成します。\n1 分ほど経過すると、o11y cloud でトレースが流れているのが確認できるはずです。ただし、より早くトレースを確認したい場合は、以下の方法があります…\nチャレンジ 開発者として、トレース ID を素早く取得するか、コンソールフィードバックを見たい場合、deployment.yaml ファイルにどのような環境変数を追加できるでしょうか？\n答えを見るにはここをクリック セクション 4「.NET Application を OpenTelemetry で計装する」のチャレンジで思い出していただければ、OTEL_TRACES_EXPORTER環境変数を使って trace を console に書き込むトリックをお見せしました。この変数を deployment.yaml に追加し、アプリケーションを再 deploy して、helloworld アプリから log を tail することで、trace id を取得して Splunk Observability Cloud で trace を見つけることができます。（ワークショップの次のセクションでは、debug exporter の使用についても説明します。これは K8s 環境でアプリケーションを debug する際の典型的な方法です。）\nまず、vi で deployment.yaml ファイルを開きます：\nvi deployment.yaml 次に、OTEL_TRACES_EXPORTER環境変数を追加します：\nenv: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=YOURINSTANCE\" # NEW VALUE HERE: - name: OTEL_TRACES_EXPORTER value: \"otlp,console\" 変更を保存してからアプリケーションを再 deploy します：\n​ Script Example Output kubectl apply -f deployment.yaml deployment.apps/helloworld configured helloworld の log を tail します：\n​ Script Example Output kubectl logs -l app=helloworld -f info: HelloWorldController[0] /hello endpoint invoked by K8s9 Activity.TraceId: 5bceb747cc7b79a77cfbde285f0f09cb Activity.SpanId: ac67afe500e7ad12 Activity.TraceFlags: Recorded Activity.ActivitySourceName: Microsoft.AspNetCore Activity.DisplayName: GET hello/{name?} Activity.Kind: Server Activity.StartTime: 2025-02-04T15:22:48.2381736Z Activity.Duration: 00:00:00.0027334 Activity.Tags: server.address: 10.43.226.224 server.port: 8080 http.request.method: GET url.scheme: http url.path: /hello/K8s9 network.protocol.version: 1.1 user_agent.original: curl/7.81.0 http.route: hello/{name?} http.response.status_code: 200 Resource associated with Activity: splunk.distro.version: 1.8.0 telemetry.distro.name: splunk-otel-dotnet telemetry.distro.version: 1.8.0 os.type: linux os.description: Debian GNU/Linux 12 (bookworm) os.build_id: 6.2.0-1018-aws os.name: Debian GNU/Linux os.version: 12 host.name: helloworld-69f5c7988b-dxkwh process.owner: app process.pid: 1 process.runtime.description: .NET 8.0.12 process.runtime.name: .NET process.runtime.version: 8.0.12 container.id: 39c2061d7605d8c390b4fe5f8054719f2fe91391a5c32df5684605202ca39ae9 telemetry.sdk.name: opentelemetry telemetry.sdk.language: dotnet telemetry.sdk.version: 1.9.0 service.name: helloworld deployment.environment: otel-jen-tko-1b75 次に、別の terminal window で curl コマンドを使って trace を生成します。log を tail している console で trace id が表示されるはずです。Activity.TraceId:の値をコピーして、APM の Trace 検索フィールドに貼り付けてください。",
    "description": "Dockerfile の更新 Kubernetes では、環境変数は通常、Docker イメージに組み込むのではなく.yamlマニフェストファイルで管理されます。そこで、Dockerfile から以下の 2 つの環境変数を削除しましょう：\nvi /home/splunk/workshop/docker-k8s-otel/helloworld/Dockerfile 次に、以下の 2 つの環境変数を削除します：\nENV OTEL_SERVICE_NAME=helloworld ENV OTEL_RESOURCE_ATTRIBUTES='deployment.environment=otel-$INSTANCE' vi での変更を保存するには、escキーを押してコマンドモードに入り、:wq!と入力してからenter/returnキーを押します。\n新しい Docker イメージのビルド 環境変数を除外した新しい Docker イメージをビルドしましょう：\ncd /home/splunk/workshop/docker-k8s-otel/helloworld docker build -t helloworld:1.2 . Note: we’ve used a different version (1.2) to distinguish the image from our earlier version. To clean up the older versions, run the following command to get the container id:\ndocker ps -a Then run the following command to delete the container:",
    "tags": [],
    "title": "アプリケーションをK8sにデプロイ",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/8-deploy-app-k8s/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops",
    "content": "このワークショップでは、以下の項目について実践経験を積むことができます：\nLinux および Kubernetes 環境で、Splunk ディストリビューションの OpenTelemetry .NET を使用してコレクターのデプロイと.NET アプリケーションの計装を実践します。 .NET アプリケーションの「Docker 化」、Docker での実行、そして Splunk OpenTelemetry 計装の追加を実践します。 Helm を使用した K8s 環境での Splunk ディストロのコレクターのデプロイを実践します。その後、コレクター設定をカスタマイズし、問題のトラブルシューティングを行います。 Tip このワークショップを最も簡単にナビゲートする方法は以下を使用することです：\nこのページの右上にある左右の矢印（\u003c | \u003e） キーボードの左（◀️）と右（▶️）のカーソルキー",
    "description": "このワークショップでは、これらの概念を説明するためにシンプルな.NETアプリケーションを使用します。さあ、始めましょう！ワークショップの終わりまでに、OpenTelemetryを使用した.NETアプリケーションの計装の実践経験を積み、そのアプリケーションのDocker化およびKubernetesへのデプロイを行います。また、Helmを使用したOpenTelemetryコレクターのデプロイ、コレクター設定のカスタマイズ、コレクター設定の問題のトラブルシューティングの経験も得られます。",
    "tags": [],
    "title": "OpenTelemetry、Docker、K8sを実践で学ぶ",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "プロジェクトのセットアップ Ninja メモ このワークショップのセクションを完了する時間は経験によって異なる場合があります。\n完成したものはこちらにあります。詰まった場合や講師と一緒に進めたい場合に利用してください。\n新しい Jenkins CI レシーバーの開発を始めるため、まずは Go プロジェクトのセットアップから始めていきます。 新しい Go プロジェクトを作成する手順は以下の通りです：\n${HOME}/go/src/jenkinscireceiver という名前の新しいディレクトリを作成し、そのディレクトリに移動します。 実際のディレクトリ名や場所は厳密ではありません。自分の開発ディレクトリを自由に選ぶことができます。 go mod init splunk.conf/workshop/example/jenkinscireceiver を実行して、Go のモジュールを初期化します。 依存関係を追跡するために使用される go.mod というファイルが作成されます。 インポートされている依存関係のチェックサム値が go.sum として保存されます。 Check-ingo.modをレビューする `` text module splunk.conf/workshop/example/jenkinscireceiver\ngo 1.20",
    "description": "プロジェクトのセットアップ Ninja メモ このワークショップのセクションを完了する時間は経験によって異なる場合があります。\n完成したものはこちらにあります。詰まった場合や講師と一緒に進めたい場合に利用してください。\n新しい Jenkins CI レシーバーの開発を始めるため、まずは Go プロジェクトのセットアップから始めていきます。 新しい Go プロジェクトを作成する手順は以下の通りです：\n${HOME}/go/src/jenkinscireceiver という名前の新しいディレクトリを作成し、そのディレクトリに移動します。 実際のディレクトリ名や場所は厳密ではありません。自分の開発ディレクトリを自由に選ぶことができます。 go mod init splunk.conf/workshop/example/jenkinscireceiver を実行して、Go のモジュールを初期化します。 依存関係を追跡するために使用される go.mod というファイルが作成されます。 インポートされている依存関係のチェックサム値が go.sum として保存されます。 Check-ingo.modをレビューする `` text module splunk.conf/workshop/example/jenkinscireceiver\ngo 1.20",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/8-develop/1-project-setup/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "デフォルト設定を使用して K8s クラスターに Splunk Distribution of OpenTelemetry コレクターを デプロイしました。このセクションでは、コレクター設定をカスタマイズする方法をいくつかの例で 説明します。\nコレクター設定の取得 コレクター設定をカスタマイズする前に、現在の設定がどのようになっているかを どのように確認するのでしょうか？\nKubernetes 環境では、コレクター設定は Config Map を使用して保存されます。\n以下のコマンドで、クラスターに存在する config map を確認できます：\n​ Script Example Output kubectl get cm -l app=splunk-otel-collector NAME DATA AGE splunk-otel-collector-otel-k8s-cluster-receiver 1 3h37m splunk-otel-collector-otel-agent 1 3h37m なぜ 2 つの config map があるのでしょうか？\n次に、以下のようにコレクターエージェントの config map を表示できます：\n​ Script Example Output kubectl describe cm splunk-otel-collector-otel-agent Name: splunk-otel-collector-otel-agent Namespace: default Labels: app=splunk-otel-collector app.kubernetes.io/instance=splunk-otel-collector app.kubernetes.io/managed-by=Helm app.kubernetes.io/name=splunk-otel-collector app.kubernetes.io/version=0.113.0 chart=splunk-otel-collector-0.113.0 helm.sh/chart=splunk-otel-collector-0.113.0 heritage=Helm release=splunk-otel-collector Annotations: meta.helm.sh/release-name: splunk-otel-collector meta.helm.sh/release-namespace: default Data ==== relay: ---- exporters: otlphttp: headers: X-SF-Token: ${SPLUNK_OBSERVABILITY_ACCESS_TOKEN} metrics_endpoint: https://ingest.us1.signalfx.com/v2/datapoint/otlp traces_endpoint: https://ingest.us1.signalfx.com/v2/trace/otlp (followed by the rest of the collector config in yaml format) K8s でコレクター設定を更新する方法 Linux インスタンスでコレクターを実行した以前の例では、コレクター設定は /etc/otel/collector/agent_config.yamlファイルで利用可能でした。その場合にコレクター設定を 変更する必要があれば、単純にこのファイルを編集し、変更を保存してから コレクターを再起動すればよかったのです。\nK8s では、少し異なる動作をします。agent_config.yamlを直接変更する代わりに、 helm チャートをデプロイするために使用されるvalues.yamlファイルを変更することで コレクター設定をカスタマイズします。\nGitHubの values.yaml ファイルには、 利用可能なカスタマイズオプションが記載されています。\n例を見てみましょう。\nInfrastructure Events Monitoring の追加 最初の例として、K8s クラスターの infrastructure events monitoring を有効にしましょう。\nこれにより、charts の Events Feed セクションの一部として Kubernetes イベントを確認できるようになります。 cluster receiver は、kubernetes-events monitor を使用して Smart Agent receiver で設定され、custom イベントを送信します。詳細についてはCollect Kubernetes eventsを参照してください。\nこれはvalues.yamlファイルに以下の行を追加することで実行されます：\nヒント：vi での開き方と保存方法は前のステップにあります。\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: ファイルが保存されたら、以下のコマンドで変更を適用できます：\n​ Script Example Output helm upgrade splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector Release \"splunk-otel-collector\" has been upgraded. Happy Helming! NAME: splunk-otel-collector LAST DEPLOYED: Fri Dec 20 01:17:03 2024 NAMESPACE: default STATUS: deployed REVISION: 2 TEST SUITE: None NOTES: Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Observability realm us1. その後、config map を表示して変更が適用されたことを確認できます：\n​ Script Example Output kubectl describe cm splunk-otel-collector-otel-k8s-cluster-receiver smartagent/kubernetes-eventsが agent config に含まれていることを確認してください：\nsmartagent/kubernetes-events: alwaysClusterReporter: true type: kubernetes-events whitelistedEvents: - involvedObjectKind: Pod reason: Created - involvedObjectKind: Pod reason: Unhealthy - involvedObjectKind: Pod reason: Failed - involvedObjectKind: Job reason: FailedCreate これらの特定の変更が適用されるのは cluster receiver config map なので、そちらを指定していることに注意してください。\nDebug Exporter の追加 collector に送信される trace と log を確認して、 Splunk に送信する前に検査したいとします。この目的のために debug exporter を使用できます。これは OpenTelemetry 関連の問題のトラブルシューティングに役立ちます。\nvalues.yaml ファイルの下部に以下のように debug exporter を追加しましょう：\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: config: receivers: ... exporters: debug: verbosity: detailed service: pipelines: traces: exporters: - debug logs: exporters: - debug ファイルが保存されたら、以下のコマンドで変更を適用できます：\n​ Script Example Output helm upgrade splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector Release \"splunk-otel-collector\" has been upgraded. Happy Helming! NAME: splunk-otel-collector LAST DEPLOYED: Fri Dec 20 01:32:03 2024 NAMESPACE: default STATUS: deployed REVISION: 3 TEST SUITE: None NOTES: Splunk OpenTelemetry Collector is installed and configured to send data to Splunk Observability realm us1. curl を使用してアプリケーションを数回実行してから、以下のコマンドで agent collector の log を tail します：\nkubectl logs -l component=otel-collector-agent -f 以下のような trace が agent collector の log に書き込まれているのが確認できるはずです：\n2024-12-20T01:43:52.929Z info Traces {\"kind\": \"exporter\", \"data_type\": \"traces\", \"name\": \"debug\", \"resource spans\": 1, \"spans\": 2} 2024-12-20T01:43:52.929Z info ResourceSpans #0 Resource SchemaURL: https://opentelemetry.io/schemas/1.6.1 Resource attributes: -\u003e splunk.distro.version: Str(1.8.0) -\u003e telemetry.distro.name: Str(splunk-otel-dotnet) -\u003e telemetry.distro.version: Str(1.8.0) -\u003e os.type: Str(linux) -\u003e os.description: Str(Debian GNU/Linux 12 (bookworm)) -\u003e os.build_id: Str(6.8.0-1021-aws) -\u003e os.name: Str(Debian GNU/Linux) -\u003e os.version: Str(12) -\u003e host.name: Str(derek-1) -\u003e process.owner: Str(app) -\u003e process.pid: Int(1) -\u003e process.runtime.description: Str(.NET 8.0.11) -\u003e process.runtime.name: Str(.NET) -\u003e process.runtime.version: Str(8.0.11) -\u003e container.id: Str(78b452a43bbaa3354a3cb474010efd6ae2367165a1356f4b4000be031b10c5aa) -\u003e telemetry.sdk.name: Str(opentelemetry) -\u003e telemetry.sdk.language: Str(dotnet) -\u003e telemetry.sdk.version: Str(1.9.0) -\u003e service.name: Str(helloworld) -\u003e deployment.environment: Str(otel-derek-1) -\u003e k8s.pod.ip: Str(10.42.0.15) -\u003e k8s.pod.labels.app: Str(helloworld) -\u003e k8s.pod.name: Str(helloworld-84865965d9-nkqsx) -\u003e k8s.namespace.name: Str(default) -\u003e k8s.pod.uid: Str(38d39bc6-1309-4022-a569-8acceef50942) -\u003e k8s.node.name: Str(derek-1) -\u003e k8s.cluster.name: Str(derek-1-cluster) そして以下のような log エントリも確認できます：\n2024-12-20T01:43:53.215Z info Logs {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\", \"resource logs\": 1, \"log records\": 2} 2024-12-20T01:43:53.215Z info ResourceLog #0 Resource SchemaURL: https://opentelemetry.io/schemas/1.6.1 Resource attributes: -\u003e splunk.distro.version: Str(1.8.0) -\u003e telemetry.distro.name: Str(splunk-otel-dotnet) -\u003e telemetry.distro.version: Str(1.8.0) -\u003e os.type: Str(linux) -\u003e os.description: Str(Debian GNU/Linux 12 (bookworm)) -\u003e os.build_id: Str(6.8.0-1021-aws) -\u003e os.name: Str(Debian GNU/Linux) -\u003e os.version: Str(12) -\u003e host.name: Str(derek-1) -\u003e process.owner: Str(app) -\u003e process.pid: Int(1) -\u003e process.runtime.description: Str(.NET 8.0.11) -\u003e process.runtime.name: Str(.NET) -\u003e process.runtime.version: Str(8.0.11) -\u003e container.id: Str(78b452a43bbaa3354a3cb474010efd6ae2367165a1356f4b4000be031b10c5aa) -\u003e telemetry.sdk.name: Str(opentelemetry) -\u003e telemetry.sdk.language: Str(dotnet) -\u003e telemetry.sdk.version: Str(1.9.0) -\u003e service.name: Str(helloworld) -\u003e deployment.environment: Str(otel-derek-1) -\u003e k8s.node.name: Str(derek-1) -\u003e k8s.cluster.name: Str(derek-1-cluster) ただし、Splunk Observability Cloud に戻ると、アプリケーションから trace と log が もはやそこに送信されていないことに気づくでしょう。\nなぜそうなったと思いますか？次のセクションで詳しく説明します。",
    "description": "デフォルト設定を使用して K8s クラスターに Splunk Distribution of OpenTelemetry コレクターを デプロイしました。このセクションでは、コレクター設定をカスタマイズする方法をいくつかの例で 説明します。\nコレクター設定の取得 コレクター設定をカスタマイズする前に、現在の設定がどのようになっているかを どのように確認するのでしょうか？\nKubernetes 環境では、コレクター設定は Config Map を使用して保存されます。\n以下のコマンドで、クラスターに存在する config map を確認できます：\n​ Script Example Output kubectl get cm -l app=splunk-otel-collector NAME DATA AGE splunk-otel-collector-otel-k8s-cluster-receiver 1 3h37m splunk-otel-collector-otel-agent 1 3h37m なぜ 2 つの config map があるのでしょうか？\n次に、以下のようにコレクターエージェントの config map を表示できます：\n​ Script Example Output kubectl describe cm splunk-otel-collector-otel-agent Name: splunk-otel-collector-otel-agent Namespace: default Labels: app=splunk-otel-collector app.kubernetes.io/instance=splunk-otel-collector app.kubernetes.io/managed-by=Helm app.kubernetes.io/name=splunk-otel-collector app.kubernetes.io/version=0.113.0 chart=splunk-otel-collector-0.113.0 helm.sh/chart=splunk-otel-collector-0.113.0 heritage=Helm release=splunk-otel-collector Annotations: meta.helm.sh/release-name: splunk-otel-collector meta.helm.sh/release-namespace: default Data ==== relay: ---- exporters: otlphttp: headers: X-SF-Token: ${SPLUNK_OBSERVABILITY_ACCESS_TOKEN} metrics_endpoint: https://ingest.us1.signalfx.com/v2/datapoint/otlp traces_endpoint: https://ingest.us1.signalfx.com/v2/trace/otlp (followed by the rest of the collector config in yaml format) K8s でコレクター設定を更新する方法 Linux インスタンスでコレクターを実行した以前の例では、コレクター設定は /etc/otel/collector/agent_config.yamlファイルで利用可能でした。その場合にコレクター設定を 変更する必要があれば、単純にこのファイルを編集し、変更を保存してから コレクターを再起動すればよかったのです。",
    "tags": [],
    "title": "OpenTelemetryコレクター設定のカスタマイズ",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/9-customize-collector-config/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "ペルソナ SREの帽子が似合っているので、引き続き着用してpaymentservice用のカスタムサービスヘルスダッシュボードの構築を依頼されたと想定します。要件は RED メトリクス、ログ、Synthetic テスト期間の結果を表示することです。\n開発チームと SRE チームが、アプリケーションやサービスの健全性の概要を必要とすることは一般的です。これらは多くの場合、壁に取り付けられた TV に表示されます。Splunk Observability Cloud は、カスタムダッシュボードを作成することでこれに最適なソリューションを提供しています。\nこのセクションでは、チームのモニターや TV に表示するためのサービスヘルスダッシュボードを構築します。",
    "description": "このセクションでは、サービスの健全性を監視するためのカスタムサービスヘルスダッシュボードの構築方法を学びます。",
    "tags": [],
    "title": "カスタムサービスヘルスダッシュボード 🏥",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/9-custom-dashboard/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "前のセクションでは、debug エクスポーターをコレクターの設定に追加し、 トレースとログのパイプラインの一部にしました。期待通りに、debug 出力が エージェントコレクターのログに書き込まれているのが確認できます。\nしかし、トレースが o11y cloud に送信されなくなっています。なぜなのかを把握して修正しましょう。\nコレクター設定を確認する values.yamlファイルを通じてコレクター設定が変更された場合は、 config map を確認してコレクターに実際に適用された設定を確認することが役立ちます：\nkubectl describe cm splunk-otel-collector-otel-agent エージェントコレクター設定のログとトレースのパイプラインを確認しましょう。次のようになっているはずです：\npipelines: logs: exporters: - debug processors: - memory_limiter - k8sattributes - filter/logs - batch - resourcedetection - resource - resource/logs - resource/add_environment receivers: - filelog - fluentforward - otlp ... traces: exporters: - debug processors: - memory_limiter - k8sattributes - batch - resourcedetection - resource - resource/add_environment receivers: - otlp - jaeger - smartagent/signalfx-forwarder - zipkin 問題がわかりますか？debug エクスポーターのみがトレースとログのパイプラインに含まれています。 以前のトレースパイプライン設定にあったotlphttpとsignalfxエクスポーターがなくなっています。 これが、もう o11y cloud でトレースが見えなくなった理由です。ログパイプラインについても、splunk_hec/platform_logs エクスポーターが削除されています。\nどのような特定のエクスポーターが以前含まれていたかをどのように知ったか？それを見つけるには、 以前のカスタマイズを元に戻してから、config map を確認して トレースパイプラインに元々何が含まれていたかを見ることもできました。あるいは、 splunk-otel-collector-chart の GitHub リポジトリ の例を参照することもでき、これにより Helm チャートで使用されるデフォルトのエージェント設定が分かります。\nこれらのエクスポーターはどのように削除されたのか？ values.yamlファイルに追加したカスタマイズを確認しましょう：\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: config: receivers: ... exporters: debug: verbosity: detailed service: pipelines: traces: exporters: - debug logs: exporters: - debug helm upgradeを使ってコレクターにvalues.yamlファイルを適用したとき、 カスタム設定は以前のコレクター設定とマージされました。 これが発生すると、リストを含むyaml設定のセクション、 例えばパイプラインセクションのエクスポーターのリストは、values.yamlファイルに 含めたもの（debug エクスポーターのみ）で置き換えられます。\n問題を修正しましょう 既存のパイプラインをカスタマイズする場合、設定のその部分を完全に再定義する必要があります。 したがって、values.yamlファイルを次のように更新する必要があります：\nlogsEngine: otel splunkObservability: infrastructureMonitoringEventsEnabled: true agent: config: receivers: ... exporters: debug: verbosity: detailed service: pipelines: traces: exporters: - otlphttp - signalfx - debug logs: exporters: - splunk_hec/platform_logs - debug 変更を適用しましょう：\nhelm upgrade splunk-otel-collector \\ --set=\"splunkObservability.realm=$REALM\" \\ --set=\"splunkObservability.accessToken=$ACCESS_TOKEN\" \\ --set=\"clusterName=$INSTANCE-cluster\" \\ --set=\"environment=otel-$INSTANCE\" \\ --set=\"splunkPlatform.token=$HEC_TOKEN\" \\ --set=\"splunkPlatform.endpoint=$HEC_URL\" \\ --set=\"splunkPlatform.index=splunk4rookies-workshop\" \\ -f values.yaml \\ splunk-otel-collector-chart/splunk-otel-collector それからエージェント config map を確認します：\nkubectl describe cm splunk-otel-collector-otel-agent 今度は、ログとトレースの両方について完全に定義されたエクスポーターパイプラインが表示されるはずです：\npipelines: logs: exporters: - splunk_hec/platform_logs - debug processors: ... traces: exporters: - otlphttp - signalfx - debug processors: ... ログ出力の確認 Splunk Distribution of OpenTelemetry .NETは、ログに使用するアプリケーション （サンプルアプリでも使用している）から、トレースコンテキストで強化されたログを自動的にエクスポートします。\nアプリケーションログはトレースメタデータで強化され、その後 OpenTelemetry Collector のローカルインスタンスに OTLP 形式でエクスポートされます。\ndebug エクスポーターによってキャプチャされたログを詳しく見て、それが発生しているかを確認しましょう。 コレクターログを tail するには、次のコマンドを使用できます：\nkubectl logs -l component=otel-collector-agent -f ログを tail したら、curl を使ってさらにトラフィックを生成できます。そうすると 次のようなものが表示されるはずです：\n2024-12-20T21:56:30.858Z info Logs {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\", \"resource logs\": 1, \"log records\": 1} 2024-12-20T21:56:30.858Z info ResourceLog #0 Resource SchemaURL: https://opentelemetry.io/schemas/1.6.1 Resource attributes: -\u003e splunk.distro.version: Str(1.8.0) -\u003e telemetry.distro.name: Str(splunk-otel-dotnet) -\u003e telemetry.distro.version: Str(1.8.0) -\u003e os.type: Str(linux) -\u003e os.description: Str(Debian GNU/Linux 12 (bookworm)) -\u003e os.build_id: Str(6.8.0-1021-aws) -\u003e os.name: Str(Debian GNU/Linux) -\u003e os.version: Str(12) -\u003e host.name: Str(derek-1) -\u003e process.owner: Str(app) -\u003e process.pid: Int(1) -\u003e process.runtime.description: Str(.NET 8.0.11) -\u003e process.runtime.name: Str(.NET) -\u003e process.runtime.version: Str(8.0.11) -\u003e container.id: Str(5bee5b8f56f4b29f230ffdd183d0367c050872fefd9049822c1ab2aa662ba242) -\u003e telemetry.sdk.name: Str(opentelemetry) -\u003e telemetry.sdk.language: Str(dotnet) -\u003e telemetry.sdk.version: Str(1.9.0) -\u003e service.name: Str(helloworld) -\u003e deployment.environment: Str(otel-derek-1) -\u003e k8s.node.name: Str(derek-1) -\u003e k8s.cluster.name: Str(derek-1-cluster) ScopeLogs #0 ScopeLogs SchemaURL: InstrumentationScope HelloWorldController LogRecord #0 ObservedTimestamp: 2024-12-20 21:56:28.486804 +0000 UTC Timestamp: 2024-12-20 21:56:28.486804 +0000 UTC SeverityText: Information SeverityNumber: Info(9) Body: Str(/hello endpoint invoked by {name}) Attributes: -\u003e name: Str(Kubernetes) Trace ID: 78db97a12b942c0252d7438d6b045447 Span ID: 5e9158aa42f96db3 Flags: 1 {\"kind\": \"exporter\", \"data_type\": \"logs\", \"name\": \"debug\"} この例では、Trace ID と Span ID が OpenTelemetry .NET 計装によってログ出力に自動的に書き込まれていることがわかります。これにより、 Splunk Observability Cloud でログとトレースを関連付けることができます。\nただし、Helm を使って K8s クラスターに OpenTelemetry collector をデプロイし、 ログ収集オプションを含める場合、OpenTelemetry collector は File Log receiver を使用して コンテナーログを自動的にキャプチャすることを覚えておいてください。\nこれにより、アプリケーションの重複ログがキャプチャされることになります。例えば、次のスクリーンショットでは サービスへの各リクエストに対して 2 つのログエントリーが表示されています：\nこれをどのように回避しますか？\nK8s での重複ログの回避 重複ログをキャプチャしないようにするには、OTEL_LOGS_EXPORTER環境変数をnoneに設定して、 Splunk Distribution of OpenTelemetry .NET が OTLP を使用してコレクターにログをエクスポートしないようにできます。 これは、deployment.yamlファイルにOTEL_LOGS_EXPORTER環境変数を追加することで実行できます：\nenv: - name: PORT value: \"8080\" - name: NODE_IP valueFrom: fieldRef: fieldPath: status.hostIP - name: OTEL_EXPORTER_OTLP_ENDPOINT value: \"http://$(NODE_IP):4318\" - name: OTEL_SERVICE_NAME value: \"helloworld\" - name: OTEL_RESOURCE_ATTRIBUTES value: \"deployment.environment=otel-$INSTANCE\" - name: OTEL_LOGS_EXPORTER value: \"none\" それから次を実行します：\n# update the deployment kubectl apply -f deployment.yaml OTEL_LOGS_EXPORTER環境変数をnoneに設定するのは簡単です。しかし、Trace ID と Span ID はアプリケーションによって生成された stdout ログに書き込まれないため、 ログとトレースを関連付けることができなくなります。\nこれを解決するには、 /home/splunk/workshop/docker-k8s-otel/helloworld/SplunkTelemetryConfigurator.csで定義されている例のような、カスタムロガーを定義する必要があります。\n次のようにProgram.csファイルを更新することで、これをアプリケーションに含めることができます：\nusing SplunkTelemetry; using Microsoft.Extensions.Logging.Console; var builder = WebApplication.CreateBuilder(args); builder.Services.AddControllers(); SplunkTelemetryConfigurator.ConfigureLogger(builder.Logging); var app = builder.Build(); app.MapControllers(); app.Run(); その後、カスタムログ設定を含む新しい Docker イメージをビルドします：\ncd /home/splunk/workshop/docker-k8s-otel/helloworld docker build -t helloworld:1.3 . それから更新されたイメージを Kubernetes にインポートします：\ncd /home/splunk # Export the image from docker docker save --output helloworld.tar helloworld:1.3 # Import the image into k3s sudo k3s ctr images import helloworld.tar 最後に、deployment.yamlファイルを更新してコンテナーイメージの 1.3 バージョンを使用する必要があります：\nspec: containers: - name: helloworld image: docker.io/library/helloworld:1.3 それから変更を適用します：\n# update the deployment kubectl apply -f deployment.yaml これで重複したログエントリーが排除されたことがわかります。そして 残りのログエントリーは JSON としてフォーマットされ、span と trace ID が含まれています：",
    "description": "前のセクションでは、debug エクスポーターをコレクターの設定に追加し、 トレースとログのパイプラインの一部にしました。期待通りに、debug 出力が エージェントコレクターのログに書き込まれているのが確認できます。\nしかし、トレースが o11y cloud に送信されなくなっています。なぜなのかを把握して修正しましょう。\nコレクター設定を確認する values.yamlファイルを通じてコレクター設定が変更された場合は、 config map を確認してコレクターに実際に適用された設定を確認することが役立ちます：\nkubectl describe cm splunk-otel-collector-otel-agent エージェントコレクター設定のログとトレースのパイプラインを確認しましょう。次のようになっているはずです：\npipelines: logs: exporters: - debug processors: - memory_limiter - k8sattributes - filter/logs - batch - resourcedetection - resource - resource/logs - resource/add_environment receivers: - filelog - fluentforward - otlp ... traces: exporters: - debug processors: - memory_limiter - k8sattributes - batch - resourcedetection - resource - resource/add_environment receivers: - otlp - jaeger - smartagent/signalfx-forwarder - zipkin 問題がわかりますか？debug エクスポーターのみがトレースとログのパイプラインに含まれています。 以前のトレースパイプライン設定にあったotlphttpとsignalfxエクスポーターがなくなっています。 これが、もう o11y cloud でトレースが見えなくなった理由です。ログパイプラインについても、splunk_hec/platform_logs エクスポーターが削除されています。",
    "tags": [],
    "title": "Troubleshoot OpenTelemetry Collector Issues",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/10-troubleshoot-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud",
    "content": "おめでとうございます。Splunk4Rookies - Observability Cloud ワークショップを修了しました。今日は Splunk Observability Cloud を使用してアプリケーションとインフラストラクチャを監視する方法に慣れました。\nこの修了証をあなたのLinkedIn プロフィールに追加して成果をアピールしましょう。\n私たちが学んだことと次にできることを振り返ってみましょう。",
    "description": "おめでとうございます。Splunk4Rookies - Observability Cloudワークショップを修了しました。今日はSplunk Observability Cloudを使用してアプリケーションとインフラストラクチャを監視する方法に慣れました。",
    "tags": [],
    "title": "ワークショップ まとめ 🎁",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/10-wrap-up/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "Configuration の構築 コンポーネントの Configuration 部分は、ユーザーがコンポーネントに対する入力を行う方法であり、設定に使用される値は以下のようである必要があります：\nそのフィールドが何を制御するのか、ユーザーが直感的に理解できる 必須項目とオプション項目が明確である 共通の名前とフィールドを再利用する オプションをシンプルに保つ ​ 良い config 悪い config --- # Required Values endpoint: http://my-jenkins-server:8089 auth: authenticator: basicauth/jenkins # Optional Values collection_interval: 10m metrics: example.metric.1: enabled: true example.metric.2: enabled: true example.metric.3: enabled: true example.metric.4: enabled: true --- jenkins_server_addr: hostname jenkins_server_api_port: 8089 interval: 10m filter_builds_by: - name: my-awesome-build status: amber track: values: example.metric.1: yes example.metric.2: yes example.metric.3: no example.metric.4: no 悪い例では、Configuration のベストプラクティスに反するとコンポーネントが使いにくくなってしまうことが理解できるはずです。 フィールドの値が何であるべきかを明確ではなく、既存のプロセッサーに移譲できる機能を含み、コレクター内の他のコンポーネントと比較してフィールドの命名に一貫性がありません。\n良い例では、必要な値をシンプルに保ち、他のコンポーネントからのフィールド名を再利用し、コンポーネントが Jenkins とコレクター間の相互作用にのみ焦点を当てています。\n設定値の中には、このコンポーネントで独自に追加するものと、コレクター内部の共有ライブラリによって提供されているものがあります。これらはビジネスロジックに取り組む際にさらに詳しく説明します。Configuration は小さく始めるべきで、ビジネスロジックに追加の機能が必要になったら、設定も追加していきましょう。\nコードを書く Configuration に必要なコードを実装するために、config.go という名前の新しいファイルを以下の内容で作成します：\npackage jenkinscireceiver import ( \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type Config struct { // HTTPClientSettings contains all the values // that are commonly shared across all HTTP interactions // performed by the collector. confighttp.HTTPClientSettings `mapstructure:\",squash\"` // ScraperControllerSettings will allow us to schedule // how often to check for updates to builds. scraperhelper.ScraperControllerSettings `mapstructure:\",squash\"` // MetricsBuilderConfig contains all the metrics // that can be configured. metadata.MetricsBuilderConfig `mapstructure:\",squash\"` }",
    "description": "Configuration の構築 コンポーネントの Configuration 部分は、ユーザーがコンポーネントに対する入力を行う方法であり、設定に使用される値は以下のようである必要があります：\nそのフィールドが何を制御するのか、ユーザーが直感的に理解できる 必須項目とオプション項目が明確である 共通の名前とフィールドを再利用する オプションをシンプルに保つ ​ 良い config 悪い config --- # Required Values endpoint: http://my-jenkins-server:8089 auth: authenticator: basicauth/jenkins # Optional Values collection_interval: 10m metrics: example.metric.1: enabled: true example.metric.2: enabled: true example.metric.3: enabled: true example.metric.4: enabled: true --- jenkins_server_addr: hostname jenkins_server_api_port: 8089 interval: 10m filter_builds_by: - name: my-awesome-build status: amber track: values: example.metric.1: yes example.metric.2: yes example.metric.3: no example.metric.4: no 悪い例では、Configuration のベストプラクティスに反するとコンポーネントが使いにくくなってしまうことが理解できるはずです。 フィールドの値が何であるべきかを明確ではなく、既存のプロセッサーに移譲できる機能を含み、コレクター内の他のコンポーネントと比較してフィールドの命名に一貫性がありません。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/8-develop/2-configuration/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ",
    "content": "概要 OpenTelemetry を使い始める場合は、バックエンドに直接データを送ることから始めるかもしれません。最初のステップとしてはよいですが、OpenTelemetry Collector をオブザーバビリティのアーキテクチャとして使用するのは多くの利点があり、本番環境では Collector を使ったデプロイを推奨しています。\nこのワークショップでは、OpenTelemetry Collector を使用することに焦点を当て、Splunk Observability Cloud で使用するためのレシーバー、プロセッサー、エクスポーターを定義し、実際にテレメトリデータを送信するためのパイプラインを設定することで、環境に合わせて Collector を活用を学びます。また、分散プラットフォームのビジネスニーズに対応するための、カスタムコンポーネントを追加できるようになるまでの道のりを進むことになります。\nNinja セクション ワークショップの途中には、展開できる Ninja セクション があります。これらはより実践的で、ワークショップ中、もしくは自分の時間を使って、さらに技術的な詳細に取り組むことができます。\nOpenTelemetry プロジェクトは頻繁に開発されているため、Ninjaセクションの内容が古くなる可能性があることに注意してください。コンテンツが古い場合には更新のリクエストを出すこともできますので、必要なものを見つけた場合はお知らせください。\nNinja: をテストして！ このワークショップを完了すると、正式に OpenTelemetry Collector ニンジャになります！\n対象者 このワークショップは、OpenTelemetry Collector のアーキテクチャとデプロイメントについてさらに学びたいと考えている開発者やシステム管理者を対象としています。\n前提条件 データ収集に関する基本的な理解 コマンドラインとvim/viの経験 Ubuntu 20.04 LTSまたは22.04 LTSが稼働するインスタンス/ホスト/VM 最小要件はAWS/EC2 t2.micro（1 CPU、1GB RAM、8GBストレージ） 学習目標 このセッションの終わりまでに、参加者は以下を行うことができるようになります：\nOpenTelemetry のコンポーネントを理解する レシーバー、プロセッサー、エクスポーターを使用してデータを収集・分析する OpenTelemetry を使用する利点を特定する 自分たちのビジネスニーズに対応するカスタムコンポーネントを構築する OpenTelemetry のアーキテクチャー %%{ init:{ \"theme\":\"base\", \"themeVariables\": { \"primaryColor\": \"#ffffff\", \"clusterBkg\": \"#eff2fb\", \"defaultLinkColor\": \"#333333\" } } }%% flowchart LR; subgraph Receivers A[OTLP] --\u003e M(Receivers) B[JAEGER] --\u003e M(Receivers) C[Prometheus] --\u003e M(Receivers) end subgraph Processors M(Receivers) --\u003e H(Filters, Attributes, etc) E(Extensions) end subgraph Exporters H(Filters, Attributes, etc) --\u003e S(OTLP) H(Filters, Attributes, etc) --\u003e T(JAEGER) H(Filters, Attributes, etc) --\u003e U(Prometheus) end",
    "description": "OpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。",
    "tags": [],
    "title": "OpenTelemetryでクラウドネイティブ環境のオブザーバビリティを実現する",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Ninjas Workshops \u003e OpenTelemetry、Docker、K8sを実践で学ぶ",
    "content": "このワークショップでは、以下の概念についてハンズオンで体験しました：\nLinux ホストにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 Splunk Distribution of OpenTelemetry .NETで.NET アプリケーションを計装する方法。 .NET アプリケーションを「Docker 化」し、Splunk Distribution of OpenTelemetry .NETで計装する方法。 Helm を使用して Kubernetes クラスターにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 コレクター設定をカスタマイズして問題をトラブルシューティングする方法。 他の言語と環境で OpenTelemetry がどのように計装されるかを確認するには、 Splunk OpenTelemetry Examples GitHub リポジトリをご覧ください。\n将来このワークショップを独自に実行するには、これらの手順を参照して、Splunk Show のSplunk4Rookies - Observability ワークショップテンプレートを使用して EC2 インスタンスをプロビジョニングしてください。",
    "description": "このワークショップでは、以下の概念についてハンズオンで体験しました：\nLinux ホストにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 Splunk Distribution of OpenTelemetry .NETで.NET アプリケーションを計装する方法。 .NET アプリケーションを「Docker 化」し、Splunk Distribution of OpenTelemetry .NETで計装する方法。 Helm を使用して Kubernetes クラスターにSplunk Distribution of the OpenTelemetry Collectorをデプロイする方法。 コレクター設定をカスタマイズして問題をトラブルシューティングする方法。 他の言語と環境で OpenTelemetry がどのように計装されるかを確認するには、 Splunk OpenTelemetry Examples GitHub リポジトリをご覧ください。\n将来このワークショップを独自に実行するには、これらの手順を参照して、Splunk Show のSplunk4Rookies - Observability ワークショップテンプレートを使用して EC2 インスタンスをプロビジョニングしてください。",
    "tags": [],
    "title": "Summary",
    "uri": "/observability-workshop/v5.99/ja/ninja-workshops/8-docker-k8s-otel/11-summary/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "コンポーネントを検討する Jenkinsからメトリクスを取得するために必要なコンポーネントの種類をおさらいしましょう：\n​ エクステンション レシーバー プロセッサー エクスポーター Ninja: コネクター エクステンションが解決するビジネスユースケースは以下の通りです：\n実行時の設定が必要な共有機能を持つ コレクターの実行時間の観察に間接的に役立つ 詳細については、エクステンションの概要を参照してください。\nレシーバーが解決するビジネスユースケースは以下の通りです：\nリモートソースからのデータの取得 リモートソースからのデータの受信 これらは一般的に pull 対 push ベースのデータ収集と呼ばれ、詳細についてはレシーバーの概要で読むことができます。\nプロセッサーが解決するビジネスユースケースは以下の通りです：\nデータ、フィールド、または値の追加または削除 データの観察と意思決定 バッファリング、キューイング、および並べ替え プロセッサーを通過するデータタイプは、下流のコンポーネントに同じデータタイプを転送する必要があることを覚えておいてください。 詳細については、プロセッサーの概要をご覧ください。\nエクスポーターが解決するビジネスユースケースは以下の通りです：\nデータをツール、サービス、またはストレージに送信する OpenTelemetryコレクターは「バックエンド」、すべてを一元化した観測可能性スイートを目指すのではなく、OpenTelemetryの創設原則に忠実であり続けることを目指しています。つまり、ベンダーに依存しない全ての人のための観測可能性です。詳細については、エクスポーターの概要をお読みください。\nコネクターは比較的新しいコンポーネントで、このワークショップではあまり触れていません。 コネクターは、異なるテレメトリタイプやパイプラインをまたいで使用できるプロセッサーのようなものだといえます。たとえば、コネクターはログとしてデータを受け取り、メトリクスとして出力したり、あるパイプラインからメトリクスを受け取り、テレメトリーデータに関するメトリクスを提供したりすることができます。\nコネクターが解決するビジネスケースは以下の通りです：\n異なるテレメトリタイプ間の変換 ログからメトリクスへ トレースからメトリクスへ メトリクスからログへ 受信したデータを観察し、自身のデータを生成する メトリクスを受け取り、データの分析メトリクスを生成する。 Ninjaセクションの一部としてプロセッサーの概要内で簡単に概要が説明されています。\nこれらのコンポーネントについて考えると、Jenkins に対応する場合はプルベースのレシーバーを開発する必要があることがわかります。",
    "description": "コンポーネントを検討する Jenkinsからメトリクスを取得するために必要なコンポーネントの種類をおさらいしましょう：\n​ エクステンション レシーバー プロセッサー エクスポーター Ninja: コネクター エクステンションが解決するビジネスユースケースは以下の通りです：\n実行時の設定が必要な共有機能を持つ コレクターの実行時間の観察に間接的に役立つ 詳細については、エクステンションの概要を参照してください。\nレシーバーが解決するビジネスユースケースは以下の通りです：\nリモートソースからのデータの取得 リモートソースからのデータの受信 これらは一般的に pull 対 push ベースのデータ収集と呼ばれ、詳細についてはレシーバーの概要で読むことができます。\nプロセッサーが解決するビジネスユースケースは以下の通りです：\nデータ、フィールド、または値の追加または削除 データの観察と意思決定 バッファリング、キューイング、および並べ替え プロセッサーを通過するデータタイプは、下流のコンポーネントに同じデータタイプを転送する必要があることを覚えておいてください。 詳細については、プロセッサーの概要をご覧ください。\nエクスポーターが解決するビジネスユースケースは以下の通りです：\nデータをツール、サービス、またはストレージに送信する OpenTelemetryコレクターは「バックエンド」、すべてを一元化した観測可能性スイートを目指すのではなく、OpenTelemetryの創設原則に忠実であり続けることを目指しています。つまり、ベンダーに依存しない全ての人のための観測可能性です。詳細については、エクスポーターの概要をお読みください。\nコネクターは比較的新しいコンポーネントで、このワークショップではあまり触れていません。 コネクターは、異なるテレメトリタイプやパイプラインをまたいで使用できるプロセッサーのようなものだといえます。たとえば、コネクターはログとしてデータを受け取り、メトリクスとして出力したり、あるパイプラインからメトリクスを受け取り、テレメトリーデータに関するメトリクスを提供したりすることができます。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/8-develop/3-component/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "メトリクスを設計する レシーバーによってキャプチャされるメトリクスを定義し、エクスポートするために、コレクターのために開発された mdatagen を使って、yaml で定義したメトリクスをコードに変換していきます。\n​ metadata.yaml gen.go --- # Type defines the name to reference the component # in the configuration file type: jenkins # Status defines the component type and the stability level status: class: receiver stability: development: [metrics] # Attributes are the expected fields reported # with the exported values. attributes: job.name: description: The name of the associated Jenkins job type: string job.status: description: Shows if the job had passed, or failed type: string enum: - failed - success - unknown # Metrics defines all the pontentially exported values from this receiver. metrics: jenkins.jobs.count: enabled: true description: Provides a count of the total number of configured jobs unit: \"{Count}\" gauge: value_type: int jenkins.job.duration: enabled: true description: Show the duration of the job unit: \"s\" gauge: value_type: int attributes: - job.name - job.status jenkins.job.commit_delta: enabled: true description: The calculation difference of the time job was finished minus commit timestamp unit: \"s\" gauge: value_type: int attributes: - job.name - job.status // To generate the additional code needed to capture metrics, // the following command to be run from the shell: // go generate -x ./... //go:generate go run github.com/open-telemetry/opentelemetry-collector-contrib/cmd/mdatagen@v0.80.0 metadata.yaml package jenkinscireceiver // There is no code defined within this file. 次のセクションに進む前に、これらのファイルをプロジェクトフォルダ内に作成してください。\nFactory の構築 Factory はソフトウェアデザインパターンの一種で、提供された Configuration を使って、動的にオブジェクト（この場合は jenkinscireceiver）を作成するものです。現実的な例では、携帯電話店に行って、あなたの正確な説明に合った携帯電話を求め、それを提供されるようなものです。\nコマンド go generate -x ./... を実行すると、定義されたメトリクスをエクスポートするために必要なすべてのコードを含む新しいフォルダ jenkinscireceiver/internal/metadata が作成されます。生成されるコードは以下の通りです：\n​ factory.go config.go scraper.go build-config.yaml project layout package jenkinscireceiver import ( \"errors\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) func NewFactory() receiver.Factory { return receiver.NewFactory( metadata.Type, newDefaultConfig, receiver.WithMetrics(newMetricsReceiver, metadata.MetricsStability), ) } func newMetricsReceiver(_ context.Context, set receiver.CreateSettings, cfg component.Config, consumer consumer.Metrics) (receiver.Metrics, error) { // Convert the configuration into the expected type conf, ok := cfg.(*Config) if !ok { return nil, errors.New(\"can not convert config\") } sc, err := newScraper(conf, set) if err != nil { return nil, err } return scraperhelper.NewScraperControllerReceiver( \u0026conf.ScraperControllerSettings, set, consumer, scraperhelper.AddScraper(sc), ) } package jenkinscireceiver import ( \"go.opentelemetry.io/collector/config/confighttp\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type Config struct { // HTTPClientSettings contains all the values // that are commonly shared across all HTTP interactions // performed by the collector. confighttp.HTTPClientSettings `mapstructure:\",squash\"` // ScraperControllerSettings will allow us to schedule // how often to check for updates to builds. scraperhelper.ScraperControllerSettings `mapstructure:\",squash\"` // MetricsBuilderConfig contains all the metrics // that can be configured. metadata.MetricsBuilderConfig `mapstructure:\",squash\"` } func newDefaultConfig() component.Config { return \u0026Config{ ScraperControllerSettings: scraperhelper.NewDefaultScraperControllerSettings(metadata.Type), HTTPClientSettings: confighttp.NewDefaultHTTPClientSettings(), MetricsBuilderConfig: metadata.DefaultMetricsBuilderConfig(), } } package jenkinscireceiver type scraper struct {} func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { // Create a our scraper with our values s := scraper{ // To be filled in later } return scraperhelper.NewScraper(metadata.Type, s.scrape) } func (scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetrics.NewMetrics(), nil } --- dist: name: otelcol description: \"Conf workshop collector\" output_path: ./dist version: v0.0.0-experimental extensions: - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/basicauthextension v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/extension/healthcheckextension v0.80.0 receivers: - gomod: go.opentelemetry.io/collector/receiver/otlpreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jaegerreceiver v0.80.0 - gomod: github.com/open-telemetry/opentelemetry-collector-contrib/receiver/prometheusreceiver v0.80.0 - gomod: splunk.conf/workshop/example/jenkinscireceiver v0.0.0 path: ./jenkinscireceiver processors: - gomod: go.opentelemetry.io/collector/processor/batchprocessor v0.80.0 exporters: - gomod: go.opentelemetry.io/collector/exporter/loggingexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlpexporter v0.80.0 - gomod: go.opentelemetry.io/collector/exporter/otlphttpexporter v0.80.0 # This replace is a go directive that allows for redefine # where to fetch the code to use since the default would be from a remote project. replaces: - splunk.conf/workshop/example/jenkinscireceiver =\u003e ./jenkinscireceiver ├── build-config.yaml └── jenkinscireceiver ├── go.mod ├── config.go ├── factory.go ├── scraper.go └── internal └── metadata これらのファイルがプロジェクトに作成されたら、go mod tidy を実行します。すると、すべての依存ライブラリが取得され、go.mod が更新されます。",
    "description": "メトリクスを設計する レシーバーによってキャプチャされるメトリクスを定義し、エクスポートするために、コレクターのために開発された mdatagen を使って、yaml で定義したメトリクスをコードに変換していきます。\n​ metadata.yaml gen.go --- # Type defines the name to reference the component # in the configuration file type: jenkins # Status defines the component type and the stability level status: class: receiver stability: development: [metrics] # Attributes are the expected fields reported # with the exported values. attributes: job.name: description: The name of the associated Jenkins job type: string job.status: description: Shows if the job had passed, or failed type: string enum: - failed - success - unknown # Metrics defines all the pontentially exported values from this receiver. metrics: jenkins.jobs.count: enabled: true description: Provides a count of the total number of configured jobs unit: \"{Count}\" gauge: value_type: int jenkins.job.duration: enabled: true description: Show the duration of the job unit: \"s\" gauge: value_type: int attributes: - job.name - job.status jenkins.job.commit_delta: enabled: true description: The calculation difference of the time job was finished minus commit timestamp unit: \"s\" gauge: value_type: int attributes: - job.name - job.status // To generate the additional code needed to capture metrics, // the following command to be run from the shell: // go generate -x ./... //go:generate go run github.com/open-telemetry/opentelemetry-collector-contrib/cmd/mdatagen@v0.80.0 metadata.yaml package jenkinscireceiver // There is no code defined within this file. 次のセクションに進む前に、これらのファイルをプロジェクトフォルダ内に作成してください。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/8-develop/4-design/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e その他のワークショップ \u003e OpenTelemetry Collector \u003e 8. Develop",
    "content": "ビジネスロジックを作る この時点では、何も行っていないカスタムコンポーネントが作成されています。ここから、Jenkins からデータを取得するための必要なロジックを追加していきましょう。\nここからのステップは以下の通りです：\nJenkinsに接続するクライアントを作成する 設定されたすべてのジョブをキャプチャする 設定されたジョブの最後のビルドのステータスを報告する コミットタイムスタンプとジョブ完了の時間差を計算する 変更を scraper.go に加えていきます。\n​ Jenkins クライアントを追加する ジョブをキャプチャする ジョブの状態を報告する 差分を報告する Jenkinsサーバーに接続するために、パッケージ “github.com/yosida95/golang-jenkins” を使用します。これには、Jenkinsサーバーからデータを読み取るために必要な機能が提供されています。\n次に、“go.opentelemetry.io/collector/receiver/scraperhelper” ライブラリのいくつかのヘルパー関数を利用して、コンポーネントの起動が完了したらJenkinsサーバーに接続できるようにするスタート関数を作成します。\npackage jenkinscireceiver import ( \"context\" jenkins \"github.com/yosida95/golang-jenkins\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/pdata/pmetric\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type scraper struct { mb *metadata.MetricsBuilder client *jenkins.Jenkins } func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { s := \u0026scraper{ mb : metadata.NewMetricsBuilder(cfg.MetricsBuilderConfig, set), } return scraperhelper.NewScraper( metadata.Type, s.scrape, scraperhelper.WithStart(func(ctx context.Context, h component.Host) error { client, err := cfg.ToClient(h, set.TelemetrySettings) if err != nil { return err } // The collector provides a means of injecting authentication // on our behalf, so this will ignore the libraries approach // and use the configured http client with authentication. s.client = jenkins.NewJenkins(nil, cfg.Endpoint) s.client.SetHTTPClient(client) return nil }), ) } func (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetric.NewMetrics(), nil } これで、Jenkinsレシーバーを初期化するために必要なすべてのコードが完成しました。\nここから先は、実装が必要な scrape メソッドに焦点を当てます。このメソッドは、設定された間隔（デフォルトでは1分）ごとに実行されます。\nJenkins サーバーの負荷状況や、どの程度のプロジェクトが実行されているかを測定するために、Jenkins で設定されているジョブの数をキャプチャしたいと考えています。これを行うために、Jenkins クライアントを呼び出してすべてのジョブをリスト化し、エラーが報告された場合はメトリクスなしでそれを返し、そうでなければメトリクスビルダーからのデータを発行します。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) // To be filled in return s.mb.Emit(), nil } 前のステップにより、すべてのジョブをキャプチャしてジョブの数をレポートできるようになりました。 このステップでは、それぞれのジョブを調査し、レポートされた値を使用してメトリクスをキャプチャしていきます。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) for _, job := range jobs { // Ensure we have valid results to start off with var ( build = job.LastCompletedBuild status = metadata.AttributeJobStatusUnknown ) // This will check the result of the job, however, // since the only defined attributes are // `success`, `failure`, and `unknown`. // it is assume that anything did not finish // with a success or failure to be an unknown status. switch build.Result { case \"aborted\", \"not_built\", \"unstable\": status = metadata.AttributeJobStatusUnknown case \"success\": status = metadata.AttributeJobStatusSuccess case \"failure\": status = metadata.AttributeJobStatusFailed } s.mb.RecordJenkinsJobDurationDataPoint( now, int64(job.LastCompletedBuild.Duration), job.Name, status, ) } return s.mb.Emit(), nil } 最後のステップでは、コミットからジョブ完了までにかかった時間を計算して、DORA メトリクス を推測するのに役立てていきます。\nfunc (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { jobs, err := s.client.GetJobs() if err != nil { return pmetric.Metrics{}, err } // Recording the timestamp to ensure // all captured data points within this scrape have the same value. now := pcommon.NewTimestampFromTime(time.Now()) // Casting to an int64 to match the expected type s.mb.RecordJenkinsJobsCountDataPoint(now, int64(len(jobs))) for _, job := range jobs { // Ensure we have valid results to start off with var ( build = job.LastCompletedBuild status = metadata.AttributeJobStatusUnknown ) // Previous step here // Ensure that the `ChangeSet` has values // set so there is a valid value for us to reference if len(build.ChangeSet.Items) == 0 { continue } // Making the assumption that the first changeset // item is the most recent change. change := build.ChangeSet.Items[0] // Record the difference from the build time // compared against the change timestamp. s.mb.RecordJenkinsJobCommitDeltaDataPoint( now, int64(build.Timestamp-change.Timestamp), job.Name, status, ) } return s.mb.Emit(), nil } これらのステップがすべて完了すると、Jenkins CI レシーバーが完成します！\n次は何をするの？ コンポーネントに必要な機能は、おそらく他にもたくさん思いつくでしょう。例えば：\nジョブで使用されたブランチ名を含めることはできますか？ ジョブのプロジェクト名を含めることはできますか？ プロジェクトのジョブの総持続時間をどのように計算しますか？ 変更が機能するかどうかをどのように検証しますか？ この時間を使って遊んでみたり、壊してみたり、変更してみたり、ビルドからのログをキャプチャしてみるなどしてください。",
    "description": "ビジネスロジックを作る この時点では、何も行っていないカスタムコンポーネントが作成されています。ここから、Jenkins からデータを取得するための必要なロジックを追加していきましょう。\nここからのステップは以下の通りです：\nJenkinsに接続するクライアントを作成する 設定されたすべてのジョブをキャプチャする 設定されたジョブの最後のビルドのステータスを報告する コミットタイムスタンプとジョブ完了の時間差を計算する 変更を scraper.go に加えていきます。\n​ Jenkins クライアントを追加する ジョブをキャプチャする ジョブの状態を報告する 差分を報告する Jenkinsサーバーに接続するために、パッケージ “github.com/yosida95/golang-jenkins” を使用します。これには、Jenkinsサーバーからデータを読み取るために必要な機能が提供されています。\n次に、“go.opentelemetry.io/collector/receiver/scraperhelper” ライブラリのいくつかのヘルパー関数を利用して、コンポーネントの起動が完了したらJenkinsサーバーに接続できるようにするスタート関数を作成します。\npackage jenkinscireceiver import ( \"context\" jenkins \"github.com/yosida95/golang-jenkins\" \"go.opentelemetry.io/collector/component\" \"go.opentelemetry.io/collector/pdata/pmetric\" \"go.opentelemetry.io/collector/receiver\" \"go.opentelemetry.io/collector/receiver/scraperhelper\" \"splunk.conf/workshop/example/jenkinscireceiver/internal/metadata\" ) type scraper struct { mb *metadata.MetricsBuilder client *jenkins.Jenkins } func newScraper(cfg *Config, set receiver.CreateSettings) (scraperhelper.Scraper, error) { s := \u0026scraper{ mb : metadata.NewMetricsBuilder(cfg.MetricsBuilderConfig, set), } return scraperhelper.NewScraper( metadata.Type, s.scrape, scraperhelper.WithStart(func(ctx context.Context, h component.Host) error { client, err := cfg.ToClient(h, set.TelemetrySettings) if err != nil { return err } // The collector provides a means of injecting authentication // on our behalf, so this will ignore the libraries approach // and use the configured http client with authentication. s.client = jenkins.NewJenkins(nil, cfg.Endpoint) s.client.SetHTTPClient(client) return nil }), ) } func (s scraper) scrape(ctx context.Context) (pmetric.Metrics, error) { // To be filled in return pmetric.NewMetrics(), nil } これで、Jenkinsレシーバーを初期化するために必要なすべてのコードが完成しました。",
    "tags": [],
    "title": "OpenTelemetry Collector を開発する",
    "uri": "/observability-workshop/v5.99/ja/other/opentelemetry-collector/8-develop/5-business-logic/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "Pet Clinic Java ワークショップJavaアプリケーションをつかったSplunk Oservabilityのワークショップです\nOpenTelemetry CollectorOpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。",
    "description": "Pet Clinic Java ワークショップJavaアプリケーションをつかったSplunk Oservabilityのワークショップです\nOpenTelemetry CollectorOpenTelemetry Collectorのコンセプトを学び、Splunk Observability Cloudにデータを送信する方法を理解しましょう。",
    "tags": [],
    "title": "その他のワークショップ",
    "uri": "/observability-workshop/v5.99/ja/other/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "よくある質問とその回答オブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\nディメンション、プロパティ、タグディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。\nOpenTelemetryでのタグ付け大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "description": "よくある質問とその回答オブザーバビリティ、DevOps、インシデント対応、Splunk On-Callに関連する一般的な質問とその回答を集めました。\nディメンション、プロパティ、タグディメンションとプロパティの比較で、どちらかを使うべきかというのはよく議論されます。\nOpenTelemetryでのタグ付け大規模な組織で OpenTelemetry を展開する際には、タグ付けのための標準化された命名規則を定義し、規則が遵守されるようにガバナンスプロセスを確立することが重要です。",
    "tags": [],
    "title": "リソース",
    "uri": "/observability-workshop/v5.99/ja/resources/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops \u003e Splunk4Rookies ワークショップ \u003e Observability Cloud \u003e 3. UI - クイックツアー \u003e 1. はじめに",
    "content": "この FAQ では、ワークショップへのログイン時に遭遇することの多い一般的な問題について説明します。\n1. 招待メールまたはパスワード更新メールが届かない 最初に行うべき手順は、noreply@signalfx.com からのメールをすべてのメールフォルダで検索することです。これは招待状やパスワード更新メールの送信に使用されるアドレスです。メールが見つからない場合は、スパム/迷惑メールフォルダを確認してください。\nメールが存在しないことが確実な場合は、インストラクターにワークショップに使用されたメールアドレスを確認してもらい、招待状を再送信してもらいましょう。\nこれがうまくいかない場合、別の解決策として、インストラクターに別のメールアドレス（例えばプライベートメールアドレス）を提供し、招待状を再送信してもらうことも可能です。\n2. パスワードが受け付けられない Splunk Observability Cloud でのパスワードの要件は以下の通りです：\n8 文字から 32 文字の間でなければなりません 少なくとも 1 つの大文字を含まなければなりません 少なくとも 1 つの数字を含まなければなりません 少なくとも 1 つの記号（例：!@#$%^\u0026*()_+）を含まなければなりません 3. 無効または不明なパスワード システムがパスワードとユーザー名の組み合わせを認識しない場合は、パスワードリセットリンクをクリックしてパスワードのリセットを試みてください。 パスワードの入力を求められます。そのアカウントが存在する場合は、パスワードをリセットできるようにメールが送信されます。そのメールの指示に従ってください。\nメールが届かない場合やユーザー名が認識されない場合は、インストラクターに連絡して支援を求めてください。\n4. その他のオプション 準備中です。",
    "description": "この FAQ では、ワークショップへのログイン時に遭遇することの多い一般的な問題について説明します。\n1. 招待メールまたはパスワード更新メールが届かない 最初に行うべき手順は、noreply@signalfx.com からのメールをすべてのメールフォルダで検索することです。これは招待状やパスワード更新メールの送信に使用されるアドレスです。メールが見つからない場合は、スパム/迷惑メールフォルダを確認してください。\nメールが存在しないことが確実な場合は、インストラクターにワークショップに使用されたメールアドレスを確認してもらい、招待状を再送信してもらいましょう。\nこれがうまくいかない場合、別の解決策として、インストラクターに別のメールアドレス（例えばプライベートメールアドレス）を提供し、招待状を再送信してもらうことも可能です。\n2. パスワードが受け付けられない Splunk Observability Cloud でのパスワードの要件は以下の通りです：\n8 文字から 32 文字の間でなければなりません 少なくとも 1 つの大文字を含まなければなりません 少なくとも 1 つの数字を含まなければなりません 少なくとも 1 つの記号（例：!@#$%^\u0026*()_+）を含まなければなりません 3. 無効または不明なパスワード システムがパスワードとユーザー名の組み合わせを認識しない場合は、パスワードリセットリンクをクリックしてパスワードのリセットを試みてください。 パスワードの入力を求められます。そのアカウントが存在する場合は、パスワードをリセットできるようにメールが送信されます。そのメールの指示に従ってください。\nメールが届かない場合やユーザー名が認識されない場合は、インストラクターに連絡して支援を求めてください。\n4. その他のオプション 準備中です。",
    "tags": [],
    "title": "ログオンFAQ",
    "uri": "/observability-workshop/v5.99/ja/splunk4rookies/observability-cloud/3-quick-tour/1-homepage/99-login-faq/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "",
    "description": "",
    "tags": [],
    "title": "カテゴリー",
    "uri": "/observability-workshop/v5.99/ja/categories/index.html"
  },
  {
    "breadcrumb": "Splunk Observability Workshops",
    "content": "",
    "description": "",
    "tags": [],
    "title": "タグ",
    "uri": "/observability-workshop/v5.99/ja/tags/index.html"
  }
]
