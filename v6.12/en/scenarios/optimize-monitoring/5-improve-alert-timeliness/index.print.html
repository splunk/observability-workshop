<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=print><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.145.0"><meta name=generator content="Relearn 8.0.0+97777ec5111409397e83f44eca496eea97697836"><meta name=description content="When monitoring hybrid and cloud environments, ensuring timely alerts for critical infrastructure and applications poses a significant challenge. Typically, this involves crafting intricate queries, meticulously scheduling searches, and managing alerts across various monitoring solutions. Moreover, the proliferation of disparate alerts generated from identical data sources often results in unnecessary duplication, contributing to alert fatigue and noise within the monitoring ecosystem.
In this section, we’ll explore how Splunk Observability Cloud addresses these challenges by enabling the effortless creation of alert criteria. Leveraging its 10-second default data collection capability, alerts can be triggered swiftly, surpassing the timeliness achieved by traditional monitoring tools. This enhanced responsiveness not only reduces Mean Time to Detect (MTTD) but also accelerates Mean Time to Resolve (MTTR), ensuring that critical issues are promptly identified and remediated."><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Improve Timeliness of Alerts :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="When monitoring hybrid and cloud environments, ensuring timely alerts for critical infrastructure and applications poses a significant challenge. Typically, this involves crafting intricate queries, meticulously scheduling searches, and managing alerts across various monitoring solutions. Moreover, the proliferation of disparate alerts generated from identical data sources often results in unnecessary duplication, contributing to alert fatigue and noise within the monitoring ecosystem.
In this section, we’ll explore how Splunk Observability Cloud addresses these challenges by enabling the effortless creation of alert criteria. Leveraging its 10-second default data collection capability, alerts can be triggered swiftly, surpassing the timeliness achieved by traditional monitoring tools. This enhanced responsiveness not only reduces Mean Time to Detect (MTTD) but also accelerates Mean Time to Resolve (MTTR), ensuring that critical issues are promptly identified and remediated."><meta property="og:url" content="https://splunk.github.io/observability-workshop/v6.12/en/scenarios/optimize-monitoring/5-improve-alert-timeliness/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="Improve Timeliness of Alerts :: Splunk Observability Cloud Workshops"><meta property="og:description" content="When monitoring hybrid and cloud environments, ensuring timely alerts for critical infrastructure and applications poses a significant challenge. Typically, this involves crafting intricate queries, meticulously scheduling searches, and managing alerts across various monitoring solutions. Moreover, the proliferation of disparate alerts generated from identical data sources often results in unnecessary duplication, contributing to alert fatigue and noise within the monitoring ecosystem.
In this section, we’ll explore how Splunk Observability Cloud addresses these challenges by enabling the effortless creation of alert criteria. Leveraging its 10-second default data collection capability, alerts can be triggered swiftly, surpassing the timeliness achieved by traditional monitoring tools. This enhanced responsiveness not only reduces Mean Time to Detect (MTTD) but also accelerates Mean Time to Resolve (MTTR), ensuring that critical issues are promptly identified and remediated."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Improve Timeliness of Alerts :: Splunk Observability Cloud Workshops"><meta itemprop=description content="When monitoring hybrid and cloud environments, ensuring timely alerts for critical infrastructure and applications poses a significant challenge. Typically, this involves crafting intricate queries, meticulously scheduling searches, and managing alerts across various monitoring solutions. Moreover, the proliferation of disparate alerts generated from identical data sources often results in unnecessary duplication, contributing to alert fatigue and noise within the monitoring ecosystem.
In this section, we’ll explore how Splunk Observability Cloud addresses these challenges by enabling the effortless creation of alert criteria. Leveraging its 10-second default data collection capability, alerts can be triggered swiftly, surpassing the timeliness achieved by traditional monitoring tools. This enhanced responsiveness not only reduces Mean Time to Detect (MTTD) but also accelerates Mean Time to Resolve (MTTR), ensuring that critical issues are promptly identified and remediated."><meta itemprop=dateModified content="2025-07-23T22:07:18+01:00"><meta itemprop=wordCount content="128"><title>Improve Timeliness of Alerts :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/v6.12/en/scenarios/optimize-monitoring/5-improve-alert-timeliness/index.html rel=canonical type=text/html title="Improve Timeliness of Alerts :: Splunk Observability Cloud Workshops"><link href=/observability-workshop/v6.12/images/favicon.ico?1761175652 rel=icon type=image/x-icon sizes=any><link href=/observability-workshop/v6.12/css/auto-complete/auto-complete.min.css?1761175652 rel=stylesheet><script src=/observability-workshop/v6.12/js/auto-complete/auto-complete.min.js?1761175652 defer></script><script src=/observability-workshop/v6.12/js/search-lunr.min.js?1761175652 defer></script><script src=/observability-workshop/v6.12/js/search.min.js?1761175652 defer></script><script>window.relearn=window.relearn||{},window.relearn.index_js_url="/observability-workshop/v6.12/searchindex.en.js?1761175652"</script><script src=/observability-workshop/v6.12/js/lunr/lunr.min.js?1761175652 defer></script><script src=/observability-workshop/v6.12/js/lunr/lunr.stemmer.support.min.js?1761175652 defer></script><script src=/observability-workshop/v6.12/js/lunr/lunr.multi.min.js?1761175652 defer></script><script src=/observability-workshop/v6.12/js/lunr/lunr.en.min.js?1761175652 defer></script><script>window.relearn=window.relearn||{},window.relearn.contentLangs=["en"]</script><link href=/observability-workshop/v6.12/fonts/fontawesome/css/fontawesome-all.min.css?1761175652 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v6.12/fonts/fontawesome/css/fontawesome-all.min.css?1761175652 rel=stylesheet></noscript><link href=/observability-workshop/v6.12/css/perfect-scrollbar/perfect-scrollbar.min.css?1761175652 rel=stylesheet><link href=/observability-workshop/v6.12/css/theme.min.css?1761175652 rel=stylesheet><link href=/observability-workshop/v6.12/css/format-print.min.css?1761175652 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/scenarios/optimize-monitoring/5-improve-alert-timeliness/index.html",window.relearn.relBasePath="../../../..",window.relearn.relBaseUri="../../../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop/v6.12",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.disableInlineCopyToClipboard=!0,window.relearn.enableBlockCodeWrap=!0,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`,window.relearn.themevariants=["auto","splunk-light","splunk-dark"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant()</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"us1",rumAccessToken:"h7q1NLX6lJz0h_5-OqQJkg",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({appplicationName:"observability-workshop",realm:"us1",rumAccessToken:"h7q1NLX6lJz0h_5-OqQJkg",recorder:"splunk",features:{video:!0}})</script></script><style>:root{--MAIN-WIDTH-MAX:130rem;--MENU-WIDTH-L:23rem}p{margin:.75rem 0}.highlight{max-height:500px;overflow-y:auto}pre:not(.mermaid){margin:0}</style></head><body class="mobile-support print" data-url=/observability-workshop/v6.12/en/scenarios/optimize-monitoring/5-improve-alert-timeliness/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v6.12/en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v6.12/en/scenarios/index.html><span itemprop=name>Scenarios</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v6.12/en/scenarios/optimize-monitoring/index.html><span itemprop=name>Optimize Cloud Monitoring</span></a><meta itemprop=position content="3">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>5. Improve Timeliness of Alerts</span><meta itemprop=position content="4"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v6.12/en/scenarios/optimize-monitoring/5-improve-alert-timeliness/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v6.12/en/scenarios/optimize-monitoring/4-correlate-metrics-logs/2-create-log-based-chart/index.html title="Create Log-based Chart (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v6.12/en/scenarios/optimize-monitoring/5-improve-alert-timeliness/1-create-custom-detector/index.html title="Create Custom Detector (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable scenarios" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=improve-timeliness-of-alerts>Improve Timeliness of Alerts</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>1 minutes</span>
</span>&nbsp;
<span class="badge cstyle blue badge-with-title"><span class=badge-title class=text-muted>Author
</span><span class=badge-content>Tim Hard</span></span><p>When monitoring hybrid and cloud environments, ensuring timely alerts for critical infrastructure and applications poses a significant challenge. Typically, this involves crafting intricate queries, meticulously scheduling searches, and managing alerts across various monitoring solutions. Moreover, the proliferation of disparate alerts generated from identical data sources often results in unnecessary duplication, contributing to alert fatigue and noise within the monitoring ecosystem.</p><p>In this section, we&rsquo;ll explore how Splunk Observability Cloud addresses these challenges by enabling the effortless creation of alert criteria. Leveraging its 10-second default data collection capability, alerts can be triggered swiftly, surpassing the timeliness achieved by traditional monitoring tools. This enhanced responsiveness not only reduces Mean Time to Detect (MTTD) but also accelerates Mean Time to Resolve (MTTR), ensuring that critical issues are promptly identified and remediated.</p><p><a href=#R-image-8c113fb507ab06c27b77f0325ab7aebe class=lightbox-link><img alt="Detector Dashboard" class="lazy lightbox figure-image" loading=lazy src=../images/detector-dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-8c113fb507ab06c27b77f0325ab7aebe><img alt="Detector Dashboard" class="lazy lightbox lightbox-image" loading=lazy src=../images/detector-dashboard.png></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jul 23, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 5. Improve Timeliness of Alerts</h1><article class=default><header class=headline></header><h1 id=create-custom-detector>Create Custom Detector</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>10 minutes</span>
</span>&nbsp;
<span class="badge cstyle blue badge-with-title"><span class=badge-title class=text-muted>Author
</span><span class=badge-content>Tim Hard</span></span><p>Splunk Observability Cloud provides detectors, events, alerts, and notifications to keep you informed when certain criteria are met. There are a number of pre-built <strong>AutoDetect Detectors</strong> that automatically surface when common problem patterns occur, such as when an EC2 instance’s CPU utilization is expected to reach its limit. Additionally, you can also create custom detectors if you want something more optimized or specific. For example, you want a message sent to a Slack channel or to an email address for the Ops team that manages this Kubernetes cluster when Memory Utilization on their pods has reached 85%.</p><details open class="box cstyle notices green"><summary class=box-label tabindex=-1><i class="fa-fw fas fa-running"></i>
Exercise: Create Custom Detector</summary><div class=box-content><p>In this section you&rsquo;ll create a detector on <strong>Pod Memory Utilization</strong> which will trigger if utilization surpasses 85%</p><ol><li><p>On the <strong>Kubernetes Pods Dashboard</strong> you cloned in section <a href=../../3-reuse-content-across-teams/2-clone-dashboards>3.2 Dashboard Cloning</a>, click the <strong>Get Alerts</strong> button (bell icon) for the <strong>Memory usage (%)</strong> chart -> Click <strong>New detector from chart</strong>.</p><p><a href=#R-image-c622e2050570735abff48f33f4809339 class=lightbox-link><img alt="New Detector from Chart" class="lazy lightbox figure-image" loading=lazy src="../../images/new-detector.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c622e2050570735abff48f33f4809339><img alt="New Detector from Chart" class="lazy lightbox lightbox-image" loading=lazy src="../../images/new-detector.png?width=40vw"></a></p></li><li><p>In the <strong>Create detector</strong> add your initials to the detector name.</p><p><a href=#R-image-541cf9d967895fd5dd991f4536307257 class=lightbox-link><img alt="Create Detector: Update Detector Name" class="lazy lightbox figure-image" loading=lazy src="../../images/create-detector-name.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-541cf9d967895fd5dd991f4536307257><img alt="Create Detector: Update Detector Name" class="lazy lightbox lightbox-image" loading=lazy src="../../images/create-detector-name.png?width=40vw"></a></p></li><li><p>Click <strong>Create alert rule</strong>.</p><p>These conditions are expressed as one or more rules that trigger an alert when the conditions in the rules are met. Importantly, multiple rules can be included in the same detector configuration which minimizes the total number of alerts that need to be created and maintained. You can see which signal this detector will alert on by the bell icon in the <strong>Alert On</strong> column. In this case, this detector will alert on the Memory Utilization for the pods running in this Kubernetes cluster.</p><p><a href=#R-image-83350d3a3768f9e9c769915a46fb3c26 class=lightbox-link><img alt="Alert Signal" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-signals.png?width=60vw" style=height:auto;width:60vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-83350d3a3768f9e9c769915a46fb3c26><img alt="Alert Signal" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-signals.png?width=60vw"></a></p></li><li><p>Click <strong>Proceed To Alert Conditions</strong>.</p><p>Many pre-built alert conditions can be applied to the metric you want to alert on. This could be as simple as a static threshold or something more complex, for example, is memory usage deviating from the historical baseline across any of your 50,000 containers?</p><p><a href=#R-image-c0b11cdf595acd5a875633e06291bd5f class=lightbox-link><img alt="Alert Conditions" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-conditions.png?width=60vw" style=height:auto;width:60vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c0b11cdf595acd5a875633e06291bd5f><img alt="Alert Conditions" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-conditions.png?width=60vw"></a></p></li><li><p>Select <strong>Static Threshold</strong>.</p></li><li><p>Click <strong>Proceed To Alert Settings</strong>.</p><p>In this case, you want the alert to trigger if any pods exceed 85% memory utilization. Once you’ve set the alert condition, the configuration is back-tested against the historical data so you can confirm that the alert configuration is accurate, meaning will the alert trigger on the criteria you’ve defined? This is also a great way to confirm if the alert generates too much noise.</p><p><a href=#R-image-495cef9514e4cbc0b55072e44222b652 class=lightbox-link><img alt="Alert Settings" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-settings.png?width=60vw" style=height:auto;width:60vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-495cef9514e4cbc0b55072e44222b652><img alt="Alert Settings" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-settings.png?width=60vw"></a></p></li><li><p>Enter 85 in the <strong>Threshold</strong> field.</p></li><li><p>Click <strong>Proceed To Alert Message</strong>.</p><p>Next, you can set the severity for this alert, you can include links to runbooks and short tips on how to respond, and you can customize the message that is included in the alert details. The message can include parameterized fields from the actual data, for example, in this case, you may want to include which Kubernetes node the pod is running on, or the <code>store.location</code> configured when you deployed the application, to provide additional context.</p><p><a href=#R-image-fa5a0d26a97ea1c63d1564846e9d72fd class=lightbox-link><img alt="Alert Message" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-message.png?width=60vw" style=height:auto;width:60vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-fa5a0d26a97ea1c63d1564846e9d72fd><img alt="Alert Message" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-message.png?width=60vw"></a></p></li><li><p>Click <strong>Proceed To Alert Recipients</strong>.</p><p>You can choose where you want this alert to be sent when it triggers. This could be to a team, specific email addresses, or to other systems such as ServiceNow, Slack, Splunk On-Call or Splunk ITSI. You can also have the alert execute a webhook which enables me to leverage automation or to integrate with many other systems such as homegrown ticketing tools. <strong>For the purpose of this workshop do not include a recipient</strong></p><p><a href=#R-image-aa3116f275a6fc0ea0bf6424f9e8d1bf class=lightbox-link><img alt="Alert Recipients" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-recipients.png?width=60vw" style=height:auto;width:60vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-aa3116f275a6fc0ea0bf6424f9e8d1bf><img alt="Alert Recipients" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-recipients.png?width=60vw"></a></p></li><li><p>Click <strong>Proceed To Alert Activation</strong>.</p><p><a href=#R-image-b719adc2b22783848789e86e995ce215 class=lightbox-link><img alt="Activate Alert" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-activate-alert.png?width=60vw" style=height:auto;width:60vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b719adc2b22783848789e86e995ce215><img alt="Activate Alert" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-activate-alert.png?width=60vw"></a></p></li><li><p>Click <strong>Activate Alert</strong>.</p><p><a href=#R-image-06f53895cb170c66bb1aa4738f61b55f class=lightbox-link><img alt="Activate Alert Message" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-activation.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-06f53895cb170c66bb1aa4738f61b55f><img alt="Activate Alert Message" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-activation.png?width=40vw"></a></p><p>You will receive a warning because no recipients were included in the Notification Policy for this detector. This can be warning can be dismissed.</p></li><li><p>Click <strong>Save</strong>.</p><p><a href=#R-image-00dd5bdcea42795ae6ed82c437359ca6 class=lightbox-link><img alt="Activate Alert Message" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-new-detector.png?width=60vw" style=height:auto;width:60vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-00dd5bdcea42795ae6ed82c437359ca6><img alt="Activate Alert Message" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-new-detector.png?width=60vw"></a></p><p>You will be taken to your newly created detector where you can see any triggered alerts.</p></li><li><p>In the upper right corner, Click <strong>Close</strong> to close the Detector.</p></li></ol><p>The detector status and any triggered alerts will automatically be included in the chart because this detector was configured for this chart.</p><p><a href=#R-image-003e912118df311ea88558e8a78365bb class=lightbox-link><img alt="Alert Chart" class="lazy lightbox figure-image" loading=lazy src="../../images/alert-chart.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-003e912118df311ea88558e8a78365bb><img alt="Alert Chart" class="lazy lightbox lightbox-image" loading=lazy src="../../images/alert-chart.png?width=40vw"></a></p><p><strong>Congratulations! You&rsquo;ve successfully created a detector that will trigger if pod memory utilization exceeds 85%. After a few minutes, the detector should trigger some alerts. You can click the detector name in the chart to view the triggered alerts.</strong></p></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jul 23, 2025</span></span></footer></article></section></div></main></div><script src=/observability-workshop/v6.12/js/clipboard/clipboard.min.js?1761175652 defer></script><script src=/observability-workshop/v6.12/js/perfect-scrollbar/perfect-scrollbar.min.js?1761175652 defer></script><script src=/observability-workshop/v6.12/js/theme.min.js?1761175652 defer></script></body></html>