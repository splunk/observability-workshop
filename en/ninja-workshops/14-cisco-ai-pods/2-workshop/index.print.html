<!doctype html><html id=R-html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=print><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.145.0"><meta name=generator content="Relearn 9.0.3+9bc97fdf9eaf3af61af9bcc11db2e010de83af95"><meta name=description content="This section includes the steps that workshop attendees will follow:
Practice deploying the OpenTelemetry Collector in the Red Hat OpenShift cluster. Practice adding Prometheus receivers to the collector to ingest infrastructure metrics. Practice monitoring the Weaviate vector database in the cluster. Practice gathering the Pure Storage metrics using Prometheus. Practice instrumenting Python services that interact with Large Language Models (LLMs) with OpenTelemetry. Understanding which details which OpenTelemetry captures in the trace from applications that interact with LLMs."><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Workshop :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="This section includes the steps that workshop attendees will follow:
Practice deploying the OpenTelemetry Collector in the Red Hat OpenShift cluster. Practice adding Prometheus receivers to the collector to ingest infrastructure metrics. Practice monitoring the Weaviate vector database in the cluster. Practice gathering the Pure Storage metrics using Prometheus. Practice instrumenting Python services that interact with Large Language Models (LLMs) with OpenTelemetry. Understanding which details which OpenTelemetry captures in the trace from applications that interact with LLMs."><meta property="og:url" content="https://splunk.github.io/observability-workshop/en/ninja-workshops/14-cisco-ai-pods/2-workshop/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="Workshop :: Splunk Observability Cloud Workshops"><meta property="og:description" content="This section includes the steps that workshop attendees will follow:
Practice deploying the OpenTelemetry Collector in the Red Hat OpenShift cluster. Practice adding Prometheus receivers to the collector to ingest infrastructure metrics. Practice monitoring the Weaviate vector database in the cluster. Practice gathering the Pure Storage metrics using Prometheus. Practice instrumenting Python services that interact with Large Language Models (LLMs) with OpenTelemetry. Understanding which details which OpenTelemetry captures in the trace from applications that interact with LLMs."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Workshop :: Splunk Observability Cloud Workshops"><meta itemprop=description content="This section includes the steps that workshop attendees will follow:
Practice deploying the OpenTelemetry Collector in the Red Hat OpenShift cluster. Practice adding Prometheus receivers to the collector to ingest infrastructure metrics. Practice monitoring the Weaviate vector database in the cluster. Practice gathering the Pure Storage metrics using Prometheus. Practice instrumenting Python services that interact with Large Language Models (LLMs) with OpenTelemetry. Understanding which details which OpenTelemetry captures in the trace from applications that interact with LLMs."><meta itemprop=dateModified content="2026-01-30T11:42:27-08:00"><meta itemprop=wordCount content="77"><title>Workshop :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/en/ninja-workshops/14-cisco-ai-pods/2-workshop/index.html rel=canonical type=text/html title="Workshop :: Splunk Observability Cloud Workshops"><link href=/observability-workshop/images/favicon.ico?1770901811 rel=icon type=image/x-icon sizes=any><link href=/observability-workshop/css/auto-complete/auto-complete.min.css?1770901811 rel=stylesheet><script src=/observability-workshop/js/auto-complete/auto-complete.min.js?1770901811 defer></script><script src=/observability-workshop/js/search-lunr.min.js?1770901811 defer></script><script src=/observability-workshop/js/search.min.js?1770901811 defer></script><script>window.relearn=window.relearn||{},window.relearn.index_js_url="/observability-workshop/searchindex.en.js?1770901811"</script><script src=/observability-workshop/js/lunr/lunr.min.js?1770901811 defer></script><script src=/observability-workshop/js/lunr/lunr.stemmer.support.min.js?1770901811 defer></script><script src=/observability-workshop/js/lunr/lunr.multi.min.js?1770901811 defer></script><script src=/observability-workshop/js/lunr/lunr.en.min.js?1770901811 defer></script><script>window.relearn=window.relearn||{},window.relearn.contentLangs=["en"]</script><link href=/observability-workshop/fonts/fontawesome/css/all.min.css?1770901811 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/fonts/fontawesome/css/all.min.css?1770901811 rel=stylesheet></noscript><link href=/observability-workshop/css/perfect-scrollbar/perfect-scrollbar.min.css?1770901811 rel=stylesheet><link href=/observability-workshop/css/theme.min.css?1770901811 rel=stylesheet><link href=/observability-workshop/css/format-print.min.css?1770901811 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/ninja-workshops/14-cisco-ai-pods/2-workshop/index.html",window.relearn.relBasePath="../../../..",window.relearn.relBaseUri="../../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop",window.relearn.disableInlineCopyToClipboard=!0,window.relearn.enableBlockCodeWrap=!0,window.T_Copy_to_clipboard=`Copy text to clipboard`,window.T_Copied_to_clipboard=`Text copied to clipboard!`,window.T_Link_copied_to_clipboard=`Link copied to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`,window.T_Browser_unsupported_feature=`This browser doesn't support this feature`,window.relearn.themevariants=["auto","splunk-light","splunk-dark"],window.relearn.customvariantprefix="my-custom-",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant")??"";(!e||!e.startsWith(window.relearn.customvariantprefix)&&!window.relearn.themevariants.includes(e)||e.startsWith(window.relearn.customvariantprefix)&&!window.localStorage.getItem(window.relearn.absBaseUri+"/variantstylesheet-"+e))&&(e=window.relearn.themevariants[0],window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant()</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"us1",rumAccessToken:"h7q1NLX6lJz0h_5-OqQJkg",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({appplicationName:"observability-workshop",realm:"us1",rumAccessToken:"h7q1NLX6lJz0h_5-OqQJkg",recorder:"splunk",features:{video:!0}})</script></script><style>:root{--MAIN-WIDTH-MAX:130rem;--MENU-WIDTH-L:23rem}p{margin:.75rem 0}.highlight{max-height:500px;overflow-y:auto}pre:not(.mermaid){margin:0}</style></head><body class="mobile-support print" data-origin=/observability-workshop/en/ninja-workshops/14-cisco-ai-pods/2-workshop/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar class=default-animation><div class="topbar-wrapper default-animation"><div class="topbar-sidebar-divider default-animation"></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar default-animation" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><span class="btn cstyle button link noborder notitle interactive"><button onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></span></div><div class="topbar-button topbar-button-toc default-animation" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><button onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-table-list"></i></button></span><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/en/ninja-workshops/index.html><span itemprop=name>Splunk4Ninjas Workshops</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/en/ninja-workshops/14-cisco-ai-pods/index.html><span itemprop=name>Monitoring Cisco AI Pods with Splunk Observability Cloud</span></a><meta itemprop=position content="3">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>2. Workshop</span><meta itemprop=position content="4"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print default-animation" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><a href=/observability-workshop/en/ninja-workshops/14-cisco-ai-pods/2-workshop/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></span></div><div class="topbar-button topbar-button-prev default-animation" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><a href=/observability-workshop/en/ninja-workshops/14-cisco-ai-pods/1-workshop-setup/10-cleanup/index.html title="Clean Up (ðŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a></span></div><div class="topbar-button topbar-button-next default-animation" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><a href=/observability-workshop/en/ninja-workshops/14-cisco-ai-pods/2-workshop/1-overview-of-workshop-environment/index.html title="Overview of the Workshop Environment (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a></span></div><div class="topbar-button topbar-button-more default-animation" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><button onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button></span><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable ninja-workshops" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=workshop>Workshop</h1><p>This section includes the steps that workshop attendees will follow:</p><ul><li>Practice deploying the <strong>OpenTelemetry Collector</strong> in the Red Hat OpenShift cluster.</li><li>Practice adding <strong>Prometheus</strong> receivers to the collector to ingest infrastructure metrics.</li><li>Practice monitoring the <strong>Weaviate</strong> vector database in the cluster.</li><li>Practice gathering the <strong>Pure Storage</strong> metrics using Prometheus.</li><li>Practice instrumenting Python services that interact with Large Language Models (LLMs) with <strong>OpenTelemetry</strong>.</li><li>Understanding which details which OpenTelemetry captures in the trace from applications that interact with LLMs.</li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 30, 2026</span></span></footer></article><section><h1 class=a11y-only>Subsections of 2. Workshop</h1><article class=default><header class=headline></header><h1 id=overview-of-the-workshop-environment>Overview of the Workshop Environment</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>5 minutes</span>
</span>&nbsp;<p><strong>Cisco&rsquo;s AI-ready PODs</strong> combine cutting-edge hardware and software to
deliver a robust, scalable, and efficient AI infrastructure.
<strong>Splunk Observability Cloud</strong> provides comprehensive visibility
into this entire stack: from infrastructure to application components.</p><p>This hands-on workshop teaches you how to monitor AI infrastructure
using OpenTelemetry and Prometheus, <strong>without requiring
access to an actual Cisco AI POD</strong>. You&rsquo;ll gain practical experience
deploying and configuring monitoring technologies in a realistic environment.</p><h2 id=lab-environment>Lab Environment<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>The workshop uses a shared <strong>OpenShift Cluster</strong> running in AWS, equipped
with NVIDIA GPUs and NVIDIA AI Enterprise software.</p><h3 id=pre-deployed-infrastructure>Pre-Deployed Infrastructure<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>The workshop instructor has deployed the following shared components to the
workshop environment:</p><ul><li><strong>NVIDIA NIM models</strong>:<ul><li><code>meta/llama-3.2-1b-instruct</code> - Processes user prompts</li><li><code>nvidia/llama-3.2-nv-embedqa-1b-v2</code> - Generates embeddings</li></ul></li><li><strong>Weaviate</strong> - A vector database for semantic search and retrieval</li><li><strong>Prometheus exporter</strong> - Simulates Pure Storage metrics typical of production AI PODs</li></ul><h3 id=your-workspace>Your Workspace<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Each participant receives a dedicated namespace within the shared cluster,
ensuring isolated environments for independent work.</p><h2 id=workshop-activities>Workshop Activities<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>During the workshop, each participant will execute the following tasks:</p><ol><li>Deploy and configure an <strong>OpenTelemetry collector</strong> in your namespace</li><li>Integrate observability data collection with the cluster infrastructure</li><li>Deploy a <strong>Python application</strong> that leverages the NVIDIA NIM models</li><li>Monitor application performance and infrastructure metrics using Splunk Observability Cloud</li></ol><h2 id=what-is-prometheus>What is Prometheus?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>While <strong>Prometheus</strong> typically refers to a full-stack monitoring system
used for storage and alerting, this workshop focuses on the Prometheus
ecosystem&rsquo;s data standards.</p><p>We will be leveraging <strong>Prometheus Exporters</strong>, which are small utilities
that translate a component&rsquo;s internal health into a standardized
metrics endpoint (e.g., http://localhost:9100/metrics).</p><p>Instead of using a full Prometheus server to collect this data, we will use
the <strong>OpenTelemetry Collector</strong>. By using its <strong>Prometheus receiver</strong>,
the collector can <strong>scrape</strong> these endpoints, allowing us to gather
rich telemetry data using a widely-supported industry format.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=connect-to-the-openshift-cluster>Connect to the OpenShift Cluster</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>5 minutes</span>
</span>&nbsp;<h2 id=connect-to-your-ec2-instance>Connect to your EC2 Instance<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Weâ€™ve prepared an Ubuntu Linux instance in AWS/EC2 for each attendee.</p><p>Using the IP address and password provided by your instructor, connect to your EC2 instance
using one of the methods below:</p><ul><li>Mac OS / Linux<ul><li>ssh splunk@IP address</li></ul></li><li>Windows 10+<ul><li>Use the OpenSSH client</li></ul></li><li>Earlier versions of Windows<ul><li>Use Putty</li></ul></li></ul><h2 id=set-the-workshop-participant-number>Set the Workshop Participant Number<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>The instructor will provide each participant with a number from 1 to 30.
Store this in an environment variable, and remember what it is, as
it will be used throughout the workshop:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>PARTICIPANT_NUMBER</span><span class=o>=</span>&lt;your participant number&gt;</span></span></code></pre></div><h2 id=install-the-openshift-cli>Install the OpenShift CLI<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>To access the OpenShift cluster, we&rsquo;ll need to install the OpenShift CLI.</p><p>We can use the following command to download the OpenShift CLI binary directly
to our EC2 instance:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0><code>curl -L -O https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/stable/openshift-client-linux.tar.gz</code></pre></div><p>Extract the contents:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0><code>tar -xvzf openshift-client-linux.tar.gz</code></pre></div><p>Move the resulting files (<code>oc</code> and <code>kubectl</code>) to a location that&rsquo;s included as part of your path. For example:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo mv oc /usr/local/bin/oc
</span></span><span class=line><span class=cl>sudo mv kubectl /usr/local/bin/kubectl</span></span></code></pre></div><h2 id=connect-to-the-openshift-cluster>Connect to the OpenShift Cluster<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Ensure the Kube config file is modifiable by the splunk user:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>chmod <span class=m>600</span> /home/splunk/.kube/config</span></span></code></pre></div><p>Use the cluster API URL and password provided by the workshop
organizer to log in to the OpenShift cluster:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>oc login https://api.&lt;cluster-domain&gt;:443 -u participant<span class=nv>$PARTICIPANT_NUMBER</span> -p <span class=s1>&#39;&lt;password&gt;&#39;</span></span></span></code></pre></div><p>Ensure you&rsquo;re connected to the OpenShift cluster:</p><div class=tab-panel data-tab-group=R-tabs-7fb94968e25d355d79a4ccbd2597daf3><div class=tab-nav><div class=tab-nav-title>&#8203;</div><button aria-controls=R-tab-id-7b03810bd0feb48d2d63868c84612ba0 aria-expanded=true data-tab-item=R-tab-f907e651164789346ae0a1e257c462d8 class="tab-nav-button tab-panel-style cstyle initial active" tabindex=-1 onclick='switchTab("R-tabs-7fb94968e25d355d79a4ccbd2597daf3","R-tab-f907e651164789346ae0a1e257c462d8")'>
<span class=tab-nav-text>Script</span>
</button>
<button aria-controls=R-tab-id-3d98af1ed31ed27329078322d36b1a6c aria-expanded=false data-tab-item=R-tab-4c50e65a8a1f9aa989870396b5c0a12b class="tab-nav-button tab-panel-style cstyle initial" onclick='switchTab("R-tabs-7fb94968e25d355d79a4ccbd2597daf3","R-tab-4c50e65a8a1f9aa989870396b5c0a12b")'>
<span class=tab-nav-text>Example Output</span></button></div><div class=tab-content-container><div id=R-tab-id-7b03810bd0feb48d2d63868c84612ba0 data-tab-item=R-tab-f907e651164789346ae0a1e257c462d8 class="tab-content tab-panel-style cstyle initial active"><div class=tab-content-text><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>oc whoami --show-server </span></span></code></pre></div></div></div><div id=R-tab-id-3d98af1ed31ed27329078322d36b1a6c data-tab-item=R-tab-4c50e65a8a1f9aa989870396b5c0a12b class="tab-content tab-panel-style cstyle initial"><div class=tab-content-text><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>https://api.***.openshiftapps.com:443</span></span></code></pre></div></div></div></div></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=deploy-the-opentelemetry-collector>Deploy the OpenTelemetry Collector</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>10 minutes</span>
</span>&nbsp;<p>In this section we&rsquo;ll deploy the OpenTelemetry Collector in our OpenShift namespace,
which gathers metrics, logs, and traces from the infrastructure and applications
running in the cluster, and sends the resulting data to Splunk Observability Cloud.</p><h2 id=deploy-the-opentelemetry-collector>Deploy the OpenTelemetry Collector<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><h3 id=ensure-helm-is-installed>Ensure Helm is installed<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Run the following command to confirm that Helm is installed:</p><div class=tab-panel data-tab-group=R-tabs-7840ea47adf48810c8cfca41d3e24855><div class=tab-nav><div class=tab-nav-title>&#8203;</div><button aria-controls=R-tab-id-0374e189b7e4d7cfe13c9c6b9e812528 aria-expanded=true data-tab-item=R-tab-f907e651164789346ae0a1e257c462d8 class="tab-nav-button tab-panel-style cstyle initial active" tabindex=-1 onclick='switchTab("R-tabs-7840ea47adf48810c8cfca41d3e24855","R-tab-f907e651164789346ae0a1e257c462d8")'>
<span class=tab-nav-text>Script</span>
</button>
<button aria-controls=R-tab-id-6fd843b56e471be92b0666c677a84f02 aria-expanded=false data-tab-item=R-tab-4c50e65a8a1f9aa989870396b5c0a12b class="tab-nav-button tab-panel-style cstyle initial" onclick='switchTab("R-tabs-7840ea47adf48810c8cfca41d3e24855","R-tab-4c50e65a8a1f9aa989870396b5c0a12b")'>
<span class=tab-nav-text>Example Output</span></button></div><div class=tab-content-container><div id=R-tab-id-0374e189b7e4d7cfe13c9c6b9e812528 data-tab-item=R-tab-f907e651164789346ae0a1e257c462d8 class="tab-content tab-panel-style cstyle initial active"><div class=tab-content-text><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm version</span></span></code></pre></div></div></div><div id=R-tab-id-6fd843b56e471be92b0666c677a84f02 data-tab-item=R-tab-4c50e65a8a1f9aa989870396b5c0a12b class="tab-content tab-panel-style cstyle initial"><div class=tab-content-text><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>version.BuildInfo<span class=o>{</span>Version:<span class=s2>&#34;v3.19.4&#34;</span>, GitCommit:<span class=s2>&#34;7cfb6e486dac026202556836bb910c37d847793e&#34;</span>, GitTreeState:<span class=s2>&#34;clean&#34;</span>, GoVersion:<span class=s2>&#34;go1.24.11&#34;</span><span class=o>}</span></span></span></code></pre></div></div></div></div></div><p>If it&rsquo;s not installed, execute the following commands:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>sudo apt-get install curl gpg apt-transport-https --yes
</span></span><span class=line><span class=cl>curl -fsSL https://packages.buildkite.com/helm-linux/helm-debian/gpgkey <span class=p>|</span> gpg --dearmor <span class=p>|</span> sudo tee /usr/share/keyrings/helm.gpg &gt; /dev/null
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s2>&#34;deb [signed-by=/usr/share/keyrings/helm.gpg] https://packages.buildkite.com/helm-linux/helm-debian/any/ any main&#34;</span> <span class=p>|</span> sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install helm</span></span></code></pre></div><h3 id=add-the-splunk-opentelemetry-collector-helm-chart>Add the Splunk OpenTelemetry Collector Helm Chart<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Add the Splunk OpenTelemetry Collector for Kubernetes&rsquo; Helm chart repository:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart</span></span></code></pre></div><p>Ensure the repository is up-to-date:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm repo update</span></span></code></pre></div><h3 id=configure-environment-variables>Configure Environment Variables<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Set environment variables to configure the Splunk environment you&rsquo;d like
the collector to send data to:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>USER_NAME</span><span class=o>=</span>workshop-participant-<span class=nv>$PARTICIPANT_NUMBER</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>CLUSTER_NAME</span><span class=o>=</span>ai-pod-<span class=nv>$USER_NAME</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>ENVIRONMENT_NAME</span><span class=o>=</span>ai-pod-<span class=nv>$USER_NAME</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>SPLUNK_INDEX</span><span class=o>=</span>splunk4rookies-workshop</span></span></code></pre></div><h3 id=deploy-the-collector>Deploy the Collector<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Navigate to the workshop directory:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> ~/workshop/cisco-ai-pods</span></span></code></pre></div><p>Then install the collector in your namespace using the following command:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm install splunk-otel-collector <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;clusterName=</span><span class=nv>$CLUSTER_NAME</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;environment=</span><span class=nv>$ENVIRONMENT_NAME</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkObservability.accessToken=</span><span class=nv>$ACCESS_TOKEN</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkObservability.realm=</span><span class=nv>$REALM</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkPlatform.endpoint=</span><span class=nv>$HEC_URL</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkPlatform.token=</span><span class=nv>$HEC_TOKEN</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkPlatform.index=</span><span class=nv>$SPLUNK_INDEX</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -f ./otel-collector/otel-collector-values.yaml <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -n <span class=nv>$USER_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  splunk-otel-collector-chart/splunk-otel-collector</span></span></code></pre></div><blockquote><p>Note that we&rsquo;re referencing a configuration file named
<code>otel-collector-values.yaml</code> when installing the collector,
which includes custom configuration.</p></blockquote><p>Run the following command to confirm that the collector pods are running:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0><code>oc get pods

NAME                                                          READY   STATUS    RESTARTS   AGE
splunk-otel-collector-agent-58rwm                             1/1     Running   0          6m40s
splunk-otel-collector-agent-8dndr                             1/1     Running   0          6m40s</code></pre></div><blockquote><p>Note: in OpenShift environments, the collector takes about three minutes to
start and transition to the <code>Running</code> state.</p></blockquote><h3 id=review-collector-data-in-splunk-observability-cloud>Review Collector Data in Splunk Observability Cloud<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Confirm that you can see your cluster in <strong>Splunk Observability Cloud</strong> by navigating to
<strong>Infrastructure Monitoring</strong> -> <strong>Kubernetes</strong> -> <strong>Kubernetes Clusters</strong> and then
adding a filter on <code>k8s.cluster.name</code> with your cluster name (i.e. <code>ai-pod-workshop-participant-1</code>):</p><p><a href=#R-image-5afea9828b7e0512a7fe9795f4cf1d17 class=lightbox-link><img alt="Kubernetes Pods" class="lazy lightbox figure-image" loading=lazy src=../../images/KubernetesPods.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-5afea9828b7e0512a7fe9795f4cf1d17><img alt="Kubernetes Pods" class="lazy lightbox lightbox-image" loading=lazy src=../../images/KubernetesPods.png></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=monitor-nvidia-components>Monitor NVIDIA Components</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>10 minutes</span>
</span>&nbsp;<p>In this section, we&rsquo;ll use the Prometheus receiver with the OpenTelemetry collector
to monitor the NVIDIA components running in the OpenShift cluster. We&rsquo;ll start by
navigating to the directory where the collector configuration file is stored:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> otel-collector</span></span></code></pre></div><h2 id=capture-the-nvidia-dcgm-exporter-metrics>Capture the NVIDIA DCGM Exporter metrics<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>The <a href=https://github.com/NVIDIA/dcgm-exporter rel=external>NVIDIA DCGM exporter</a> is running
in our OpenShift cluster. It exposes GPU metrics that we can send to Splunk.</p><p>To do this, let&rsquo;s customize the configuration of the collector by editing the
<code>otel-collector-values.yaml</code> file that we used earlier when deploying the collector.</p><p>Add the following content, just below the <code>kubeletstats</code> receiver:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>      </span><span class=nt>receiver_creator/nvidia</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=c># Name of the extensions to watch for endpoints to start and stop.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>watch_observers</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=w> </span><span class=l>k8s_observer ]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>prometheus/dcgm</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>scrape_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                  </span>- <span class=nt>job_name</span><span class=p>:</span><span class=w> </span><span class=l>gpu-metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>scrape_interval</span><span class=p>:</span><span class=w> </span><span class=l>60s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>static_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                      </span>- <span class=nt>targets</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                          </span>- <span class=s1>&#39;`endpoint`:9400&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>rule</span><span class=p>:</span><span class=w> </span><span class=l>type == &#34;pod&#34; &amp;&amp; labels[&#34;app&#34;] == &#34;nvidia-dcgm-exporter&#34;</span></span></span></code></pre></div><p>This tells the collector to look for pods with a label of <code>app=nvidia-dcgm-exporter</code>.
And when it finds a pod with this label, it will connect to port 9400 of the pod and scrape
the default metrics endpoint (<code>/v1/metrics</code>).</p><blockquote><p>Why are we using the <strong>receiver_creator</strong> receiver instead of just the <strong>Prometheus</strong> receiver?</p><ul><li>The <strong>Prometheus</strong> receiver uses a static configuration that scrapes metrics from predefined endpoints.</li><li>The <strong>receiver_creator</strong> receiver enables dynamic creation of receivers (including Prometheus receivers) based on runtime information, allowing for scalable and flexible scraping setups.</li><li>Using <strong>receiver_creator</strong> can simplify configurations in dynamic environments by automating the management of multiple Prometheus scraping targets.</li></ul></blockquote><p>To ensure this new receiver is used, we&rsquo;ll need to add a new pipeline to the
<code>otel-collector-values.yaml</code> file as well.</p><p>Add the following code to the bottom of the file:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>    </span><span class=nt>service</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>pipelines</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>metrics/nvidia-metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>exporters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>signalfx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>processors</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>memory_limiter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>batch</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>resourcedetection</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>resource</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>receiver_creator/nvidia</span></span></span></code></pre></div><p>We&rsquo;ll add one more Prometheus receiver related to NVIDIA in the next section.</p><h2 id=capture-the-nvidia-nim-metrics>Capture the NVIDIA NIM metrics<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>The <code>meta-llama-3-2-1b-instruct</code> large language model was deployed to the
OpenShift cluster using NVIDIA NIM. It includes a Prometheus endpoint
that we can scrape with the collector. Let&rsquo;s add the following to the
<code>otel-collector-values.yaml</code> file, just below the <code>prometheus/dcgm</code> receiver
we added earlier:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>          </span><span class=nt>prometheus/nim-llm</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>scrape_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                  </span>- <span class=nt>job_name</span><span class=p>:</span><span class=w> </span><span class=l>nim-for-llm-metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>scrape_interval</span><span class=p>:</span><span class=w> </span><span class=l>60s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>metrics_path</span><span class=p>:</span><span class=w> </span><span class=l>/v1/metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>static_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                      </span>- <span class=nt>targets</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                          </span>- <span class=s1>&#39;`endpoint`:8000&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>rule</span><span class=p>:</span><span class=w> </span><span class=l>type == &#34;pod&#34; &amp;&amp; labels[&#34;app&#34;] == &#34;meta-llama-3-2-1b-instruct&#34;</span></span></span></code></pre></div><p>This tells the collector to look for pods with a label of <code>app=meta-llama-3-2-1b-instruct</code>.
And when it finds a pod with this label, it will connect to port 8000 of the pod and scrape
the <code>/v1/metrics</code> metrics endpoint.</p><p>There&rsquo;s no need to make changes to the pipeline, as this receiver will already be picked up
as part of the <code>receiver_creator/nvidia</code> receiver.</p><h2 id=add-a-filter-processor>Add a Filter Processor<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Scraping Prometheus endpoints can result in a large number of metrics, sometimes
with high cardinality.</p><p>Let&rsquo;s add a filter processor that defines exactly what metrics we want to send to Splunk.
Specifically, we&rsquo;ll send <strong>only</strong> the metrics that are utilized by a dashboard chart or an
alert detector.</p><p>Add the following code to the <code>otel-collector-values.yaml</code> file, after the exporters section
but before the receivers section:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>    </span><span class=nt>processors</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>filter/metrics_to_be_included</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=c># Include only metrics used in charts and detectors</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>include</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>match_type</span><span class=p>:</span><span class=w> </span><span class=l>strict</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>metric_names</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_FB_FREE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_FB_USED</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_GPU_TEMP</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_GPU_UTIL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_MEM_CLOCK</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_MEM_COPY_UTIL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_MEMORY_TEMP</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_POWER_USAGE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_SM_CLOCK</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_TOTAL_ENERGY_CONSUMPTION</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_PROF_DRAM_ACTIVE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_PROF_GR_ENGINE_ACTIVE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_PROF_PCIE_RX_BYTES</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_PROF_PCIE_TX_BYTES</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_PROF_PIPE_TENSOR_ACTIVE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>generation_tokens_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_info</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_alloc_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_alloc_bytes_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_buck_hash_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_frees_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_gc_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_heap_alloc_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_heap_idle_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_heap_inuse_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_heap_objects</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_heap_released_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_heap_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_last_gc_time_seconds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_lookups_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_mallocs_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_mcache_inuse_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_mcache_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_mspan_inuse_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_mspan_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_next_gc_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_other_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_stack_inuse_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_stack_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_memstats_sys_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>go_sched_gomaxprocs_threads</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>gpu_cache_usage_perc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>gpu_total_energy_consumption_joules</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>http.server.active_requests</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>num_request_max</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>num_requests_running</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>num_requests_waiting</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>process_cpu_seconds_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>process_max_fds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>process_open_fds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>process_resident_memory_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>process_start_time_seconds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>process_virtual_memory_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>process_virtual_memory_max_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>promhttp_metric_handler_requests_in_flight</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>promhttp_metric_handler_requests_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>prompt_tokens_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>python_gc_collections_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>python_gc_objects_collected_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>python_gc_objects_uncollectable_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>python_info</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>request_finish_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>request_success_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>system.cpu.time</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>e2e_request_latency_seconds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>time_to_first_token_seconds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>time_per_output_token_seconds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>request_prompt_tokens</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>request_generation_tokens</span></span></span></code></pre></div><p>Ensure the <code>filter/metrics_to_be_included</code> processor is included in the
<code>metrics/nvidia-metrics</code> pipeline we added earlier:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>    service:
</span></span><span class=line><span class=cl>      pipelines:
</span></span><span class=line><span class=cl>        metrics/nvidia-metrics:
</span></span><span class=line><span class=cl>          exporters:
</span></span><span class=line><span class=cl>            - signalfx
</span></span><span class=line><span class=cl>          processors:
</span></span><span class=line><span class=cl>            - memory_limiter
</span></span><span class=line><span class=cl>            - filter/metrics_to_be_included
</span></span><span class=line><span class=cl>            - batch
</span></span><span class=line><span class=cl>            - resourcedetection
</span></span><span class=line><span class=cl>            - resource
</span></span><span class=line><span class=cl>          receivers:
</span></span><span class=line><span class=cl>            - receiver_creator/nvidia</span></span></code></pre></div><h2 id=verify-changes>Verify Changes<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Take a moment to compare the contents of your modified <code>otel-collector-values.yaml</code>
file with the <code>otel-collector-values-with-nvidia.yaml</code> file.
Update your file if needed to ensure the contents match. Remember that indentation is important
for <code>yaml</code> files, and needs to be precise.</p><p>Because restarting the collector in an OpenShift environment takes about 3 minutes,
we&rsquo;ll wait until we&rsquo;ve completed all configuration changes before initiating a restart.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=monitor-the-vector-database>Monitor the Vector Database</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>5 minutes</span>
</span>&nbsp;<p>In this step, we&rsquo;ll configure the Prometheus receiver to monitor the Weaviate vector database.</p><h2 id=what-is-a-vector-database>What is a Vector Database?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>A <strong>vector database</strong> stores and indexes data as numerical &ldquo;vector embeddings,&rdquo; which capture
the <strong>semantic meaning</strong> of information like text or images. Unlike traditional databases,
they excel at <strong>similarity searches</strong>, finding conceptually related data points rather
than exact matches.</p><h2 id=how-is-a-vector-database-used>How is a Vector Database Used?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Vector databases play a key role in a pattern called
<strong>Retrieval Augmented Generation (RAG)</strong>, which is widely used by
applications that leverage Large Language Models (LLMs).</p><p>The pattern is as follows:</p><ul><li>The end-user asks a question to the application</li><li>The application takes the question and calculates a vector embedding for it</li><li>The app then performs a similarity search, looking for related documents in the vector database</li><li>The app then takes the original question and the related documents, and sends it to the LLM as context</li><li>The LLM reviews the context and returns a response to the application</li></ul><h2 id=capture-weaviate-metrics-with-prometheus>Capture Weaviate Metrics with Prometheus<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Let&rsquo;s modify the OpenTelemetry collector configuration to scrape Weaviate&rsquo;s Prometheus
metrics.</p><p>To do so, let&rsquo;s add an additional Prometheus receiver creator section
to the <code>otel-collector-values.yaml</code> file:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>      </span><span class=nt>receiver_creator/weaviate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=c># Name of the extensions to watch for endpoints to start and stop.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>watch_observers</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=w> </span><span class=l>k8s_observer ]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>prometheus/weaviate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>scrape_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                  </span>- <span class=nt>job_name</span><span class=p>:</span><span class=w> </span><span class=l>weaviate-metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>scrape_interval</span><span class=p>:</span><span class=w> </span><span class=l>60s</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>static_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                      </span>- <span class=nt>targets</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                          </span>- <span class=s1>&#39;`endpoint`:2112&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>rule</span><span class=p>:</span><span class=w> </span><span class=l>type == &#34;pod&#34; &amp;&amp; labels[&#34;app&#34;] == &#34;weaviate&#34;</span></span></span></code></pre></div><p>We&rsquo;ll need to ensure that Weaviate&rsquo;s metrics are added to the <code>filter/metrics_to_be_included</code> filter
processor configuration as well:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>    </span><span class=nt>processors</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>filter/metrics_to_be_included</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=c># Include only metrics used in charts and detectors</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>include</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>match_type</span><span class=p>:</span><span class=w> </span><span class=l>strict</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>metric_names</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_FB_FREE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>object_count</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>vector_index_size</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>vector_index_operations</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>vector_index_tombstones</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>vector_index_tombstone_cleanup_threads</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>vector_index_tombstone_cleanup_threads</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>requests_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>objects_durations_ms_sum</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>objects_durations_ms_count</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>batch_delete_durations_ms_sum</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>batch_delete_durations_ms_count</span></span></span></code></pre></div><p>We also want to add a Resource processor to the configuration file, with the following configuration:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>      </span><span class=nt>resource/weaviate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>attributes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=l>weaviate.instance.id</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>from_attribute</span><span class=p>:</span><span class=w> </span><span class=l>service.instance.id</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>action</span><span class=p>:</span><span class=w> </span><span class=l>insert</span></span></span></code></pre></div><p>This processor takes the <code>service.instance.id</code> property on the Weaviate metrics
and copies it into a new property called <code>weaviate.instance.id</code>. This is done so
that we can more easily distinguish Weaviate metrics from other metrics that use
<code>service.instance.id</code>, which is a standard OpenTelemetry property used in
Splunk Observability Cloud.</p><p>We&rsquo;ll need to add a new metrics pipeline for Weaviate metrics as well (we
need to use a separate pipeline since we don&rsquo;t want the <code>weaviate.instance.id</code>
metric to be added to non-Weaviate metrics):</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>        </span><span class=nt>metrics/weaviate</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>exporters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>signalfx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>processors</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>memory_limiter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>filter/metrics_to_be_included</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>resource/weaviate</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>batch</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>resourcedetection</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>resource</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>receiver_creator/weaviate</span></span></span></code></pre></div><p>Take a moment to compare the
contents of your modified <code>otel-collector-values.yaml</code> file with the
<code>otel-collector-values-with-weaviate.yaml</code> file.
Update your file as needed to ensure the contents match. Remember that indentation is important
for <code>yaml</code> files, and needs to be precise.</p><p>Because restarting the collector in an OpenShift environment takes about 3 minutes,
we&rsquo;ll wait until we&rsquo;ve completed all configuration changes before initiating a restart.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=monitor-storage>Monitor Storage</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>5 minutes</span>
</span>&nbsp;<p>In this step, we&rsquo;ll configure the Prometheus receiver to monitor the storage.</p><h2 id=what-storage-do-cisco-ai-pods-utilize>What storage do Cisco AI PODs utilize?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Cisco AI PODs have a number of different storage options, including Pure Storage,
VAST, and NetApp.</p><p>The workshop will focus on Pure Storage.</p><h2 id=how-do-we-capture-pure-storage-metrics>How do we capture Pure Storage metrics?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Cisco AI PODs that utilize Pure Storage also use a technology called Portworx,
which provides persistent storage for Kubernetes.</p><p>Portworx includes a metrics endpoint that we can scrape using the Prometheus receiver.</p><h2 id=capture-storage-metrics-with-prometheus>Capture Storage Metrics with Prometheus<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Let&rsquo;s modify the OpenTelemetry collector configuration to scrape Portworx metrics
with the Prometheus receiver.</p><p>To do so, let&rsquo;s add an additional Prometheus receiver creator section
to the <code>otel-collector-values.yaml</code> file:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>      </span><span class=nt>receiver_creator/storage</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=c># Name of the extensions to watch for endpoints to start and stop.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>watch_observers</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=w> </span><span class=l>k8s_observer ]</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>prometheus/portworx</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>config</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>scrape_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                  </span>- <span class=nt>job_name</span><span class=p>:</span><span class=w> </span><span class=l>portworx-metrics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                    </span><span class=nt>static_configs</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                      </span>- <span class=nt>targets</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                          </span>- <span class=s1>&#39;`endpoint`:17001&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                          </span>- <span class=s1>&#39;`endpoint`:17018&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>rule</span><span class=p>:</span><span class=w> </span><span class=l>type == &#34;pod&#34; &amp;&amp; labels[&#34;app&#34;] == &#34;portworx-metrics-sim&#34;</span></span></span></code></pre></div><p>We&rsquo;ll need to ensure that Portworx metrics are added to the <code>filter/metrics_to_be_included</code> filter
processor configuration as well:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>    </span><span class=nt>processors</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>filter/metrics_to_be_included</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>metrics</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=c># Include only metrics used in charts and detectors</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>include</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>match_type</span><span class=p>:</span><span class=w> </span><span class=l>strict</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>metric_names</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>DCGM_FI_DEV_FB_FREE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_cluster_cpu_percent</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_cluster_disk_total_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_cluster_disk_utilized_bytes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_cluster_status_nodes_offline</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_cluster_status_nodes_online</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_volume_read_latency_seconds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_volume_reads_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_volume_readthroughput</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_volume_write_latency_seconds</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_volume_writes_total</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>px_volume_writethroughput</span></span></span></code></pre></div><p>We&rsquo;ll need to add a new metrics pipeline for Portworx metrics as well:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>        </span><span class=nt>metrics/storage</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>exporters</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>signalfx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>processors</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>memory_limiter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>filter/metrics_to_be_included</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>batch</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>resourcedetection</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>resource</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>receivers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=l>receiver_creator/storage</span></span></span></code></pre></div><p>Take a moment to compare the
contents of your modified <code>otel-collector-values.yaml</code> file with the
<code>otel-collector-values-with-portworx.yaml</code> file.
Update your file as needed to ensure the contents match. Remember that indentation is important
for <code>yaml</code> files, and needs to be precise.</p><p>Because restarting the collector in an OpenShift environment takes about 3 minutes,
we&rsquo;ll wait until we&rsquo;ve completed all configuration changes before initiating a restart.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=review-ai-pod-dashboards>Review AI POD Dashboards</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>10 minutes</span>
</span>&nbsp;<p>In this section, we&rsquo;ll review the AI POD dashboards in Splunk Observability Cloud
to confirm that the data from NVIDIA, Pure Storage, and Weaviate is captured
as expected.</p><h2 id=update-the-opentelemetry-collector-config>Update the OpenTelemetry Collector Config<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>We can apply the collector configuration changes by running the following Helm command:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm upgrade splunk-otel-collector <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;clusterName=</span><span class=nv>$CLUSTER_NAME</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;environment=</span><span class=nv>$ENVIRONMENT_NAME</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkObservability.accessToken=</span><span class=nv>$ACCESS_TOKEN</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkObservability.realm=</span><span class=nv>$REALM</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkPlatform.endpoint=</span><span class=nv>$HEC_URL</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkPlatform.token=</span><span class=nv>$HEC_TOKEN</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set<span class=o>=</span><span class=s2>&#34;splunkPlatform.index=</span><span class=nv>$SPLUNK_INDEX</span><span class=s2>&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -f ./otel-collector-values.yaml <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -n <span class=nv>$USER_NAME</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  splunk-otel-collector-chart/splunk-otel-collector</span></span></code></pre></div><h2 id=review-the-ai-pod-overview-dashboard-tab>Review the AI POD Overview Dashboard Tab<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Navigate to <code>Dashboards</code> in Splunk Observability Cloud, then search for the
<code>Cisco AI PODs Dashboard</code>, which is included in the <code>Built-in dashboard groups</code>.
Ensure the dashboard is filtered on your OpenShift cluster name.
The charts should be populated as in the following example:</p><p><a href=#R-image-6e20e2075233f9d272e8d16c60233249 class=lightbox-link><img alt="Kubernetes Pods" class="lazy lightbox figure-image" loading=lazy src=../../images/Cisco-AI-Pod-dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-6e20e2075233f9d272e8d16c60233249><img alt="Kubernetes Pods" class="lazy lightbox lightbox-image" loading=lazy src=../../images/Cisco-AI-Pod-dashboard.png></a></p><h2 id=review-the-pure-storage-dashboard-tab>Review the Pure Storage Dashboard Tab<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Navigate to the <code>PURE STORAGE</code> tab and ensure the dashboard is filtered
on your OpenShift cluster name. The charts should be populated as in the
following example:</p><p><a href=#R-image-af9df4cbf6a9c5fd363da06808854ae8 class=lightbox-link><img alt="Pure Storage Dashboard" class="lazy lightbox figure-image" loading=lazy src=../../images/PureStorage.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-af9df4cbf6a9c5fd363da06808854ae8><img alt="Pure Storage Dashboard" class="lazy lightbox lightbox-image" loading=lazy src=../../images/PureStorage.png></a></p><h2 id=review-the-weaviate-infrastructure-navigator>Review the Weaviate Infrastructure Navigator<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Since Weaviate isn&rsquo;t included by default with an AI POD, it&rsquo;s
not included on the out-of-the-box AI POD dashboard. Instead,
we can view Weaviate performance data using one of the infrastructure
navigators.</p><p>In Splunk Observability Cloud, navigate to <code>Infrastructure</code> -> <code>AI Frameworks</code> -> <code>Weaviate</code>.
Filter on the <code>k8s.cluster.name</code> of interest, and ensure the navigator is populated as in the
following example:</p><p><a href=#R-image-e841459c6743f8e328907cc8efc0dc2f class=lightbox-link><img alt="Kubernetes Pods" class="lazy lightbox figure-image" loading=lazy src=../../images/WeaviateNavigator.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e841459c6743f8e328907cc8efc0dc2f><img alt="Kubernetes Pods" class="lazy lightbox lightbox-image" loading=lazy src=../../images/WeaviateNavigator.png></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=review-the-llm-application>Review the LLM Application</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>15 minutes</span>
</span>&nbsp;<p>In the final step of the workshop, we&rsquo;ll deploy an application to our OpenShift cluster
that uses the instruct and embeddings models.</p><h2 id=what-is-langchain>What is LangChain?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Like most applications that interact with LLMs, our application is written in Python.
It also uses <a href=https://www.langchain.com/ rel=external>LangChain</a>, which is an open-source orchestration
framework that simplifies the development of applications powered by LLMs.</p><h2 id=application-overview>Application Overview<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><h3 id=connect-to-the-llms>Connect to the LLMs<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Our application starts by connecting to two LLMs that we&rsquo;ll be using:</p><ul><li><code>meta/llama-3.2-1b-instruct</code>: used for responding to user prompts</li><li><code>nvidia/llama-3.2-nv-embedqa-1b-v2</code>: used to calculate embeddings</li></ul><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># connect to a LLM NIM at the specified endpoint, specifying a specific model</span>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>ChatNVIDIA</span><span class=p>(</span><span class=n>base_url</span><span class=o>=</span><span class=n>INSTRUCT_MODEL_URL</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=s2>&#34;meta/llama-3.2-1b-instruct&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Initialize and connect to a NeMo Retriever Text Embedding NIM (nvidia/llama-3.2-nv-embedqa-1b-v2)</span>
</span></span><span class=line><span class=cl><span class=n>embeddings_model</span> <span class=o>=</span> <span class=n>NVIDIAEmbeddings</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;nvidia/llama-3.2-nv-embedqa-1b-v2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                   <span class=n>base_url</span><span class=o>=</span><span class=n>EMBEDDINGS_MODEL_URL</span><span class=p>)</span></span></span></code></pre></div><blockquote><p>Why are there two models? Here&rsquo;s a helpful analogy:</p><ul><li>The Embedding model is the &ldquo;Librarian&rdquo; (it helps find the right books),</li><li>The Instruct model is the &ldquo;Writer&rdquo; (it reads the books and writes the answer).</li></ul></blockquote><h3 id=define-the-prompt-template>Define the Prompt Template<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>The application then defines a prompt template that will be used in interactions
with the <code>meta/llama-3.2-1b-instruct</code> LLM:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=s2>&#34;system&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;You are a helpful and friendly AI!&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Your responses should be concise and no longer than two sentences.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Do not hallucinate. Say you don&#39;t know if you don&#39;t have this information.&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Answer the question using only the context&#34;</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;</span><span class=se>\n\n</span><span class=s2>Question: </span><span class=si>{question}</span><span class=se>\n\n</span><span class=s2>Context: </span><span class=si>{context}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;</span><span class=si>{question}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>])</span></span></span></code></pre></div><blockquote><p>Note how we&rsquo;re explicitly instructing the LLM to just say it doesn&rsquo;t know the answer if
it doesn&rsquo;t know, which helps minimize hallucinations. There&rsquo;s also a placeholder for
us to provide context that the LLM can use to answer the question.</p></blockquote><h3 id=connect-to-the-vector-database>Connect to the Vector Database<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>The application then connects to the vector database that was pre-populated
with NVIDIA data sheet documents:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>weaviate_client</span> <span class=o>=</span> <span class=n>weaviate</span><span class=o>.</span><span class=n>connect_to_custom</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>http_host</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;WEAVIATE_HTTP_HOST&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>http_port</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;WEAVIATE_HTTP_PORT&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>http_secure</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>grpc_host</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;WEAVIATE_GRPC_HOST&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>grpc_port</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s1>&#39;WEAVIATE_GRPC_PORT&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>grpc_secure</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=n>vector_store</span> <span class=o>=</span> <span class=n>WeaviateVectorStore</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>client</span><span class=o>=</span><span class=n>weaviate_client</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>embedding</span><span class=o>=</span><span class=n>embeddings_model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>index_name</span><span class=o>=</span><span class=s2>&#34;CustomDocs&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>text_key</span><span class=o>=</span><span class=s2>&#34;page_content&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span></span></span></code></pre></div><h3 id=define-the-chain>Define the Chain<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>The application uses <strong>LCEL (LangChain Expression Language)</strong> to define the chain.
The <code>|</code> (pipe) symbol works like an assembly line; the output of one step becomes
the input for the next.</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>chain</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;context&#34;</span><span class=p>:</span> <span class=n>vector_store</span><span class=o>.</span><span class=n>as_retriever</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;question&#34;</span><span class=p>:</span> <span class=n>RunnablePassthrough</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>prompt</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>llm</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>StrOutputParser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span></span></span></code></pre></div><p>Let&rsquo;s break this down step-by-step:</p><ul><li><strong>Step 1: The Input Map {â€¦}</strong>: We are preparing the ingredients for our prompt.<ul><li>context: We turn our vector store into a retriever. This acts like a search engine that finds the most relevant snippets from our NVIDIA data sheets based on the userâ€™s question.</li><li>question: We use RunnablePassthrough() to ensure the userâ€™s original question is passed directly into the prompt.</li><li><strong>Note</strong>: These keys (context and question) map directly to the {context} and {question} placeholders we defined in our prompt template earlier.</li></ul></li><li><strong>Step 2: The prompt</strong>: This is the instruction manual. It takes the context and the question and formats them using the prompt template (e.g., &ldquo;Answer the question using only the context&mldr;&rdquo;).</li><li><strong>Step 3: The llm</strong>: This is the &ldquo;Engine&rdquo; (like GPT-4). It reads the formatted prompt and generates a response.</li><li><strong>Step 4: The StrOutputParser()</strong>: By default, AI models return complex objects. This &ldquo;cleaner&rdquo; ensures we get back a simple, readable string of text.</li></ul><h3 id=invoke-the-chain>Invoke the Chain<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Finally, the application invokes the chain by passing the end user&rsquo;s question in
as input:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>question</span><span class=p>)</span></span></span></code></pre></div><p>This is the &ldquo;Start&rdquo; button. You drop the end users&rsquo; question into the beginning of the pipeline,
and it flows through the retriever, the prompt, and the LLM until the answer comes
out the other side.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=instrument-the-llm-application>Instrument the LLM Application</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>10 minutes</span>
</span>&nbsp;<h2 id=instrument-the-application-with-opentelemetry>Instrument the Application with OpenTelemetry<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><h3 id=instrumentation-packages>Instrumentation Packages<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>To capture metrics, traces, and logs from our application, we&rsquo;ve instrumented it with OpenTelemetry.
This required adding the following package to the <code>requirements.txt</code> file (which ultimately gets
installed with <code>pip install</code>):</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0><code>splunk-opentelemetry==2.8.0</code></pre></div><p>We also added the following to the <code>Dockerfile</code> used to build the
container image for this application, to install additional OpenTelemetry
instrumentation packages:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=c># Add additional OpenTelemetry instrumentation packages</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>RUN</span> opentelemetry-bootstrap --action<span class=o>=</span>install</span></span></code></pre></div><p>Then we modified the <code>ENTRYPOINT</code> in the <code>Dockerfile</code> to call <code>opentelemetry-instrument</code>
when running the application:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>ENTRYPOINT</span> <span class=p>[</span><span class=s2>&#34;opentelemetry-instrument&#34;</span><span class=p>,</span> <span class=s2>&#34;flask&#34;</span><span class=p>,</span> <span class=s2>&#34;run&#34;</span><span class=p>,</span> <span class=s2>&#34;-p&#34;</span><span class=p>,</span> <span class=s2>&#34;8080&#34;</span><span class=p>,</span> <span class=s2>&#34;--host&#34;</span><span class=p>,</span> <span class=s2>&#34;0.0.0.0&#34;</span><span class=p>]</span></span></span></code></pre></div><p>Finally, to enhance the traces and metrics collected with OpenTelemetry from this
LangChain application, we added additional Splunk instrumentation packages:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0><code>splunk-otel-instrumentation-langchain==0.1.4
splunk-otel-util-genai==0.1.4</code></pre></div><h3 id=environment-variables>Environment Variables<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>To instrument the application with OpenTelemetry, we also included several
environment variables in the Kubernetes manifest file used to deploy the application:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>  </span><span class=nt>env</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_SERVICE_NAME</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;llm-app&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_EXPORTER_OTLP_ENDPOINT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;http://splunk-otel-collector-agent:4317&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_EXPORTER_OTLP_PROTOCOL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;grpc&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=c># filter out health check requests to the root URL</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_PYTHON_EXCLUDED_URLS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;^(https?://)?[^/]+(/)?$&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_PYTHON_DISABLED_INSTRUMENTATIONS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;httpx,requests&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_INSTRUMENTATION_LANGCHAIN_CAPTURE_MESSAGE_CONTENT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_LOGS_EXPORTER</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;otlp&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_PYTHON_LOG_CORRELATION</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;delta&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT_MODE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;SPAN_AND_EVENT&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_INSTRUMENTATION_GENAI_EMITTERS</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;span_metric_event,splunk&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>OTEL_INSTRUMENTATION_GENAI_EMITTERS_EVALUATION</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;replace-category:SplunkEvaluationResults&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>SPLUNK_PROFILER_ENABLED</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span></span></span></code></pre></div><p>Note that the <code>OTEL_INSTRUMENTATION_LANGCHAIN_CAPTURE_MESSAGE_CONTENT</code> and
<code>OTEL_INSTRUMENTATION_GENAI_*</code> environment variables are specific to the
LangChain instrumentation we&rsquo;ve used.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=deploy-the-llm-application>Deploy the LLM Application</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>10 minutes</span>
</span>&nbsp;<h2 id=deploy-the-llm-application>Deploy the LLM Application<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Use the following command to deploy this application to the OpenShift cluster:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>oc apply -f ./llm-app/k8s-manifest.yaml</span></span></code></pre></div><blockquote><p>Note: to build a Docker image for this Python application, we executed the following commands:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> workshop/cisco-ai-pods/llm-app
</span></span><span class=line><span class=cl>docker build --platform linux/amd64 -t ghcr.io/splunk/cisco-ai-pod-workshop-app:1.0 .
</span></span><span class=line><span class=cl>docker push ghcr.io/splunk/cisco-ai-pod-workshop-app:1.0</span></span></code></pre></div></blockquote><h2 id=test-the-llm-application>Test the LLM Application<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Let&rsquo;s ensure the application is working as expected.</p><p>Start a pod that has access to the curl command:</p><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>oc run curl --rm -it --image<span class=o>=</span>curlimages/curl:latest <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --overrides<span class=o>=</span><span class=s1>&#39;{
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;spec&#34;: {
</span></span></span><span class=line><span class=cl><span class=s1>      &#34;containers&#34;: [{
</span></span></span><span class=line><span class=cl><span class=s1>        &#34;name&#34;: &#34;curl&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>        &#34;image&#34;: &#34;curlimages/curl:latest&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>        &#34;stdin&#34;: true,
</span></span></span><span class=line><span class=cl><span class=s1>        &#34;tty&#34;: true,
</span></span></span><span class=line><span class=cl><span class=s1>        &#34;command&#34;: [&#34;sh&#34;],
</span></span></span><span class=line><span class=cl><span class=s1>        &#34;resources&#34;: {
</span></span></span><span class=line><span class=cl><span class=s1>          &#34;limits&#34;: {
</span></span></span><span class=line><span class=cl><span class=s1>            &#34;cpu&#34;: &#34;50m&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>            &#34;memory&#34;: &#34;100Mi&#34;
</span></span></span><span class=line><span class=cl><span class=s1>          },
</span></span></span><span class=line><span class=cl><span class=s1>          &#34;requests&#34;: {
</span></span></span><span class=line><span class=cl><span class=s1>            &#34;cpu&#34;: &#34;50m&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>            &#34;memory&#34;: &#34;100Mi&#34;
</span></span></span><span class=line><span class=cl><span class=s1>          }
</span></span></span><span class=line><span class=cl><span class=s1>        }
</span></span></span><span class=line><span class=cl><span class=s1>      }]
</span></span></span><span class=line><span class=cl><span class=s1>    }
</span></span></span><span class=line><span class=cl><span class=s1>  }&#39;</span></span></span></code></pre></div><p>Then run the following command to send a question to the LLM:</p><div class=tab-panel data-tab-group=R-tabs-afb013a00373f7ba40f6ca8cddf18259><div class=tab-nav><div class=tab-nav-title>&#8203;</div><button aria-controls=R-tab-id-9210611ea9635b210e3fa90f1470a0a0 aria-expanded=true data-tab-item=R-tab-f907e651164789346ae0a1e257c462d8 class="tab-nav-button tab-panel-style cstyle initial active" tabindex=-1 onclick='switchTab("R-tabs-afb013a00373f7ba40f6ca8cddf18259","R-tab-f907e651164789346ae0a1e257c462d8")'>
<span class=tab-nav-text>Script</span>
</button>
<button aria-controls=R-tab-id-9a9c3784cbd4768def7bf98224744d50 aria-expanded=false data-tab-item=R-tab-4c50e65a8a1f9aa989870396b5c0a12b class="tab-nav-button tab-panel-style cstyle initial" onclick='switchTab("R-tabs-afb013a00373f7ba40f6ca8cddf18259","R-tab-4c50e65a8a1f9aa989870396b5c0a12b")'>
<span class=tab-nav-text>Example Output</span></button></div><div class=tab-content-container><div id=R-tab-id-9210611ea9635b210e3fa90f1470a0a0 data-tab-item=R-tab-f907e651164789346ae0a1e257c462d8 class="tab-content tab-panel-style cstyle initial active"><div class=tab-content-text><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -X <span class=s2>&#34;POST&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span> <span class=s1>&#39;http://llm-app:8080/askquestion&#39;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -H <span class=s1>&#39;Accept: application/json&#39;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -H <span class=s1>&#39;Content-Type: application/json&#39;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -d <span class=s1>&#39;{
</span></span></span><span class=line><span class=cl><span class=s1>    &#34;question&#34;: &#34;How much memory does the NVIDIA H200 have?&#34;
</span></span></span><span class=line><span class=cl><span class=s1>  }&#39;</span></span></span></code></pre></div></div></div><div id=R-tab-id-9a9c3784cbd4768def7bf98224744d50 data-tab-item=R-tab-4c50e65a8a1f9aa989870396b5c0a12b class="tab-content tab-panel-style cstyle initial"><div class=tab-content-text><div class="highlight actionbar-wrapper wrap-code" dir=auto><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>The NVIDIA H200 has 141GB of HBM3e memory, which is twice the capacity of the NVIDIA H100 Tensor Core GPU with 1.4X more memory bandwidth.</span></span></code></pre></div></div></div></div></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=review-metrics-traces-and-logs>Review Metrics, Traces, and Logs</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>10 minutes</span>
</span>&nbsp;<h2 id=view-trace-data-in-splunk-observability-cloud>View Trace Data in Splunk Observability Cloud<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>In Splunk Observability Cloud, navigate to <code>APM</code> and then select <code>Service Map</code>.
Ensure your environment name is selected (e.g. <code>ai-pod-workshop-participant-1</code>).<br>You should see a service map that looks like the following:</p><p><a href=#R-image-498f27f57862aeedc9855b53a477a3d1 class=lightbox-link><img alt="Service Map" class="lazy lightbox figure-image" loading=lazy src=../../images/ServiceMap.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-498f27f57862aeedc9855b53a477a3d1><img alt="Service Map" class="lazy lightbox lightbox-image" loading=lazy src=../../images/ServiceMap.png></a></p><p>Click on <code>Traces</code> on the right-hand side menu. Then select one of the slower running
traces. It should look like the following example:</p><p><a href=#R-image-4f0122ac6111a7b159cf294a85b3682e class=lightbox-link><img alt=Trace class="lazy lightbox figure-image" loading=lazy src=../../images/Trace.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4f0122ac6111a7b159cf294a85b3682e><img alt=Trace class="lazy lightbox lightbox-image" loading=lazy src=../../images/Trace.png></a></p><p>The trace shows all the interactions that our application executed to return an answer
to the users question (i.e. &ldquo;How much memory does the NVIDIA H200 have?&rdquo;)</p><p>For example, we can see where our application performed a similarity search to look
for documents related to the question at hand in the Weaviate vector database.</p><p>We can also see how the application created a prompt to send to the LLM, including the
context that was retrieved from the vector database:</p><p><a href=#R-image-d479624e57abbc655234d0a4a4a88a12 class=lightbox-link><img alt="Prompt Template" class="lazy lightbox figure-image" loading=lazy src=../../images/PromptTemplate.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d479624e57abbc655234d0a4a4a88a12><img alt="Prompt Template" class="lazy lightbox lightbox-image" loading=lazy src=../../images/PromptTemplate.png></a></p><p>Finally, we can see the response from the LLM, the time it took, and the number of
input and output tokens utilized:</p><p><a href=#R-image-61efee871f5ef023e99bc3b245016219 class=lightbox-link><img alt="LLM Response" class="lazy lightbox figure-image" loading=lazy src=../../images/LLMResponse.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-61efee871f5ef023e99bc3b245016219><img alt="LLM Response" class="lazy lightbox lightbox-image" loading=lazy src=../../images/LLMResponse.png></a></p><h2 id=confirm-metrics-are-sent-to-splunk>Confirm Metrics are Sent to Splunk<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Navigate to <code>Dashboards</code> in Splunk Observability Cloud, then search for the
<code>Cisco AI PODs Dashboard</code>, which is included in the <code>Built-in dashboard groups</code>.
Navigate to the <code>NIM FOR LLMS</code> tab and ensure the dashboard is filtered
on your OpenShift cluster name. The charts should be populated as in the
following example:</p><p><a href=#R-image-990a03743f413eae596a4c8dcf78dc38 class=lightbox-link><img alt="NIM LLMS Dashboard" class="lazy lightbox figure-image" loading=lazy src=../../images/NIMLLM.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-990a03743f413eae596a4c8dcf78dc38><img alt="NIM LLMS Dashboard" class="lazy lightbox lightbox-image" loading=lazy src=../../images/NIMLLM.png></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article><article class=default><header class=headline></header><h1 id=wrap-up>Wrap-Up</h1><span class="badge cstyle primary badge-with-title"><span class=badge-title><i class="fa-fw fas fa-clock"></i></span><span class=badge-content>5 minutes</span>
</span>&nbsp;<h2 id=wrap-up>Wrap-Up<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>We hope you enjoyed this workshop, which provided hands-on experience deploying and working
with several of the technologies that are used to monitor Cisco AI PODs with
Splunk Observability Cloud. Specifically, you had the opportunity to:</p><ul><li>Work with a RedHat OpenShift cluster with GPU-based worker nodes.</li><li>Work with the NVIDIA NIM Operator and NVIDIA GPU Operator.</li><li>Work with Large Language Models (LLMs) deployed using NVIDIA NIM to the cluster.</li><li>Deploy the OpenTelemetry Collector in the Red Hat OpenShift cluster.</li><li>Add Prometheus receivers to the collector to ingest infrastructure metrics.</li><li>Monitor the Weaviate vector database in the cluster.</li><li>Configure monitoring for Pure Storage metrics using Prometheus.</li><li>Instrument Python services that interact with Large Language Models (LLMs) with OpenTelemetry.</li><li>Understand which details which OpenTelemetry captures in the trace from applications that interact with LLMs.</li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Feb 6, 2026</span></span></footer></article></section></div></main></div><script src=/observability-workshop/js/perfect-scrollbar/perfect-scrollbar.min.js?1770901811 defer></script><script src=/observability-workshop/js/theme.min.js?1770901811 defer></script><div id=toast-container role=status aria-live=polite aria-atomic=false></div></body></html>