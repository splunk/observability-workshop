<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=print><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=generator content="Relearn 7.2.1"><meta name=description content="Scenario Description"><meta name=author content><meta name=twitter:card content="summary"><meta name=twitter:title content="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><meta name=twitter:description content="Scenario Description"><meta property="og:url" content="https://splunk.github.io/observability-workshop/v5.85/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html"><meta property="og:site_name" content="Splunk Observability Cloud Workshops"><meta property="og:title" content="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><meta property="og:description" content="Scenario Description"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><meta itemprop=description content="Scenario Description"><meta itemprop=dateModified content="2025-03-03T12:27:20+00:00"><meta itemprop=wordCount content="346"><title>Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops</title>
<link href=https://splunk.github.io/observability-workshop/v5.85/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html rel=canonical type=text/html title="Ingest Processor for Observability Cloud :: Splunk Observability Cloud Workshops"><link href=/observability-workshop/v5.85/images/favicon.ico?1741799547 rel=icon type=image/x-icon sizes=any><link href=/observability-workshop/v5.85/css/fontawesome-all.min.css?1741799547 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.85/css/fontawesome-all.min.css?1741799547 rel=stylesheet></noscript><link href=/observability-workshop/v5.85/css/auto-complete.css?1741799547 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/observability-workshop/v5.85/css/auto-complete.css?1741799547 rel=stylesheet></noscript><link href=/observability-workshop/v5.85/css/perfect-scrollbar.min.css?1741799547 rel=stylesheet><link href=/observability-workshop/v5.85/css/theme.min.css?1741799547 rel=stylesheet><link href=/observability-workshop/v5.85/css/format-print.min.css?1741799547 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../../..",window.relearn.relBaseUri="../../../../..",window.relearn.absBaseUri="https://splunk.github.io/observability-workshop/v5.85",window.relearn.min=`.min`,window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.themevariants=["auto","splunk-light","splunk-dark"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}}))},window.relearn.markVariant=function(){var t=window.localStorage.getItem(window.relearn.absBaseUri+"/variant"),e=document.querySelector("#R-select-variant");e&&(e.value=t)},window.relearn.initVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web.js crossorigin=anonymous></script><script src=https://cdn.signalfx.com/o11y-gdi-rum/latest/splunk-otel-web-session-recorder.js crossorigin=anonymous></script><script>SplunkRum.init({realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA",applicationName:"observability-workshop",deploymentEnvironment:"splunk.github.io",version:"1.0"}),SplunkSessionRecorder.init({app:"observability-workshop",realm:"us1",rumAccessToken:"dp3FKraOS_wVhe-l7eCOsA"})</script></script><style>:root{--MAIN-WIDTH-MAX:130rem;--MENU-WIDTH-L:23rem}p{margin:.75rem 0}.highlight{max-height:500px;overflow-y:auto}pre:not(.mermaid){margin:0}</style></head><body class="mobile-support print disableInlineCopyToClipboard" data-url=/observability-workshop/v5.85/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div><div class="topbar-button topbar-button-toc" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title="Table of Contents (CTRL+ALT+t)"><i class="fa-fw fas fa-list-alt"></i></button><div class=topbar-content><div class=topbar-content-wrapper></div></div></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.85/en/index.html><span itemprop=name>Splunk Observability Workshops</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/observability-workshop/v5.85/en/ninja-workshops/index.html><span itemprop=name>Ninja Workshops</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Ingest Processor for Observability Cloud</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.85/en/ninja-workshops/11-ingest_processor_for_observability_cloud/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-prev" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.85/en/ninja-workshops/9-solving-problems-with-o11y-cloud/6-summary/index.html title="Summary (ü°ê)"><i class="fa-fw fas fa-chevron-left"></i></a></div><div class="topbar-button topbar-button-next" data-content-empty=disable data-width-s=show data-width-m=show data-width-l=show><a class=topbar-control href=/observability-workshop/v5.85/en/ninja-workshops/11-ingest_processor_for_observability_cloud/1-getting-started/index.html title="Getting Started (ü°í)"><i class="fa-fw fas fa-chevron-right"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable ninja-workshops" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=ingest-processor-for-observability-cloud>Ingest Processor for Observability Cloud</h1><span class="badge cstyle blue badge-with-title"><span class=badge-title class=text-muted>Author
</span><span class=badge-content>Tim Hard</span></span><p>As infrastructure and application environments become exceedingly complex, the volume of data they generate continues to grow significantly. This increase in data volume and variety makes it challenging to gain actionable insights and can impact problem identification and troubleshooting efficiencies. Additionally, the cost of storing and accessing this data can skyrocket. Many data sources, particularly logs and events, provide critical visibility into system operations. However, in most cases, only a few details from these extensive logs are actually needed for effective monitoring and alerting.</p><p><strong>Common Challenges:</strong></p><ul><li>Increasing complexity of infrastructure and application environments.</li><li>Significant growth in data volume generated by these environments.</li><li>Challenges in gaining actionable insights from large volumes of data.</li><li>High costs associated with storing and accessing extensive data.</li><li>Logs and events provide critical visibility but often contain only a few essential details.</li></ul><p>To address these challenges, Splunk Ingest Processor provides a powerful new feature: the ability to convert log events into metrics. Metrics are more efficient to store and process, allowing for faster identification of issues, thereby reducing Mean Time to Detection (MTTD). When retaining the original log or event is necessary, they can be stored in cheaper storage solutions such as S3, reducing the overall cost of data ingestion and computation required for searching them.</p><p><strong>Solution:</strong></p><ul><li>Convert log events into metrics where possible.</li><li>Retain original logs or events in cheaper storage solutions if needed.</li><li>Utilize federated search for accessing and analyzing retained logs.</li></ul><p><strong>Outcomes:</strong></p><ul><li>Metrics are more efficient to store and process.</li><li>Faster identification of problems, reducing Mean Time to Detection (MTTD).</li><li>Lower overall data ingestion and computation costs.</li><li>Enhanced monitoring efficiency and resource optimization.</li><li>Maintain high visibility into system operations with reduced operational costs.</li></ul><p>In this workshop you&rsquo;ll have the opportunity to get hands on with Ingest Processor and Splunk Observability Cloud to see how it can be used to address the challenges outlined above.</p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Tip</summary><div class=box-content><p>The easiest way to navigate through this workshop is by using:</p><ul><li>the left/right arrows (<strong>&lt;</strong> | <strong>></strong>) on the top right of this page</li><li>the left (‚óÄÔ∏è) and right (‚ñ∂Ô∏è) cursor keys on your keyboard</li></ul></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of Ingest Processor for Observability Cloud</h1><article class=default><header class=headline></header><h1 id=getting-started>Getting Started</h1><p>During this <em><strong>technical</strong></em> Ingest Processor<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> for Splunk Observability Cloud workshop you will have the opportunity to get hands-on with Ingest Processor in Splunk Enterprise Cloud.</p><p>To simplify the workshop modules, a pre-configured Splunk Enterprise Cloud instance is provided.</p><p>The instance is pre-configured with all the requirements for creating an Ingest Processor pipeline.</p><p>This workshop will introduce you to the benefits of using Ingest Processor to convert robust logs to metrics and send those metrics to Splunk Observability Cloud. By the end of these technical workshops, you will have a good understanding of some key features and capabilities of Ingest Processor in Splunk Enterprise Cloud and the value of using Splunk Observability Cloud as a destination within an Ingest Processor pipeline.</p><p>Here are the instructions on how to access your pre-configured <a href=/observability-workshop/v5.85/en/ninja-workshops/11-ingest_processor_for_observability_cloud/1-getting-started/1-access-cloud-instances/index.html>Splunk Enterprise Cloud</a> instance.</p><p><a href=#R-image-4d79b2bcb9b619f042068465e14be5f0 class=lightbox-link><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4d79b2bcb9b619f042068465e14be5f0><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png></a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://docs.splunk.com/Documentation/SplunkCloud/9.3.2408/IngestProcessor/AboutIngestProcessorSolution rel=external target=_blank><strong>Ingest Processor</strong></a> is a data processing capability that works within your Splunk Cloud Platform deployment. Use the Ingest Processor to configure data flows, control data format, apply transformation rules prior to indexing, and route to destinations.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 1. Getting Started</h1><article class=default><header class=headline></header><h1 id=how-to-connect-to-your-workshop-environment>How to connect to your workshop environment</h1><ol><li>How to retrieve the URL for your Splunk Enterprise Cloud instances.</li><li>How to access the Splunk Observability Cloud workshop organization.</li></ol><hr><h2 id=1-splunk-cloud-instances>1. Splunk Cloud Instances</h2><p>There are three instances that will be used throughout this workshop which have already been provisioned for you:</p><ol><li>Splunk Enterprise Cloud</li><li>Splunk Ingest Processor (SCS Tenant)</li><li>Splunk Observability Cloud</li></ol><p>The Splunk Enterprise Cloud and Ingest Processor instances are hosted in <a href=https://show.splunk.com rel=external target=_blank>Splunk Show</a>. If you were invited to the workshop, you should have received an email with an invite to the event in <a href=https://show.splunk.com rel=external target=_blank>Splunk Show</a> or a link to the event will have been provided at the beginning of the workshop.</p><p>Login to Splunk Show using your <a href=https://login.splunk.com/ rel=external target=_blank>splunk.com</a> credentials. You should see the event for this workshop. Open the event to see the instance details for your Splunk Cloud and Ingest Processor instances.</p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>Take note of the <code>User Id</code> provided in your Splunk Show event details. This number will be included in the <code>sourcetype</code> that you will use for searching and filtering the Kubernetes data. Because this is a shared environment only use the participant number provided so that other participants data is not effected.</p></div></details><p><a href=#R-image-47f9cdaead6c3c35c71d49006cf5e754 class=lightbox-link><img alt="Splunk Show Instance Information" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/show_instance_information.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-47f9cdaead6c3c35c71d49006cf5e754><img alt="Splunk Show Instance Information" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/show_instance_information.png></a></p><h2 id=2-splunk-observability-cloud-instances>2. Splunk Observability Cloud Instances</h2><p>You should have also received an email to access the Splunk Observability Cloud workshop organization (You may need to check your spam folder). If you have not received an email, let your workshop instructor know. To access the environment click the <strong>Join Now</strong> button.</p><p><a href=#R-image-b4725a146c18a7474c4cad2039b3bc0c class=lightbox-link><img alt="Splunk Observability Cloud Invitation" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/workshop_invitation.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b4725a146c18a7474c4cad2039b3bc0c><img alt="Splunk Observability Cloud Invitation" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/workshop_invitation.png></a></p><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info-circle"></i>
Important</summary><div class=box-content><p>If you access the event before the workshop start time, your instances may not be available yet. Don&rsquo;t worry, they will be provided once the workshop begins.</p></div></details><p>Additionally, you have been invited to a Splunk Observability Cloud workshop organization. The invitation includes a link to the environment. If you don&rsquo;t have a Splunk Observability Cloud account already, you will be asked to create one. If you already have one, you can log in to the instance and, you will see the workshop organization in your available organizations.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=how-ingest-processor-works>How Ingest Processor Works</h1><h6 id=system-architecture>System architecture</h6><p>The primary components of the Ingest Processor service include the Ingest Processor service and SPL2 pipelines that support data processing. The following diagram provides an overview of how the components of the Ingest Processor solution work together:</p><p><a href=#R-image-e070f690a15184cbab75d586973bb3ca class=lightbox-link><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-e070f690a15184cbab75d586973bb3ca><img alt="Splunk Ingest Processor Architecture" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../images/IngestProcessor-architecture-diagram_release_updated2.png></a></p><h6 id=ingest-processor-service>Ingest Processor service</h6><p>The Ingest Processor service is a cloud service hosted by Splunk. It is part of the data management experience, which is a set of services that fulfill a variety of data ingest and processing use cases.</p><p>You can use the Ingest Processor service to do the following:</p><ul><li>Create and apply SPL2 pipelines that determine how each Ingest Processor processes and routes the data that it receives.</li><li>Define source types to identify the kind of data that you want to process and determine how the Ingest Processor breaks and merges that data into distinct events.</li><li>Create connections to the destinations that you want your Ingest Processor to send processed data to.</li></ul><h6 id=pipelines>Pipelines</h6><p>A pipeline is a set of data processing instructions written in SPL2. When you create a pipeline, you write a specialized SPL2 statement that specifies which data to process, how to process it, and where to send the results. When you apply a pipeline, the Ingest Processor uses those instructions to process all the data that it receives from data sources such as Splunk forwarders, HTTP clients, and logging agents.</p><p>Each pipeline selects and works with a subset of all the data that the Ingest Processor receives. For example, you can create a pipeline that selects events with the source type <code>cisco_syslog</code> from the incoming data, and then sends them to a specified index in Splunk Cloud Platform. This subset of selected data is called a partition. For more information, see <a href=http://docs.splunk.com/Documentation/SplunkCloud/latest/IngestProcessor/Architecture#Partitions rel=external target=_blank>Partitions</a>.</p><p>The Ingest Processor solution supports only the commands and functions that are part of the <code>IngestProcessor</code> profile. For information about the specific SPL2 commands and functions that you can use to write pipelines for Ingest Processor, see <a href=http://docs.splunk.com/Documentation/SplunkCloud/latest/IngestProcessor/PipelinesOverview rel=external target=_blank>Ingest Processor pipeline syntax</a>. For a summary of how the <code>IngestProcessor</code> profile supports different commands and functions compared to other SPL2 profiles, see the following pages in the <em>SPL2 Search Reference</em>:</p><ul><li><a href=http://docs.splunk.com/Documentation/SCS/current/SearchReference/CompatibilityQuickReferenceforSPL2commands rel=external target=_blank>Compatibility Quick Reference for SPL2 commands</a></li><li><a href=http://docs.splunk.com/Documentation/SCS/current/SearchReference/CompatibilityQuickReferenceforSPL2evaluationfunctions rel=external target=_blank>Compatibility Quick Reference for SPL2 evaluation functions</a></li></ul><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=create-an-ingest-pipeline>Create an Ingest Pipeline</h1><h2 id=scenario-overview>Scenario Overview</h2><p>In this scenario you will be playing the role of a Splunk Admin responsible for managing your organizations Splunk Enterprise Cloud environment. You recently worked with an internal application team on instrumenting their Kubernetes environment with Splunk APM and Infrastructure monitoring using OpenTelemetry to monitor their critical microservice applications.</p><p>The logs from the Kubernetes environment are also being collected and sent to Splunk Enter Prize Cloud. These logs include:</p><ul><li>Pod logs (application logs)</li><li>Kubernetes Events</li><li>Kubernetes Cluster Logs<ul><li>Control Plane Node logs</li><li>Worker Node logs</li><li>Audit Logs</li></ul></li></ul><p>As a Splunk Admin you want to ensure that the data you are collecting is optimized, so it can be analyzed in the most efficient way possible. Taking this approach accelerates troubleshooting and ensures efficient license utilization.</p><p>One way to accomplish this is by using Ingest Processor to convert robust logs to metrics and use Splunk Observability Cloud as the destination for those metrics. Not only does this make collecting the logs more efficient, you have the added ability of using the newly created metrics in Splunk Observability which can then be correlated with Splunk APM data (traces) and Splunk Infrastructure Monitoring data providing additional troubleshooting context. Because Splunk Observability Cloud uses a streaming metrics pipeline, the metrics can be alerted on in real-time speeding up problem identification. Additionally, you can use the Metrics Pipeline Management functionality to further optimize the data by aggregating, dropping unnecessary fields, and archiving less important or unneeded metrics.</p><p>In the next step you&rsquo;ll create an Ingest Processor Pipeline which will convert Kubernetes Audit Logs to metrics that will be sent to Observability Cloud.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 3. Create an Ingest Pipeline</h1><article class=default><header class=headline></header><h1 id=login-to-splunk-cloud>Login to Splunk Cloud</h1><p>In this section you will create an Ingest Pipeline which will convert Kubernetes Audit Logs to metrics which are sent to the Splunk Observability Cloud workshop organization. Before getting started you will need to access the Splunk Cloud and Ingest Processor SCS Tenant environments provided in the Splunk Show event details.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Pre-requisite: Login to Splunk Enterprise Cloud</summary><div class=box-content><p><strong>1.</strong> Open the <strong>Ingest Processor Cloud Stack</strong> URL provided in the Splunk Show event details.</p><p><a href=#R-image-c0baf0dfc8303612ba2b768a077562c5 class=lightbox-link><img alt="Splunk Cloud Instance Details" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/show_instances_sec.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c0baf0dfc8303612ba2b768a077562c5><img alt="Splunk Cloud Instance Details" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/show_instances_sec.png></a></p><p><strong>2.</strong> In the Connection info click on the <strong>Stack URL</strong> link to open your Splunk Cloud stack.</p><p><a href=#R-image-9b1fd77d65a06c80aec848b4ad27ccdc class=lightbox-link><img alt="Splunk Cloud Connection Details" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/sec_connection_details.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-9b1fd77d65a06c80aec848b4ad27ccdc><img alt="Splunk Cloud Connection Details" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/sec_connection_details.png></a></p><p><strong>3.</strong> Use the <code>admin</code> username and password to login to Splunk Cloud.</p><p><a href=#R-image-880fe99e5b289ef292ef5c1f98780d9c class=lightbox-link><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/sec_login.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-880fe99e5b289ef292ef5c1f98780d9c><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/sec_login.png></a></p><p><strong>4.</strong> After logging in, if prompted, accept the Terms of Service and click <strong>OK</strong></p><p><a href=#R-image-57f043980d883766715096a1a44c9d58 class=lightbox-link><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/sec_terms.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-57f043980d883766715096a1a44c9d58><img alt="Splunk Cloud Login" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/sec_terms.png></a></p><p><strong>5.</strong> Navigate back to the Splunk Show event details and select the Ingest Processor SCS Tenant</p><p><a href=#R-image-93affd4728f4c735f2ee4498c7d3da87 class=lightbox-link><img alt="Ingest Processor Connection Details" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/show_instances_scs.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-93affd4728f4c735f2ee4498c7d3da87><img alt="Ingest Processor Connection Details" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/show_instances_scs.png></a></p><p><strong>6.</strong> Click on the <strong>Console URL</strong> to access the <strong>Ingest Processor SCS Tenant</strong></p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Single Sign-On (SSO)</strong>
Single Sign-on (SSO) is configured between the Splunk Data Management service (‚ÄòSCS Tenant‚Äô) and Splunk Cloud environments, so if you already logged in to your Splunk Cloud stack you should automatically be logged in to Splunk Data Management service. If you are prompted for credentials, use the credentials provided in the Splunk Cloud Stack on Splunk Show event (listed under the ‚ÄòSplunk Cloud Stack‚Äô section.)</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=review-kubernetes-audit-logs>Review Kubernetes Audit Logs</h1><p>In this section you will review the Kubernetes Audit Logs that are being collected. You can see that the events are quite robust, which can make charting them inefficient. To address this, you will create an Ingest Pipeline in Ingest Processor that will convert these events to metrics that will be sent to Splunk Observability Cloud. This will allow you to chart the events much more efficiently and take advantage of the real-time streaming metrics in Splunk Observability Cloud.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Create Ingest Pipeline</summary><div class=box-content><p><strong>1.</strong> Open your <strong>Ingest Processor Cloud Stack</strong> instance using the URL provided in the Splunk Show workshop details.</p><p><strong>2.</strong> Navigate to <strong>Apps</strong> ‚Üí <strong>Search and Reporting</strong></p><p><a href=#R-image-ee173849a8b73f4f944d58babdbae46a class=lightbox-link><img alt="Search and Reporting" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/search_and_reporting.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-ee173849a8b73f4f944d58babdbae46a><img alt="Search and Reporting" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/search_and_reporting.png?width=20vw"></a></p><p><strong>3.</strong> In the search bar, enter the following SPL search string.</p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>Make sure to replace <code>USER_ID</code> with the User ID provided in your Splunk Show instance information.</p></div></details><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=c1>### Replace USER_ID with the User ID provided in your Splunk Show instance information</span>
</span></span><span class=line><span class=cl><span class=nv>index</span><span class=o>=</span>main <span class=nv>sourcetype</span><span class=o>=</span><span class=s2>&#34;kube:apiserver:audit:USER_ID&#34;</span></span></span></code></pre></div><p><strong>4.</strong> Press <strong>Enter</strong> or click the green magnifying glass to run the search.</p><p><a href=#R-image-cd10cad2fa4ab641b3101f88edd1741c class=lightbox-link><img alt="Kubernetes Audit Log" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/k8s_audit_log.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-cd10cad2fa4ab641b3101f88edd1741c><img alt="Kubernetes Audit Log" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/k8s_audit_log.png></a></p><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info-circle"></i>
Note</summary><div class=box-content><p>You should now see the Kubernetes Audit Logs for your environment. Notice that the events are fairly robust. Explore the available fields and start to think about what information would be good candidates for metrics and dimensions. Ask yourself: What fields would I like to chart, and how would I like to be able to filter, group, or split those fields?</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=create-an-ingest-pipeline>Create an Ingest Pipeline</h1><p>In this section you will create an Ingest Pipeline which will convert Kubernetes Audit Logs to metrics which are sent to the Splunk Observability Cloud workshop organization.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Create Ingest Pipeline</summary><div class=box-content><p><strong>1.</strong> Open the <strong>Ingest Processor SCS Tenant</strong> using the connection details provided in the Splunk Show event.</p><p><a href=#R-image-caf898b65440748ba9d6ccbc2ef538e8 class=lightbox-link><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/data_management_home.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-caf898b65440748ba9d6ccbc2ef538e8><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/data_management_home.png?width=40vw"></a></p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p>When you open the <strong>Ingest Processor SCS Tenant</strong>, if you are taken to a welcome page, click on <strong>Launch</strong> under <strong>Splunk Cloud Platform</strong> to be taken to the Data Management page where you will configure the Ingest Pipeline.</p><p><a href=#R-image-1ae7dd76fba7cefe604cf20280a712c9 class=lightbox-link><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/launch_scp.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-1ae7dd76fba7cefe604cf20280a712c9><img alt="Launch Splunk Cloud Platform" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/launch_scp.png></a></p></div></details><p><strong>2.</strong> From the Splunk Data Management console select <strong>Pipelines</strong> ‚Üí <strong>New pipeline</strong> ‚Üí <strong>Ingest Processor pipeline</strong>.</p><p><a href=#R-image-efdccc1bfbfe09899a831532d822ae60 class=lightbox-link><img alt="New Ingest Processor Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/new_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-efdccc1bfbfe09899a831532d822ae60><img alt="New Ingest Processor Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/new_pipeline.png?width=40vw"></a></p><p><strong>3.</strong> In the <strong>Get started</strong> step of the Ingest Processor configuration page select <strong>Blank Pipeline</strong> and click <strong>Next</strong>.</p><p><a href=#R-image-787a9618b741a780215459479656dd62 class=lightbox-link><img alt="Blank Ingest Processor Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/blank_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-787a9618b741a780215459479656dd62><img alt="Blank Ingest Processor Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/blank_pipeline.png?width=40vw"></a></p><p><strong>4.</strong> In the <strong>Define your pipeline‚Äôs partition</strong> step of the Ingest Processor configuration page select <strong>Partition by sourcetype</strong>. Select the <strong>= equals</strong> Operator and enter <code>kube:apiserver:audit:USER_ID</code> (Be sure to replace USER_ID with the User ID you were assigned) for the value. Click <strong>Apply</strong>.</p><p><a href=#R-image-3dd6ea2c18928489926dca7f01cfdbf5 class=lightbox-link><img alt="Add Partition" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/add_partition.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-3dd6ea2c18928489926dca7f01cfdbf5><img alt="Add Partition" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/add_partition.png?width=40vw"></a></p><p><strong>5.</strong> Click <strong>Next</strong></p><p><strong>6.</strong> In the <strong>Add sample data</strong> step of the Ingest Processor configuration page select <strong>Capture new snapshot</strong>. Enter <code>k8s_audit_USER_ID</code> (Be sure to replace USER_ID with the User ID you were assigned) for the Snapshot name and click <strong>Capture</strong>.</p><p><a href=#R-image-981e3f0a4b0c22d9071f8852bf624d44 class=lightbox-link><img alt="Capture Snapshot" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/capture_snapshot.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-981e3f0a4b0c22d9071f8852bf624d44><img alt="Capture Snapshot" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/capture_snapshot.png?width=40vw"></a></p><p><strong>7.</strong> Make sure your newly created snapshot (<code>k8s_audit_USER_ID</code>) is selected and then click <strong>Next</strong>.</p><p><a href=#R-image-1165de0c17be53e88c9a847807b8c2cc class=lightbox-link><img alt="Configure Snapshot Sourcetype" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/capture_snapshot_sourcetype.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-1165de0c17be53e88c9a847807b8c2cc><img alt="Configure Snapshot Sourcetype" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/capture_snapshot_sourcetype.png?width=20vw"></a></p><p><strong>8.</strong> In the <strong>Select a metrics destination</strong> step of the Ingest Processor configuration page select <strong>show_o11y_org</strong>. Click <strong>Next</strong>.</p><p><a href=#R-image-9b7da32860e12b61007f42ef58d4c394 class=lightbox-link><img alt="Metrics Destination" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/metrics_destination.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-9b7da32860e12b61007f42ef58d4c394><img alt="Metrics Destination" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/metrics_destination.png?width=20vw"></a></p><p><strong>9.</strong> In the <strong>Select a data destination</strong> step of the Ingest Processor configuration page select <strong>splunk_indexer</strong>. Under <strong>Specify how you want your events to be routed to an index</strong> select <strong>Default</strong>. Click <strong>Done</strong>.</p><p><a href=#R-image-17c12d9791e83b1b4ac9e575ae9b35fc class=lightbox-link><img alt="Event Routing" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/event_routing.png?width=20vw" style=height:auto;width:20vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-17c12d9791e83b1b4ac9e575ae9b35fc><img alt="Event Routing" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/event_routing.png?width=20vw"></a></p><p><strong>10.</strong> In the <strong>Pipeline search field</strong> replace the default search with the following.</p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Replace <code>UNIQUE_FIELD</code> in the metric name with a unique value (such as your initials) which will be used to identify your metric in Observability Cloud.</strong></p></div></details><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>/*A valid SPL2 statement for a pipeline must start with &#34;$pipeline&#34;, and include &#34;from $source&#34; and &#34;into $destination&#34;.*/
</span></span><span class=line><span class=cl>/* Import logs_to_metrics */
</span></span><span class=line><span class=cl>import logs_to_metrics from /splunk/ingest/commands
</span></span><span class=line><span class=cl>$pipeline =
</span></span><span class=line><span class=cl>| from $source
</span></span><span class=line><span class=cl>| thru [
</span></span><span class=line><span class=cl>        //define the metric name, type, and value for the Kubernetes Events
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        // REPLACE UNIQUE_FIELD WITH YOUR INITIALS
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        | logs_to_metrics name=&#34;k8s_audit_UNIQUE_FIELD&#34; metrictype=&#34;counter&#34; value=1 time=_time
</span></span><span class=line><span class=cl>        | into $metrics_destination
</span></span><span class=line><span class=cl>    ]
</span></span><span class=line><span class=cl>| eval index = &#34;kube_logs&#34;
</span></span><span class=line><span class=cl>| into $destination;</span></span></code></pre></div><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
New to SPL2?</summary><div class=box-content><p>Here is a breakdown of what the SPL2 query is doing:</p><ul><li>First, you are importing the built-in <code>logs_to_metrics</code> command which will be used to convert the kubernetes events to metrics.</li><li>You&rsquo;re using the source data, which you can see on the right is any event from the <code>kube:apiserver:audit</code> sourcetype.</li><li>Now, you use the <code>thru</code> command which writes the source dataset to the following command, in this case <code>logs_to_metrics</code>.</li><li>You can see that the metric name (<code>k8s_audit</code>), metric type (<code>counter</code>), value, and timestamp are all provided for the metric. You‚Äôre using a value of 1 for this metric because we want to count the number of times the event occurs.</li><li>Next, you choose the destination for the metric using the into <code>$metrics_destintation</code> command, which is our Splunk Observability Cloud organization</li><li>Finally, you can send the raw log events to another destination, in this case another index, so they are retained if we ever need to access them.</li></ul></div></details><p><strong>11.</strong> In the upper-right corner click the <strong>Preview</strong> button <a href=#R-image-ec5cca90af4c31610e895328ea11207a class=lightbox-link><img alt="Preview Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-ec5cca90af4c31610e895328ea11207a><img alt="Preview Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline"></a> or press CTRL+Enter (CMD+Enter on Mac). From the <strong>Previewing $pipeline</strong> dropdown select <strong>$metrics_destination</strong>. Confirm you are seeing a preview of the metrics that will be sent to Splunk Observability Cloud.</p><p><a href=#R-image-0ca9435b7f87f1f043ab686f0405cc66 class=lightbox-link><img alt="Preview Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/preview_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-0ca9435b7f87f1f043ab686f0405cc66><img alt="Preview Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/preview_pipeline.png?width=40vw"></a></p><p><strong>12.</strong> In the upper-right corner click the <strong>Save pipeline</strong> button <a href=#R-image-449df8e1789fe69c37008f375ae91821 class=lightbox-link><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-449df8e1789fe69c37008f375ae91821><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline"></a>. Enter <code>Kubernetes Audit Logs2Metrics USER_ID</code> for your pipeline name and click <strong>Save</strong>.</p><p><a href=#R-image-19844e16ebb64cd109a00e52c6e7cdbc class=lightbox-link><img alt="Save Pipeline Dialog" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_pipeline_dialog.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-19844e16ebb64cd109a00e52c6e7cdbc><img alt="Save Pipeline Dialog" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_pipeline_dialog.png?width=40vw"></a></p><p><strong>13.</strong> After clicking save you will be asked if you would like to apply the newly created pipeline. Click <strong>Yes, apply</strong>.</p><p><a href=#R-image-d8a3dc481c730b7178d3221bf9dd46b0 class=lightbox-link><img alt="Apply Pipeline Dialog" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/apply_pipeline_dialog.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d8a3dc481c730b7178d3221bf9dd46b0><img alt="Apply Pipeline Dialog" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/apply_pipeline_dialog.png?width=40vw"></a></p><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info-circle"></i>
Note</summary><div class=box-content><p>The Ingest Pipeline should now be sending metrics to Splunk Observability Cloud. Keep this tab open as it will be used it again in the next section.</p><p>In the next step you&rsquo;ll confirm the pipeline is working by viewing the metrics you just created in Splunk Observability Cloud.</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=confirm-metrics-in-observability-cloud>Confirm Metrics in Observability Cloud</h1><p>Now that an Ingest Pipeline has been configured to convert Kubernetes Audit Logs into metrics and send them to Splunk Observability Cloud the metrics should be available. To confirm the metrics are being collected complete the following steps:</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Confirm Metrics in Splunk Observability Cloud</summary><div class=box-content><p><strong>1.</strong> Login to the <strong>Splunk Observability Cloud</strong> organization you were invited for the workshop. In the upper-right corner, click the <strong>+</strong> Icon ‚Üí <strong>Chart</strong> to create a new chart.</p><p><a href=#R-image-c4b0e6b31acfd22c8c38244ea5892141 class=lightbox-link><img alt="Create New Chart" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/create_new_chart.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-c4b0e6b31acfd22c8c38244ea5892141><img alt="Create New Chart" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/create_new_chart.png?width=40vw"></a></p><p><strong>2.</strong> In the <strong>Plot Editor</strong> of the newly created chart enter the metric name you used while configuring the <strong>Ingest Pipeline</strong>.</p><p><a href=#R-image-2c938ce9bde37d23c76947b969178a7e class=lightbox-link><img alt="Review Metric" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/review_metric.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2c938ce9bde37d23c76947b969178a7e><img alt="Review Metric" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/review_metric.png?width=40vw"></a></p><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info-circle"></i>
Info</summary><div class=box-content><p>You should see the metric you created in the Ingest Pipeline. Keep this tab open as it will be used again in the next section.</p><p>In the next step you will update the ingest pipeline to add dimensions to the metric, so you have additional context for alerting and troubleshooting.</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=update-pipeline-and-visualize-metrics>Update Pipeline and Visualize Metrics</h1><h2 id=context-matters>Context Matters</h2><p>In the previous section, you reviewed the raw Kubernetes audit logs and created an Ingest Processor Pipeline to convert them to metrics and send those metrics to Splunk Observability Cloud.</p><p>Now that this pipeline is defined we are collecting the new metrics in Splunk Observability Cloud. This is a great start; however, you will only see a single metric showing the total number of Kubernetes audit events for a given time period. It would be much more valuable to add dimensions so that you can split the metric by the event type, user, response status, and so on.</p><p>In this section you will update the Ingest Processor Pipeline to include additional dimensions from the Kubernetes audit logs to the metrics that are being collected. This will allow you to further filter, group, visualize, and alert on specific aspects of the audit logs. After updating the metric, you will create a new dashboard showing the status of the different types of actions associated with the logs.</p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><section><h1 class=a11y-only>Subsections of 4. Update Pipeline and Visualize Metrics</h1><article class=default><header class=headline></header><h1 id=update-ingest-pipeline>Update Ingest Pipeline</h1><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Update Ingest Pipeline</summary><div class=box-content><p><strong>1.</strong> Navigate back to the configuration page for the Ingest Pipeline you created in the previous step.</p><p><a href=#R-image-971fc7b031a07c81059702c3a6abef0d class=lightbox-link><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/ingest_pipeline.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-971fc7b031a07c81059702c3a6abef0d><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/ingest_pipeline.png?width=40vw"></a></p><p><strong>2.</strong> To add dimensions to the metric from the raw Kubernetes audit logs update the SPL2 query you created for the pipeline by replacing the <code>logs_to_metrics</code> portion of the query with the following:</p><details open class="box cstyle notices primary"><summary class=box-label><i class="fa-fw fas fa-lightbulb"></i>
Note</summary><div class=box-content><p><strong>Be sure to update the metric name field (<code>name="k8s_audit_UNIQUE_FIELD"</code>) to the name you provided in the original pipeline</strong></p></div></details><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>| logs_to_metrics name=&#34;k8s_audit_UNIQUE_FIELD&#34; metrictype=&#34;counter&#34; value=1 time=_time dimensions={&#34;level&#34;: _raw.level, &#34;response_status&#34;: _raw.responseStatus.code, &#34;namespace&#34;: _raw.objectRef.namespace, &#34;resource&#34;: _raw.objectRef.resource, &#34;user&#34;: _raw.user.username, &#34;action&#34;: _raw.verb}</span></span></code></pre></div><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info"></i>
Note</summary><div class=box-content><p>Using the <code>dimensions</code> field in the SPL2 query you can add dimensions from the raw events to the metrics that will be sent to Splunk Observability Cloud. In this case you are adding the event response status, namespace, Kubernetes resource, user, and verb (action that was performed). These dimensions can be used to create more granular dashboards and alerts.</p><p>You should consider adding any common tags across your services so that you can take advantage of context propagation and related content in Splunk Observability Cloud.</p></div></details><p>The updated pipeline should now be the following:</p><div class="highlight wrap-code"><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>/*A valid SPL2 statement for a pipeline must start with &#34;$pipeline&#34;, and include &#34;from $source&#34; and &#34;into $destination&#34;.*/
</span></span><span class=line><span class=cl>/* Import logs_to_metrics */
</span></span><span class=line><span class=cl>import logs_to_metrics from /splunk/ingest/commands
</span></span><span class=line><span class=cl>$pipeline =
</span></span><span class=line><span class=cl>| from $source
</span></span><span class=line><span class=cl>| thru [
</span></span><span class=line><span class=cl>        //define the metric name, type, and value for the Kubernetes Events
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        // REPLACE UNIQUE_FIELD WITH YOUR INITIALS
</span></span><span class=line><span class=cl>        //
</span></span><span class=line><span class=cl>        | logs_to_metrics name=&#34;k8s_audit_UNIQUE_FIELD&#34; metrictype=&#34;counter&#34; value=1 time=_time dimensions={&#34;level&#34;: _raw.level, &#34;response_status&#34;: _raw.responseStatus.code, &#34;namespace&#34;: _raw.objectRef.namespace, &#34;resource&#34;: _raw.objectRef.resource, &#34;user&#34;: _raw.user.username, &#34;action&#34;: _raw.verb}
</span></span><span class=line><span class=cl>        | into $metrics_destination
</span></span><span class=line><span class=cl>    ]
</span></span><span class=line><span class=cl>| eval index = &#34;kube_logs&#34;
</span></span><span class=line><span class=cl>| into $destination;</span></span></code></pre></div><p><strong>3.</strong> In the upper-right corner click the <strong>Preview</strong> button <a href=#R-image-9eb1a389874f4fa799ca39c6d8a64902 class=lightbox-link><img alt="Preview Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-9eb1a389874f4fa799ca39c6d8a64902><img alt="Preview Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/preview.png?height=20px&classes=inline"></a> or press CTRL+Enter (CMD+Enter on Mac). From the <strong>Previewing $pipeline</strong> dropdown select <strong>$metrics_destination</strong>. Confirm you are seeing a preview of the metrics that will be sent to Splunk Observability Cloud.</p><p><a href=#R-image-2a5bf3c0908fada0b22f3af46bc3bd7e class=lightbox-link><img alt="Ingest Pipeline Dimensions" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/ingest_pipeline_dimensions.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2a5bf3c0908fada0b22f3af46bc3bd7e><img alt="Ingest Pipeline Dimensions" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/ingest_pipeline_dimensions.png?width=40vw"></a></p><p><strong>4.</strong> Confirm you are seeing the dimensions in the dimensions column of the preview table. You can view the entire dimensions object by clicking into the table.</p><p><a href=#R-image-34d9d3b26683cf2d82fc8f7a2968fa64 class=lightbox-link><img alt="Ingest Pipeline Dimensions Review" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/ingest_pipeline_dimensions_field.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-34d9d3b26683cf2d82fc8f7a2968fa64><img alt="Ingest Pipeline Dimensions Review" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/ingest_pipeline_dimensions_field.png?width=40vw"></a></p><p><strong>5.</strong> In the upper-right corner click the <strong>Save pipeline</strong> button <a href=#R-image-2d82318a93856f15b586fa7aa75a4068 class=lightbox-link><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-2d82318a93856f15b586fa7aa75a4068><img alt="Save Pipeline Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_pipeline_btn.png?height=20px&classes=inline"></a>. On the ‚ÄúYou are editing an active pipeline modal‚Äù click <strong>Save</strong>.</p><p><a href=#R-image-b90f6a468e1fe50ba4db93d86da00eec class=lightbox-link><img alt="Save Updated Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_updated_pipeline.png?width=30vw" style=height:auto;width:30vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-b90f6a468e1fe50ba4db93d86da00eec><img alt="Save Updated Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_updated_pipeline.png?width=30vw"></a></p><details open class="box cstyle notices info"><summary class=box-label><i class="fa-fw fas fa-info-circle"></i>
Note</summary><div class=box-content><p>Because this pipeline is already active, the changes you made will take effect immediately. Your metric should now be split into multiple metric timeseries using the dimensions you added.</p><p>In the next step you will create a visualization using different dimensions from the Kubernetes audit events.</p></div></details></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article><article class=default><header class=headline></header><h1 id=visualize-kubernetes-audit-event-metrics>Visualize Kubernetes Audit Event Metrics</h1><p>Now that your metric has dimensions you will create a chart showing the health of different Kubernetes actions using the <code>verb</code> dimension from the events.</p><details open class="box cstyle notices green"><summary class=box-label><i class="fa-fw fas fa-running"></i>
Exercise: Visualize Kubernetes Audit Event Metrics</summary><div class=box-content><p><strong>1.</strong> If you closed the chart you created in the previous section, in the upper-right corner, click the <strong>+</strong> Icon ‚Üí <strong>Chart</strong> to create a new chart.</p><p><a href=#R-image-6e1ef19cf988827201ac4ba8356f0718 class=lightbox-link><img alt="Create New Chart" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/create_new_chart.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-6e1ef19cf988827201ac4ba8356f0718><img alt="Create New Chart" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/create_new_chart.png?width=40vw"></a></p><p><strong>2.</strong> In the <strong>Plot Editor</strong> of the newly created chart enter <code>k8s_audit*</code> in the metric name field. You will use a wildcard here so that you can see all the metrics that are being ingested.</p><p><a href=#R-image-d83b9e48f3d4d2e3073de44bd98859ec class=lightbox-link><img alt="Review Metric" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/review_metric.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d83b9e48f3d4d2e3073de44bd98859ec><img alt="Review Metric" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/review_metric.png?width=40vw"></a></p><p><strong>3.</strong> Notice the change from one to many metrics, which is when you updated the pipeline to include the dimensions. Now that we have this metric available, let&rsquo;s adjust the chart to show us if any of our actions have errors associated with them.</p><p><a href=#R-image-da5bff538771491f7283011f23d33067 class=lightbox-link><img alt="Metric Timeseries" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/metric_timeseries.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-da5bff538771491f7283011f23d33067><img alt="Metric Timeseries" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/metric_timeseries.png?width=40vw"></a></p><p>First you&rsquo;ll filter the Kubernetes events to only those that were not successful using the HTTP response code which is available in the <strong>response_status</strong> field. We only want events that have a response code of <strong>409</strong>, which indicates that there was a conflict (for example a trying to create a resource that already exists) or <strong>503</strong>, which indicates that the API was unresponsive for the request.</p><p><strong>4.</strong> In the plot editor of your chart click the <strong>Add filter</strong>, use <strong>response_status</strong> for the field and select <strong>409.0</strong> and <strong>503.0</strong> for the values.</p><p>Next, you‚Äôll add a function to the chart which will calculate the total number of events grouped by the <strong>resource</strong>, <strong>action</strong>, and <strong>response status</strong>. This will allow us to see exactly which actions and the associated resources had errors. Now we are only looking at Kubernetes events that were not successful.</p><p><strong>5.</strong> Click <strong>Add analytics</strong> ‚Üí <strong>Sum</strong> ‚Üí <strong>Sum:Aggregation</strong> and add <strong>resource</strong>, <strong>action</strong>, and <strong>response_status</strong> in the <strong>Group by</strong> field.</p><p><a href=#R-image-d25e5ebc74e48c227751904d53b86f89 class=lightbox-link><img alt="Add Metric Filters" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/add_metric_filters.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-d25e5ebc74e48c227751904d53b86f89><img alt="Add Metric Filters" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/add_metric_filters.png?width=40vw"></a></p><p><strong>6.</strong> Using the chart type along the top buttons, change the chart to a <strong>heatmap</strong>. Next to the <strong>Plot editor</strong>, click <strong>Chart options</strong>. In the <strong>Group by</strong> section select <strong>response_status</strong> then <strong>action</strong>. Change the <strong>Color threshold</strong> from <strong>Auto</strong> to <strong>Fixed</strong>. Click the blue <strong>+ button</strong> to add another threshold. Change the <strong>Down arrow to Yellow</strong>, the <strong>Middle to orange</strong>. Leave the <strong>Up arrow as red</strong>. Enter <strong>5 for the middle threshold</strong> and <strong>20 for the upper threshold</strong>.</p><p><a href=#R-image-86e4f8ca0c6d284cea1bc7f06b99e8d8 class=lightbox-link><img alt="Configure Thresholds" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/configure_thresholds.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-86e4f8ca0c6d284cea1bc7f06b99e8d8><img alt="Configure Thresholds" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/configure_thresholds.png?width=40vw"></a></p><p><strong>7.</strong> In the upper right corner of the chart click the blue <strong>Save as&mldr;</strong> <a href=#R-image-41cf7183d1e4de7c9791413a9c4cd6a4 class=lightbox-link><img alt="Preview Button" class="noborder inline lazy lightbox noshadow figure-image" loading=lazy src="../../images/save_as_btn.png?height=20px&classes=inline" style=height:20px;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-41cf7183d1e4de7c9791413a9c4cd6a4><img alt="Preview Button" class="noborder inline lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/save_as_btn.png?height=20px&classes=inline"></a> button. Enter a name for your chart (For Example: Kubernetes Audit Logs - Conflicts and Failures).</p><p><a href=#R-image-a242e1073f5a8a7bd3403c04d5f4ad8b class=lightbox-link><img alt="Chart Name" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/chart_name.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-a242e1073f5a8a7bd3403c04d5f4ad8b><img alt="Chart Name" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/chart_name.png></a></p><p><strong>8.</strong> On the <strong>Choose a dashboard</strong> select <strong>New dashboard</strong>.</p><p><a href=#R-image-58c4364067953f5c6658273cd819e3ae class=lightbox-link><img alt="New Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/new_dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-58c4364067953f5c6658273cd819e3ae><img alt="New Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/new_dashboard.png></a></p><p><strong>9.</strong> Enter a name for your dashboard that includes your initials, so you can easily find it later. Click <strong>Save</strong>.</p><p><a href=#R-image-01cf5e88f722b02aee1b3c860c47671a class=lightbox-link><img alt="New Dashboard Name" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/dashboard_name.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-01cf5e88f722b02aee1b3c860c47671a><img alt="New Dashboard Name" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/dashboard_name.png></a></p><p><strong>10.</strong> Make sure the new dashboard you just created is selected and click <strong>Ok</strong>.</p><p><a href=#R-image-537295808556c25633bdd642407d3a5b class=lightbox-link><img alt="Save New Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src=../../images/save_new_dashboard.png style=height:auto;width:auto></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-537295808556c25633bdd642407d3a5b><img alt="Save New Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src=../../images/save_new_dashboard.png></a></p><p>You should now be taken to your new Kubernetes Audit Events dashboard with the chart you created. You can add new charts from other metrics in your environment, such as application errors and response times from the applications running in the Kubernetes cluster, or other Kubernetes metrics such as pod phase, pod memory utilization, etc. giving you a correlated view of your Kubernetes environment from cluster events to application health.</p><p><a href=#R-image-846189dcb02987afe22728f2591b18f5 class=lightbox-link><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../../images/audit_dashboard.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-846189dcb02987afe22728f2591b18f5><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../../images/audit_dashboard.png?width=40vw"></a></p></div></details><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Mar 3, 2025</span></span></footer></article></section><article class=default><header class=headline></header><h1 id=conclusion>Conclusion</h1><p>In this workshop, you walked through the entire process of optimizing Kubernetes log management by converting detailed log events into actionable metrics using <strong>Splunk Ingest Pipelines</strong>. You started by defining a pipeline that efficiently converts Kubernetes audit logs into metrics, drastically reducing the data volume while retaining critical information. You then ensured the raw log events were securely stored in S3 for long-term retention and deeper analysis.</p><p><a href=#R-image-bf0a03ac55cfd3cce3b4ce078017d4b3 class=lightbox-link><img alt="Kubernetes Audit Event" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/audit_event.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-bf0a03ac55cfd3cce3b4ce078017d4b3><img alt="Kubernetes Audit Event" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/audit_event.png?width=40vw"></a></p><p>Next, you demonstrated how to enhance these metrics by adding key dimensions from the raw events, enabling us to drill down into specific actions and resources. you created a chart that filtered the metrics to focus on errors, breaking them out by resource and action. This allowed us to pinpoint exactly where issues were occurring in real-time.</p><p><a href=#R-image-36f38e25df6274d3a124ce7044bcf81c class=lightbox-link><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/ingest_pipeline_dimensions.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-36f38e25df6274d3a124ce7044bcf81c><img alt="Ingest Pipeline" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/ingest_pipeline_dimensions.png?width=40vw"></a></p><p>The real-time architecture of <strong>Splunk Observability Cloud</strong> means that these metrics can trigger alerts the moment an issue is detected, significantly reducing the Mean Time to Detection (MTTD). Additionally, you showed how this chart can be easily saved to new or existing dashboards, ensuring ongoing visibility and monitoring of critical metrics.</p><p><a href=#R-image-4ec084b20cd52b40f81bb0d670979770 class=lightbox-link><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/audit_dashboard.png?width=40vw" style=height:auto;width:40vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-4ec084b20cd52b40f81bb0d670979770><img alt="Audit Dashboard" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/audit_dashboard.png?width=40vw"></a></p><p>The value behind this approach is clear: by converting logs to metrics using <strong>Ingest Processor</strong>, you not only streamline data processing and reduce storage costs but also gain the ability to monitor and respond to issues in real-time using <strong>Splunk Observability Cloud</strong>. This results in faster problem resolution, improved system reliability, and more efficient resource utilization, all while maintaining the ability to retain and access the original logs for compliance or deeper analysis.</p><center><h1>Happy Splunking!</h1></center><p><a href=#R-image-caeb113153d45508373b783afedd686e class=lightbox-link><img alt="Dancing Buttercup" class="noborder lazy lightbox noshadow figure-image" loading=lazy src="../images/Splunk-dancing-buttercup-GIF-103.gif?width=30vw" style=height:auto;width:30vw></a>
<a href=javascript:history.back(); class=lightbox-back id=R-image-caeb113153d45508373b783afedd686e><img alt="Dancing Buttercup" class="noborder lazy lightbox noshadow lightbox-image" loading=lazy src="../images/Splunk-dancing-buttercup-GIF-103.gif?width=30vw"></a></p><footer class=footline><span class="badge cstyle note badge-with-title"><span class=badge-title class=text-muted>Last Modified
</span><span class=badge-content>Jan 29, 2025</span></span></footer></article></section></div></main></div><script src=/observability-workshop/v5.85/js/clipboard.min.js?1741799547 defer></script><script src=/observability-workshop/v5.85/js/perfect-scrollbar.min.js?1741799547 defer></script><script src=/observability-workshop/v5.85/js/theme.js?1741799547 defer></script></body></html>